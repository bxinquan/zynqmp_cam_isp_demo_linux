static PyObject* pyopencv_cv_AKAZE_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_descriptor_type = NULL;
    AKAZE_DescriptorType descriptor_type=AKAZE::DESCRIPTOR_MLDB;
    PyObject* pyobj_descriptor_size = NULL;
    int descriptor_size=0;
    PyObject* pyobj_descriptor_channels = NULL;
    int descriptor_channels=3;
    PyObject* pyobj_threshold = NULL;
    float threshold=0.001f;
    PyObject* pyobj_nOctaves = NULL;
    int nOctaves=4;
    PyObject* pyobj_nOctaveLayers = NULL;
    int nOctaveLayers=4;
    PyObject* pyobj_diffusivity = NULL;
    KAZE_DiffusivityType diffusivity=KAZE::DIFF_PM_G2;
    Ptr<AKAZE> retval;

    const char* keywords[] = { "descriptor_type", "descriptor_size", "descriptor_channels", "threshold", "nOctaves", "nOctaveLayers", "diffusivity", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOOOO:AKAZE_create", (char**)keywords, &pyobj_descriptor_type, &pyobj_descriptor_size, &pyobj_descriptor_channels, &pyobj_threshold, &pyobj_nOctaves, &pyobj_nOctaveLayers, &pyobj_diffusivity) &&
        pyopencv_to_safe(pyobj_descriptor_type, descriptor_type, ArgInfo("descriptor_type", 0)) &&
        pyopencv_to_safe(pyobj_descriptor_size, descriptor_size, ArgInfo("descriptor_size", 0)) &&
        pyopencv_to_safe(pyobj_descriptor_channels, descriptor_channels, ArgInfo("descriptor_channels", 0)) &&
        pyopencv_to_safe(pyobj_threshold, threshold, ArgInfo("threshold", 0)) &&
        pyopencv_to_safe(pyobj_nOctaves, nOctaves, ArgInfo("nOctaves", 0)) &&
        pyopencv_to_safe(pyobj_nOctaveLayers, nOctaveLayers, ArgInfo("nOctaveLayers", 0)) &&
        pyopencv_to_safe(pyobj_diffusivity, diffusivity, ArgInfo("diffusivity", 0)) )
    {
        ERRWRAP2(retval = cv::AKAZE::create(descriptor_type, descriptor_size, descriptor_channels, threshold, nOctaves, nOctaveLayers, diffusivity));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_AffineFeature_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_backend = NULL;
    Ptr<Feature2D> backend;
    PyObject* pyobj_maxTilt = NULL;
    int maxTilt=5;
    PyObject* pyobj_minTilt = NULL;
    int minTilt=0;
    PyObject* pyobj_tiltStep = NULL;
    float tiltStep=1.4142135623730951f;
    PyObject* pyobj_rotateStepBase = NULL;
    float rotateStepBase=72;
    Ptr<AffineFeature> retval;

    const char* keywords[] = { "backend", "maxTilt", "minTilt", "tiltStep", "rotateStepBase", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOO:AffineFeature_create", (char**)keywords, &pyobj_backend, &pyobj_maxTilt, &pyobj_minTilt, &pyobj_tiltStep, &pyobj_rotateStepBase) &&
        pyopencv_to_safe(pyobj_backend, backend, ArgInfo("backend", 0)) &&
        pyopencv_to_safe(pyobj_maxTilt, maxTilt, ArgInfo("maxTilt", 0)) &&
        pyopencv_to_safe(pyobj_minTilt, minTilt, ArgInfo("minTilt", 0)) &&
        pyopencv_to_safe(pyobj_tiltStep, tiltStep, ArgInfo("tiltStep", 0)) &&
        pyopencv_to_safe(pyobj_rotateStepBase, rotateStepBase, ArgInfo("rotateStepBase", 0)) )
    {
        ERRWRAP2(retval = cv::AffineFeature::create(backend, maxTilt, minTilt, tiltStep, rotateStepBase));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_AgastFeatureDetector_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_threshold = NULL;
    int threshold=10;
    PyObject* pyobj_nonmaxSuppression = NULL;
    bool nonmaxSuppression=true;
    PyObject* pyobj_type = NULL;
    AgastFeatureDetector_DetectorType type=AgastFeatureDetector::OAST_9_16;
    Ptr<AgastFeatureDetector> retval;

    const char* keywords[] = { "threshold", "nonmaxSuppression", "type", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOO:AgastFeatureDetector_create", (char**)keywords, &pyobj_threshold, &pyobj_nonmaxSuppression, &pyobj_type) &&
        pyopencv_to_safe(pyobj_threshold, threshold, ArgInfo("threshold", 0)) &&
        pyopencv_to_safe(pyobj_nonmaxSuppression, nonmaxSuppression, ArgInfo("nonmaxSuppression", 0)) &&
        pyopencv_to_safe(pyobj_type, type, ArgInfo("type", 0)) )
    {
        ERRWRAP2(retval = cv::AgastFeatureDetector::create(threshold, nonmaxSuppression, type));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_BFMatcher_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_normType = NULL;
    int normType=NORM_L2;
    PyObject* pyobj_crossCheck = NULL;
    bool crossCheck=false;
    Ptr<BFMatcher> retval;

    const char* keywords[] = { "normType", "crossCheck", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OO:BFMatcher_create", (char**)keywords, &pyobj_normType, &pyobj_crossCheck) &&
        pyopencv_to_safe(pyobj_normType, normType, ArgInfo("normType", 0)) &&
        pyopencv_to_safe(pyobj_crossCheck, crossCheck, ArgInfo("crossCheck", 0)) )
    {
        ERRWRAP2(retval = cv::BFMatcher::create(normType, crossCheck));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_BRISK_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(3);

    {
    PyObject* pyobj_thresh = NULL;
    int thresh=30;
    PyObject* pyobj_octaves = NULL;
    int octaves=3;
    PyObject* pyobj_patternScale = NULL;
    float patternScale=1.0f;
    Ptr<BRISK> retval;

    const char* keywords[] = { "thresh", "octaves", "patternScale", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOO:BRISK_create", (char**)keywords, &pyobj_thresh, &pyobj_octaves, &pyobj_patternScale) &&
        pyopencv_to_safe(pyobj_thresh, thresh, ArgInfo("thresh", 0)) &&
        pyopencv_to_safe(pyobj_octaves, octaves, ArgInfo("octaves", 0)) &&
        pyopencv_to_safe(pyobj_patternScale, patternScale, ArgInfo("patternScale", 0)) )
    {
        ERRWRAP2(retval = cv::BRISK::create(thresh, octaves, patternScale));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_radiusList = NULL;
    vector_float radiusList;
    PyObject* pyobj_numberList = NULL;
    vector_int numberList;
    PyObject* pyobj_dMax = NULL;
    float dMax=5.85f;
    PyObject* pyobj_dMin = NULL;
    float dMin=8.2f;
    PyObject* pyobj_indexChange = NULL;
    vector_int indexChange=std::vector<int>();
    Ptr<BRISK> retval;

    const char* keywords[] = { "radiusList", "numberList", "dMax", "dMin", "indexChange", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:BRISK_create", (char**)keywords, &pyobj_radiusList, &pyobj_numberList, &pyobj_dMax, &pyobj_dMin, &pyobj_indexChange) &&
        pyopencv_to_safe(pyobj_radiusList, radiusList, ArgInfo("radiusList", 0)) &&
        pyopencv_to_safe(pyobj_numberList, numberList, ArgInfo("numberList", 0)) &&
        pyopencv_to_safe(pyobj_dMax, dMax, ArgInfo("dMax", 0)) &&
        pyopencv_to_safe(pyobj_dMin, dMin, ArgInfo("dMin", 0)) &&
        pyopencv_to_safe(pyobj_indexChange, indexChange, ArgInfo("indexChange", 0)) )
    {
        ERRWRAP2(retval = cv::BRISK::create(radiusList, numberList, dMax, dMin, indexChange));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_thresh = NULL;
    int thresh=0;
    PyObject* pyobj_octaves = NULL;
    int octaves=0;
    PyObject* pyobj_radiusList = NULL;
    vector_float radiusList;
    PyObject* pyobj_numberList = NULL;
    vector_int numberList;
    PyObject* pyobj_dMax = NULL;
    float dMax=5.85f;
    PyObject* pyobj_dMin = NULL;
    float dMin=8.2f;
    PyObject* pyobj_indexChange = NULL;
    vector_int indexChange=std::vector<int>();
    Ptr<BRISK> retval;

    const char* keywords[] = { "thresh", "octaves", "radiusList", "numberList", "dMax", "dMin", "indexChange", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:BRISK_create", (char**)keywords, &pyobj_thresh, &pyobj_octaves, &pyobj_radiusList, &pyobj_numberList, &pyobj_dMax, &pyobj_dMin, &pyobj_indexChange) &&
        pyopencv_to_safe(pyobj_thresh, thresh, ArgInfo("thresh", 0)) &&
        pyopencv_to_safe(pyobj_octaves, octaves, ArgInfo("octaves", 0)) &&
        pyopencv_to_safe(pyobj_radiusList, radiusList, ArgInfo("radiusList", 0)) &&
        pyopencv_to_safe(pyobj_numberList, numberList, ArgInfo("numberList", 0)) &&
        pyopencv_to_safe(pyobj_dMax, dMax, ArgInfo("dMax", 0)) &&
        pyopencv_to_safe(pyobj_dMin, dMin, ArgInfo("dMin", 0)) &&
        pyopencv_to_safe(pyobj_indexChange, indexChange, ArgInfo("indexChange", 0)) )
    {
        ERRWRAP2(retval = cv::BRISK::create(thresh, octaves, radiusList, numberList, dMax, dMin, indexChange));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("BRISK_create");

    return NULL;
}

static PyObject* pyopencv_cv_CamShift(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_probImage = NULL;
    Mat probImage;
    PyObject* pyobj_window = NULL;
    Rect window;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria;
    RotatedRect retval;

    const char* keywords[] = { "probImage", "window", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:CamShift", (char**)keywords, &pyobj_probImage, &pyobj_window, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_probImage, probImage, ArgInfo("probImage", 0)) &&
        pyopencv_to_safe(pyobj_window, window, ArgInfo("window", 1)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(retval = cv::CamShift(probImage, window, criteria));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(window));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_probImage = NULL;
    UMat probImage;
    PyObject* pyobj_window = NULL;
    Rect window;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria;
    RotatedRect retval;

    const char* keywords[] = { "probImage", "window", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:CamShift", (char**)keywords, &pyobj_probImage, &pyobj_window, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_probImage, probImage, ArgInfo("probImage", 0)) &&
        pyopencv_to_safe(pyobj_window, window, ArgInfo("window", 1)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(retval = cv::CamShift(probImage, window, criteria));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(window));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("CamShift");

    return NULL;
}

static PyObject* pyopencv_cv_Canny(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(4);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_edges = NULL;
    Mat edges;
    PyObject* pyobj_threshold1 = NULL;
    double threshold1=0;
    PyObject* pyobj_threshold2 = NULL;
    double threshold2=0;
    PyObject* pyobj_apertureSize = NULL;
    int apertureSize=3;
    PyObject* pyobj_L2gradient = NULL;
    bool L2gradient=false;

    const char* keywords[] = { "image", "threshold1", "threshold2", "edges", "apertureSize", "L2gradient", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:Canny", (char**)keywords, &pyobj_image, &pyobj_threshold1, &pyobj_threshold2, &pyobj_edges, &pyobj_apertureSize, &pyobj_L2gradient) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_edges, edges, ArgInfo("edges", 1)) &&
        pyopencv_to_safe(pyobj_threshold1, threshold1, ArgInfo("threshold1", 0)) &&
        pyopencv_to_safe(pyobj_threshold2, threshold2, ArgInfo("threshold2", 0)) &&
        pyopencv_to_safe(pyobj_apertureSize, apertureSize, ArgInfo("apertureSize", 0)) &&
        pyopencv_to_safe(pyobj_L2gradient, L2gradient, ArgInfo("L2gradient", 0)) )
    {
        ERRWRAP2(cv::Canny(image, edges, threshold1, threshold2, apertureSize, L2gradient));
        return pyopencv_from(edges);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_edges = NULL;
    UMat edges;
    PyObject* pyobj_threshold1 = NULL;
    double threshold1=0;
    PyObject* pyobj_threshold2 = NULL;
    double threshold2=0;
    PyObject* pyobj_apertureSize = NULL;
    int apertureSize=3;
    PyObject* pyobj_L2gradient = NULL;
    bool L2gradient=false;

    const char* keywords[] = { "image", "threshold1", "threshold2", "edges", "apertureSize", "L2gradient", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:Canny", (char**)keywords, &pyobj_image, &pyobj_threshold1, &pyobj_threshold2, &pyobj_edges, &pyobj_apertureSize, &pyobj_L2gradient) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_edges, edges, ArgInfo("edges", 1)) &&
        pyopencv_to_safe(pyobj_threshold1, threshold1, ArgInfo("threshold1", 0)) &&
        pyopencv_to_safe(pyobj_threshold2, threshold2, ArgInfo("threshold2", 0)) &&
        pyopencv_to_safe(pyobj_apertureSize, apertureSize, ArgInfo("apertureSize", 0)) &&
        pyopencv_to_safe(pyobj_L2gradient, L2gradient, ArgInfo("L2gradient", 0)) )
    {
        ERRWRAP2(cv::Canny(image, edges, threshold1, threshold2, apertureSize, L2gradient));
        return pyopencv_from(edges);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_dx = NULL;
    Mat dx;
    PyObject* pyobj_dy = NULL;
    Mat dy;
    PyObject* pyobj_edges = NULL;
    Mat edges;
    PyObject* pyobj_threshold1 = NULL;
    double threshold1=0;
    PyObject* pyobj_threshold2 = NULL;
    double threshold2=0;
    PyObject* pyobj_L2gradient = NULL;
    bool L2gradient=false;

    const char* keywords[] = { "dx", "dy", "threshold1", "threshold2", "edges", "L2gradient", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OO:Canny", (char**)keywords, &pyobj_dx, &pyobj_dy, &pyobj_threshold1, &pyobj_threshold2, &pyobj_edges, &pyobj_L2gradient) &&
        pyopencv_to_safe(pyobj_dx, dx, ArgInfo("dx", 0)) &&
        pyopencv_to_safe(pyobj_dy, dy, ArgInfo("dy", 0)) &&
        pyopencv_to_safe(pyobj_edges, edges, ArgInfo("edges", 1)) &&
        pyopencv_to_safe(pyobj_threshold1, threshold1, ArgInfo("threshold1", 0)) &&
        pyopencv_to_safe(pyobj_threshold2, threshold2, ArgInfo("threshold2", 0)) &&
        pyopencv_to_safe(pyobj_L2gradient, L2gradient, ArgInfo("L2gradient", 0)) )
    {
        ERRWRAP2(cv::Canny(dx, dy, edges, threshold1, threshold2, L2gradient));
        return pyopencv_from(edges);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_dx = NULL;
    UMat dx;
    PyObject* pyobj_dy = NULL;
    UMat dy;
    PyObject* pyobj_edges = NULL;
    UMat edges;
    PyObject* pyobj_threshold1 = NULL;
    double threshold1=0;
    PyObject* pyobj_threshold2 = NULL;
    double threshold2=0;
    PyObject* pyobj_L2gradient = NULL;
    bool L2gradient=false;

    const char* keywords[] = { "dx", "dy", "threshold1", "threshold2", "edges", "L2gradient", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OO:Canny", (char**)keywords, &pyobj_dx, &pyobj_dy, &pyobj_threshold1, &pyobj_threshold2, &pyobj_edges, &pyobj_L2gradient) &&
        pyopencv_to_safe(pyobj_dx, dx, ArgInfo("dx", 0)) &&
        pyopencv_to_safe(pyobj_dy, dy, ArgInfo("dy", 0)) &&
        pyopencv_to_safe(pyobj_edges, edges, ArgInfo("edges", 1)) &&
        pyopencv_to_safe(pyobj_threshold1, threshold1, ArgInfo("threshold1", 0)) &&
        pyopencv_to_safe(pyobj_threshold2, threshold2, ArgInfo("threshold2", 0)) &&
        pyopencv_to_safe(pyobj_L2gradient, L2gradient, ArgInfo("L2gradient", 0)) )
    {
        ERRWRAP2(cv::Canny(dx, dy, edges, threshold1, threshold2, L2gradient));
        return pyopencv_from(edges);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("Canny");

    return NULL;
}

static PyObject* pyopencv_cv_CascadeClassifier_convert(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_oldcascade = NULL;
    String oldcascade;
    PyObject* pyobj_newcascade = NULL;
    String newcascade;
    bool retval;

    const char* keywords[] = { "oldcascade", "newcascade", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:CascadeClassifier_convert", (char**)keywords, &pyobj_oldcascade, &pyobj_newcascade) &&
        pyopencv_to_safe(pyobj_oldcascade, oldcascade, ArgInfo("oldcascade", 0)) &&
        pyopencv_to_safe(pyobj_newcascade, newcascade, ArgInfo("newcascade", 0)) )
    {
        ERRWRAP2(retval = cv::CascadeClassifier::convert(oldcascade, newcascade));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_DISOpticalFlow_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_preset = NULL;
    int preset=DISOpticalFlow::PRESET_FAST;
    Ptr<DISOpticalFlow> retval;

    const char* keywords[] = { "preset", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|O:DISOpticalFlow_create", (char**)keywords, &pyobj_preset) &&
        pyopencv_to_safe(pyobj_preset, preset, ArgInfo("preset", 0)) )
    {
        ERRWRAP2(retval = cv::DISOpticalFlow::create(preset));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_DescriptorMatcher_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_descriptorMatcherType = NULL;
    String descriptorMatcherType;
    Ptr<DescriptorMatcher> retval;

    const char* keywords[] = { "descriptorMatcherType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:DescriptorMatcher_create", (char**)keywords, &pyobj_descriptorMatcherType) &&
        pyopencv_to_safe(pyobj_descriptorMatcherType, descriptorMatcherType, ArgInfo("descriptorMatcherType", 0)) )
    {
        ERRWRAP2(retval = cv::DescriptorMatcher::create(descriptorMatcherType));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_matcherType = NULL;
    DescriptorMatcher_MatcherType matcherType=static_cast<DescriptorMatcher_MatcherType>(0);
    Ptr<DescriptorMatcher> retval;

    const char* keywords[] = { "matcherType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:DescriptorMatcher_create", (char**)keywords, &pyobj_matcherType) &&
        pyopencv_to_safe(pyobj_matcherType, matcherType, ArgInfo("matcherType", 0)) )
    {
        ERRWRAP2(retval = cv::DescriptorMatcher::create(matcherType));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("DescriptorMatcher_create");

    return NULL;
}

static PyObject* pyopencv_cv_EMD(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_signature1 = NULL;
    Mat signature1;
    PyObject* pyobj_signature2 = NULL;
    Mat signature2;
    PyObject* pyobj_distType = NULL;
    int distType=0;
    PyObject* pyobj_cost = NULL;
    Mat cost;
    PyObject* pyobj_lowerBound = NULL;
    Ptr<float> lowerBound;
    PyObject* pyobj_flow = NULL;
    Mat flow;
    float retval;

    const char* keywords[] = { "signature1", "signature2", "distType", "cost", "lowerBound", "flow", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:EMD", (char**)keywords, &pyobj_signature1, &pyobj_signature2, &pyobj_distType, &pyobj_cost, &pyobj_lowerBound, &pyobj_flow) &&
        pyopencv_to_safe(pyobj_signature1, signature1, ArgInfo("signature1", 0)) &&
        pyopencv_to_safe(pyobj_signature2, signature2, ArgInfo("signature2", 0)) &&
        pyopencv_to_safe(pyobj_distType, distType, ArgInfo("distType", 0)) &&
        pyopencv_to_safe(pyobj_cost, cost, ArgInfo("cost", 0)) &&
        pyopencv_to_safe(pyobj_lowerBound, lowerBound, ArgInfo("lowerBound", 1)) &&
        pyopencv_to_safe(pyobj_flow, flow, ArgInfo("flow", 1)) )
    {
        ERRWRAP2(retval = cv::wrapperEMD(signature1, signature2, distType, cost, lowerBound, flow));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(lowerBound), pyopencv_from(flow));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_signature1 = NULL;
    UMat signature1;
    PyObject* pyobj_signature2 = NULL;
    UMat signature2;
    PyObject* pyobj_distType = NULL;
    int distType=0;
    PyObject* pyobj_cost = NULL;
    UMat cost;
    PyObject* pyobj_lowerBound = NULL;
    Ptr<float> lowerBound;
    PyObject* pyobj_flow = NULL;
    UMat flow;
    float retval;

    const char* keywords[] = { "signature1", "signature2", "distType", "cost", "lowerBound", "flow", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:EMD", (char**)keywords, &pyobj_signature1, &pyobj_signature2, &pyobj_distType, &pyobj_cost, &pyobj_lowerBound, &pyobj_flow) &&
        pyopencv_to_safe(pyobj_signature1, signature1, ArgInfo("signature1", 0)) &&
        pyopencv_to_safe(pyobj_signature2, signature2, ArgInfo("signature2", 0)) &&
        pyopencv_to_safe(pyobj_distType, distType, ArgInfo("distType", 0)) &&
        pyopencv_to_safe(pyobj_cost, cost, ArgInfo("cost", 0)) &&
        pyopencv_to_safe(pyobj_lowerBound, lowerBound, ArgInfo("lowerBound", 1)) &&
        pyopencv_to_safe(pyobj_flow, flow, ArgInfo("flow", 1)) )
    {
        ERRWRAP2(retval = cv::wrapperEMD(signature1, signature2, distType, cost, lowerBound, flow));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(lowerBound), pyopencv_from(flow));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("EMD");

    return NULL;
}

static PyObject* pyopencv_cv_FarnebackOpticalFlow_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_numLevels = NULL;
    int numLevels=5;
    PyObject* pyobj_pyrScale = NULL;
    double pyrScale=0.5;
    PyObject* pyobj_fastPyramids = NULL;
    bool fastPyramids=false;
    PyObject* pyobj_winSize = NULL;
    int winSize=13;
    PyObject* pyobj_numIters = NULL;
    int numIters=10;
    PyObject* pyobj_polyN = NULL;
    int polyN=5;
    PyObject* pyobj_polySigma = NULL;
    double polySigma=1.1;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    Ptr<FarnebackOpticalFlow> retval;

    const char* keywords[] = { "numLevels", "pyrScale", "fastPyramids", "winSize", "numIters", "polyN", "polySigma", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOOOOO:FarnebackOpticalFlow_create", (char**)keywords, &pyobj_numLevels, &pyobj_pyrScale, &pyobj_fastPyramids, &pyobj_winSize, &pyobj_numIters, &pyobj_polyN, &pyobj_polySigma, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_numLevels, numLevels, ArgInfo("numLevels", 0)) &&
        pyopencv_to_safe(pyobj_pyrScale, pyrScale, ArgInfo("pyrScale", 0)) &&
        pyopencv_to_safe(pyobj_fastPyramids, fastPyramids, ArgInfo("fastPyramids", 0)) &&
        pyopencv_to_safe(pyobj_winSize, winSize, ArgInfo("winSize", 0)) &&
        pyopencv_to_safe(pyobj_numIters, numIters, ArgInfo("numIters", 0)) &&
        pyopencv_to_safe(pyobj_polyN, polyN, ArgInfo("polyN", 0)) &&
        pyopencv_to_safe(pyobj_polySigma, polySigma, ArgInfo("polySigma", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(retval = cv::FarnebackOpticalFlow::create(numLevels, pyrScale, fastPyramids, winSize, numIters, polyN, polySigma, flags));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FastFeatureDetector_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_threshold = NULL;
    int threshold=10;
    PyObject* pyobj_nonmaxSuppression = NULL;
    bool nonmaxSuppression=true;
    PyObject* pyobj_type = NULL;
    FastFeatureDetector_DetectorType type=FastFeatureDetector::TYPE_9_16;
    Ptr<FastFeatureDetector> retval;

    const char* keywords[] = { "threshold", "nonmaxSuppression", "type", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOO:FastFeatureDetector_create", (char**)keywords, &pyobj_threshold, &pyobj_nonmaxSuppression, &pyobj_type) &&
        pyopencv_to_safe(pyobj_threshold, threshold, ArgInfo("threshold", 0)) &&
        pyopencv_to_safe(pyobj_nonmaxSuppression, nonmaxSuppression, ArgInfo("nonmaxSuppression", 0)) &&
        pyopencv_to_safe(pyobj_type, type, ArgInfo("type", 0)) )
    {
        ERRWRAP2(retval = cv::FastFeatureDetector::create(threshold, nonmaxSuppression, type));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_FlannBasedMatcher_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    Ptr<FlannBasedMatcher> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::FlannBasedMatcher::create());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_GFTTDetector_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_maxCorners = NULL;
    int maxCorners=1000;
    PyObject* pyobj_qualityLevel = NULL;
    double qualityLevel=0.01;
    PyObject* pyobj_minDistance = NULL;
    double minDistance=1;
    PyObject* pyobj_blockSize = NULL;
    int blockSize=3;
    PyObject* pyobj_useHarrisDetector = NULL;
    bool useHarrisDetector=false;
    PyObject* pyobj_k = NULL;
    double k=0.04;
    Ptr<GFTTDetector> retval;

    const char* keywords[] = { "maxCorners", "qualityLevel", "minDistance", "blockSize", "useHarrisDetector", "k", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOOO:GFTTDetector_create", (char**)keywords, &pyobj_maxCorners, &pyobj_qualityLevel, &pyobj_minDistance, &pyobj_blockSize, &pyobj_useHarrisDetector, &pyobj_k) &&
        pyopencv_to_safe(pyobj_maxCorners, maxCorners, ArgInfo("maxCorners", 0)) &&
        pyopencv_to_safe(pyobj_qualityLevel, qualityLevel, ArgInfo("qualityLevel", 0)) &&
        pyopencv_to_safe(pyobj_minDistance, minDistance, ArgInfo("minDistance", 0)) &&
        pyopencv_to_safe(pyobj_blockSize, blockSize, ArgInfo("blockSize", 0)) &&
        pyopencv_to_safe(pyobj_useHarrisDetector, useHarrisDetector, ArgInfo("useHarrisDetector", 0)) &&
        pyopencv_to_safe(pyobj_k, k, ArgInfo("k", 0)) )
    {
        ERRWRAP2(retval = cv::GFTTDetector::create(maxCorners, qualityLevel, minDistance, blockSize, useHarrisDetector, k));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_maxCorners = NULL;
    int maxCorners=0;
    PyObject* pyobj_qualityLevel = NULL;
    double qualityLevel=0;
    PyObject* pyobj_minDistance = NULL;
    double minDistance=0;
    PyObject* pyobj_blockSize = NULL;
    int blockSize=0;
    PyObject* pyobj_gradiantSize = NULL;
    int gradiantSize=0;
    PyObject* pyobj_useHarrisDetector = NULL;
    bool useHarrisDetector=false;
    PyObject* pyobj_k = NULL;
    double k=0.04;
    Ptr<GFTTDetector> retval;

    const char* keywords[] = { "maxCorners", "qualityLevel", "minDistance", "blockSize", "gradiantSize", "useHarrisDetector", "k", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OO:GFTTDetector_create", (char**)keywords, &pyobj_maxCorners, &pyobj_qualityLevel, &pyobj_minDistance, &pyobj_blockSize, &pyobj_gradiantSize, &pyobj_useHarrisDetector, &pyobj_k) &&
        pyopencv_to_safe(pyobj_maxCorners, maxCorners, ArgInfo("maxCorners", 0)) &&
        pyopencv_to_safe(pyobj_qualityLevel, qualityLevel, ArgInfo("qualityLevel", 0)) &&
        pyopencv_to_safe(pyobj_minDistance, minDistance, ArgInfo("minDistance", 0)) &&
        pyopencv_to_safe(pyobj_blockSize, blockSize, ArgInfo("blockSize", 0)) &&
        pyopencv_to_safe(pyobj_gradiantSize, gradiantSize, ArgInfo("gradiantSize", 0)) &&
        pyopencv_to_safe(pyobj_useHarrisDetector, useHarrisDetector, ArgInfo("useHarrisDetector", 0)) &&
        pyopencv_to_safe(pyobj_k, k, ArgInfo("k", 0)) )
    {
        ERRWRAP2(retval = cv::GFTTDetector::create(maxCorners, qualityLevel, minDistance, blockSize, gradiantSize, useHarrisDetector, k));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("GFTTDetector_create");

    return NULL;
}

static PyObject* pyopencv_cv_GaussianBlur(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_ksize = NULL;
    Size ksize;
    PyObject* pyobj_sigmaX = NULL;
    double sigmaX=0;
    PyObject* pyobj_sigmaY = NULL;
    double sigmaY=0;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "ksize", "sigmaX", "dst", "sigmaY", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:GaussianBlur", (char**)keywords, &pyobj_src, &pyobj_ksize, &pyobj_sigmaX, &pyobj_dst, &pyobj_sigmaY, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) &&
        pyopencv_to_safe(pyobj_sigmaX, sigmaX, ArgInfo("sigmaX", 0)) &&
        pyopencv_to_safe(pyobj_sigmaY, sigmaY, ArgInfo("sigmaY", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::GaussianBlur(src, dst, ksize, sigmaX, sigmaY, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_ksize = NULL;
    Size ksize;
    PyObject* pyobj_sigmaX = NULL;
    double sigmaX=0;
    PyObject* pyobj_sigmaY = NULL;
    double sigmaY=0;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "ksize", "sigmaX", "dst", "sigmaY", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:GaussianBlur", (char**)keywords, &pyobj_src, &pyobj_ksize, &pyobj_sigmaX, &pyobj_dst, &pyobj_sigmaY, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) &&
        pyopencv_to_safe(pyobj_sigmaX, sigmaX, ArgInfo("sigmaX", 0)) &&
        pyopencv_to_safe(pyobj_sigmaY, sigmaY, ArgInfo("sigmaY", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::GaussianBlur(src, dst, ksize, sigmaX, sigmaY, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("GaussianBlur");

    return NULL;
}

static PyObject* pyopencv_cv_HOGDescriptor_getDaimlerPeopleDetector(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    std::vector<float> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::HOGDescriptor::getDaimlerPeopleDetector());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_HOGDescriptor_getDefaultPeopleDetector(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    std::vector<float> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::HOGDescriptor::getDefaultPeopleDetector());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_HoughCircles(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_circles = NULL;
    Mat circles;
    PyObject* pyobj_method = NULL;
    int method=0;
    PyObject* pyobj_dp = NULL;
    double dp=0;
    PyObject* pyobj_minDist = NULL;
    double minDist=0;
    PyObject* pyobj_param1 = NULL;
    double param1=100;
    PyObject* pyobj_param2 = NULL;
    double param2=100;
    PyObject* pyobj_minRadius = NULL;
    int minRadius=0;
    PyObject* pyobj_maxRadius = NULL;
    int maxRadius=0;

    const char* keywords[] = { "image", "method", "dp", "minDist", "circles", "param1", "param2", "minRadius", "maxRadius", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOOO:HoughCircles", (char**)keywords, &pyobj_image, &pyobj_method, &pyobj_dp, &pyobj_minDist, &pyobj_circles, &pyobj_param1, &pyobj_param2, &pyobj_minRadius, &pyobj_maxRadius) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_circles, circles, ArgInfo("circles", 1)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) &&
        pyopencv_to_safe(pyobj_dp, dp, ArgInfo("dp", 0)) &&
        pyopencv_to_safe(pyobj_minDist, minDist, ArgInfo("minDist", 0)) &&
        pyopencv_to_safe(pyobj_param1, param1, ArgInfo("param1", 0)) &&
        pyopencv_to_safe(pyobj_param2, param2, ArgInfo("param2", 0)) &&
        pyopencv_to_safe(pyobj_minRadius, minRadius, ArgInfo("minRadius", 0)) &&
        pyopencv_to_safe(pyobj_maxRadius, maxRadius, ArgInfo("maxRadius", 0)) )
    {
        ERRWRAP2(cv::HoughCircles(image, circles, method, dp, minDist, param1, param2, minRadius, maxRadius));
        return pyopencv_from(circles);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_circles = NULL;
    UMat circles;
    PyObject* pyobj_method = NULL;
    int method=0;
    PyObject* pyobj_dp = NULL;
    double dp=0;
    PyObject* pyobj_minDist = NULL;
    double minDist=0;
    PyObject* pyobj_param1 = NULL;
    double param1=100;
    PyObject* pyobj_param2 = NULL;
    double param2=100;
    PyObject* pyobj_minRadius = NULL;
    int minRadius=0;
    PyObject* pyobj_maxRadius = NULL;
    int maxRadius=0;

    const char* keywords[] = { "image", "method", "dp", "minDist", "circles", "param1", "param2", "minRadius", "maxRadius", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOOO:HoughCircles", (char**)keywords, &pyobj_image, &pyobj_method, &pyobj_dp, &pyobj_minDist, &pyobj_circles, &pyobj_param1, &pyobj_param2, &pyobj_minRadius, &pyobj_maxRadius) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_circles, circles, ArgInfo("circles", 1)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) &&
        pyopencv_to_safe(pyobj_dp, dp, ArgInfo("dp", 0)) &&
        pyopencv_to_safe(pyobj_minDist, minDist, ArgInfo("minDist", 0)) &&
        pyopencv_to_safe(pyobj_param1, param1, ArgInfo("param1", 0)) &&
        pyopencv_to_safe(pyobj_param2, param2, ArgInfo("param2", 0)) &&
        pyopencv_to_safe(pyobj_minRadius, minRadius, ArgInfo("minRadius", 0)) &&
        pyopencv_to_safe(pyobj_maxRadius, maxRadius, ArgInfo("maxRadius", 0)) )
    {
        ERRWRAP2(cv::HoughCircles(image, circles, method, dp, minDist, param1, param2, minRadius, maxRadius));
        return pyopencv_from(circles);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("HoughCircles");

    return NULL;
}

static PyObject* pyopencv_cv_HoughLines(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_lines = NULL;
    Mat lines;
    PyObject* pyobj_rho = NULL;
    double rho=0;
    PyObject* pyobj_theta = NULL;
    double theta=0;
    PyObject* pyobj_threshold = NULL;
    int threshold=0;
    PyObject* pyobj_srn = NULL;
    double srn=0;
    PyObject* pyobj_stn = NULL;
    double stn=0;
    PyObject* pyobj_min_theta = NULL;
    double min_theta=0;
    PyObject* pyobj_max_theta = NULL;
    double max_theta=CV_PI;

    const char* keywords[] = { "image", "rho", "theta", "threshold", "lines", "srn", "stn", "min_theta", "max_theta", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOOO:HoughLines", (char**)keywords, &pyobj_image, &pyobj_rho, &pyobj_theta, &pyobj_threshold, &pyobj_lines, &pyobj_srn, &pyobj_stn, &pyobj_min_theta, &pyobj_max_theta) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_lines, lines, ArgInfo("lines", 1)) &&
        pyopencv_to_safe(pyobj_rho, rho, ArgInfo("rho", 0)) &&
        pyopencv_to_safe(pyobj_theta, theta, ArgInfo("theta", 0)) &&
        pyopencv_to_safe(pyobj_threshold, threshold, ArgInfo("threshold", 0)) &&
        pyopencv_to_safe(pyobj_srn, srn, ArgInfo("srn", 0)) &&
        pyopencv_to_safe(pyobj_stn, stn, ArgInfo("stn", 0)) &&
        pyopencv_to_safe(pyobj_min_theta, min_theta, ArgInfo("min_theta", 0)) &&
        pyopencv_to_safe(pyobj_max_theta, max_theta, ArgInfo("max_theta", 0)) )
    {
        ERRWRAP2(cv::HoughLines(image, lines, rho, theta, threshold, srn, stn, min_theta, max_theta));
        return pyopencv_from(lines);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_lines = NULL;
    UMat lines;
    PyObject* pyobj_rho = NULL;
    double rho=0;
    PyObject* pyobj_theta = NULL;
    double theta=0;
    PyObject* pyobj_threshold = NULL;
    int threshold=0;
    PyObject* pyobj_srn = NULL;
    double srn=0;
    PyObject* pyobj_stn = NULL;
    double stn=0;
    PyObject* pyobj_min_theta = NULL;
    double min_theta=0;
    PyObject* pyobj_max_theta = NULL;
    double max_theta=CV_PI;

    const char* keywords[] = { "image", "rho", "theta", "threshold", "lines", "srn", "stn", "min_theta", "max_theta", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOOO:HoughLines", (char**)keywords, &pyobj_image, &pyobj_rho, &pyobj_theta, &pyobj_threshold, &pyobj_lines, &pyobj_srn, &pyobj_stn, &pyobj_min_theta, &pyobj_max_theta) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_lines, lines, ArgInfo("lines", 1)) &&
        pyopencv_to_safe(pyobj_rho, rho, ArgInfo("rho", 0)) &&
        pyopencv_to_safe(pyobj_theta, theta, ArgInfo("theta", 0)) &&
        pyopencv_to_safe(pyobj_threshold, threshold, ArgInfo("threshold", 0)) &&
        pyopencv_to_safe(pyobj_srn, srn, ArgInfo("srn", 0)) &&
        pyopencv_to_safe(pyobj_stn, stn, ArgInfo("stn", 0)) &&
        pyopencv_to_safe(pyobj_min_theta, min_theta, ArgInfo("min_theta", 0)) &&
        pyopencv_to_safe(pyobj_max_theta, max_theta, ArgInfo("max_theta", 0)) )
    {
        ERRWRAP2(cv::HoughLines(image, lines, rho, theta, threshold, srn, stn, min_theta, max_theta));
        return pyopencv_from(lines);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("HoughLines");

    return NULL;
}

static PyObject* pyopencv_cv_HoughLinesP(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_lines = NULL;
    Mat lines;
    PyObject* pyobj_rho = NULL;
    double rho=0;
    PyObject* pyobj_theta = NULL;
    double theta=0;
    PyObject* pyobj_threshold = NULL;
    int threshold=0;
    PyObject* pyobj_minLineLength = NULL;
    double minLineLength=0;
    PyObject* pyobj_maxLineGap = NULL;
    double maxLineGap=0;

    const char* keywords[] = { "image", "rho", "theta", "threshold", "lines", "minLineLength", "maxLineGap", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:HoughLinesP", (char**)keywords, &pyobj_image, &pyobj_rho, &pyobj_theta, &pyobj_threshold, &pyobj_lines, &pyobj_minLineLength, &pyobj_maxLineGap) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_lines, lines, ArgInfo("lines", 1)) &&
        pyopencv_to_safe(pyobj_rho, rho, ArgInfo("rho", 0)) &&
        pyopencv_to_safe(pyobj_theta, theta, ArgInfo("theta", 0)) &&
        pyopencv_to_safe(pyobj_threshold, threshold, ArgInfo("threshold", 0)) &&
        pyopencv_to_safe(pyobj_minLineLength, minLineLength, ArgInfo("minLineLength", 0)) &&
        pyopencv_to_safe(pyobj_maxLineGap, maxLineGap, ArgInfo("maxLineGap", 0)) )
    {
        ERRWRAP2(cv::HoughLinesP(image, lines, rho, theta, threshold, minLineLength, maxLineGap));
        return pyopencv_from(lines);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_lines = NULL;
    UMat lines;
    PyObject* pyobj_rho = NULL;
    double rho=0;
    PyObject* pyobj_theta = NULL;
    double theta=0;
    PyObject* pyobj_threshold = NULL;
    int threshold=0;
    PyObject* pyobj_minLineLength = NULL;
    double minLineLength=0;
    PyObject* pyobj_maxLineGap = NULL;
    double maxLineGap=0;

    const char* keywords[] = { "image", "rho", "theta", "threshold", "lines", "minLineLength", "maxLineGap", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:HoughLinesP", (char**)keywords, &pyobj_image, &pyobj_rho, &pyobj_theta, &pyobj_threshold, &pyobj_lines, &pyobj_minLineLength, &pyobj_maxLineGap) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_lines, lines, ArgInfo("lines", 1)) &&
        pyopencv_to_safe(pyobj_rho, rho, ArgInfo("rho", 0)) &&
        pyopencv_to_safe(pyobj_theta, theta, ArgInfo("theta", 0)) &&
        pyopencv_to_safe(pyobj_threshold, threshold, ArgInfo("threshold", 0)) &&
        pyopencv_to_safe(pyobj_minLineLength, minLineLength, ArgInfo("minLineLength", 0)) &&
        pyopencv_to_safe(pyobj_maxLineGap, maxLineGap, ArgInfo("maxLineGap", 0)) )
    {
        ERRWRAP2(cv::HoughLinesP(image, lines, rho, theta, threshold, minLineLength, maxLineGap));
        return pyopencv_from(lines);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("HoughLinesP");

    return NULL;
}

static PyObject* pyopencv_cv_HoughLinesPointSet(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj__point = NULL;
    Mat _point;
    PyObject* pyobj__lines = NULL;
    Mat _lines;
    PyObject* pyobj_lines_max = NULL;
    int lines_max=0;
    PyObject* pyobj_threshold = NULL;
    int threshold=0;
    PyObject* pyobj_min_rho = NULL;
    double min_rho=0;
    PyObject* pyobj_max_rho = NULL;
    double max_rho=0;
    PyObject* pyobj_rho_step = NULL;
    double rho_step=0;
    PyObject* pyobj_min_theta = NULL;
    double min_theta=0;
    PyObject* pyobj_max_theta = NULL;
    double max_theta=0;
    PyObject* pyobj_theta_step = NULL;
    double theta_step=0;

    const char* keywords[] = { "_point", "lines_max", "threshold", "min_rho", "max_rho", "rho_step", "min_theta", "max_theta", "theta_step", "_lines", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOOOO|O:HoughLinesPointSet", (char**)keywords, &pyobj__point, &pyobj_lines_max, &pyobj_threshold, &pyobj_min_rho, &pyobj_max_rho, &pyobj_rho_step, &pyobj_min_theta, &pyobj_max_theta, &pyobj_theta_step, &pyobj__lines) &&
        pyopencv_to_safe(pyobj__point, _point, ArgInfo("_point", 0)) &&
        pyopencv_to_safe(pyobj__lines, _lines, ArgInfo("_lines", 1)) &&
        pyopencv_to_safe(pyobj_lines_max, lines_max, ArgInfo("lines_max", 0)) &&
        pyopencv_to_safe(pyobj_threshold, threshold, ArgInfo("threshold", 0)) &&
        pyopencv_to_safe(pyobj_min_rho, min_rho, ArgInfo("min_rho", 0)) &&
        pyopencv_to_safe(pyobj_max_rho, max_rho, ArgInfo("max_rho", 0)) &&
        pyopencv_to_safe(pyobj_rho_step, rho_step, ArgInfo("rho_step", 0)) &&
        pyopencv_to_safe(pyobj_min_theta, min_theta, ArgInfo("min_theta", 0)) &&
        pyopencv_to_safe(pyobj_max_theta, max_theta, ArgInfo("max_theta", 0)) &&
        pyopencv_to_safe(pyobj_theta_step, theta_step, ArgInfo("theta_step", 0)) )
    {
        ERRWRAP2(cv::HoughLinesPointSet(_point, _lines, lines_max, threshold, min_rho, max_rho, rho_step, min_theta, max_theta, theta_step));
        return pyopencv_from(_lines);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj__point = NULL;
    UMat _point;
    PyObject* pyobj__lines = NULL;
    UMat _lines;
    PyObject* pyobj_lines_max = NULL;
    int lines_max=0;
    PyObject* pyobj_threshold = NULL;
    int threshold=0;
    PyObject* pyobj_min_rho = NULL;
    double min_rho=0;
    PyObject* pyobj_max_rho = NULL;
    double max_rho=0;
    PyObject* pyobj_rho_step = NULL;
    double rho_step=0;
    PyObject* pyobj_min_theta = NULL;
    double min_theta=0;
    PyObject* pyobj_max_theta = NULL;
    double max_theta=0;
    PyObject* pyobj_theta_step = NULL;
    double theta_step=0;

    const char* keywords[] = { "_point", "lines_max", "threshold", "min_rho", "max_rho", "rho_step", "min_theta", "max_theta", "theta_step", "_lines", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOOOO|O:HoughLinesPointSet", (char**)keywords, &pyobj__point, &pyobj_lines_max, &pyobj_threshold, &pyobj_min_rho, &pyobj_max_rho, &pyobj_rho_step, &pyobj_min_theta, &pyobj_max_theta, &pyobj_theta_step, &pyobj__lines) &&
        pyopencv_to_safe(pyobj__point, _point, ArgInfo("_point", 0)) &&
        pyopencv_to_safe(pyobj__lines, _lines, ArgInfo("_lines", 1)) &&
        pyopencv_to_safe(pyobj_lines_max, lines_max, ArgInfo("lines_max", 0)) &&
        pyopencv_to_safe(pyobj_threshold, threshold, ArgInfo("threshold", 0)) &&
        pyopencv_to_safe(pyobj_min_rho, min_rho, ArgInfo("min_rho", 0)) &&
        pyopencv_to_safe(pyobj_max_rho, max_rho, ArgInfo("max_rho", 0)) &&
        pyopencv_to_safe(pyobj_rho_step, rho_step, ArgInfo("rho_step", 0)) &&
        pyopencv_to_safe(pyobj_min_theta, min_theta, ArgInfo("min_theta", 0)) &&
        pyopencv_to_safe(pyobj_max_theta, max_theta, ArgInfo("max_theta", 0)) &&
        pyopencv_to_safe(pyobj_theta_step, theta_step, ArgInfo("theta_step", 0)) )
    {
        ERRWRAP2(cv::HoughLinesPointSet(_point, _lines, lines_max, threshold, min_rho, max_rho, rho_step, min_theta, max_theta, theta_step));
        return pyopencv_from(_lines);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("HoughLinesPointSet");

    return NULL;
}

static PyObject* pyopencv_cv_HoughLinesWithAccumulator(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_lines = NULL;
    Mat lines;
    PyObject* pyobj_rho = NULL;
    double rho=0;
    PyObject* pyobj_theta = NULL;
    double theta=0;
    PyObject* pyobj_threshold = NULL;
    int threshold=0;
    PyObject* pyobj_srn = NULL;
    double srn=0;
    PyObject* pyobj_stn = NULL;
    double stn=0;
    PyObject* pyobj_min_theta = NULL;
    double min_theta=0;
    PyObject* pyobj_max_theta = NULL;
    double max_theta=CV_PI;

    const char* keywords[] = { "image", "rho", "theta", "threshold", "lines", "srn", "stn", "min_theta", "max_theta", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOOO:HoughLinesWithAccumulator", (char**)keywords, &pyobj_image, &pyobj_rho, &pyobj_theta, &pyobj_threshold, &pyobj_lines, &pyobj_srn, &pyobj_stn, &pyobj_min_theta, &pyobj_max_theta) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_lines, lines, ArgInfo("lines", 1)) &&
        pyopencv_to_safe(pyobj_rho, rho, ArgInfo("rho", 0)) &&
        pyopencv_to_safe(pyobj_theta, theta, ArgInfo("theta", 0)) &&
        pyopencv_to_safe(pyobj_threshold, threshold, ArgInfo("threshold", 0)) &&
        pyopencv_to_safe(pyobj_srn, srn, ArgInfo("srn", 0)) &&
        pyopencv_to_safe(pyobj_stn, stn, ArgInfo("stn", 0)) &&
        pyopencv_to_safe(pyobj_min_theta, min_theta, ArgInfo("min_theta", 0)) &&
        pyopencv_to_safe(pyobj_max_theta, max_theta, ArgInfo("max_theta", 0)) )
    {
        ERRWRAP2(cv::HoughLinesWithAccumulator(image, lines, rho, theta, threshold, srn, stn, min_theta, max_theta));
        return pyopencv_from(lines);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_lines = NULL;
    UMat lines;
    PyObject* pyobj_rho = NULL;
    double rho=0;
    PyObject* pyobj_theta = NULL;
    double theta=0;
    PyObject* pyobj_threshold = NULL;
    int threshold=0;
    PyObject* pyobj_srn = NULL;
    double srn=0;
    PyObject* pyobj_stn = NULL;
    double stn=0;
    PyObject* pyobj_min_theta = NULL;
    double min_theta=0;
    PyObject* pyobj_max_theta = NULL;
    double max_theta=CV_PI;

    const char* keywords[] = { "image", "rho", "theta", "threshold", "lines", "srn", "stn", "min_theta", "max_theta", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOOO:HoughLinesWithAccumulator", (char**)keywords, &pyobj_image, &pyobj_rho, &pyobj_theta, &pyobj_threshold, &pyobj_lines, &pyobj_srn, &pyobj_stn, &pyobj_min_theta, &pyobj_max_theta) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_lines, lines, ArgInfo("lines", 1)) &&
        pyopencv_to_safe(pyobj_rho, rho, ArgInfo("rho", 0)) &&
        pyopencv_to_safe(pyobj_theta, theta, ArgInfo("theta", 0)) &&
        pyopencv_to_safe(pyobj_threshold, threshold, ArgInfo("threshold", 0)) &&
        pyopencv_to_safe(pyobj_srn, srn, ArgInfo("srn", 0)) &&
        pyopencv_to_safe(pyobj_stn, stn, ArgInfo("stn", 0)) &&
        pyopencv_to_safe(pyobj_min_theta, min_theta, ArgInfo("min_theta", 0)) &&
        pyopencv_to_safe(pyobj_max_theta, max_theta, ArgInfo("max_theta", 0)) )
    {
        ERRWRAP2(cv::HoughLinesWithAccumulator(image, lines, rho, theta, threshold, srn, stn, min_theta, max_theta));
        return pyopencv_from(lines);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("HoughLinesWithAccumulator");

    return NULL;
}

static PyObject* pyopencv_cv_HuMoments(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_m = NULL;
    Moments m;
    PyObject* pyobj_hu = NULL;
    Mat hu;

    const char* keywords[] = { "m", "hu", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:HuMoments", (char**)keywords, &pyobj_m, &pyobj_hu) &&
        pyopencv_to_safe(pyobj_m, m, ArgInfo("m", 0)) &&
        pyopencv_to_safe(pyobj_hu, hu, ArgInfo("hu", 1)) )
    {
        ERRWRAP2(cv::HuMoments(m, hu));
        return pyopencv_from(hu);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_m = NULL;
    Moments m;
    PyObject* pyobj_hu = NULL;
    UMat hu;

    const char* keywords[] = { "m", "hu", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:HuMoments", (char**)keywords, &pyobj_m, &pyobj_hu) &&
        pyopencv_to_safe(pyobj_m, m, ArgInfo("m", 0)) &&
        pyopencv_to_safe(pyobj_hu, hu, ArgInfo("hu", 1)) )
    {
        ERRWRAP2(cv::HuMoments(m, hu));
        return pyopencv_from(hu);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("HuMoments");

    return NULL;
}

static PyObject* pyopencv_cv_KAZE_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_extended = NULL;
    bool extended=false;
    PyObject* pyobj_upright = NULL;
    bool upright=false;
    PyObject* pyobj_threshold = NULL;
    float threshold=0.001f;
    PyObject* pyobj_nOctaves = NULL;
    int nOctaves=4;
    PyObject* pyobj_nOctaveLayers = NULL;
    int nOctaveLayers=4;
    PyObject* pyobj_diffusivity = NULL;
    KAZE_DiffusivityType diffusivity=KAZE::DIFF_PM_G2;
    Ptr<KAZE> retval;

    const char* keywords[] = { "extended", "upright", "threshold", "nOctaves", "nOctaveLayers", "diffusivity", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOOO:KAZE_create", (char**)keywords, &pyobj_extended, &pyobj_upright, &pyobj_threshold, &pyobj_nOctaves, &pyobj_nOctaveLayers, &pyobj_diffusivity) &&
        pyopencv_to_safe(pyobj_extended, extended, ArgInfo("extended", 0)) &&
        pyopencv_to_safe(pyobj_upright, upright, ArgInfo("upright", 0)) &&
        pyopencv_to_safe(pyobj_threshold, threshold, ArgInfo("threshold", 0)) &&
        pyopencv_to_safe(pyobj_nOctaves, nOctaves, ArgInfo("nOctaves", 0)) &&
        pyopencv_to_safe(pyobj_nOctaveLayers, nOctaveLayers, ArgInfo("nOctaveLayers", 0)) &&
        pyopencv_to_safe(pyobj_diffusivity, diffusivity, ArgInfo("diffusivity", 0)) )
    {
        ERRWRAP2(retval = cv::KAZE::create(extended, upright, threshold, nOctaves, nOctaveLayers, diffusivity));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_KeyPoint_convert(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_keypoints = NULL;
    vector_KeyPoint keypoints;
    vector_Point2f points2f;
    PyObject* pyobj_keypointIndexes = NULL;
    vector_int keypointIndexes=std::vector<int>();

    const char* keywords[] = { "keypoints", "keypointIndexes", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:KeyPoint_convert", (char**)keywords, &pyobj_keypoints, &pyobj_keypointIndexes) &&
        pyopencv_to_safe(pyobj_keypoints, keypoints, ArgInfo("keypoints", 0)) &&
        pyopencv_to_safe(pyobj_keypointIndexes, keypointIndexes, ArgInfo("keypointIndexes", 0)) )
    {
        ERRWRAP2(cv::KeyPoint::convert(keypoints, points2f, keypointIndexes));
        return pyopencv_from(points2f);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_points2f = NULL;
    vector_Point2f points2f;
    vector_KeyPoint keypoints;
    PyObject* pyobj_size = NULL;
    float size=1;
    PyObject* pyobj_response = NULL;
    float response=1;
    PyObject* pyobj_octave = NULL;
    int octave=0;
    PyObject* pyobj_class_id = NULL;
    int class_id=-1;

    const char* keywords[] = { "points2f", "size", "response", "octave", "class_id", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOO:KeyPoint_convert", (char**)keywords, &pyobj_points2f, &pyobj_size, &pyobj_response, &pyobj_octave, &pyobj_class_id) &&
        pyopencv_to_safe(pyobj_points2f, points2f, ArgInfo("points2f", 0)) &&
        pyopencv_to_safe(pyobj_size, size, ArgInfo("size", 0)) &&
        pyopencv_to_safe(pyobj_response, response, ArgInfo("response", 0)) &&
        pyopencv_to_safe(pyobj_octave, octave, ArgInfo("octave", 0)) &&
        pyopencv_to_safe(pyobj_class_id, class_id, ArgInfo("class_id", 0)) )
    {
        ERRWRAP2(cv::KeyPoint::convert(points2f, keypoints, size, response, octave, class_id));
        return pyopencv_from(keypoints);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("KeyPoint_convert");

    return NULL;
}

static PyObject* pyopencv_cv_KeyPoint_overlap(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_kp1 = NULL;
    KeyPoint kp1;
    PyObject* pyobj_kp2 = NULL;
    KeyPoint kp2;
    float retval;

    const char* keywords[] = { "kp1", "kp2", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:KeyPoint_overlap", (char**)keywords, &pyobj_kp1, &pyobj_kp2) &&
        pyopencv_to_safe(pyobj_kp1, kp1, ArgInfo("kp1", 0)) &&
        pyopencv_to_safe(pyobj_kp2, kp2, ArgInfo("kp2", 0)) )
    {
        ERRWRAP2(retval = cv::KeyPoint::overlap(kp1, kp2));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_LUT(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_lut = NULL;
    Mat lut;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src", "lut", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:LUT", (char**)keywords, &pyobj_src, &pyobj_lut, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_lut, lut, ArgInfo("lut", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::LUT(src, lut, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_lut = NULL;
    UMat lut;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "src", "lut", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:LUT", (char**)keywords, &pyobj_src, &pyobj_lut, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_lut, lut, ArgInfo("lut", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::LUT(src, lut, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("LUT");

    return NULL;
}

static PyObject* pyopencv_cv_Laplacian(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_ddepth = NULL;
    int ddepth=0;
    PyObject* pyobj_ksize = NULL;
    int ksize=1;
    PyObject* pyobj_scale = NULL;
    double scale=1;
    PyObject* pyobj_delta = NULL;
    double delta=0;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "ddepth", "dst", "ksize", "scale", "delta", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOOO:Laplacian", (char**)keywords, &pyobj_src, &pyobj_ddepth, &pyobj_dst, &pyobj_ksize, &pyobj_scale, &pyobj_delta, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_ddepth, ddepth, ArgInfo("ddepth", 0)) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) &&
        pyopencv_to_safe(pyobj_scale, scale, ArgInfo("scale", 0)) &&
        pyopencv_to_safe(pyobj_delta, delta, ArgInfo("delta", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::Laplacian(src, dst, ddepth, ksize, scale, delta, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_ddepth = NULL;
    int ddepth=0;
    PyObject* pyobj_ksize = NULL;
    int ksize=1;
    PyObject* pyobj_scale = NULL;
    double scale=1;
    PyObject* pyobj_delta = NULL;
    double delta=0;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "ddepth", "dst", "ksize", "scale", "delta", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOOO:Laplacian", (char**)keywords, &pyobj_src, &pyobj_ddepth, &pyobj_dst, &pyobj_ksize, &pyobj_scale, &pyobj_delta, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_ddepth, ddepth, ArgInfo("ddepth", 0)) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) &&
        pyopencv_to_safe(pyobj_scale, scale, ArgInfo("scale", 0)) &&
        pyopencv_to_safe(pyobj_delta, delta, ArgInfo("delta", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::Laplacian(src, dst, ddepth, ksize, scale, delta, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("Laplacian");

    return NULL;
}

static PyObject* pyopencv_cv_MSER_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj__delta = NULL;
    int _delta=5;
    PyObject* pyobj__min_area = NULL;
    int _min_area=60;
    PyObject* pyobj__max_area = NULL;
    int _max_area=14400;
    PyObject* pyobj__max_variation = NULL;
    double _max_variation=0.25;
    PyObject* pyobj__min_diversity = NULL;
    double _min_diversity=.2;
    PyObject* pyobj__max_evolution = NULL;
    int _max_evolution=200;
    PyObject* pyobj__area_threshold = NULL;
    double _area_threshold=1.01;
    PyObject* pyobj__min_margin = NULL;
    double _min_margin=0.003;
    PyObject* pyobj__edge_blur_size = NULL;
    int _edge_blur_size=5;
    Ptr<MSER> retval;

    const char* keywords[] = { "_delta", "_min_area", "_max_area", "_max_variation", "_min_diversity", "_max_evolution", "_area_threshold", "_min_margin", "_edge_blur_size", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOOOOOO:MSER_create", (char**)keywords, &pyobj__delta, &pyobj__min_area, &pyobj__max_area, &pyobj__max_variation, &pyobj__min_diversity, &pyobj__max_evolution, &pyobj__area_threshold, &pyobj__min_margin, &pyobj__edge_blur_size) &&
        pyopencv_to_safe(pyobj__delta, _delta, ArgInfo("_delta", 0)) &&
        pyopencv_to_safe(pyobj__min_area, _min_area, ArgInfo("_min_area", 0)) &&
        pyopencv_to_safe(pyobj__max_area, _max_area, ArgInfo("_max_area", 0)) &&
        pyopencv_to_safe(pyobj__max_variation, _max_variation, ArgInfo("_max_variation", 0)) &&
        pyopencv_to_safe(pyobj__min_diversity, _min_diversity, ArgInfo("_min_diversity", 0)) &&
        pyopencv_to_safe(pyobj__max_evolution, _max_evolution, ArgInfo("_max_evolution", 0)) &&
        pyopencv_to_safe(pyobj__area_threshold, _area_threshold, ArgInfo("_area_threshold", 0)) &&
        pyopencv_to_safe(pyobj__min_margin, _min_margin, ArgInfo("_min_margin", 0)) &&
        pyopencv_to_safe(pyobj__edge_blur_size, _edge_blur_size, ArgInfo("_edge_blur_size", 0)) )
    {
        ERRWRAP2(retval = cv::MSER::create(_delta, _min_area, _max_area, _max_variation, _min_diversity, _max_evolution, _area_threshold, _min_margin, _edge_blur_size));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_Mahalanobis(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_v1 = NULL;
    Mat v1;
    PyObject* pyobj_v2 = NULL;
    Mat v2;
    PyObject* pyobj_icovar = NULL;
    Mat icovar;
    double retval;

    const char* keywords[] = { "v1", "v2", "icovar", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:Mahalanobis", (char**)keywords, &pyobj_v1, &pyobj_v2, &pyobj_icovar) &&
        pyopencv_to_safe(pyobj_v1, v1, ArgInfo("v1", 0)) &&
        pyopencv_to_safe(pyobj_v2, v2, ArgInfo("v2", 0)) &&
        pyopencv_to_safe(pyobj_icovar, icovar, ArgInfo("icovar", 0)) )
    {
        ERRWRAP2(retval = cv::Mahalanobis(v1, v2, icovar));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_v1 = NULL;
    UMat v1;
    PyObject* pyobj_v2 = NULL;
    UMat v2;
    PyObject* pyobj_icovar = NULL;
    UMat icovar;
    double retval;

    const char* keywords[] = { "v1", "v2", "icovar", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:Mahalanobis", (char**)keywords, &pyobj_v1, &pyobj_v2, &pyobj_icovar) &&
        pyopencv_to_safe(pyobj_v1, v1, ArgInfo("v1", 0)) &&
        pyopencv_to_safe(pyobj_v2, v2, ArgInfo("v2", 0)) &&
        pyopencv_to_safe(pyobj_icovar, icovar, ArgInfo("icovar", 0)) )
    {
        ERRWRAP2(retval = cv::Mahalanobis(v1, v2, icovar));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("Mahalanobis");

    return NULL;
}

static PyObject* pyopencv_cv_ORB_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_nfeatures = NULL;
    int nfeatures=500;
    PyObject* pyobj_scaleFactor = NULL;
    float scaleFactor=1.2f;
    PyObject* pyobj_nlevels = NULL;
    int nlevels=8;
    PyObject* pyobj_edgeThreshold = NULL;
    int edgeThreshold=31;
    PyObject* pyobj_firstLevel = NULL;
    int firstLevel=0;
    PyObject* pyobj_WTA_K = NULL;
    int WTA_K=2;
    PyObject* pyobj_scoreType = NULL;
    ORB_ScoreType scoreType=ORB::HARRIS_SCORE;
    PyObject* pyobj_patchSize = NULL;
    int patchSize=31;
    PyObject* pyobj_fastThreshold = NULL;
    int fastThreshold=20;
    Ptr<ORB> retval;

    const char* keywords[] = { "nfeatures", "scaleFactor", "nlevels", "edgeThreshold", "firstLevel", "WTA_K", "scoreType", "patchSize", "fastThreshold", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOOOOOO:ORB_create", (char**)keywords, &pyobj_nfeatures, &pyobj_scaleFactor, &pyobj_nlevels, &pyobj_edgeThreshold, &pyobj_firstLevel, &pyobj_WTA_K, &pyobj_scoreType, &pyobj_patchSize, &pyobj_fastThreshold) &&
        pyopencv_to_safe(pyobj_nfeatures, nfeatures, ArgInfo("nfeatures", 0)) &&
        pyopencv_to_safe(pyobj_scaleFactor, scaleFactor, ArgInfo("scaleFactor", 0)) &&
        pyopencv_to_safe(pyobj_nlevels, nlevels, ArgInfo("nlevels", 0)) &&
        pyopencv_to_safe(pyobj_edgeThreshold, edgeThreshold, ArgInfo("edgeThreshold", 0)) &&
        pyopencv_to_safe(pyobj_firstLevel, firstLevel, ArgInfo("firstLevel", 0)) &&
        pyopencv_to_safe(pyobj_WTA_K, WTA_K, ArgInfo("WTA_K", 0)) &&
        pyopencv_to_safe(pyobj_scoreType, scoreType, ArgInfo("scoreType", 0)) &&
        pyopencv_to_safe(pyobj_patchSize, patchSize, ArgInfo("patchSize", 0)) &&
        pyopencv_to_safe(pyobj_fastThreshold, fastThreshold, ArgInfo("fastThreshold", 0)) )
    {
        ERRWRAP2(retval = cv::ORB::create(nfeatures, scaleFactor, nlevels, edgeThreshold, firstLevel, WTA_K, scoreType, patchSize, fastThreshold));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_PCABackProject(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_data = NULL;
    Mat data;
    PyObject* pyobj_mean = NULL;
    Mat mean;
    PyObject* pyobj_eigenvectors = NULL;
    Mat eigenvectors;
    PyObject* pyobj_result = NULL;
    Mat result;

    const char* keywords[] = { "data", "mean", "eigenvectors", "result", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:PCABackProject", (char**)keywords, &pyobj_data, &pyobj_mean, &pyobj_eigenvectors, &pyobj_result) &&
        pyopencv_to_safe(pyobj_data, data, ArgInfo("data", 0)) &&
        pyopencv_to_safe(pyobj_mean, mean, ArgInfo("mean", 0)) &&
        pyopencv_to_safe(pyobj_eigenvectors, eigenvectors, ArgInfo("eigenvectors", 0)) &&
        pyopencv_to_safe(pyobj_result, result, ArgInfo("result", 1)) )
    {
        ERRWRAP2(cv::PCABackProject(data, mean, eigenvectors, result));
        return pyopencv_from(result);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_data = NULL;
    UMat data;
    PyObject* pyobj_mean = NULL;
    UMat mean;
    PyObject* pyobj_eigenvectors = NULL;
    UMat eigenvectors;
    PyObject* pyobj_result = NULL;
    UMat result;

    const char* keywords[] = { "data", "mean", "eigenvectors", "result", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:PCABackProject", (char**)keywords, &pyobj_data, &pyobj_mean, &pyobj_eigenvectors, &pyobj_result) &&
        pyopencv_to_safe(pyobj_data, data, ArgInfo("data", 0)) &&
        pyopencv_to_safe(pyobj_mean, mean, ArgInfo("mean", 0)) &&
        pyopencv_to_safe(pyobj_eigenvectors, eigenvectors, ArgInfo("eigenvectors", 0)) &&
        pyopencv_to_safe(pyobj_result, result, ArgInfo("result", 1)) )
    {
        ERRWRAP2(cv::PCABackProject(data, mean, eigenvectors, result));
        return pyopencv_from(result);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("PCABackProject");

    return NULL;
}

static PyObject* pyopencv_cv_PCACompute(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(4);

    {
    PyObject* pyobj_data = NULL;
    Mat data;
    PyObject* pyobj_mean = NULL;
    Mat mean;
    PyObject* pyobj_eigenvectors = NULL;
    Mat eigenvectors;
    PyObject* pyobj_maxComponents = NULL;
    int maxComponents=0;

    const char* keywords[] = { "data", "mean", "eigenvectors", "maxComponents", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:PCACompute", (char**)keywords, &pyobj_data, &pyobj_mean, &pyobj_eigenvectors, &pyobj_maxComponents) &&
        pyopencv_to_safe(pyobj_data, data, ArgInfo("data", 0)) &&
        pyopencv_to_safe(pyobj_mean, mean, ArgInfo("mean", 1)) &&
        pyopencv_to_safe(pyobj_eigenvectors, eigenvectors, ArgInfo("eigenvectors", 1)) &&
        pyopencv_to_safe(pyobj_maxComponents, maxComponents, ArgInfo("maxComponents", 0)) )
    {
        ERRWRAP2(cv::PCACompute(data, mean, eigenvectors, maxComponents));
        return Py_BuildValue("(NN)", pyopencv_from(mean), pyopencv_from(eigenvectors));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_data = NULL;
    UMat data;
    PyObject* pyobj_mean = NULL;
    UMat mean;
    PyObject* pyobj_eigenvectors = NULL;
    UMat eigenvectors;
    PyObject* pyobj_maxComponents = NULL;
    int maxComponents=0;

    const char* keywords[] = { "data", "mean", "eigenvectors", "maxComponents", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:PCACompute", (char**)keywords, &pyobj_data, &pyobj_mean, &pyobj_eigenvectors, &pyobj_maxComponents) &&
        pyopencv_to_safe(pyobj_data, data, ArgInfo("data", 0)) &&
        pyopencv_to_safe(pyobj_mean, mean, ArgInfo("mean", 1)) &&
        pyopencv_to_safe(pyobj_eigenvectors, eigenvectors, ArgInfo("eigenvectors", 1)) &&
        pyopencv_to_safe(pyobj_maxComponents, maxComponents, ArgInfo("maxComponents", 0)) )
    {
        ERRWRAP2(cv::PCACompute(data, mean, eigenvectors, maxComponents));
        return Py_BuildValue("(NN)", pyopencv_from(mean), pyopencv_from(eigenvectors));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_data = NULL;
    Mat data;
    PyObject* pyobj_mean = NULL;
    Mat mean;
    PyObject* pyobj_eigenvectors = NULL;
    Mat eigenvectors;
    PyObject* pyobj_retainedVariance = NULL;
    double retainedVariance=0;

    const char* keywords[] = { "data", "mean", "retainedVariance", "eigenvectors", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:PCACompute", (char**)keywords, &pyobj_data, &pyobj_mean, &pyobj_retainedVariance, &pyobj_eigenvectors) &&
        pyopencv_to_safe(pyobj_data, data, ArgInfo("data", 0)) &&
        pyopencv_to_safe(pyobj_mean, mean, ArgInfo("mean", 1)) &&
        pyopencv_to_safe(pyobj_eigenvectors, eigenvectors, ArgInfo("eigenvectors", 1)) &&
        pyopencv_to_safe(pyobj_retainedVariance, retainedVariance, ArgInfo("retainedVariance", 0)) )
    {
        ERRWRAP2(cv::PCACompute(data, mean, eigenvectors, retainedVariance));
        return Py_BuildValue("(NN)", pyopencv_from(mean), pyopencv_from(eigenvectors));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_data = NULL;
    UMat data;
    PyObject* pyobj_mean = NULL;
    UMat mean;
    PyObject* pyobj_eigenvectors = NULL;
    UMat eigenvectors;
    PyObject* pyobj_retainedVariance = NULL;
    double retainedVariance=0;

    const char* keywords[] = { "data", "mean", "retainedVariance", "eigenvectors", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:PCACompute", (char**)keywords, &pyobj_data, &pyobj_mean, &pyobj_retainedVariance, &pyobj_eigenvectors) &&
        pyopencv_to_safe(pyobj_data, data, ArgInfo("data", 0)) &&
        pyopencv_to_safe(pyobj_mean, mean, ArgInfo("mean", 1)) &&
        pyopencv_to_safe(pyobj_eigenvectors, eigenvectors, ArgInfo("eigenvectors", 1)) &&
        pyopencv_to_safe(pyobj_retainedVariance, retainedVariance, ArgInfo("retainedVariance", 0)) )
    {
        ERRWRAP2(cv::PCACompute(data, mean, eigenvectors, retainedVariance));
        return Py_BuildValue("(NN)", pyopencv_from(mean), pyopencv_from(eigenvectors));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("PCACompute");

    return NULL;
}

static PyObject* pyopencv_cv_PCACompute2(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(4);

    {
    PyObject* pyobj_data = NULL;
    Mat data;
    PyObject* pyobj_mean = NULL;
    Mat mean;
    PyObject* pyobj_eigenvectors = NULL;
    Mat eigenvectors;
    PyObject* pyobj_eigenvalues = NULL;
    Mat eigenvalues;
    PyObject* pyobj_maxComponents = NULL;
    int maxComponents=0;

    const char* keywords[] = { "data", "mean", "eigenvectors", "eigenvalues", "maxComponents", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:PCACompute2", (char**)keywords, &pyobj_data, &pyobj_mean, &pyobj_eigenvectors, &pyobj_eigenvalues, &pyobj_maxComponents) &&
        pyopencv_to_safe(pyobj_data, data, ArgInfo("data", 0)) &&
        pyopencv_to_safe(pyobj_mean, mean, ArgInfo("mean", 1)) &&
        pyopencv_to_safe(pyobj_eigenvectors, eigenvectors, ArgInfo("eigenvectors", 1)) &&
        pyopencv_to_safe(pyobj_eigenvalues, eigenvalues, ArgInfo("eigenvalues", 1)) &&
        pyopencv_to_safe(pyobj_maxComponents, maxComponents, ArgInfo("maxComponents", 0)) )
    {
        ERRWRAP2(cv::PCACompute(data, mean, eigenvectors, eigenvalues, maxComponents));
        return Py_BuildValue("(NNN)", pyopencv_from(mean), pyopencv_from(eigenvectors), pyopencv_from(eigenvalues));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_data = NULL;
    UMat data;
    PyObject* pyobj_mean = NULL;
    UMat mean;
    PyObject* pyobj_eigenvectors = NULL;
    UMat eigenvectors;
    PyObject* pyobj_eigenvalues = NULL;
    UMat eigenvalues;
    PyObject* pyobj_maxComponents = NULL;
    int maxComponents=0;

    const char* keywords[] = { "data", "mean", "eigenvectors", "eigenvalues", "maxComponents", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:PCACompute2", (char**)keywords, &pyobj_data, &pyobj_mean, &pyobj_eigenvectors, &pyobj_eigenvalues, &pyobj_maxComponents) &&
        pyopencv_to_safe(pyobj_data, data, ArgInfo("data", 0)) &&
        pyopencv_to_safe(pyobj_mean, mean, ArgInfo("mean", 1)) &&
        pyopencv_to_safe(pyobj_eigenvectors, eigenvectors, ArgInfo("eigenvectors", 1)) &&
        pyopencv_to_safe(pyobj_eigenvalues, eigenvalues, ArgInfo("eigenvalues", 1)) &&
        pyopencv_to_safe(pyobj_maxComponents, maxComponents, ArgInfo("maxComponents", 0)) )
    {
        ERRWRAP2(cv::PCACompute(data, mean, eigenvectors, eigenvalues, maxComponents));
        return Py_BuildValue("(NNN)", pyopencv_from(mean), pyopencv_from(eigenvectors), pyopencv_from(eigenvalues));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_data = NULL;
    Mat data;
    PyObject* pyobj_mean = NULL;
    Mat mean;
    PyObject* pyobj_eigenvectors = NULL;
    Mat eigenvectors;
    PyObject* pyobj_eigenvalues = NULL;
    Mat eigenvalues;
    PyObject* pyobj_retainedVariance = NULL;
    double retainedVariance=0;

    const char* keywords[] = { "data", "mean", "retainedVariance", "eigenvectors", "eigenvalues", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:PCACompute2", (char**)keywords, &pyobj_data, &pyobj_mean, &pyobj_retainedVariance, &pyobj_eigenvectors, &pyobj_eigenvalues) &&
        pyopencv_to_safe(pyobj_data, data, ArgInfo("data", 0)) &&
        pyopencv_to_safe(pyobj_mean, mean, ArgInfo("mean", 1)) &&
        pyopencv_to_safe(pyobj_eigenvectors, eigenvectors, ArgInfo("eigenvectors", 1)) &&
        pyopencv_to_safe(pyobj_eigenvalues, eigenvalues, ArgInfo("eigenvalues", 1)) &&
        pyopencv_to_safe(pyobj_retainedVariance, retainedVariance, ArgInfo("retainedVariance", 0)) )
    {
        ERRWRAP2(cv::PCACompute(data, mean, eigenvectors, eigenvalues, retainedVariance));
        return Py_BuildValue("(NNN)", pyopencv_from(mean), pyopencv_from(eigenvectors), pyopencv_from(eigenvalues));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_data = NULL;
    UMat data;
    PyObject* pyobj_mean = NULL;
    UMat mean;
    PyObject* pyobj_eigenvectors = NULL;
    UMat eigenvectors;
    PyObject* pyobj_eigenvalues = NULL;
    UMat eigenvalues;
    PyObject* pyobj_retainedVariance = NULL;
    double retainedVariance=0;

    const char* keywords[] = { "data", "mean", "retainedVariance", "eigenvectors", "eigenvalues", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:PCACompute2", (char**)keywords, &pyobj_data, &pyobj_mean, &pyobj_retainedVariance, &pyobj_eigenvectors, &pyobj_eigenvalues) &&
        pyopencv_to_safe(pyobj_data, data, ArgInfo("data", 0)) &&
        pyopencv_to_safe(pyobj_mean, mean, ArgInfo("mean", 1)) &&
        pyopencv_to_safe(pyobj_eigenvectors, eigenvectors, ArgInfo("eigenvectors", 1)) &&
        pyopencv_to_safe(pyobj_eigenvalues, eigenvalues, ArgInfo("eigenvalues", 1)) &&
        pyopencv_to_safe(pyobj_retainedVariance, retainedVariance, ArgInfo("retainedVariance", 0)) )
    {
        ERRWRAP2(cv::PCACompute(data, mean, eigenvectors, eigenvalues, retainedVariance));
        return Py_BuildValue("(NNN)", pyopencv_from(mean), pyopencv_from(eigenvectors), pyopencv_from(eigenvalues));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("PCACompute2");

    return NULL;
}

static PyObject* pyopencv_cv_PCAProject(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_data = NULL;
    Mat data;
    PyObject* pyobj_mean = NULL;
    Mat mean;
    PyObject* pyobj_eigenvectors = NULL;
    Mat eigenvectors;
    PyObject* pyobj_result = NULL;
    Mat result;

    const char* keywords[] = { "data", "mean", "eigenvectors", "result", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:PCAProject", (char**)keywords, &pyobj_data, &pyobj_mean, &pyobj_eigenvectors, &pyobj_result) &&
        pyopencv_to_safe(pyobj_data, data, ArgInfo("data", 0)) &&
        pyopencv_to_safe(pyobj_mean, mean, ArgInfo("mean", 0)) &&
        pyopencv_to_safe(pyobj_eigenvectors, eigenvectors, ArgInfo("eigenvectors", 0)) &&
        pyopencv_to_safe(pyobj_result, result, ArgInfo("result", 1)) )
    {
        ERRWRAP2(cv::PCAProject(data, mean, eigenvectors, result));
        return pyopencv_from(result);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_data = NULL;
    UMat data;
    PyObject* pyobj_mean = NULL;
    UMat mean;
    PyObject* pyobj_eigenvectors = NULL;
    UMat eigenvectors;
    PyObject* pyobj_result = NULL;
    UMat result;

    const char* keywords[] = { "data", "mean", "eigenvectors", "result", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:PCAProject", (char**)keywords, &pyobj_data, &pyobj_mean, &pyobj_eigenvectors, &pyobj_result) &&
        pyopencv_to_safe(pyobj_data, data, ArgInfo("data", 0)) &&
        pyopencv_to_safe(pyobj_mean, mean, ArgInfo("mean", 0)) &&
        pyopencv_to_safe(pyobj_eigenvectors, eigenvectors, ArgInfo("eigenvectors", 0)) &&
        pyopencv_to_safe(pyobj_result, result, ArgInfo("result", 1)) )
    {
        ERRWRAP2(cv::PCAProject(data, mean, eigenvectors, result));
        return pyopencv_from(result);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("PCAProject");

    return NULL;
}

static PyObject* pyopencv_cv_PSNR(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src1 = NULL;
    Mat src1;
    PyObject* pyobj_src2 = NULL;
    Mat src2;
    PyObject* pyobj_R = NULL;
    double R=255.;
    double retval;

    const char* keywords[] = { "src1", "src2", "R", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:PSNR", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_R) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) )
    {
        ERRWRAP2(retval = cv::PSNR(src1, src2, R));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src1 = NULL;
    UMat src1;
    PyObject* pyobj_src2 = NULL;
    UMat src2;
    PyObject* pyobj_R = NULL;
    double R=255.;
    double retval;

    const char* keywords[] = { "src1", "src2", "R", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:PSNR", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_R) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) )
    {
        ERRWRAP2(retval = cv::PSNR(src1, src2, R));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("PSNR");

    return NULL;
}

static PyObject* pyopencv_cv_RQDecomp3x3(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_mtxR = NULL;
    Mat mtxR;
    PyObject* pyobj_mtxQ = NULL;
    Mat mtxQ;
    PyObject* pyobj_Qx = NULL;
    Mat Qx;
    PyObject* pyobj_Qy = NULL;
    Mat Qy;
    PyObject* pyobj_Qz = NULL;
    Mat Qz;
    Vec3d retval;

    const char* keywords[] = { "src", "mtxR", "mtxQ", "Qx", "Qy", "Qz", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOOO:RQDecomp3x3", (char**)keywords, &pyobj_src, &pyobj_mtxR, &pyobj_mtxQ, &pyobj_Qx, &pyobj_Qy, &pyobj_Qz) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_mtxR, mtxR, ArgInfo("mtxR", 1)) &&
        pyopencv_to_safe(pyobj_mtxQ, mtxQ, ArgInfo("mtxQ", 1)) &&
        pyopencv_to_safe(pyobj_Qx, Qx, ArgInfo("Qx", 1)) &&
        pyopencv_to_safe(pyobj_Qy, Qy, ArgInfo("Qy", 1)) &&
        pyopencv_to_safe(pyobj_Qz, Qz, ArgInfo("Qz", 1)) )
    {
        ERRWRAP2(retval = cv::RQDecomp3x3(src, mtxR, mtxQ, Qx, Qy, Qz));
        return Py_BuildValue("(NNNNNN)", pyopencv_from(retval), pyopencv_from(mtxR), pyopencv_from(mtxQ), pyopencv_from(Qx), pyopencv_from(Qy), pyopencv_from(Qz));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_mtxR = NULL;
    UMat mtxR;
    PyObject* pyobj_mtxQ = NULL;
    UMat mtxQ;
    PyObject* pyobj_Qx = NULL;
    UMat Qx;
    PyObject* pyobj_Qy = NULL;
    UMat Qy;
    PyObject* pyobj_Qz = NULL;
    UMat Qz;
    Vec3d retval;

    const char* keywords[] = { "src", "mtxR", "mtxQ", "Qx", "Qy", "Qz", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOOO:RQDecomp3x3", (char**)keywords, &pyobj_src, &pyobj_mtxR, &pyobj_mtxQ, &pyobj_Qx, &pyobj_Qy, &pyobj_Qz) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_mtxR, mtxR, ArgInfo("mtxR", 1)) &&
        pyopencv_to_safe(pyobj_mtxQ, mtxQ, ArgInfo("mtxQ", 1)) &&
        pyopencv_to_safe(pyobj_Qx, Qx, ArgInfo("Qx", 1)) &&
        pyopencv_to_safe(pyobj_Qy, Qy, ArgInfo("Qy", 1)) &&
        pyopencv_to_safe(pyobj_Qz, Qz, ArgInfo("Qz", 1)) )
    {
        ERRWRAP2(retval = cv::RQDecomp3x3(src, mtxR, mtxQ, Qx, Qy, Qz));
        return Py_BuildValue("(NNNNNN)", pyopencv_from(retval), pyopencv_from(mtxR), pyopencv_from(mtxQ), pyopencv_from(Qx), pyopencv_from(Qy), pyopencv_from(Qz));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("RQDecomp3x3");

    return NULL;
}

static PyObject* pyopencv_cv_Rodrigues(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_jacobian = NULL;
    Mat jacobian;

    const char* keywords[] = { "src", "dst", "jacobian", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:Rodrigues", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_jacobian) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_jacobian, jacobian, ArgInfo("jacobian", 1)) )
    {
        ERRWRAP2(cv::Rodrigues(src, dst, jacobian));
        return Py_BuildValue("(NN)", pyopencv_from(dst), pyopencv_from(jacobian));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_jacobian = NULL;
    UMat jacobian;

    const char* keywords[] = { "src", "dst", "jacobian", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:Rodrigues", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_jacobian) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_jacobian, jacobian, ArgInfo("jacobian", 1)) )
    {
        ERRWRAP2(cv::Rodrigues(src, dst, jacobian));
        return Py_BuildValue("(NN)", pyopencv_from(dst), pyopencv_from(jacobian));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("Rodrigues");

    return NULL;
}

static PyObject* pyopencv_cv_SIFT_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_nfeatures = NULL;
    int nfeatures=0;
    PyObject* pyobj_nOctaveLayers = NULL;
    int nOctaveLayers=3;
    PyObject* pyobj_contrastThreshold = NULL;
    double contrastThreshold=0.04;
    PyObject* pyobj_edgeThreshold = NULL;
    double edgeThreshold=10;
    PyObject* pyobj_sigma = NULL;
    double sigma=1.6;
    Ptr<SIFT> retval;

    const char* keywords[] = { "nfeatures", "nOctaveLayers", "contrastThreshold", "edgeThreshold", "sigma", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOO:SIFT_create", (char**)keywords, &pyobj_nfeatures, &pyobj_nOctaveLayers, &pyobj_contrastThreshold, &pyobj_edgeThreshold, &pyobj_sigma) &&
        pyopencv_to_safe(pyobj_nfeatures, nfeatures, ArgInfo("nfeatures", 0)) &&
        pyopencv_to_safe(pyobj_nOctaveLayers, nOctaveLayers, ArgInfo("nOctaveLayers", 0)) &&
        pyopencv_to_safe(pyobj_contrastThreshold, contrastThreshold, ArgInfo("contrastThreshold", 0)) &&
        pyopencv_to_safe(pyobj_edgeThreshold, edgeThreshold, ArgInfo("edgeThreshold", 0)) &&
        pyopencv_to_safe(pyobj_sigma, sigma, ArgInfo("sigma", 0)) )
    {
        ERRWRAP2(retval = cv::SIFT::create(nfeatures, nOctaveLayers, contrastThreshold, edgeThreshold, sigma));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_nfeatures = NULL;
    int nfeatures=0;
    PyObject* pyobj_nOctaveLayers = NULL;
    int nOctaveLayers=0;
    PyObject* pyobj_contrastThreshold = NULL;
    double contrastThreshold=0;
    PyObject* pyobj_edgeThreshold = NULL;
    double edgeThreshold=0;
    PyObject* pyobj_sigma = NULL;
    double sigma=0;
    PyObject* pyobj_descriptorType = NULL;
    int descriptorType=0;
    Ptr<SIFT> retval;

    const char* keywords[] = { "nfeatures", "nOctaveLayers", "contrastThreshold", "edgeThreshold", "sigma", "descriptorType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO:SIFT_create", (char**)keywords, &pyobj_nfeatures, &pyobj_nOctaveLayers, &pyobj_contrastThreshold, &pyobj_edgeThreshold, &pyobj_sigma, &pyobj_descriptorType) &&
        pyopencv_to_safe(pyobj_nfeatures, nfeatures, ArgInfo("nfeatures", 0)) &&
        pyopencv_to_safe(pyobj_nOctaveLayers, nOctaveLayers, ArgInfo("nOctaveLayers", 0)) &&
        pyopencv_to_safe(pyobj_contrastThreshold, contrastThreshold, ArgInfo("contrastThreshold", 0)) &&
        pyopencv_to_safe(pyobj_edgeThreshold, edgeThreshold, ArgInfo("edgeThreshold", 0)) &&
        pyopencv_to_safe(pyobj_sigma, sigma, ArgInfo("sigma", 0)) &&
        pyopencv_to_safe(pyobj_descriptorType, descriptorType, ArgInfo("descriptorType", 0)) )
    {
        ERRWRAP2(retval = cv::SIFT::create(nfeatures, nOctaveLayers, contrastThreshold, edgeThreshold, sigma, descriptorType));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("SIFT_create");

    return NULL;
}

static PyObject* pyopencv_cv_SVBackSubst(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_w = NULL;
    Mat w;
    PyObject* pyobj_u = NULL;
    Mat u;
    PyObject* pyobj_vt = NULL;
    Mat vt;
    PyObject* pyobj_rhs = NULL;
    Mat rhs;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "w", "u", "vt", "rhs", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:SVBackSubst", (char**)keywords, &pyobj_w, &pyobj_u, &pyobj_vt, &pyobj_rhs, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_w, w, ArgInfo("w", 0)) &&
        pyopencv_to_safe(pyobj_u, u, ArgInfo("u", 0)) &&
        pyopencv_to_safe(pyobj_vt, vt, ArgInfo("vt", 0)) &&
        pyopencv_to_safe(pyobj_rhs, rhs, ArgInfo("rhs", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::SVBackSubst(w, u, vt, rhs, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_w = NULL;
    UMat w;
    PyObject* pyobj_u = NULL;
    UMat u;
    PyObject* pyobj_vt = NULL;
    UMat vt;
    PyObject* pyobj_rhs = NULL;
    UMat rhs;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "w", "u", "vt", "rhs", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:SVBackSubst", (char**)keywords, &pyobj_w, &pyobj_u, &pyobj_vt, &pyobj_rhs, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_w, w, ArgInfo("w", 0)) &&
        pyopencv_to_safe(pyobj_u, u, ArgInfo("u", 0)) &&
        pyopencv_to_safe(pyobj_vt, vt, ArgInfo("vt", 0)) &&
        pyopencv_to_safe(pyobj_rhs, rhs, ArgInfo("rhs", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::SVBackSubst(w, u, vt, rhs, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("SVBackSubst");

    return NULL;
}

static PyObject* pyopencv_cv_SVDecomp(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_w = NULL;
    Mat w;
    PyObject* pyobj_u = NULL;
    Mat u;
    PyObject* pyobj_vt = NULL;
    Mat vt;
    PyObject* pyobj_flags = NULL;
    int flags=0;

    const char* keywords[] = { "src", "w", "u", "vt", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOO:SVDecomp", (char**)keywords, &pyobj_src, &pyobj_w, &pyobj_u, &pyobj_vt, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_w, w, ArgInfo("w", 1)) &&
        pyopencv_to_safe(pyobj_u, u, ArgInfo("u", 1)) &&
        pyopencv_to_safe(pyobj_vt, vt, ArgInfo("vt", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::SVDecomp(src, w, u, vt, flags));
        return Py_BuildValue("(NNN)", pyopencv_from(w), pyopencv_from(u), pyopencv_from(vt));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_w = NULL;
    UMat w;
    PyObject* pyobj_u = NULL;
    UMat u;
    PyObject* pyobj_vt = NULL;
    UMat vt;
    PyObject* pyobj_flags = NULL;
    int flags=0;

    const char* keywords[] = { "src", "w", "u", "vt", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOO:SVDecomp", (char**)keywords, &pyobj_src, &pyobj_w, &pyobj_u, &pyobj_vt, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_w, w, ArgInfo("w", 1)) &&
        pyopencv_to_safe(pyobj_u, u, ArgInfo("u", 1)) &&
        pyopencv_to_safe(pyobj_vt, vt, ArgInfo("vt", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::SVDecomp(src, w, u, vt, flags));
        return Py_BuildValue("(NNN)", pyopencv_from(w), pyopencv_from(u), pyopencv_from(vt));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("SVDecomp");

    return NULL;
}

static PyObject* pyopencv_cv_Scharr(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_ddepth = NULL;
    int ddepth=0;
    PyObject* pyobj_dx = NULL;
    int dx=0;
    PyObject* pyobj_dy = NULL;
    int dy=0;
    PyObject* pyobj_scale = NULL;
    double scale=1;
    PyObject* pyobj_delta = NULL;
    double delta=0;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "ddepth", "dx", "dy", "dst", "scale", "delta", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOO:Scharr", (char**)keywords, &pyobj_src, &pyobj_ddepth, &pyobj_dx, &pyobj_dy, &pyobj_dst, &pyobj_scale, &pyobj_delta, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_ddepth, ddepth, ArgInfo("ddepth", 0)) &&
        pyopencv_to_safe(pyobj_dx, dx, ArgInfo("dx", 0)) &&
        pyopencv_to_safe(pyobj_dy, dy, ArgInfo("dy", 0)) &&
        pyopencv_to_safe(pyobj_scale, scale, ArgInfo("scale", 0)) &&
        pyopencv_to_safe(pyobj_delta, delta, ArgInfo("delta", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::Scharr(src, dst, ddepth, dx, dy, scale, delta, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_ddepth = NULL;
    int ddepth=0;
    PyObject* pyobj_dx = NULL;
    int dx=0;
    PyObject* pyobj_dy = NULL;
    int dy=0;
    PyObject* pyobj_scale = NULL;
    double scale=1;
    PyObject* pyobj_delta = NULL;
    double delta=0;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "ddepth", "dx", "dy", "dst", "scale", "delta", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOO:Scharr", (char**)keywords, &pyobj_src, &pyobj_ddepth, &pyobj_dx, &pyobj_dy, &pyobj_dst, &pyobj_scale, &pyobj_delta, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_ddepth, ddepth, ArgInfo("ddepth", 0)) &&
        pyopencv_to_safe(pyobj_dx, dx, ArgInfo("dx", 0)) &&
        pyopencv_to_safe(pyobj_dy, dy, ArgInfo("dy", 0)) &&
        pyopencv_to_safe(pyobj_scale, scale, ArgInfo("scale", 0)) &&
        pyopencv_to_safe(pyobj_delta, delta, ArgInfo("delta", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::Scharr(src, dst, ddepth, dx, dy, scale, delta, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("Scharr");

    return NULL;
}

static PyObject* pyopencv_cv_SimpleBlobDetector_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_parameters = NULL;
    SimpleBlobDetector_Params parameters=SimpleBlobDetector::Params();
    Ptr<SimpleBlobDetector> retval;

    const char* keywords[] = { "parameters", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|O:SimpleBlobDetector_create", (char**)keywords, &pyobj_parameters) &&
        pyopencv_to_safe(pyobj_parameters, parameters, ArgInfo("parameters", 0)) )
    {
        ERRWRAP2(retval = cv::SimpleBlobDetector::create(parameters));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_Sobel(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_ddepth = NULL;
    int ddepth=0;
    PyObject* pyobj_dx = NULL;
    int dx=0;
    PyObject* pyobj_dy = NULL;
    int dy=0;
    PyObject* pyobj_ksize = NULL;
    int ksize=3;
    PyObject* pyobj_scale = NULL;
    double scale=1;
    PyObject* pyobj_delta = NULL;
    double delta=0;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "ddepth", "dx", "dy", "dst", "ksize", "scale", "delta", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOOO:Sobel", (char**)keywords, &pyobj_src, &pyobj_ddepth, &pyobj_dx, &pyobj_dy, &pyobj_dst, &pyobj_ksize, &pyobj_scale, &pyobj_delta, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_ddepth, ddepth, ArgInfo("ddepth", 0)) &&
        pyopencv_to_safe(pyobj_dx, dx, ArgInfo("dx", 0)) &&
        pyopencv_to_safe(pyobj_dy, dy, ArgInfo("dy", 0)) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) &&
        pyopencv_to_safe(pyobj_scale, scale, ArgInfo("scale", 0)) &&
        pyopencv_to_safe(pyobj_delta, delta, ArgInfo("delta", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::Sobel(src, dst, ddepth, dx, dy, ksize, scale, delta, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_ddepth = NULL;
    int ddepth=0;
    PyObject* pyobj_dx = NULL;
    int dx=0;
    PyObject* pyobj_dy = NULL;
    int dy=0;
    PyObject* pyobj_ksize = NULL;
    int ksize=3;
    PyObject* pyobj_scale = NULL;
    double scale=1;
    PyObject* pyobj_delta = NULL;
    double delta=0;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "ddepth", "dx", "dy", "dst", "ksize", "scale", "delta", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOOO:Sobel", (char**)keywords, &pyobj_src, &pyobj_ddepth, &pyobj_dx, &pyobj_dy, &pyobj_dst, &pyobj_ksize, &pyobj_scale, &pyobj_delta, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_ddepth, ddepth, ArgInfo("ddepth", 0)) &&
        pyopencv_to_safe(pyobj_dx, dx, ArgInfo("dx", 0)) &&
        pyopencv_to_safe(pyobj_dy, dy, ArgInfo("dy", 0)) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) &&
        pyopencv_to_safe(pyobj_scale, scale, ArgInfo("scale", 0)) &&
        pyopencv_to_safe(pyobj_delta, delta, ArgInfo("delta", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::Sobel(src, dst, ddepth, dx, dy, ksize, scale, delta, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("Sobel");

    return NULL;
}

static PyObject* pyopencv_cv_SparsePyrLKOpticalFlow_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_winSize = NULL;
    Size winSize=Size(21, 21);
    PyObject* pyobj_maxLevel = NULL;
    int maxLevel=3;
    PyObject* pyobj_crit = NULL;
    TermCriteria crit=TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, 0.01);
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_minEigThreshold = NULL;
    double minEigThreshold=1e-4;
    Ptr<SparsePyrLKOpticalFlow> retval;

    const char* keywords[] = { "winSize", "maxLevel", "crit", "flags", "minEigThreshold", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOO:SparsePyrLKOpticalFlow_create", (char**)keywords, &pyobj_winSize, &pyobj_maxLevel, &pyobj_crit, &pyobj_flags, &pyobj_minEigThreshold) &&
        pyopencv_to_safe(pyobj_winSize, winSize, ArgInfo("winSize", 0)) &&
        pyopencv_to_safe(pyobj_maxLevel, maxLevel, ArgInfo("maxLevel", 0)) &&
        pyopencv_to_safe(pyobj_crit, crit, ArgInfo("crit", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_minEigThreshold, minEigThreshold, ArgInfo("minEigThreshold", 0)) )
    {
        ERRWRAP2(retval = cv::SparsePyrLKOpticalFlow::create(winSize, maxLevel, crit, flags, minEigThreshold));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoBM_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_numDisparities = NULL;
    int numDisparities=0;
    PyObject* pyobj_blockSize = NULL;
    int blockSize=21;
    Ptr<StereoBM> retval;

    const char* keywords[] = { "numDisparities", "blockSize", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OO:StereoBM_create", (char**)keywords, &pyobj_numDisparities, &pyobj_blockSize) &&
        pyopencv_to_safe(pyobj_numDisparities, numDisparities, ArgInfo("numDisparities", 0)) &&
        pyopencv_to_safe(pyobj_blockSize, blockSize, ArgInfo("blockSize", 0)) )
    {
        ERRWRAP2(retval = cv::StereoBM::create(numDisparities, blockSize));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_StereoSGBM_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_minDisparity = NULL;
    int minDisparity=0;
    PyObject* pyobj_numDisparities = NULL;
    int numDisparities=16;
    PyObject* pyobj_blockSize = NULL;
    int blockSize=3;
    PyObject* pyobj_P1 = NULL;
    int P1=0;
    PyObject* pyobj_P2 = NULL;
    int P2=0;
    PyObject* pyobj_disp12MaxDiff = NULL;
    int disp12MaxDiff=0;
    PyObject* pyobj_preFilterCap = NULL;
    int preFilterCap=0;
    PyObject* pyobj_uniquenessRatio = NULL;
    int uniquenessRatio=0;
    PyObject* pyobj_speckleWindowSize = NULL;
    int speckleWindowSize=0;
    PyObject* pyobj_speckleRange = NULL;
    int speckleRange=0;
    PyObject* pyobj_mode = NULL;
    int mode=StereoSGBM::MODE_SGBM;
    Ptr<StereoSGBM> retval;

    const char* keywords[] = { "minDisparity", "numDisparities", "blockSize", "P1", "P2", "disp12MaxDiff", "preFilterCap", "uniquenessRatio", "speckleWindowSize", "speckleRange", "mode", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOOOOOOOO:StereoSGBM_create", (char**)keywords, &pyobj_minDisparity, &pyobj_numDisparities, &pyobj_blockSize, &pyobj_P1, &pyobj_P2, &pyobj_disp12MaxDiff, &pyobj_preFilterCap, &pyobj_uniquenessRatio, &pyobj_speckleWindowSize, &pyobj_speckleRange, &pyobj_mode) &&
        pyopencv_to_safe(pyobj_minDisparity, minDisparity, ArgInfo("minDisparity", 0)) &&
        pyopencv_to_safe(pyobj_numDisparities, numDisparities, ArgInfo("numDisparities", 0)) &&
        pyopencv_to_safe(pyobj_blockSize, blockSize, ArgInfo("blockSize", 0)) &&
        pyopencv_to_safe(pyobj_P1, P1, ArgInfo("P1", 0)) &&
        pyopencv_to_safe(pyobj_P2, P2, ArgInfo("P2", 0)) &&
        pyopencv_to_safe(pyobj_disp12MaxDiff, disp12MaxDiff, ArgInfo("disp12MaxDiff", 0)) &&
        pyopencv_to_safe(pyobj_preFilterCap, preFilterCap, ArgInfo("preFilterCap", 0)) &&
        pyopencv_to_safe(pyobj_uniquenessRatio, uniquenessRatio, ArgInfo("uniquenessRatio", 0)) &&
        pyopencv_to_safe(pyobj_speckleWindowSize, speckleWindowSize, ArgInfo("speckleWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_speckleRange, speckleRange, ArgInfo("speckleRange", 0)) &&
        pyopencv_to_safe(pyobj_mode, mode, ArgInfo("mode", 0)) )
    {
        ERRWRAP2(retval = cv::StereoSGBM::create(minDisparity, numDisparities, blockSize, P1, P2, disp12MaxDiff, preFilterCap, uniquenessRatio, speckleWindowSize, speckleRange, mode));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_Stitcher_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_mode = NULL;
    Mode mode=Stitcher::PANORAMA;
    Ptr<Stitcher> retval;

    const char* keywords[] = { "mode", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|O:Stitcher_create", (char**)keywords, &pyobj_mode) &&
        pyopencv_to_safe(pyobj_mode, mode, ArgInfo("mode", 0)) )
    {
        ERRWRAP2(retval = cv::Stitcher::create(mode));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_TrackerCSRT_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_parameters = NULL;
    TrackerCSRT_Params parameters=TrackerCSRT::Params();
    Ptr<TrackerCSRT> retval;

    const char* keywords[] = { "parameters", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|O:TrackerCSRT_create", (char**)keywords, &pyobj_parameters) &&
        pyopencv_to_safe(pyobj_parameters, parameters, ArgInfo("parameters", 0)) )
    {
        ERRWRAP2(retval = cv::TrackerCSRT::create(parameters));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_TrackerGOTURN_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_parameters = NULL;
    TrackerGOTURN_Params parameters=TrackerGOTURN::Params();
    Ptr<TrackerGOTURN> retval;

    const char* keywords[] = { "parameters", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|O:TrackerGOTURN_create", (char**)keywords, &pyobj_parameters) &&
        pyopencv_to_safe(pyobj_parameters, parameters, ArgInfo("parameters", 0)) )
    {
        ERRWRAP2(retval = cv::TrackerGOTURN::create(parameters));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_TrackerKCF_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_parameters = NULL;
    TrackerKCF_Params parameters=TrackerKCF::Params();
    Ptr<TrackerKCF> retval;

    const char* keywords[] = { "parameters", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|O:TrackerKCF_create", (char**)keywords, &pyobj_parameters) &&
        pyopencv_to_safe(pyobj_parameters, parameters, ArgInfo("parameters", 0)) )
    {
        ERRWRAP2(retval = cv::TrackerKCF::create(parameters));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_TrackerMIL_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_parameters = NULL;
    TrackerMIL_Params parameters=TrackerMIL::Params();
    Ptr<TrackerMIL> retval;

    const char* keywords[] = { "parameters", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|O:TrackerMIL_create", (char**)keywords, &pyobj_parameters) &&
        pyopencv_to_safe(pyobj_parameters, parameters, ArgInfo("parameters", 0)) )
    {
        ERRWRAP2(retval = cv::TrackerMIL::create(parameters));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_UMat_context(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    void* retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv_UMat_context());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_UMat_queue(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    void* retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv_UMat_queue());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_VariationalRefinement_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    Ptr<VariationalRefinement> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::VariationalRefinement::create());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_VideoWriter_fourcc(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_c1 = NULL;
    char c1;
    PyObject* pyobj_c2 = NULL;
    char c2;
    PyObject* pyobj_c3 = NULL;
    char c3;
    PyObject* pyobj_c4 = NULL;
    char c4;
    int retval;

    const char* keywords[] = { "c1", "c2", "c3", "c4", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO:VideoWriter_fourcc", (char**)keywords, &pyobj_c1, &pyobj_c2, &pyobj_c3, &pyobj_c4) &&
        convert_to_char(pyobj_c1, &c1, ArgInfo("c1", 0)) &&
        convert_to_char(pyobj_c2, &c2, ArgInfo("c2", 0)) &&
        convert_to_char(pyobj_c3, &c3, ArgInfo("c3", 0)) &&
        convert_to_char(pyobj_c4, &c4, ArgInfo("c4", 0)) )
    {
        ERRWRAP2(retval = cv::VideoWriter::fourcc(c1, c2, c3, c4));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_absdiff(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src1 = NULL;
    Mat src1;
    PyObject* pyobj_src2 = NULL;
    Mat src2;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src1", "src2", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:absdiff", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::absdiff(src1, src2, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src1 = NULL;
    UMat src1;
    PyObject* pyobj_src2 = NULL;
    UMat src2;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "src1", "src2", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:absdiff", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::absdiff(src1, src2, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("absdiff");

    return NULL;
}

static PyObject* pyopencv_cv_accumulate(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_mask = NULL;
    Mat mask;

    const char* keywords[] = { "src", "dst", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:accumulate", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::accumulate(src, dst, mask));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_mask = NULL;
    UMat mask;

    const char* keywords[] = { "src", "dst", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:accumulate", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::accumulate(src, dst, mask));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("accumulate");

    return NULL;
}

static PyObject* pyopencv_cv_accumulateProduct(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src1 = NULL;
    Mat src1;
    PyObject* pyobj_src2 = NULL;
    Mat src2;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_mask = NULL;
    Mat mask;

    const char* keywords[] = { "src1", "src2", "dst", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:accumulateProduct", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_dst, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::accumulateProduct(src1, src2, dst, mask));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src1 = NULL;
    UMat src1;
    PyObject* pyobj_src2 = NULL;
    UMat src2;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_mask = NULL;
    UMat mask;

    const char* keywords[] = { "src1", "src2", "dst", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:accumulateProduct", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_dst, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::accumulateProduct(src1, src2, dst, mask));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("accumulateProduct");

    return NULL;
}

static PyObject* pyopencv_cv_accumulateSquare(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_mask = NULL;
    Mat mask;

    const char* keywords[] = { "src", "dst", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:accumulateSquare", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::accumulateSquare(src, dst, mask));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_mask = NULL;
    UMat mask;

    const char* keywords[] = { "src", "dst", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:accumulateSquare", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::accumulateSquare(src, dst, mask));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("accumulateSquare");

    return NULL;
}

static PyObject* pyopencv_cv_accumulateWeighted(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_alpha = NULL;
    double alpha=0;
    PyObject* pyobj_mask = NULL;
    Mat mask;

    const char* keywords[] = { "src", "dst", "alpha", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:accumulateWeighted", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_alpha, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::accumulateWeighted(src, dst, alpha, mask));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_alpha = NULL;
    double alpha=0;
    PyObject* pyobj_mask = NULL;
    UMat mask;

    const char* keywords[] = { "src", "dst", "alpha", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:accumulateWeighted", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_alpha, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::accumulateWeighted(src, dst, alpha, mask));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("accumulateWeighted");

    return NULL;
}

static PyObject* pyopencv_cv_adaptiveThreshold(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_maxValue = NULL;
    double maxValue=0;
    PyObject* pyobj_adaptiveMethod = NULL;
    int adaptiveMethod=0;
    PyObject* pyobj_thresholdType = NULL;
    int thresholdType=0;
    PyObject* pyobj_blockSize = NULL;
    int blockSize=0;
    PyObject* pyobj_C = NULL;
    double C=0;

    const char* keywords[] = { "src", "maxValue", "adaptiveMethod", "thresholdType", "blockSize", "C", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|O:adaptiveThreshold", (char**)keywords, &pyobj_src, &pyobj_maxValue, &pyobj_adaptiveMethod, &pyobj_thresholdType, &pyobj_blockSize, &pyobj_C, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_maxValue, maxValue, ArgInfo("maxValue", 0)) &&
        pyopencv_to_safe(pyobj_adaptiveMethod, adaptiveMethod, ArgInfo("adaptiveMethod", 0)) &&
        pyopencv_to_safe(pyobj_thresholdType, thresholdType, ArgInfo("thresholdType", 0)) &&
        pyopencv_to_safe(pyobj_blockSize, blockSize, ArgInfo("blockSize", 0)) &&
        pyopencv_to_safe(pyobj_C, C, ArgInfo("C", 0)) )
    {
        ERRWRAP2(cv::adaptiveThreshold(src, dst, maxValue, adaptiveMethod, thresholdType, blockSize, C));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_maxValue = NULL;
    double maxValue=0;
    PyObject* pyobj_adaptiveMethod = NULL;
    int adaptiveMethod=0;
    PyObject* pyobj_thresholdType = NULL;
    int thresholdType=0;
    PyObject* pyobj_blockSize = NULL;
    int blockSize=0;
    PyObject* pyobj_C = NULL;
    double C=0;

    const char* keywords[] = { "src", "maxValue", "adaptiveMethod", "thresholdType", "blockSize", "C", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|O:adaptiveThreshold", (char**)keywords, &pyobj_src, &pyobj_maxValue, &pyobj_adaptiveMethod, &pyobj_thresholdType, &pyobj_blockSize, &pyobj_C, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_maxValue, maxValue, ArgInfo("maxValue", 0)) &&
        pyopencv_to_safe(pyobj_adaptiveMethod, adaptiveMethod, ArgInfo("adaptiveMethod", 0)) &&
        pyopencv_to_safe(pyobj_thresholdType, thresholdType, ArgInfo("thresholdType", 0)) &&
        pyopencv_to_safe(pyobj_blockSize, blockSize, ArgInfo("blockSize", 0)) &&
        pyopencv_to_safe(pyobj_C, C, ArgInfo("C", 0)) )
    {
        ERRWRAP2(cv::adaptiveThreshold(src, dst, maxValue, adaptiveMethod, thresholdType, blockSize, C));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("adaptiveThreshold");

    return NULL;
}

static PyObject* pyopencv_cv_add(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src1 = NULL;
    Mat src1;
    PyObject* pyobj_src2 = NULL;
    Mat src2;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_dtype = NULL;
    int dtype=-1;

    const char* keywords[] = { "src1", "src2", "dst", "mask", "dtype", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:add", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_dst, &pyobj_mask, &pyobj_dtype) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_dtype, dtype, ArgInfo("dtype", 0)) )
    {
        ERRWRAP2(cv::add(src1, src2, dst, mask, dtype));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src1 = NULL;
    UMat src1;
    PyObject* pyobj_src2 = NULL;
    UMat src2;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    PyObject* pyobj_dtype = NULL;
    int dtype=-1;

    const char* keywords[] = { "src1", "src2", "dst", "mask", "dtype", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:add", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_dst, &pyobj_mask, &pyobj_dtype) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_dtype, dtype, ArgInfo("dtype", 0)) )
    {
        ERRWRAP2(cv::add(src1, src2, dst, mask, dtype));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("add");

    return NULL;
}

static PyObject* pyopencv_cv_addText(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_text = NULL;
    String text;
    PyObject* pyobj_org = NULL;
    Point org;
    PyObject* pyobj_nameFont = NULL;
    String nameFont;
    PyObject* pyobj_pointSize = NULL;
    int pointSize=-1;
    PyObject* pyobj_color = NULL;
    Scalar color=Scalar::all(0);
    PyObject* pyobj_weight = NULL;
    int weight=QT_FONT_NORMAL;
    PyObject* pyobj_style = NULL;
    int style=QT_STYLE_NORMAL;
    PyObject* pyobj_spacing = NULL;
    int spacing=0;

    const char* keywords[] = { "img", "text", "org", "nameFont", "pointSize", "color", "weight", "style", "spacing", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOOO:addText", (char**)keywords, &pyobj_img, &pyobj_text, &pyobj_org, &pyobj_nameFont, &pyobj_pointSize, &pyobj_color, &pyobj_weight, &pyobj_style, &pyobj_spacing) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_text, text, ArgInfo("text", 0)) &&
        pyopencv_to_safe(pyobj_org, org, ArgInfo("org", 0)) &&
        pyopencv_to_safe(pyobj_nameFont, nameFont, ArgInfo("nameFont", 0)) &&
        pyopencv_to_safe(pyobj_pointSize, pointSize, ArgInfo("pointSize", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_weight, weight, ArgInfo("weight", 0)) &&
        pyopencv_to_safe(pyobj_style, style, ArgInfo("style", 0)) &&
        pyopencv_to_safe(pyobj_spacing, spacing, ArgInfo("spacing", 0)) )
    {
        ERRWRAP2(cv::addText(img, text, org, nameFont, pointSize, color, weight, style, spacing));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_text = NULL;
    String text;
    PyObject* pyobj_org = NULL;
    Point org;
    PyObject* pyobj_nameFont = NULL;
    String nameFont;
    PyObject* pyobj_pointSize = NULL;
    int pointSize=-1;
    PyObject* pyobj_color = NULL;
    Scalar color=Scalar::all(0);
    PyObject* pyobj_weight = NULL;
    int weight=QT_FONT_NORMAL;
    PyObject* pyobj_style = NULL;
    int style=QT_STYLE_NORMAL;
    PyObject* pyobj_spacing = NULL;
    int spacing=0;

    const char* keywords[] = { "img", "text", "org", "nameFont", "pointSize", "color", "weight", "style", "spacing", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOOO:addText", (char**)keywords, &pyobj_img, &pyobj_text, &pyobj_org, &pyobj_nameFont, &pyobj_pointSize, &pyobj_color, &pyobj_weight, &pyobj_style, &pyobj_spacing) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_text, text, ArgInfo("text", 0)) &&
        pyopencv_to_safe(pyobj_org, org, ArgInfo("org", 0)) &&
        pyopencv_to_safe(pyobj_nameFont, nameFont, ArgInfo("nameFont", 0)) &&
        pyopencv_to_safe(pyobj_pointSize, pointSize, ArgInfo("pointSize", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_weight, weight, ArgInfo("weight", 0)) &&
        pyopencv_to_safe(pyobj_style, style, ArgInfo("style", 0)) &&
        pyopencv_to_safe(pyobj_spacing, spacing, ArgInfo("spacing", 0)) )
    {
        ERRWRAP2(cv::addText(img, text, org, nameFont, pointSize, color, weight, style, spacing));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("addText");

    return NULL;
}

static PyObject* pyopencv_cv_addWeighted(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src1 = NULL;
    Mat src1;
    PyObject* pyobj_alpha = NULL;
    double alpha=0;
    PyObject* pyobj_src2 = NULL;
    Mat src2;
    PyObject* pyobj_beta = NULL;
    double beta=0;
    PyObject* pyobj_gamma = NULL;
    double gamma=0;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_dtype = NULL;
    int dtype=-1;

    const char* keywords[] = { "src1", "alpha", "src2", "beta", "gamma", "dst", "dtype", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OO:addWeighted", (char**)keywords, &pyobj_src1, &pyobj_alpha, &pyobj_src2, &pyobj_beta, &pyobj_gamma, &pyobj_dst, &pyobj_dtype) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_beta, beta, ArgInfo("beta", 0)) &&
        pyopencv_to_safe(pyobj_gamma, gamma, ArgInfo("gamma", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_dtype, dtype, ArgInfo("dtype", 0)) )
    {
        ERRWRAP2(cv::addWeighted(src1, alpha, src2, beta, gamma, dst, dtype));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src1 = NULL;
    UMat src1;
    PyObject* pyobj_alpha = NULL;
    double alpha=0;
    PyObject* pyobj_src2 = NULL;
    UMat src2;
    PyObject* pyobj_beta = NULL;
    double beta=0;
    PyObject* pyobj_gamma = NULL;
    double gamma=0;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_dtype = NULL;
    int dtype=-1;

    const char* keywords[] = { "src1", "alpha", "src2", "beta", "gamma", "dst", "dtype", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OO:addWeighted", (char**)keywords, &pyobj_src1, &pyobj_alpha, &pyobj_src2, &pyobj_beta, &pyobj_gamma, &pyobj_dst, &pyobj_dtype) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_beta, beta, ArgInfo("beta", 0)) &&
        pyopencv_to_safe(pyobj_gamma, gamma, ArgInfo("gamma", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_dtype, dtype, ArgInfo("dtype", 0)) )
    {
        ERRWRAP2(cv::addWeighted(src1, alpha, src2, beta, gamma, dst, dtype));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("addWeighted");

    return NULL;
}

static PyObject* pyopencv_cv_applyColorMap(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(4);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_colormap = NULL;
    int colormap=0;

    const char* keywords[] = { "src", "colormap", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:applyColorMap", (char**)keywords, &pyobj_src, &pyobj_colormap, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_colormap, colormap, ArgInfo("colormap", 0)) )
    {
        ERRWRAP2(cv::applyColorMap(src, dst, colormap));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_colormap = NULL;
    int colormap=0;

    const char* keywords[] = { "src", "colormap", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:applyColorMap", (char**)keywords, &pyobj_src, &pyobj_colormap, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_colormap, colormap, ArgInfo("colormap", 0)) )
    {
        ERRWRAP2(cv::applyColorMap(src, dst, colormap));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_userColor = NULL;
    Mat userColor;

    const char* keywords[] = { "src", "userColor", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:applyColorMap", (char**)keywords, &pyobj_src, &pyobj_userColor, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_userColor, userColor, ArgInfo("userColor", 0)) )
    {
        ERRWRAP2(cv::applyColorMap(src, dst, userColor));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_userColor = NULL;
    UMat userColor;

    const char* keywords[] = { "src", "userColor", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:applyColorMap", (char**)keywords, &pyobj_src, &pyobj_userColor, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_userColor, userColor, ArgInfo("userColor", 0)) )
    {
        ERRWRAP2(cv::applyColorMap(src, dst, userColor));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("applyColorMap");

    return NULL;
}

static PyObject* pyopencv_cv_approxPolyDP(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_curve = NULL;
    Mat curve;
    PyObject* pyobj_approxCurve = NULL;
    Mat approxCurve;
    PyObject* pyobj_epsilon = NULL;
    double epsilon=0;
    PyObject* pyobj_closed = NULL;
    bool closed=0;

    const char* keywords[] = { "curve", "epsilon", "closed", "approxCurve", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:approxPolyDP", (char**)keywords, &pyobj_curve, &pyobj_epsilon, &pyobj_closed, &pyobj_approxCurve) &&
        pyopencv_to_safe(pyobj_curve, curve, ArgInfo("curve", 0)) &&
        pyopencv_to_safe(pyobj_approxCurve, approxCurve, ArgInfo("approxCurve", 1)) &&
        pyopencv_to_safe(pyobj_epsilon, epsilon, ArgInfo("epsilon", 0)) &&
        pyopencv_to_safe(pyobj_closed, closed, ArgInfo("closed", 0)) )
    {
        ERRWRAP2(cv::approxPolyDP(curve, approxCurve, epsilon, closed));
        return pyopencv_from(approxCurve);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_curve = NULL;
    UMat curve;
    PyObject* pyobj_approxCurve = NULL;
    UMat approxCurve;
    PyObject* pyobj_epsilon = NULL;
    double epsilon=0;
    PyObject* pyobj_closed = NULL;
    bool closed=0;

    const char* keywords[] = { "curve", "epsilon", "closed", "approxCurve", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:approxPolyDP", (char**)keywords, &pyobj_curve, &pyobj_epsilon, &pyobj_closed, &pyobj_approxCurve) &&
        pyopencv_to_safe(pyobj_curve, curve, ArgInfo("curve", 0)) &&
        pyopencv_to_safe(pyobj_approxCurve, approxCurve, ArgInfo("approxCurve", 1)) &&
        pyopencv_to_safe(pyobj_epsilon, epsilon, ArgInfo("epsilon", 0)) &&
        pyopencv_to_safe(pyobj_closed, closed, ArgInfo("closed", 0)) )
    {
        ERRWRAP2(cv::approxPolyDP(curve, approxCurve, epsilon, closed));
        return pyopencv_from(approxCurve);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("approxPolyDP");

    return NULL;
}

static PyObject* pyopencv_cv_arcLength(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_curve = NULL;
    Mat curve;
    PyObject* pyobj_closed = NULL;
    bool closed=0;
    double retval;

    const char* keywords[] = { "curve", "closed", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:arcLength", (char**)keywords, &pyobj_curve, &pyobj_closed) &&
        pyopencv_to_safe(pyobj_curve, curve, ArgInfo("curve", 0)) &&
        pyopencv_to_safe(pyobj_closed, closed, ArgInfo("closed", 0)) )
    {
        ERRWRAP2(retval = cv::arcLength(curve, closed));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_curve = NULL;
    UMat curve;
    PyObject* pyobj_closed = NULL;
    bool closed=0;
    double retval;

    const char* keywords[] = { "curve", "closed", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:arcLength", (char**)keywords, &pyobj_curve, &pyobj_closed) &&
        pyopencv_to_safe(pyobj_curve, curve, ArgInfo("curve", 0)) &&
        pyopencv_to_safe(pyobj_closed, closed, ArgInfo("closed", 0)) )
    {
        ERRWRAP2(retval = cv::arcLength(curve, closed));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("arcLength");

    return NULL;
}

static PyObject* pyopencv_cv_arrowedLine(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_pt1 = NULL;
    Point pt1;
    PyObject* pyobj_pt2 = NULL;
    Point pt2;
    PyObject* pyobj_color = NULL;
    Scalar color;
    PyObject* pyobj_thickness = NULL;
    int thickness=1;
    PyObject* pyobj_line_type = NULL;
    int line_type=8;
    PyObject* pyobj_shift = NULL;
    int shift=0;
    PyObject* pyobj_tipLength = NULL;
    double tipLength=0.1;

    const char* keywords[] = { "img", "pt1", "pt2", "color", "thickness", "line_type", "shift", "tipLength", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOO:arrowedLine", (char**)keywords, &pyobj_img, &pyobj_pt1, &pyobj_pt2, &pyobj_color, &pyobj_thickness, &pyobj_line_type, &pyobj_shift, &pyobj_tipLength) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_pt1, pt1, ArgInfo("pt1", 0)) &&
        pyopencv_to_safe(pyobj_pt2, pt2, ArgInfo("pt2", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_thickness, thickness, ArgInfo("thickness", 0)) &&
        pyopencv_to_safe(pyobj_line_type, line_type, ArgInfo("line_type", 0)) &&
        pyopencv_to_safe(pyobj_shift, shift, ArgInfo("shift", 0)) &&
        pyopencv_to_safe(pyobj_tipLength, tipLength, ArgInfo("tipLength", 0)) )
    {
        ERRWRAP2(cv::arrowedLine(img, pt1, pt2, color, thickness, line_type, shift, tipLength));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_pt1 = NULL;
    Point pt1;
    PyObject* pyobj_pt2 = NULL;
    Point pt2;
    PyObject* pyobj_color = NULL;
    Scalar color;
    PyObject* pyobj_thickness = NULL;
    int thickness=1;
    PyObject* pyobj_line_type = NULL;
    int line_type=8;
    PyObject* pyobj_shift = NULL;
    int shift=0;
    PyObject* pyobj_tipLength = NULL;
    double tipLength=0.1;

    const char* keywords[] = { "img", "pt1", "pt2", "color", "thickness", "line_type", "shift", "tipLength", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOO:arrowedLine", (char**)keywords, &pyobj_img, &pyobj_pt1, &pyobj_pt2, &pyobj_color, &pyobj_thickness, &pyobj_line_type, &pyobj_shift, &pyobj_tipLength) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_pt1, pt1, ArgInfo("pt1", 0)) &&
        pyopencv_to_safe(pyobj_pt2, pt2, ArgInfo("pt2", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_thickness, thickness, ArgInfo("thickness", 0)) &&
        pyopencv_to_safe(pyobj_line_type, line_type, ArgInfo("line_type", 0)) &&
        pyopencv_to_safe(pyobj_shift, shift, ArgInfo("shift", 0)) &&
        pyopencv_to_safe(pyobj_tipLength, tipLength, ArgInfo("tipLength", 0)) )
    {
        ERRWRAP2(cv::arrowedLine(img, pt1, pt2, color, thickness, line_type, shift, tipLength));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("arrowedLine");

    return NULL;
}

static PyObject* pyopencv_cv_batchDistance(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src1 = NULL;
    Mat src1;
    PyObject* pyobj_src2 = NULL;
    Mat src2;
    PyObject* pyobj_dist = NULL;
    Mat dist;
    PyObject* pyobj_dtype = NULL;
    int dtype=0;
    PyObject* pyobj_nidx = NULL;
    Mat nidx;
    PyObject* pyobj_normType = NULL;
    int normType=NORM_L2;
    PyObject* pyobj_K = NULL;
    int K=0;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_update = NULL;
    int update=0;
    PyObject* pyobj_crosscheck = NULL;
    bool crosscheck=false;

    const char* keywords[] = { "src1", "src2", "dtype", "dist", "nidx", "normType", "K", "mask", "update", "crosscheck", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOOOOO:batchDistance", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_dtype, &pyobj_dist, &pyobj_nidx, &pyobj_normType, &pyobj_K, &pyobj_mask, &pyobj_update, &pyobj_crosscheck) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dist, dist, ArgInfo("dist", 1)) &&
        pyopencv_to_safe(pyobj_dtype, dtype, ArgInfo("dtype", 0)) &&
        pyopencv_to_safe(pyobj_nidx, nidx, ArgInfo("nidx", 1)) &&
        pyopencv_to_safe(pyobj_normType, normType, ArgInfo("normType", 0)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_update, update, ArgInfo("update", 0)) &&
        pyopencv_to_safe(pyobj_crosscheck, crosscheck, ArgInfo("crosscheck", 0)) )
    {
        ERRWRAP2(cv::batchDistance(src1, src2, dist, dtype, nidx, normType, K, mask, update, crosscheck));
        return Py_BuildValue("(NN)", pyopencv_from(dist), pyopencv_from(nidx));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src1 = NULL;
    UMat src1;
    PyObject* pyobj_src2 = NULL;
    UMat src2;
    PyObject* pyobj_dist = NULL;
    UMat dist;
    PyObject* pyobj_dtype = NULL;
    int dtype=0;
    PyObject* pyobj_nidx = NULL;
    UMat nidx;
    PyObject* pyobj_normType = NULL;
    int normType=NORM_L2;
    PyObject* pyobj_K = NULL;
    int K=0;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    PyObject* pyobj_update = NULL;
    int update=0;
    PyObject* pyobj_crosscheck = NULL;
    bool crosscheck=false;

    const char* keywords[] = { "src1", "src2", "dtype", "dist", "nidx", "normType", "K", "mask", "update", "crosscheck", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOOOOO:batchDistance", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_dtype, &pyobj_dist, &pyobj_nidx, &pyobj_normType, &pyobj_K, &pyobj_mask, &pyobj_update, &pyobj_crosscheck) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dist, dist, ArgInfo("dist", 1)) &&
        pyopencv_to_safe(pyobj_dtype, dtype, ArgInfo("dtype", 0)) &&
        pyopencv_to_safe(pyobj_nidx, nidx, ArgInfo("nidx", 1)) &&
        pyopencv_to_safe(pyobj_normType, normType, ArgInfo("normType", 0)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_update, update, ArgInfo("update", 0)) &&
        pyopencv_to_safe(pyobj_crosscheck, crosscheck, ArgInfo("crosscheck", 0)) )
    {
        ERRWRAP2(cv::batchDistance(src1, src2, dist, dtype, nidx, normType, K, mask, update, crosscheck));
        return Py_BuildValue("(NN)", pyopencv_from(dist), pyopencv_from(nidx));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("batchDistance");

    return NULL;
}

static PyObject* pyopencv_cv_bilateralFilter(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_d = NULL;
    int d=0;
    PyObject* pyobj_sigmaColor = NULL;
    double sigmaColor=0;
    PyObject* pyobj_sigmaSpace = NULL;
    double sigmaSpace=0;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "d", "sigmaColor", "sigmaSpace", "dst", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OO:bilateralFilter", (char**)keywords, &pyobj_src, &pyobj_d, &pyobj_sigmaColor, &pyobj_sigmaSpace, &pyobj_dst, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_d, d, ArgInfo("d", 0)) &&
        pyopencv_to_safe(pyobj_sigmaColor, sigmaColor, ArgInfo("sigmaColor", 0)) &&
        pyopencv_to_safe(pyobj_sigmaSpace, sigmaSpace, ArgInfo("sigmaSpace", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::bilateralFilter(src, dst, d, sigmaColor, sigmaSpace, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_d = NULL;
    int d=0;
    PyObject* pyobj_sigmaColor = NULL;
    double sigmaColor=0;
    PyObject* pyobj_sigmaSpace = NULL;
    double sigmaSpace=0;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "d", "sigmaColor", "sigmaSpace", "dst", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OO:bilateralFilter", (char**)keywords, &pyobj_src, &pyobj_d, &pyobj_sigmaColor, &pyobj_sigmaSpace, &pyobj_dst, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_d, d, ArgInfo("d", 0)) &&
        pyopencv_to_safe(pyobj_sigmaColor, sigmaColor, ArgInfo("sigmaColor", 0)) &&
        pyopencv_to_safe(pyobj_sigmaSpace, sigmaSpace, ArgInfo("sigmaSpace", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::bilateralFilter(src, dst, d, sigmaColor, sigmaSpace, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("bilateralFilter");

    return NULL;
}

static PyObject* pyopencv_cv_bitwise_and(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src1 = NULL;
    Mat src1;
    PyObject* pyobj_src2 = NULL;
    Mat src2;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_mask = NULL;
    Mat mask;

    const char* keywords[] = { "src1", "src2", "dst", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:bitwise_and", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_dst, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::bitwise_and(src1, src2, dst, mask));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src1 = NULL;
    UMat src1;
    PyObject* pyobj_src2 = NULL;
    UMat src2;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_mask = NULL;
    UMat mask;

    const char* keywords[] = { "src1", "src2", "dst", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:bitwise_and", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_dst, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::bitwise_and(src1, src2, dst, mask));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("bitwise_and");

    return NULL;
}

static PyObject* pyopencv_cv_bitwise_not(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_mask = NULL;
    Mat mask;

    const char* keywords[] = { "src", "dst", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:bitwise_not", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::bitwise_not(src, dst, mask));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_mask = NULL;
    UMat mask;

    const char* keywords[] = { "src", "dst", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:bitwise_not", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::bitwise_not(src, dst, mask));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("bitwise_not");

    return NULL;
}

static PyObject* pyopencv_cv_bitwise_or(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src1 = NULL;
    Mat src1;
    PyObject* pyobj_src2 = NULL;
    Mat src2;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_mask = NULL;
    Mat mask;

    const char* keywords[] = { "src1", "src2", "dst", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:bitwise_or", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_dst, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::bitwise_or(src1, src2, dst, mask));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src1 = NULL;
    UMat src1;
    PyObject* pyobj_src2 = NULL;
    UMat src2;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_mask = NULL;
    UMat mask;

    const char* keywords[] = { "src1", "src2", "dst", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:bitwise_or", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_dst, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::bitwise_or(src1, src2, dst, mask));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("bitwise_or");

    return NULL;
}

static PyObject* pyopencv_cv_bitwise_xor(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src1 = NULL;
    Mat src1;
    PyObject* pyobj_src2 = NULL;
    Mat src2;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_mask = NULL;
    Mat mask;

    const char* keywords[] = { "src1", "src2", "dst", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:bitwise_xor", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_dst, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::bitwise_xor(src1, src2, dst, mask));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src1 = NULL;
    UMat src1;
    PyObject* pyobj_src2 = NULL;
    UMat src2;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_mask = NULL;
    UMat mask;

    const char* keywords[] = { "src1", "src2", "dst", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:bitwise_xor", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_dst, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::bitwise_xor(src1, src2, dst, mask));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("bitwise_xor");

    return NULL;
}

static PyObject* pyopencv_cv_blendLinear(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src1 = NULL;
    Mat src1;
    PyObject* pyobj_src2 = NULL;
    Mat src2;
    PyObject* pyobj_weights1 = NULL;
    Mat weights1;
    PyObject* pyobj_weights2 = NULL;
    Mat weights2;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src1", "src2", "weights1", "weights2", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:blendLinear", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_weights1, &pyobj_weights2, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_weights1, weights1, ArgInfo("weights1", 0)) &&
        pyopencv_to_safe(pyobj_weights2, weights2, ArgInfo("weights2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::blendLinear(src1, src2, weights1, weights2, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src1 = NULL;
    UMat src1;
    PyObject* pyobj_src2 = NULL;
    UMat src2;
    PyObject* pyobj_weights1 = NULL;
    UMat weights1;
    PyObject* pyobj_weights2 = NULL;
    UMat weights2;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "src1", "src2", "weights1", "weights2", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:blendLinear", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_weights1, &pyobj_weights2, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_weights1, weights1, ArgInfo("weights1", 0)) &&
        pyopencv_to_safe(pyobj_weights2, weights2, ArgInfo("weights2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::blendLinear(src1, src2, weights1, weights2, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("blendLinear");

    return NULL;
}

static PyObject* pyopencv_cv_blur(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_ksize = NULL;
    Size ksize;
    PyObject* pyobj_anchor = NULL;
    Point anchor=Point(-1,-1);
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "ksize", "dst", "anchor", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:blur", (char**)keywords, &pyobj_src, &pyobj_ksize, &pyobj_dst, &pyobj_anchor, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) &&
        pyopencv_to_safe(pyobj_anchor, anchor, ArgInfo("anchor", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::blur(src, dst, ksize, anchor, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_ksize = NULL;
    Size ksize;
    PyObject* pyobj_anchor = NULL;
    Point anchor=Point(-1,-1);
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "ksize", "dst", "anchor", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:blur", (char**)keywords, &pyobj_src, &pyobj_ksize, &pyobj_dst, &pyobj_anchor, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) &&
        pyopencv_to_safe(pyobj_anchor, anchor, ArgInfo("anchor", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::blur(src, dst, ksize, anchor, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("blur");

    return NULL;
}

static PyObject* pyopencv_cv_borderInterpolate(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_p = NULL;
    int p=0;
    PyObject* pyobj_len = NULL;
    int len=0;
    PyObject* pyobj_borderType = NULL;
    int borderType=0;
    int retval;

    const char* keywords[] = { "p", "len", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:borderInterpolate", (char**)keywords, &pyobj_p, &pyobj_len, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_p, p, ArgInfo("p", 0)) &&
        pyopencv_to_safe(pyobj_len, len, ArgInfo("len", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(retval = cv::borderInterpolate(p, len, borderType));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_boundingRect(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_array = NULL;
    Mat array;
    Rect retval;

    const char* keywords[] = { "array", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:boundingRect", (char**)keywords, &pyobj_array) &&
        pyopencv_to_safe(pyobj_array, array, ArgInfo("array", 0)) )
    {
        ERRWRAP2(retval = cv::boundingRect(array));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_array = NULL;
    UMat array;
    Rect retval;

    const char* keywords[] = { "array", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:boundingRect", (char**)keywords, &pyobj_array) &&
        pyopencv_to_safe(pyobj_array, array, ArgInfo("array", 0)) )
    {
        ERRWRAP2(retval = cv::boundingRect(array));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("boundingRect");

    return NULL;
}

static PyObject* pyopencv_cv_boxFilter(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_ddepth = NULL;
    int ddepth=0;
    PyObject* pyobj_ksize = NULL;
    Size ksize;
    PyObject* pyobj_anchor = NULL;
    Point anchor=Point(-1,-1);
    PyObject* pyobj_normalize = NULL;
    bool normalize=true;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "ddepth", "ksize", "dst", "anchor", "normalize", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOO:boxFilter", (char**)keywords, &pyobj_src, &pyobj_ddepth, &pyobj_ksize, &pyobj_dst, &pyobj_anchor, &pyobj_normalize, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_ddepth, ddepth, ArgInfo("ddepth", 0)) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) &&
        pyopencv_to_safe(pyobj_anchor, anchor, ArgInfo("anchor", 0)) &&
        pyopencv_to_safe(pyobj_normalize, normalize, ArgInfo("normalize", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::boxFilter(src, dst, ddepth, ksize, anchor, normalize, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_ddepth = NULL;
    int ddepth=0;
    PyObject* pyobj_ksize = NULL;
    Size ksize;
    PyObject* pyobj_anchor = NULL;
    Point anchor=Point(-1,-1);
    PyObject* pyobj_normalize = NULL;
    bool normalize=true;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "ddepth", "ksize", "dst", "anchor", "normalize", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOO:boxFilter", (char**)keywords, &pyobj_src, &pyobj_ddepth, &pyobj_ksize, &pyobj_dst, &pyobj_anchor, &pyobj_normalize, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_ddepth, ddepth, ArgInfo("ddepth", 0)) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) &&
        pyopencv_to_safe(pyobj_anchor, anchor, ArgInfo("anchor", 0)) &&
        pyopencv_to_safe(pyobj_normalize, normalize, ArgInfo("normalize", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::boxFilter(src, dst, ddepth, ksize, anchor, normalize, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("boxFilter");

    return NULL;
}

static PyObject* pyopencv_cv_boxPoints(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_box = NULL;
    RotatedRect box;
    PyObject* pyobj_points = NULL;
    Mat points;

    const char* keywords[] = { "box", "points", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:boxPoints", (char**)keywords, &pyobj_box, &pyobj_points) &&
        pyopencv_to_safe(pyobj_box, box, ArgInfo("box", 0)) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 1)) )
    {
        ERRWRAP2(cv::boxPoints(box, points));
        return pyopencv_from(points);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_box = NULL;
    RotatedRect box;
    PyObject* pyobj_points = NULL;
    UMat points;

    const char* keywords[] = { "box", "points", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:boxPoints", (char**)keywords, &pyobj_box, &pyobj_points) &&
        pyopencv_to_safe(pyobj_box, box, ArgInfo("box", 0)) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 1)) )
    {
        ERRWRAP2(cv::boxPoints(box, points));
        return pyopencv_from(points);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("boxPoints");

    return NULL;
}

static PyObject* pyopencv_cv_buildOpticalFlowPyramid(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_pyramid = NULL;
    vector_Mat pyramid;
    PyObject* pyobj_winSize = NULL;
    Size winSize;
    PyObject* pyobj_maxLevel = NULL;
    int maxLevel=0;
    PyObject* pyobj_withDerivatives = NULL;
    bool withDerivatives=true;
    PyObject* pyobj_pyrBorder = NULL;
    int pyrBorder=BORDER_REFLECT_101;
    PyObject* pyobj_derivBorder = NULL;
    int derivBorder=BORDER_CONSTANT;
    PyObject* pyobj_tryReuseInputImage = NULL;
    bool tryReuseInputImage=true;
    int retval;

    const char* keywords[] = { "img", "winSize", "maxLevel", "pyramid", "withDerivatives", "pyrBorder", "derivBorder", "tryReuseInputImage", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOOO:buildOpticalFlowPyramid", (char**)keywords, &pyobj_img, &pyobj_winSize, &pyobj_maxLevel, &pyobj_pyramid, &pyobj_withDerivatives, &pyobj_pyrBorder, &pyobj_derivBorder, &pyobj_tryReuseInputImage) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_pyramid, pyramid, ArgInfo("pyramid", 1)) &&
        pyopencv_to_safe(pyobj_winSize, winSize, ArgInfo("winSize", 0)) &&
        pyopencv_to_safe(pyobj_maxLevel, maxLevel, ArgInfo("maxLevel", 0)) &&
        pyopencv_to_safe(pyobj_withDerivatives, withDerivatives, ArgInfo("withDerivatives", 0)) &&
        pyopencv_to_safe(pyobj_pyrBorder, pyrBorder, ArgInfo("pyrBorder", 0)) &&
        pyopencv_to_safe(pyobj_derivBorder, derivBorder, ArgInfo("derivBorder", 0)) &&
        pyopencv_to_safe(pyobj_tryReuseInputImage, tryReuseInputImage, ArgInfo("tryReuseInputImage", 0)) )
    {
        ERRWRAP2(retval = cv::buildOpticalFlowPyramid(img, pyramid, winSize, maxLevel, withDerivatives, pyrBorder, derivBorder, tryReuseInputImage));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(pyramid));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_pyramid = NULL;
    vector_UMat pyramid;
    PyObject* pyobj_winSize = NULL;
    Size winSize;
    PyObject* pyobj_maxLevel = NULL;
    int maxLevel=0;
    PyObject* pyobj_withDerivatives = NULL;
    bool withDerivatives=true;
    PyObject* pyobj_pyrBorder = NULL;
    int pyrBorder=BORDER_REFLECT_101;
    PyObject* pyobj_derivBorder = NULL;
    int derivBorder=BORDER_CONSTANT;
    PyObject* pyobj_tryReuseInputImage = NULL;
    bool tryReuseInputImage=true;
    int retval;

    const char* keywords[] = { "img", "winSize", "maxLevel", "pyramid", "withDerivatives", "pyrBorder", "derivBorder", "tryReuseInputImage", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOOO:buildOpticalFlowPyramid", (char**)keywords, &pyobj_img, &pyobj_winSize, &pyobj_maxLevel, &pyobj_pyramid, &pyobj_withDerivatives, &pyobj_pyrBorder, &pyobj_derivBorder, &pyobj_tryReuseInputImage) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_pyramid, pyramid, ArgInfo("pyramid", 1)) &&
        pyopencv_to_safe(pyobj_winSize, winSize, ArgInfo("winSize", 0)) &&
        pyopencv_to_safe(pyobj_maxLevel, maxLevel, ArgInfo("maxLevel", 0)) &&
        pyopencv_to_safe(pyobj_withDerivatives, withDerivatives, ArgInfo("withDerivatives", 0)) &&
        pyopencv_to_safe(pyobj_pyrBorder, pyrBorder, ArgInfo("pyrBorder", 0)) &&
        pyopencv_to_safe(pyobj_derivBorder, derivBorder, ArgInfo("derivBorder", 0)) &&
        pyopencv_to_safe(pyobj_tryReuseInputImage, tryReuseInputImage, ArgInfo("tryReuseInputImage", 0)) )
    {
        ERRWRAP2(retval = cv::buildOpticalFlowPyramid(img, pyramid, winSize, maxLevel, withDerivatives, pyrBorder, derivBorder, tryReuseInputImage));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(pyramid));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("buildOpticalFlowPyramid");

    return NULL;
}

static PyObject* pyopencv_cv_calcBackProject(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_images = NULL;
    vector_Mat images;
    PyObject* pyobj_channels = NULL;
    vector_int channels;
    PyObject* pyobj_hist = NULL;
    Mat hist;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_ranges = NULL;
    vector_float ranges;
    PyObject* pyobj_scale = NULL;
    double scale=0;

    const char* keywords[] = { "images", "channels", "hist", "ranges", "scale", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|O:calcBackProject", (char**)keywords, &pyobj_images, &pyobj_channels, &pyobj_hist, &pyobj_ranges, &pyobj_scale, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_images, images, ArgInfo("images", 0)) &&
        pyopencv_to_safe(pyobj_channels, channels, ArgInfo("channels", 0)) &&
        pyopencv_to_safe(pyobj_hist, hist, ArgInfo("hist", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_ranges, ranges, ArgInfo("ranges", 0)) &&
        pyopencv_to_safe(pyobj_scale, scale, ArgInfo("scale", 0)) )
    {
        ERRWRAP2(cv::calcBackProject(images, channels, hist, dst, ranges, scale));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_images = NULL;
    vector_UMat images;
    PyObject* pyobj_channels = NULL;
    vector_int channels;
    PyObject* pyobj_hist = NULL;
    UMat hist;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_ranges = NULL;
    vector_float ranges;
    PyObject* pyobj_scale = NULL;
    double scale=0;

    const char* keywords[] = { "images", "channels", "hist", "ranges", "scale", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|O:calcBackProject", (char**)keywords, &pyobj_images, &pyobj_channels, &pyobj_hist, &pyobj_ranges, &pyobj_scale, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_images, images, ArgInfo("images", 0)) &&
        pyopencv_to_safe(pyobj_channels, channels, ArgInfo("channels", 0)) &&
        pyopencv_to_safe(pyobj_hist, hist, ArgInfo("hist", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_ranges, ranges, ArgInfo("ranges", 0)) &&
        pyopencv_to_safe(pyobj_scale, scale, ArgInfo("scale", 0)) )
    {
        ERRWRAP2(cv::calcBackProject(images, channels, hist, dst, ranges, scale));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("calcBackProject");

    return NULL;
}

static PyObject* pyopencv_cv_calcCovarMatrix(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_samples = NULL;
    Mat samples;
    PyObject* pyobj_covar = NULL;
    Mat covar;
    PyObject* pyobj_mean = NULL;
    Mat mean;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_ctype = NULL;
    int ctype=CV_64F;

    const char* keywords[] = { "samples", "mean", "flags", "covar", "ctype", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:calcCovarMatrix", (char**)keywords, &pyobj_samples, &pyobj_mean, &pyobj_flags, &pyobj_covar, &pyobj_ctype) &&
        pyopencv_to_safe(pyobj_samples, samples, ArgInfo("samples", 0)) &&
        pyopencv_to_safe(pyobj_covar, covar, ArgInfo("covar", 1)) &&
        pyopencv_to_safe(pyobj_mean, mean, ArgInfo("mean", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_ctype, ctype, ArgInfo("ctype", 0)) )
    {
        ERRWRAP2(cv::calcCovarMatrix(samples, covar, mean, flags, ctype));
        return Py_BuildValue("(NN)", pyopencv_from(covar), pyopencv_from(mean));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_samples = NULL;
    UMat samples;
    PyObject* pyobj_covar = NULL;
    UMat covar;
    PyObject* pyobj_mean = NULL;
    UMat mean;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_ctype = NULL;
    int ctype=CV_64F;

    const char* keywords[] = { "samples", "mean", "flags", "covar", "ctype", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:calcCovarMatrix", (char**)keywords, &pyobj_samples, &pyobj_mean, &pyobj_flags, &pyobj_covar, &pyobj_ctype) &&
        pyopencv_to_safe(pyobj_samples, samples, ArgInfo("samples", 0)) &&
        pyopencv_to_safe(pyobj_covar, covar, ArgInfo("covar", 1)) &&
        pyopencv_to_safe(pyobj_mean, mean, ArgInfo("mean", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_ctype, ctype, ArgInfo("ctype", 0)) )
    {
        ERRWRAP2(cv::calcCovarMatrix(samples, covar, mean, flags, ctype));
        return Py_BuildValue("(NN)", pyopencv_from(covar), pyopencv_from(mean));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("calcCovarMatrix");

    return NULL;
}

static PyObject* pyopencv_cv_calcHist(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_images = NULL;
    vector_Mat images;
    PyObject* pyobj_channels = NULL;
    vector_int channels;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_hist = NULL;
    Mat hist;
    PyObject* pyobj_histSize = NULL;
    vector_int histSize;
    PyObject* pyobj_ranges = NULL;
    vector_float ranges;
    PyObject* pyobj_accumulate = NULL;
    bool accumulate=false;

    const char* keywords[] = { "images", "channels", "mask", "histSize", "ranges", "hist", "accumulate", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OO:calcHist", (char**)keywords, &pyobj_images, &pyobj_channels, &pyobj_mask, &pyobj_histSize, &pyobj_ranges, &pyobj_hist, &pyobj_accumulate) &&
        pyopencv_to_safe(pyobj_images, images, ArgInfo("images", 0)) &&
        pyopencv_to_safe(pyobj_channels, channels, ArgInfo("channels", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_hist, hist, ArgInfo("hist", 1)) &&
        pyopencv_to_safe(pyobj_histSize, histSize, ArgInfo("histSize", 0)) &&
        pyopencv_to_safe(pyobj_ranges, ranges, ArgInfo("ranges", 0)) &&
        pyopencv_to_safe(pyobj_accumulate, accumulate, ArgInfo("accumulate", 0)) )
    {
        ERRWRAP2(cv::calcHist(images, channels, mask, hist, histSize, ranges, accumulate));
        return pyopencv_from(hist);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_images = NULL;
    vector_UMat images;
    PyObject* pyobj_channels = NULL;
    vector_int channels;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    PyObject* pyobj_hist = NULL;
    UMat hist;
    PyObject* pyobj_histSize = NULL;
    vector_int histSize;
    PyObject* pyobj_ranges = NULL;
    vector_float ranges;
    PyObject* pyobj_accumulate = NULL;
    bool accumulate=false;

    const char* keywords[] = { "images", "channels", "mask", "histSize", "ranges", "hist", "accumulate", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OO:calcHist", (char**)keywords, &pyobj_images, &pyobj_channels, &pyobj_mask, &pyobj_histSize, &pyobj_ranges, &pyobj_hist, &pyobj_accumulate) &&
        pyopencv_to_safe(pyobj_images, images, ArgInfo("images", 0)) &&
        pyopencv_to_safe(pyobj_channels, channels, ArgInfo("channels", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_hist, hist, ArgInfo("hist", 1)) &&
        pyopencv_to_safe(pyobj_histSize, histSize, ArgInfo("histSize", 0)) &&
        pyopencv_to_safe(pyobj_ranges, ranges, ArgInfo("ranges", 0)) &&
        pyopencv_to_safe(pyobj_accumulate, accumulate, ArgInfo("accumulate", 0)) )
    {
        ERRWRAP2(cv::calcHist(images, channels, mask, hist, histSize, ranges, accumulate));
        return pyopencv_from(hist);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("calcHist");

    return NULL;
}

static PyObject* pyopencv_cv_calcOpticalFlowFarneback(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_prev = NULL;
    Mat prev;
    PyObject* pyobj_next = NULL;
    Mat next;
    PyObject* pyobj_flow = NULL;
    Mat flow;
    PyObject* pyobj_pyr_scale = NULL;
    double pyr_scale=0;
    PyObject* pyobj_levels = NULL;
    int levels=0;
    PyObject* pyobj_winsize = NULL;
    int winsize=0;
    PyObject* pyobj_iterations = NULL;
    int iterations=0;
    PyObject* pyobj_poly_n = NULL;
    int poly_n=0;
    PyObject* pyobj_poly_sigma = NULL;
    double poly_sigma=0;
    PyObject* pyobj_flags = NULL;
    int flags=0;

    const char* keywords[] = { "prev", "next", "flow", "pyr_scale", "levels", "winsize", "iterations", "poly_n", "poly_sigma", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOOOOO:calcOpticalFlowFarneback", (char**)keywords, &pyobj_prev, &pyobj_next, &pyobj_flow, &pyobj_pyr_scale, &pyobj_levels, &pyobj_winsize, &pyobj_iterations, &pyobj_poly_n, &pyobj_poly_sigma, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_prev, prev, ArgInfo("prev", 0)) &&
        pyopencv_to_safe(pyobj_next, next, ArgInfo("next", 0)) &&
        pyopencv_to_safe(pyobj_flow, flow, ArgInfo("flow", 1)) &&
        pyopencv_to_safe(pyobj_pyr_scale, pyr_scale, ArgInfo("pyr_scale", 0)) &&
        pyopencv_to_safe(pyobj_levels, levels, ArgInfo("levels", 0)) &&
        pyopencv_to_safe(pyobj_winsize, winsize, ArgInfo("winsize", 0)) &&
        pyopencv_to_safe(pyobj_iterations, iterations, ArgInfo("iterations", 0)) &&
        pyopencv_to_safe(pyobj_poly_n, poly_n, ArgInfo("poly_n", 0)) &&
        pyopencv_to_safe(pyobj_poly_sigma, poly_sigma, ArgInfo("poly_sigma", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::calcOpticalFlowFarneback(prev, next, flow, pyr_scale, levels, winsize, iterations, poly_n, poly_sigma, flags));
        return pyopencv_from(flow);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_prev = NULL;
    UMat prev;
    PyObject* pyobj_next = NULL;
    UMat next;
    PyObject* pyobj_flow = NULL;
    UMat flow;
    PyObject* pyobj_pyr_scale = NULL;
    double pyr_scale=0;
    PyObject* pyobj_levels = NULL;
    int levels=0;
    PyObject* pyobj_winsize = NULL;
    int winsize=0;
    PyObject* pyobj_iterations = NULL;
    int iterations=0;
    PyObject* pyobj_poly_n = NULL;
    int poly_n=0;
    PyObject* pyobj_poly_sigma = NULL;
    double poly_sigma=0;
    PyObject* pyobj_flags = NULL;
    int flags=0;

    const char* keywords[] = { "prev", "next", "flow", "pyr_scale", "levels", "winsize", "iterations", "poly_n", "poly_sigma", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOOOOO:calcOpticalFlowFarneback", (char**)keywords, &pyobj_prev, &pyobj_next, &pyobj_flow, &pyobj_pyr_scale, &pyobj_levels, &pyobj_winsize, &pyobj_iterations, &pyobj_poly_n, &pyobj_poly_sigma, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_prev, prev, ArgInfo("prev", 0)) &&
        pyopencv_to_safe(pyobj_next, next, ArgInfo("next", 0)) &&
        pyopencv_to_safe(pyobj_flow, flow, ArgInfo("flow", 1)) &&
        pyopencv_to_safe(pyobj_pyr_scale, pyr_scale, ArgInfo("pyr_scale", 0)) &&
        pyopencv_to_safe(pyobj_levels, levels, ArgInfo("levels", 0)) &&
        pyopencv_to_safe(pyobj_winsize, winsize, ArgInfo("winsize", 0)) &&
        pyopencv_to_safe(pyobj_iterations, iterations, ArgInfo("iterations", 0)) &&
        pyopencv_to_safe(pyobj_poly_n, poly_n, ArgInfo("poly_n", 0)) &&
        pyopencv_to_safe(pyobj_poly_sigma, poly_sigma, ArgInfo("poly_sigma", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::calcOpticalFlowFarneback(prev, next, flow, pyr_scale, levels, winsize, iterations, poly_n, poly_sigma, flags));
        return pyopencv_from(flow);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("calcOpticalFlowFarneback");

    return NULL;
}

static PyObject* pyopencv_cv_calcOpticalFlowPyrLK(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_prevImg = NULL;
    Mat prevImg;
    PyObject* pyobj_nextImg = NULL;
    Mat nextImg;
    PyObject* pyobj_prevPts = NULL;
    Mat prevPts;
    PyObject* pyobj_nextPts = NULL;
    Mat nextPts;
    PyObject* pyobj_status = NULL;
    Mat status;
    PyObject* pyobj_err = NULL;
    Mat err;
    PyObject* pyobj_winSize = NULL;
    Size winSize=Size(21,21);
    PyObject* pyobj_maxLevel = NULL;
    int maxLevel=3;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, 0.01);
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_minEigThreshold = NULL;
    double minEigThreshold=1e-4;

    const char* keywords[] = { "prevImg", "nextImg", "prevPts", "nextPts", "status", "err", "winSize", "maxLevel", "criteria", "flags", "minEigThreshold", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOOOOO:calcOpticalFlowPyrLK", (char**)keywords, &pyobj_prevImg, &pyobj_nextImg, &pyobj_prevPts, &pyobj_nextPts, &pyobj_status, &pyobj_err, &pyobj_winSize, &pyobj_maxLevel, &pyobj_criteria, &pyobj_flags, &pyobj_minEigThreshold) &&
        pyopencv_to_safe(pyobj_prevImg, prevImg, ArgInfo("prevImg", 0)) &&
        pyopencv_to_safe(pyobj_nextImg, nextImg, ArgInfo("nextImg", 0)) &&
        pyopencv_to_safe(pyobj_prevPts, prevPts, ArgInfo("prevPts", 0)) &&
        pyopencv_to_safe(pyobj_nextPts, nextPts, ArgInfo("nextPts", 1)) &&
        pyopencv_to_safe(pyobj_status, status, ArgInfo("status", 1)) &&
        pyopencv_to_safe(pyobj_err, err, ArgInfo("err", 1)) &&
        pyopencv_to_safe(pyobj_winSize, winSize, ArgInfo("winSize", 0)) &&
        pyopencv_to_safe(pyobj_maxLevel, maxLevel, ArgInfo("maxLevel", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_minEigThreshold, minEigThreshold, ArgInfo("minEigThreshold", 0)) )
    {
        ERRWRAP2(cv::calcOpticalFlowPyrLK(prevImg, nextImg, prevPts, nextPts, status, err, winSize, maxLevel, criteria, flags, minEigThreshold));
        return Py_BuildValue("(NNN)", pyopencv_from(nextPts), pyopencv_from(status), pyopencv_from(err));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_prevImg = NULL;
    UMat prevImg;
    PyObject* pyobj_nextImg = NULL;
    UMat nextImg;
    PyObject* pyobj_prevPts = NULL;
    UMat prevPts;
    PyObject* pyobj_nextPts = NULL;
    UMat nextPts;
    PyObject* pyobj_status = NULL;
    UMat status;
    PyObject* pyobj_err = NULL;
    UMat err;
    PyObject* pyobj_winSize = NULL;
    Size winSize=Size(21,21);
    PyObject* pyobj_maxLevel = NULL;
    int maxLevel=3;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, 0.01);
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_minEigThreshold = NULL;
    double minEigThreshold=1e-4;

    const char* keywords[] = { "prevImg", "nextImg", "prevPts", "nextPts", "status", "err", "winSize", "maxLevel", "criteria", "flags", "minEigThreshold", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOOOOO:calcOpticalFlowPyrLK", (char**)keywords, &pyobj_prevImg, &pyobj_nextImg, &pyobj_prevPts, &pyobj_nextPts, &pyobj_status, &pyobj_err, &pyobj_winSize, &pyobj_maxLevel, &pyobj_criteria, &pyobj_flags, &pyobj_minEigThreshold) &&
        pyopencv_to_safe(pyobj_prevImg, prevImg, ArgInfo("prevImg", 0)) &&
        pyopencv_to_safe(pyobj_nextImg, nextImg, ArgInfo("nextImg", 0)) &&
        pyopencv_to_safe(pyobj_prevPts, prevPts, ArgInfo("prevPts", 0)) &&
        pyopencv_to_safe(pyobj_nextPts, nextPts, ArgInfo("nextPts", 1)) &&
        pyopencv_to_safe(pyobj_status, status, ArgInfo("status", 1)) &&
        pyopencv_to_safe(pyobj_err, err, ArgInfo("err", 1)) &&
        pyopencv_to_safe(pyobj_winSize, winSize, ArgInfo("winSize", 0)) &&
        pyopencv_to_safe(pyobj_maxLevel, maxLevel, ArgInfo("maxLevel", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_minEigThreshold, minEigThreshold, ArgInfo("minEigThreshold", 0)) )
    {
        ERRWRAP2(cv::calcOpticalFlowPyrLK(prevImg, nextImg, prevPts, nextPts, status, err, winSize, maxLevel, criteria, flags, minEigThreshold));
        return Py_BuildValue("(NNN)", pyopencv_from(nextPts), pyopencv_from(status), pyopencv_from(err));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("calcOpticalFlowPyrLK");

    return NULL;
}

static PyObject* pyopencv_cv_calibrateCamera(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_objectPoints = NULL;
    vector_Mat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    vector_Mat imagePoints;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    Mat distCoeffs;
    PyObject* pyobj_rvecs = NULL;
    vector_Mat rvecs;
    PyObject* pyobj_tvecs = NULL;
    vector_Mat tvecs;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria( TermCriteria::COUNT + TermCriteria::EPS, 30, DBL_EPSILON);
    double retval;

    const char* keywords[] = { "objectPoints", "imagePoints", "imageSize", "cameraMatrix", "distCoeffs", "rvecs", "tvecs", "flags", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OOOO:calibrateCamera", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints, &pyobj_imageSize, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvecs, &pyobj_tvecs, &pyobj_flags, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 0)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 1)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 1)) &&
        pyopencv_to_safe(pyobj_rvecs, rvecs, ArgInfo("rvecs", 1)) &&
        pyopencv_to_safe(pyobj_tvecs, tvecs, ArgInfo("tvecs", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(retval = cv::calibrateCamera(objectPoints, imagePoints, imageSize, cameraMatrix, distCoeffs, rvecs, tvecs, flags, criteria));
        return Py_BuildValue("(NNNNN)", pyopencv_from(retval), pyopencv_from(cameraMatrix), pyopencv_from(distCoeffs), pyopencv_from(rvecs), pyopencv_from(tvecs));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_objectPoints = NULL;
    vector_UMat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    vector_UMat imagePoints;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    UMat distCoeffs;
    PyObject* pyobj_rvecs = NULL;
    vector_UMat rvecs;
    PyObject* pyobj_tvecs = NULL;
    vector_UMat tvecs;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria( TermCriteria::COUNT + TermCriteria::EPS, 30, DBL_EPSILON);
    double retval;

    const char* keywords[] = { "objectPoints", "imagePoints", "imageSize", "cameraMatrix", "distCoeffs", "rvecs", "tvecs", "flags", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OOOO:calibrateCamera", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints, &pyobj_imageSize, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvecs, &pyobj_tvecs, &pyobj_flags, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 0)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 1)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 1)) &&
        pyopencv_to_safe(pyobj_rvecs, rvecs, ArgInfo("rvecs", 1)) &&
        pyopencv_to_safe(pyobj_tvecs, tvecs, ArgInfo("tvecs", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(retval = cv::calibrateCamera(objectPoints, imagePoints, imageSize, cameraMatrix, distCoeffs, rvecs, tvecs, flags, criteria));
        return Py_BuildValue("(NNNNN)", pyopencv_from(retval), pyopencv_from(cameraMatrix), pyopencv_from(distCoeffs), pyopencv_from(rvecs), pyopencv_from(tvecs));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("calibrateCamera");

    return NULL;
}

static PyObject* pyopencv_cv_calibrateCameraExtended(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_objectPoints = NULL;
    vector_Mat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    vector_Mat imagePoints;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    Mat distCoeffs;
    PyObject* pyobj_rvecs = NULL;
    vector_Mat rvecs;
    PyObject* pyobj_tvecs = NULL;
    vector_Mat tvecs;
    PyObject* pyobj_stdDeviationsIntrinsics = NULL;
    Mat stdDeviationsIntrinsics;
    PyObject* pyobj_stdDeviationsExtrinsics = NULL;
    Mat stdDeviationsExtrinsics;
    PyObject* pyobj_perViewErrors = NULL;
    Mat perViewErrors;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria( TermCriteria::COUNT + TermCriteria::EPS, 30, DBL_EPSILON);
    double retval;

    const char* keywords[] = { "objectPoints", "imagePoints", "imageSize", "cameraMatrix", "distCoeffs", "rvecs", "tvecs", "stdDeviationsIntrinsics", "stdDeviationsExtrinsics", "perViewErrors", "flags", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OOOOOOO:calibrateCameraExtended", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints, &pyobj_imageSize, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvecs, &pyobj_tvecs, &pyobj_stdDeviationsIntrinsics, &pyobj_stdDeviationsExtrinsics, &pyobj_perViewErrors, &pyobj_flags, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 0)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 1)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 1)) &&
        pyopencv_to_safe(pyobj_rvecs, rvecs, ArgInfo("rvecs", 1)) &&
        pyopencv_to_safe(pyobj_tvecs, tvecs, ArgInfo("tvecs", 1)) &&
        pyopencv_to_safe(pyobj_stdDeviationsIntrinsics, stdDeviationsIntrinsics, ArgInfo("stdDeviationsIntrinsics", 1)) &&
        pyopencv_to_safe(pyobj_stdDeviationsExtrinsics, stdDeviationsExtrinsics, ArgInfo("stdDeviationsExtrinsics", 1)) &&
        pyopencv_to_safe(pyobj_perViewErrors, perViewErrors, ArgInfo("perViewErrors", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(retval = cv::calibrateCamera(objectPoints, imagePoints, imageSize, cameraMatrix, distCoeffs, rvecs, tvecs, stdDeviationsIntrinsics, stdDeviationsExtrinsics, perViewErrors, flags, criteria));
        return Py_BuildValue("(NNNNNNNN)", pyopencv_from(retval), pyopencv_from(cameraMatrix), pyopencv_from(distCoeffs), pyopencv_from(rvecs), pyopencv_from(tvecs), pyopencv_from(stdDeviationsIntrinsics), pyopencv_from(stdDeviationsExtrinsics), pyopencv_from(perViewErrors));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_objectPoints = NULL;
    vector_UMat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    vector_UMat imagePoints;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    UMat distCoeffs;
    PyObject* pyobj_rvecs = NULL;
    vector_UMat rvecs;
    PyObject* pyobj_tvecs = NULL;
    vector_UMat tvecs;
    PyObject* pyobj_stdDeviationsIntrinsics = NULL;
    UMat stdDeviationsIntrinsics;
    PyObject* pyobj_stdDeviationsExtrinsics = NULL;
    UMat stdDeviationsExtrinsics;
    PyObject* pyobj_perViewErrors = NULL;
    UMat perViewErrors;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria( TermCriteria::COUNT + TermCriteria::EPS, 30, DBL_EPSILON);
    double retval;

    const char* keywords[] = { "objectPoints", "imagePoints", "imageSize", "cameraMatrix", "distCoeffs", "rvecs", "tvecs", "stdDeviationsIntrinsics", "stdDeviationsExtrinsics", "perViewErrors", "flags", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OOOOOOO:calibrateCameraExtended", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints, &pyobj_imageSize, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvecs, &pyobj_tvecs, &pyobj_stdDeviationsIntrinsics, &pyobj_stdDeviationsExtrinsics, &pyobj_perViewErrors, &pyobj_flags, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 0)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 1)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 1)) &&
        pyopencv_to_safe(pyobj_rvecs, rvecs, ArgInfo("rvecs", 1)) &&
        pyopencv_to_safe(pyobj_tvecs, tvecs, ArgInfo("tvecs", 1)) &&
        pyopencv_to_safe(pyobj_stdDeviationsIntrinsics, stdDeviationsIntrinsics, ArgInfo("stdDeviationsIntrinsics", 1)) &&
        pyopencv_to_safe(pyobj_stdDeviationsExtrinsics, stdDeviationsExtrinsics, ArgInfo("stdDeviationsExtrinsics", 1)) &&
        pyopencv_to_safe(pyobj_perViewErrors, perViewErrors, ArgInfo("perViewErrors", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(retval = cv::calibrateCamera(objectPoints, imagePoints, imageSize, cameraMatrix, distCoeffs, rvecs, tvecs, stdDeviationsIntrinsics, stdDeviationsExtrinsics, perViewErrors, flags, criteria));
        return Py_BuildValue("(NNNNNNNN)", pyopencv_from(retval), pyopencv_from(cameraMatrix), pyopencv_from(distCoeffs), pyopencv_from(rvecs), pyopencv_from(tvecs), pyopencv_from(stdDeviationsIntrinsics), pyopencv_from(stdDeviationsExtrinsics), pyopencv_from(perViewErrors));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("calibrateCameraExtended");

    return NULL;
}

static PyObject* pyopencv_cv_calibrateCameraRO(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_objectPoints = NULL;
    vector_Mat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    vector_Mat imagePoints;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_iFixedPoint = NULL;
    int iFixedPoint=0;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    Mat distCoeffs;
    PyObject* pyobj_rvecs = NULL;
    vector_Mat rvecs;
    PyObject* pyobj_tvecs = NULL;
    vector_Mat tvecs;
    PyObject* pyobj_newObjPoints = NULL;
    Mat newObjPoints;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria( TermCriteria::COUNT + TermCriteria::EPS, 30, DBL_EPSILON);
    double retval;

    const char* keywords[] = { "objectPoints", "imagePoints", "imageSize", "iFixedPoint", "cameraMatrix", "distCoeffs", "rvecs", "tvecs", "newObjPoints", "flags", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|OOOOO:calibrateCameraRO", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints, &pyobj_imageSize, &pyobj_iFixedPoint, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvecs, &pyobj_tvecs, &pyobj_newObjPoints, &pyobj_flags, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 0)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_iFixedPoint, iFixedPoint, ArgInfo("iFixedPoint", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 1)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 1)) &&
        pyopencv_to_safe(pyobj_rvecs, rvecs, ArgInfo("rvecs", 1)) &&
        pyopencv_to_safe(pyobj_tvecs, tvecs, ArgInfo("tvecs", 1)) &&
        pyopencv_to_safe(pyobj_newObjPoints, newObjPoints, ArgInfo("newObjPoints", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(retval = cv::calibrateCameraRO(objectPoints, imagePoints, imageSize, iFixedPoint, cameraMatrix, distCoeffs, rvecs, tvecs, newObjPoints, flags, criteria));
        return Py_BuildValue("(NNNNNN)", pyopencv_from(retval), pyopencv_from(cameraMatrix), pyopencv_from(distCoeffs), pyopencv_from(rvecs), pyopencv_from(tvecs), pyopencv_from(newObjPoints));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_objectPoints = NULL;
    vector_UMat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    vector_UMat imagePoints;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_iFixedPoint = NULL;
    int iFixedPoint=0;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    UMat distCoeffs;
    PyObject* pyobj_rvecs = NULL;
    vector_UMat rvecs;
    PyObject* pyobj_tvecs = NULL;
    vector_UMat tvecs;
    PyObject* pyobj_newObjPoints = NULL;
    UMat newObjPoints;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria( TermCriteria::COUNT + TermCriteria::EPS, 30, DBL_EPSILON);
    double retval;

    const char* keywords[] = { "objectPoints", "imagePoints", "imageSize", "iFixedPoint", "cameraMatrix", "distCoeffs", "rvecs", "tvecs", "newObjPoints", "flags", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|OOOOO:calibrateCameraRO", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints, &pyobj_imageSize, &pyobj_iFixedPoint, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvecs, &pyobj_tvecs, &pyobj_newObjPoints, &pyobj_flags, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 0)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_iFixedPoint, iFixedPoint, ArgInfo("iFixedPoint", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 1)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 1)) &&
        pyopencv_to_safe(pyobj_rvecs, rvecs, ArgInfo("rvecs", 1)) &&
        pyopencv_to_safe(pyobj_tvecs, tvecs, ArgInfo("tvecs", 1)) &&
        pyopencv_to_safe(pyobj_newObjPoints, newObjPoints, ArgInfo("newObjPoints", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(retval = cv::calibrateCameraRO(objectPoints, imagePoints, imageSize, iFixedPoint, cameraMatrix, distCoeffs, rvecs, tvecs, newObjPoints, flags, criteria));
        return Py_BuildValue("(NNNNNN)", pyopencv_from(retval), pyopencv_from(cameraMatrix), pyopencv_from(distCoeffs), pyopencv_from(rvecs), pyopencv_from(tvecs), pyopencv_from(newObjPoints));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("calibrateCameraRO");

    return NULL;
}

static PyObject* pyopencv_cv_calibrateCameraROExtended(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_objectPoints = NULL;
    vector_Mat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    vector_Mat imagePoints;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_iFixedPoint = NULL;
    int iFixedPoint=0;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    Mat distCoeffs;
    PyObject* pyobj_rvecs = NULL;
    vector_Mat rvecs;
    PyObject* pyobj_tvecs = NULL;
    vector_Mat tvecs;
    PyObject* pyobj_newObjPoints = NULL;
    Mat newObjPoints;
    PyObject* pyobj_stdDeviationsIntrinsics = NULL;
    Mat stdDeviationsIntrinsics;
    PyObject* pyobj_stdDeviationsExtrinsics = NULL;
    Mat stdDeviationsExtrinsics;
    PyObject* pyobj_stdDeviationsObjPoints = NULL;
    Mat stdDeviationsObjPoints;
    PyObject* pyobj_perViewErrors = NULL;
    Mat perViewErrors;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria( TermCriteria::COUNT + TermCriteria::EPS, 30, DBL_EPSILON);
    double retval;

    const char* keywords[] = { "objectPoints", "imagePoints", "imageSize", "iFixedPoint", "cameraMatrix", "distCoeffs", "rvecs", "tvecs", "newObjPoints", "stdDeviationsIntrinsics", "stdDeviationsExtrinsics", "stdDeviationsObjPoints", "perViewErrors", "flags", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|OOOOOOOOO:calibrateCameraROExtended", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints, &pyobj_imageSize, &pyobj_iFixedPoint, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvecs, &pyobj_tvecs, &pyobj_newObjPoints, &pyobj_stdDeviationsIntrinsics, &pyobj_stdDeviationsExtrinsics, &pyobj_stdDeviationsObjPoints, &pyobj_perViewErrors, &pyobj_flags, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 0)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_iFixedPoint, iFixedPoint, ArgInfo("iFixedPoint", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 1)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 1)) &&
        pyopencv_to_safe(pyobj_rvecs, rvecs, ArgInfo("rvecs", 1)) &&
        pyopencv_to_safe(pyobj_tvecs, tvecs, ArgInfo("tvecs", 1)) &&
        pyopencv_to_safe(pyobj_newObjPoints, newObjPoints, ArgInfo("newObjPoints", 1)) &&
        pyopencv_to_safe(pyobj_stdDeviationsIntrinsics, stdDeviationsIntrinsics, ArgInfo("stdDeviationsIntrinsics", 1)) &&
        pyopencv_to_safe(pyobj_stdDeviationsExtrinsics, stdDeviationsExtrinsics, ArgInfo("stdDeviationsExtrinsics", 1)) &&
        pyopencv_to_safe(pyobj_stdDeviationsObjPoints, stdDeviationsObjPoints, ArgInfo("stdDeviationsObjPoints", 1)) &&
        pyopencv_to_safe(pyobj_perViewErrors, perViewErrors, ArgInfo("perViewErrors", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(retval = cv::calibrateCameraRO(objectPoints, imagePoints, imageSize, iFixedPoint, cameraMatrix, distCoeffs, rvecs, tvecs, newObjPoints, stdDeviationsIntrinsics, stdDeviationsExtrinsics, stdDeviationsObjPoints, perViewErrors, flags, criteria));
        return Py_BuildValue("(NNNNNNNNNN)", pyopencv_from(retval), pyopencv_from(cameraMatrix), pyopencv_from(distCoeffs), pyopencv_from(rvecs), pyopencv_from(tvecs), pyopencv_from(newObjPoints), pyopencv_from(stdDeviationsIntrinsics), pyopencv_from(stdDeviationsExtrinsics), pyopencv_from(stdDeviationsObjPoints), pyopencv_from(perViewErrors));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_objectPoints = NULL;
    vector_UMat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    vector_UMat imagePoints;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_iFixedPoint = NULL;
    int iFixedPoint=0;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    UMat distCoeffs;
    PyObject* pyobj_rvecs = NULL;
    vector_UMat rvecs;
    PyObject* pyobj_tvecs = NULL;
    vector_UMat tvecs;
    PyObject* pyobj_newObjPoints = NULL;
    UMat newObjPoints;
    PyObject* pyobj_stdDeviationsIntrinsics = NULL;
    UMat stdDeviationsIntrinsics;
    PyObject* pyobj_stdDeviationsExtrinsics = NULL;
    UMat stdDeviationsExtrinsics;
    PyObject* pyobj_stdDeviationsObjPoints = NULL;
    UMat stdDeviationsObjPoints;
    PyObject* pyobj_perViewErrors = NULL;
    UMat perViewErrors;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria( TermCriteria::COUNT + TermCriteria::EPS, 30, DBL_EPSILON);
    double retval;

    const char* keywords[] = { "objectPoints", "imagePoints", "imageSize", "iFixedPoint", "cameraMatrix", "distCoeffs", "rvecs", "tvecs", "newObjPoints", "stdDeviationsIntrinsics", "stdDeviationsExtrinsics", "stdDeviationsObjPoints", "perViewErrors", "flags", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|OOOOOOOOO:calibrateCameraROExtended", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints, &pyobj_imageSize, &pyobj_iFixedPoint, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvecs, &pyobj_tvecs, &pyobj_newObjPoints, &pyobj_stdDeviationsIntrinsics, &pyobj_stdDeviationsExtrinsics, &pyobj_stdDeviationsObjPoints, &pyobj_perViewErrors, &pyobj_flags, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 0)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_iFixedPoint, iFixedPoint, ArgInfo("iFixedPoint", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 1)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 1)) &&
        pyopencv_to_safe(pyobj_rvecs, rvecs, ArgInfo("rvecs", 1)) &&
        pyopencv_to_safe(pyobj_tvecs, tvecs, ArgInfo("tvecs", 1)) &&
        pyopencv_to_safe(pyobj_newObjPoints, newObjPoints, ArgInfo("newObjPoints", 1)) &&
        pyopencv_to_safe(pyobj_stdDeviationsIntrinsics, stdDeviationsIntrinsics, ArgInfo("stdDeviationsIntrinsics", 1)) &&
        pyopencv_to_safe(pyobj_stdDeviationsExtrinsics, stdDeviationsExtrinsics, ArgInfo("stdDeviationsExtrinsics", 1)) &&
        pyopencv_to_safe(pyobj_stdDeviationsObjPoints, stdDeviationsObjPoints, ArgInfo("stdDeviationsObjPoints", 1)) &&
        pyopencv_to_safe(pyobj_perViewErrors, perViewErrors, ArgInfo("perViewErrors", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(retval = cv::calibrateCameraRO(objectPoints, imagePoints, imageSize, iFixedPoint, cameraMatrix, distCoeffs, rvecs, tvecs, newObjPoints, stdDeviationsIntrinsics, stdDeviationsExtrinsics, stdDeviationsObjPoints, perViewErrors, flags, criteria));
        return Py_BuildValue("(NNNNNNNNNN)", pyopencv_from(retval), pyopencv_from(cameraMatrix), pyopencv_from(distCoeffs), pyopencv_from(rvecs), pyopencv_from(tvecs), pyopencv_from(newObjPoints), pyopencv_from(stdDeviationsIntrinsics), pyopencv_from(stdDeviationsExtrinsics), pyopencv_from(stdDeviationsObjPoints), pyopencv_from(perViewErrors));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("calibrateCameraROExtended");

    return NULL;
}

static PyObject* pyopencv_cv_calibrateHandEye(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_R_gripper2base = NULL;
    vector_Mat R_gripper2base;
    PyObject* pyobj_t_gripper2base = NULL;
    vector_Mat t_gripper2base;
    PyObject* pyobj_R_target2cam = NULL;
    vector_Mat R_target2cam;
    PyObject* pyobj_t_target2cam = NULL;
    vector_Mat t_target2cam;
    PyObject* pyobj_R_cam2gripper = NULL;
    Mat R_cam2gripper;
    PyObject* pyobj_t_cam2gripper = NULL;
    Mat t_cam2gripper;
    PyObject* pyobj_method = NULL;
    HandEyeCalibrationMethod method=CALIB_HAND_EYE_TSAI;

    const char* keywords[] = { "R_gripper2base", "t_gripper2base", "R_target2cam", "t_target2cam", "R_cam2gripper", "t_cam2gripper", "method", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:calibrateHandEye", (char**)keywords, &pyobj_R_gripper2base, &pyobj_t_gripper2base, &pyobj_R_target2cam, &pyobj_t_target2cam, &pyobj_R_cam2gripper, &pyobj_t_cam2gripper, &pyobj_method) &&
        pyopencv_to_safe(pyobj_R_gripper2base, R_gripper2base, ArgInfo("R_gripper2base", 0)) &&
        pyopencv_to_safe(pyobj_t_gripper2base, t_gripper2base, ArgInfo("t_gripper2base", 0)) &&
        pyopencv_to_safe(pyobj_R_target2cam, R_target2cam, ArgInfo("R_target2cam", 0)) &&
        pyopencv_to_safe(pyobj_t_target2cam, t_target2cam, ArgInfo("t_target2cam", 0)) &&
        pyopencv_to_safe(pyobj_R_cam2gripper, R_cam2gripper, ArgInfo("R_cam2gripper", 1)) &&
        pyopencv_to_safe(pyobj_t_cam2gripper, t_cam2gripper, ArgInfo("t_cam2gripper", 1)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) )
    {
        ERRWRAP2(cv::calibrateHandEye(R_gripper2base, t_gripper2base, R_target2cam, t_target2cam, R_cam2gripper, t_cam2gripper, method));
        return Py_BuildValue("(NN)", pyopencv_from(R_cam2gripper), pyopencv_from(t_cam2gripper));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_R_gripper2base = NULL;
    vector_UMat R_gripper2base;
    PyObject* pyobj_t_gripper2base = NULL;
    vector_UMat t_gripper2base;
    PyObject* pyobj_R_target2cam = NULL;
    vector_UMat R_target2cam;
    PyObject* pyobj_t_target2cam = NULL;
    vector_UMat t_target2cam;
    PyObject* pyobj_R_cam2gripper = NULL;
    UMat R_cam2gripper;
    PyObject* pyobj_t_cam2gripper = NULL;
    UMat t_cam2gripper;
    PyObject* pyobj_method = NULL;
    HandEyeCalibrationMethod method=CALIB_HAND_EYE_TSAI;

    const char* keywords[] = { "R_gripper2base", "t_gripper2base", "R_target2cam", "t_target2cam", "R_cam2gripper", "t_cam2gripper", "method", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:calibrateHandEye", (char**)keywords, &pyobj_R_gripper2base, &pyobj_t_gripper2base, &pyobj_R_target2cam, &pyobj_t_target2cam, &pyobj_R_cam2gripper, &pyobj_t_cam2gripper, &pyobj_method) &&
        pyopencv_to_safe(pyobj_R_gripper2base, R_gripper2base, ArgInfo("R_gripper2base", 0)) &&
        pyopencv_to_safe(pyobj_t_gripper2base, t_gripper2base, ArgInfo("t_gripper2base", 0)) &&
        pyopencv_to_safe(pyobj_R_target2cam, R_target2cam, ArgInfo("R_target2cam", 0)) &&
        pyopencv_to_safe(pyobj_t_target2cam, t_target2cam, ArgInfo("t_target2cam", 0)) &&
        pyopencv_to_safe(pyobj_R_cam2gripper, R_cam2gripper, ArgInfo("R_cam2gripper", 1)) &&
        pyopencv_to_safe(pyobj_t_cam2gripper, t_cam2gripper, ArgInfo("t_cam2gripper", 1)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) )
    {
        ERRWRAP2(cv::calibrateHandEye(R_gripper2base, t_gripper2base, R_target2cam, t_target2cam, R_cam2gripper, t_cam2gripper, method));
        return Py_BuildValue("(NN)", pyopencv_from(R_cam2gripper), pyopencv_from(t_cam2gripper));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("calibrateHandEye");

    return NULL;
}

static PyObject* pyopencv_cv_calibrateRobotWorldHandEye(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_R_world2cam = NULL;
    vector_Mat R_world2cam;
    PyObject* pyobj_t_world2cam = NULL;
    vector_Mat t_world2cam;
    PyObject* pyobj_R_base2gripper = NULL;
    vector_Mat R_base2gripper;
    PyObject* pyobj_t_base2gripper = NULL;
    vector_Mat t_base2gripper;
    PyObject* pyobj_R_base2world = NULL;
    Mat R_base2world;
    PyObject* pyobj_t_base2world = NULL;
    Mat t_base2world;
    PyObject* pyobj_R_gripper2cam = NULL;
    Mat R_gripper2cam;
    PyObject* pyobj_t_gripper2cam = NULL;
    Mat t_gripper2cam;
    PyObject* pyobj_method = NULL;
    RobotWorldHandEyeCalibrationMethod method=CALIB_ROBOT_WORLD_HAND_EYE_SHAH;

    const char* keywords[] = { "R_world2cam", "t_world2cam", "R_base2gripper", "t_base2gripper", "R_base2world", "t_base2world", "R_gripper2cam", "t_gripper2cam", "method", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOOO:calibrateRobotWorldHandEye", (char**)keywords, &pyobj_R_world2cam, &pyobj_t_world2cam, &pyobj_R_base2gripper, &pyobj_t_base2gripper, &pyobj_R_base2world, &pyobj_t_base2world, &pyobj_R_gripper2cam, &pyobj_t_gripper2cam, &pyobj_method) &&
        pyopencv_to_safe(pyobj_R_world2cam, R_world2cam, ArgInfo("R_world2cam", 0)) &&
        pyopencv_to_safe(pyobj_t_world2cam, t_world2cam, ArgInfo("t_world2cam", 0)) &&
        pyopencv_to_safe(pyobj_R_base2gripper, R_base2gripper, ArgInfo("R_base2gripper", 0)) &&
        pyopencv_to_safe(pyobj_t_base2gripper, t_base2gripper, ArgInfo("t_base2gripper", 0)) &&
        pyopencv_to_safe(pyobj_R_base2world, R_base2world, ArgInfo("R_base2world", 1)) &&
        pyopencv_to_safe(pyobj_t_base2world, t_base2world, ArgInfo("t_base2world", 1)) &&
        pyopencv_to_safe(pyobj_R_gripper2cam, R_gripper2cam, ArgInfo("R_gripper2cam", 1)) &&
        pyopencv_to_safe(pyobj_t_gripper2cam, t_gripper2cam, ArgInfo("t_gripper2cam", 1)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) )
    {
        ERRWRAP2(cv::calibrateRobotWorldHandEye(R_world2cam, t_world2cam, R_base2gripper, t_base2gripper, R_base2world, t_base2world, R_gripper2cam, t_gripper2cam, method));
        return Py_BuildValue("(NNNN)", pyopencv_from(R_base2world), pyopencv_from(t_base2world), pyopencv_from(R_gripper2cam), pyopencv_from(t_gripper2cam));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_R_world2cam = NULL;
    vector_UMat R_world2cam;
    PyObject* pyobj_t_world2cam = NULL;
    vector_UMat t_world2cam;
    PyObject* pyobj_R_base2gripper = NULL;
    vector_UMat R_base2gripper;
    PyObject* pyobj_t_base2gripper = NULL;
    vector_UMat t_base2gripper;
    PyObject* pyobj_R_base2world = NULL;
    UMat R_base2world;
    PyObject* pyobj_t_base2world = NULL;
    UMat t_base2world;
    PyObject* pyobj_R_gripper2cam = NULL;
    UMat R_gripper2cam;
    PyObject* pyobj_t_gripper2cam = NULL;
    UMat t_gripper2cam;
    PyObject* pyobj_method = NULL;
    RobotWorldHandEyeCalibrationMethod method=CALIB_ROBOT_WORLD_HAND_EYE_SHAH;

    const char* keywords[] = { "R_world2cam", "t_world2cam", "R_base2gripper", "t_base2gripper", "R_base2world", "t_base2world", "R_gripper2cam", "t_gripper2cam", "method", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOOO:calibrateRobotWorldHandEye", (char**)keywords, &pyobj_R_world2cam, &pyobj_t_world2cam, &pyobj_R_base2gripper, &pyobj_t_base2gripper, &pyobj_R_base2world, &pyobj_t_base2world, &pyobj_R_gripper2cam, &pyobj_t_gripper2cam, &pyobj_method) &&
        pyopencv_to_safe(pyobj_R_world2cam, R_world2cam, ArgInfo("R_world2cam", 0)) &&
        pyopencv_to_safe(pyobj_t_world2cam, t_world2cam, ArgInfo("t_world2cam", 0)) &&
        pyopencv_to_safe(pyobj_R_base2gripper, R_base2gripper, ArgInfo("R_base2gripper", 0)) &&
        pyopencv_to_safe(pyobj_t_base2gripper, t_base2gripper, ArgInfo("t_base2gripper", 0)) &&
        pyopencv_to_safe(pyobj_R_base2world, R_base2world, ArgInfo("R_base2world", 1)) &&
        pyopencv_to_safe(pyobj_t_base2world, t_base2world, ArgInfo("t_base2world", 1)) &&
        pyopencv_to_safe(pyobj_R_gripper2cam, R_gripper2cam, ArgInfo("R_gripper2cam", 1)) &&
        pyopencv_to_safe(pyobj_t_gripper2cam, t_gripper2cam, ArgInfo("t_gripper2cam", 1)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) )
    {
        ERRWRAP2(cv::calibrateRobotWorldHandEye(R_world2cam, t_world2cam, R_base2gripper, t_base2gripper, R_base2world, t_base2world, R_gripper2cam, t_gripper2cam, method));
        return Py_BuildValue("(NNNN)", pyopencv_from(R_base2world), pyopencv_from(t_base2world), pyopencv_from(R_gripper2cam), pyopencv_from(t_gripper2cam));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("calibrateRobotWorldHandEye");

    return NULL;
}

static PyObject* pyopencv_cv_calibrationMatrixValues(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_apertureWidth = NULL;
    double apertureWidth=0;
    PyObject* pyobj_apertureHeight = NULL;
    double apertureHeight=0;
    double fovx;
    double fovy;
    double focalLength;
    Point2d principalPoint;
    double aspectRatio;

    const char* keywords[] = { "cameraMatrix", "imageSize", "apertureWidth", "apertureHeight", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO:calibrationMatrixValues", (char**)keywords, &pyobj_cameraMatrix, &pyobj_imageSize, &pyobj_apertureWidth, &pyobj_apertureHeight) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_apertureWidth, apertureWidth, ArgInfo("apertureWidth", 0)) &&
        pyopencv_to_safe(pyobj_apertureHeight, apertureHeight, ArgInfo("apertureHeight", 0)) )
    {
        ERRWRAP2(cv::calibrationMatrixValues(cameraMatrix, imageSize, apertureWidth, apertureHeight, fovx, fovy, focalLength, principalPoint, aspectRatio));
        return Py_BuildValue("(NNNNN)", pyopencv_from(fovx), pyopencv_from(fovy), pyopencv_from(focalLength), pyopencv_from(principalPoint), pyopencv_from(aspectRatio));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_apertureWidth = NULL;
    double apertureWidth=0;
    PyObject* pyobj_apertureHeight = NULL;
    double apertureHeight=0;
    double fovx;
    double fovy;
    double focalLength;
    Point2d principalPoint;
    double aspectRatio;

    const char* keywords[] = { "cameraMatrix", "imageSize", "apertureWidth", "apertureHeight", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO:calibrationMatrixValues", (char**)keywords, &pyobj_cameraMatrix, &pyobj_imageSize, &pyobj_apertureWidth, &pyobj_apertureHeight) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_apertureWidth, apertureWidth, ArgInfo("apertureWidth", 0)) &&
        pyopencv_to_safe(pyobj_apertureHeight, apertureHeight, ArgInfo("apertureHeight", 0)) )
    {
        ERRWRAP2(cv::calibrationMatrixValues(cameraMatrix, imageSize, apertureWidth, apertureHeight, fovx, fovy, focalLength, principalPoint, aspectRatio));
        return Py_BuildValue("(NNNNN)", pyopencv_from(fovx), pyopencv_from(fovy), pyopencv_from(focalLength), pyopencv_from(principalPoint), pyopencv_from(aspectRatio));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("calibrationMatrixValues");

    return NULL;
}

static PyObject* pyopencv_cv_cartToPolar(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_x = NULL;
    Mat x;
    PyObject* pyobj_y = NULL;
    Mat y;
    PyObject* pyobj_magnitude = NULL;
    Mat magnitude;
    PyObject* pyobj_angle = NULL;
    Mat angle;
    PyObject* pyobj_angleInDegrees = NULL;
    bool angleInDegrees=false;

    const char* keywords[] = { "x", "y", "magnitude", "angle", "angleInDegrees", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:cartToPolar", (char**)keywords, &pyobj_x, &pyobj_y, &pyobj_magnitude, &pyobj_angle, &pyobj_angleInDegrees) &&
        pyopencv_to_safe(pyobj_x, x, ArgInfo("x", 0)) &&
        pyopencv_to_safe(pyobj_y, y, ArgInfo("y", 0)) &&
        pyopencv_to_safe(pyobj_magnitude, magnitude, ArgInfo("magnitude", 1)) &&
        pyopencv_to_safe(pyobj_angle, angle, ArgInfo("angle", 1)) &&
        pyopencv_to_safe(pyobj_angleInDegrees, angleInDegrees, ArgInfo("angleInDegrees", 0)) )
    {
        ERRWRAP2(cv::cartToPolar(x, y, magnitude, angle, angleInDegrees));
        return Py_BuildValue("(NN)", pyopencv_from(magnitude), pyopencv_from(angle));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_x = NULL;
    UMat x;
    PyObject* pyobj_y = NULL;
    UMat y;
    PyObject* pyobj_magnitude = NULL;
    UMat magnitude;
    PyObject* pyobj_angle = NULL;
    UMat angle;
    PyObject* pyobj_angleInDegrees = NULL;
    bool angleInDegrees=false;

    const char* keywords[] = { "x", "y", "magnitude", "angle", "angleInDegrees", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:cartToPolar", (char**)keywords, &pyobj_x, &pyobj_y, &pyobj_magnitude, &pyobj_angle, &pyobj_angleInDegrees) &&
        pyopencv_to_safe(pyobj_x, x, ArgInfo("x", 0)) &&
        pyopencv_to_safe(pyobj_y, y, ArgInfo("y", 0)) &&
        pyopencv_to_safe(pyobj_magnitude, magnitude, ArgInfo("magnitude", 1)) &&
        pyopencv_to_safe(pyobj_angle, angle, ArgInfo("angle", 1)) &&
        pyopencv_to_safe(pyobj_angleInDegrees, angleInDegrees, ArgInfo("angleInDegrees", 0)) )
    {
        ERRWRAP2(cv::cartToPolar(x, y, magnitude, angle, angleInDegrees));
        return Py_BuildValue("(NN)", pyopencv_from(magnitude), pyopencv_from(angle));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("cartToPolar");

    return NULL;
}

static PyObject* pyopencv_cv_checkChessboard(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_size = NULL;
    Size size;
    bool retval;

    const char* keywords[] = { "img", "size", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:checkChessboard", (char**)keywords, &pyobj_img, &pyobj_size) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_size, size, ArgInfo("size", 0)) )
    {
        ERRWRAP2(retval = cv::checkChessboard(img, size));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_size = NULL;
    Size size;
    bool retval;

    const char* keywords[] = { "img", "size", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:checkChessboard", (char**)keywords, &pyobj_img, &pyobj_size) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_size, size, ArgInfo("size", 0)) )
    {
        ERRWRAP2(retval = cv::checkChessboard(img, size));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("checkChessboard");

    return NULL;
}

static PyObject* pyopencv_cv_checkHardwareSupport(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_feature = NULL;
    int feature=0;
    bool retval;

    const char* keywords[] = { "feature", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:checkHardwareSupport", (char**)keywords, &pyobj_feature) &&
        pyopencv_to_safe(pyobj_feature, feature, ArgInfo("feature", 0)) )
    {
        ERRWRAP2(retval = cv::checkHardwareSupport(feature));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_checkRange(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_a = NULL;
    Mat a;
    PyObject* pyobj_quiet = NULL;
    bool quiet=true;
    Point pos;
    PyObject* pyobj_minVal = NULL;
    double minVal=-DBL_MAX;
    PyObject* pyobj_maxVal = NULL;
    double maxVal=DBL_MAX;
    bool retval;

    const char* keywords[] = { "a", "quiet", "minVal", "maxVal", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:checkRange", (char**)keywords, &pyobj_a, &pyobj_quiet, &pyobj_minVal, &pyobj_maxVal) &&
        pyopencv_to_safe(pyobj_a, a, ArgInfo("a", 0)) &&
        pyopencv_to_safe(pyobj_quiet, quiet, ArgInfo("quiet", 0)) &&
        pyopencv_to_safe(pyobj_minVal, minVal, ArgInfo("minVal", 0)) &&
        pyopencv_to_safe(pyobj_maxVal, maxVal, ArgInfo("maxVal", 0)) )
    {
        ERRWRAP2(retval = cv::checkRange(a, quiet, &pos, minVal, maxVal));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(pos));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_a = NULL;
    UMat a;
    PyObject* pyobj_quiet = NULL;
    bool quiet=true;
    Point pos;
    PyObject* pyobj_minVal = NULL;
    double minVal=-DBL_MAX;
    PyObject* pyobj_maxVal = NULL;
    double maxVal=DBL_MAX;
    bool retval;

    const char* keywords[] = { "a", "quiet", "minVal", "maxVal", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:checkRange", (char**)keywords, &pyobj_a, &pyobj_quiet, &pyobj_minVal, &pyobj_maxVal) &&
        pyopencv_to_safe(pyobj_a, a, ArgInfo("a", 0)) &&
        pyopencv_to_safe(pyobj_quiet, quiet, ArgInfo("quiet", 0)) &&
        pyopencv_to_safe(pyobj_minVal, minVal, ArgInfo("minVal", 0)) &&
        pyopencv_to_safe(pyobj_maxVal, maxVal, ArgInfo("maxVal", 0)) )
    {
        ERRWRAP2(retval = cv::checkRange(a, quiet, &pos, minVal, maxVal));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(pos));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("checkRange");

    return NULL;
}

static PyObject* pyopencv_cv_circle(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_center = NULL;
    Point center;
    PyObject* pyobj_radius = NULL;
    int radius=0;
    PyObject* pyobj_color = NULL;
    Scalar color;
    PyObject* pyobj_thickness = NULL;
    int thickness=1;
    PyObject* pyobj_lineType = NULL;
    int lineType=LINE_8;
    PyObject* pyobj_shift = NULL;
    int shift=0;

    const char* keywords[] = { "img", "center", "radius", "color", "thickness", "lineType", "shift", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:circle", (char**)keywords, &pyobj_img, &pyobj_center, &pyobj_radius, &pyobj_color, &pyobj_thickness, &pyobj_lineType, &pyobj_shift) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_center, center, ArgInfo("center", 0)) &&
        pyopencv_to_safe(pyobj_radius, radius, ArgInfo("radius", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_thickness, thickness, ArgInfo("thickness", 0)) &&
        pyopencv_to_safe(pyobj_lineType, lineType, ArgInfo("lineType", 0)) &&
        pyopencv_to_safe(pyobj_shift, shift, ArgInfo("shift", 0)) )
    {
        ERRWRAP2(cv::circle(img, center, radius, color, thickness, lineType, shift));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_center = NULL;
    Point center;
    PyObject* pyobj_radius = NULL;
    int radius=0;
    PyObject* pyobj_color = NULL;
    Scalar color;
    PyObject* pyobj_thickness = NULL;
    int thickness=1;
    PyObject* pyobj_lineType = NULL;
    int lineType=LINE_8;
    PyObject* pyobj_shift = NULL;
    int shift=0;

    const char* keywords[] = { "img", "center", "radius", "color", "thickness", "lineType", "shift", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:circle", (char**)keywords, &pyobj_img, &pyobj_center, &pyobj_radius, &pyobj_color, &pyobj_thickness, &pyobj_lineType, &pyobj_shift) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_center, center, ArgInfo("center", 0)) &&
        pyopencv_to_safe(pyobj_radius, radius, ArgInfo("radius", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_thickness, thickness, ArgInfo("thickness", 0)) &&
        pyopencv_to_safe(pyobj_lineType, lineType, ArgInfo("lineType", 0)) &&
        pyopencv_to_safe(pyobj_shift, shift, ArgInfo("shift", 0)) )
    {
        ERRWRAP2(cv::circle(img, center, radius, color, thickness, lineType, shift));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("circle");

    return NULL;
}

static PyObject* pyopencv_cv_clipLine(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_imgRect = NULL;
    Rect imgRect;
    PyObject* pyobj_pt1 = NULL;
    Point pt1;
    PyObject* pyobj_pt2 = NULL;
    Point pt2;
    bool retval;

    const char* keywords[] = { "imgRect", "pt1", "pt2", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:clipLine", (char**)keywords, &pyobj_imgRect, &pyobj_pt1, &pyobj_pt2) &&
        pyopencv_to_safe(pyobj_imgRect, imgRect, ArgInfo("imgRect", 0)) &&
        pyopencv_to_safe(pyobj_pt1, pt1, ArgInfo("pt1", 1)) &&
        pyopencv_to_safe(pyobj_pt2, pt2, ArgInfo("pt2", 1)) )
    {
        ERRWRAP2(retval = cv::clipLine(imgRect, pt1, pt2));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(pt1), pyopencv_from(pt2));
    }

    return NULL;
}

static PyObject* pyopencv_cv_colorChange(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_red_mul = NULL;
    float red_mul=1.0f;
    PyObject* pyobj_green_mul = NULL;
    float green_mul=1.0f;
    PyObject* pyobj_blue_mul = NULL;
    float blue_mul=1.0f;

    const char* keywords[] = { "src", "mask", "dst", "red_mul", "green_mul", "blue_mul", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOO:colorChange", (char**)keywords, &pyobj_src, &pyobj_mask, &pyobj_dst, &pyobj_red_mul, &pyobj_green_mul, &pyobj_blue_mul) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_red_mul, red_mul, ArgInfo("red_mul", 0)) &&
        pyopencv_to_safe(pyobj_green_mul, green_mul, ArgInfo("green_mul", 0)) &&
        pyopencv_to_safe(pyobj_blue_mul, blue_mul, ArgInfo("blue_mul", 0)) )
    {
        ERRWRAP2(cv::colorChange(src, mask, dst, red_mul, green_mul, blue_mul));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_red_mul = NULL;
    float red_mul=1.0f;
    PyObject* pyobj_green_mul = NULL;
    float green_mul=1.0f;
    PyObject* pyobj_blue_mul = NULL;
    float blue_mul=1.0f;

    const char* keywords[] = { "src", "mask", "dst", "red_mul", "green_mul", "blue_mul", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOO:colorChange", (char**)keywords, &pyobj_src, &pyobj_mask, &pyobj_dst, &pyobj_red_mul, &pyobj_green_mul, &pyobj_blue_mul) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_red_mul, red_mul, ArgInfo("red_mul", 0)) &&
        pyopencv_to_safe(pyobj_green_mul, green_mul, ArgInfo("green_mul", 0)) &&
        pyopencv_to_safe(pyobj_blue_mul, blue_mul, ArgInfo("blue_mul", 0)) )
    {
        ERRWRAP2(cv::colorChange(src, mask, dst, red_mul, green_mul, blue_mul));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("colorChange");

    return NULL;
}

static PyObject* pyopencv_cv_compare(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src1 = NULL;
    Mat src1;
    PyObject* pyobj_src2 = NULL;
    Mat src2;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_cmpop = NULL;
    int cmpop=0;

    const char* keywords[] = { "src1", "src2", "cmpop", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:compare", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_cmpop, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_cmpop, cmpop, ArgInfo("cmpop", 0)) )
    {
        ERRWRAP2(cv::compare(src1, src2, dst, cmpop));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src1 = NULL;
    UMat src1;
    PyObject* pyobj_src2 = NULL;
    UMat src2;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_cmpop = NULL;
    int cmpop=0;

    const char* keywords[] = { "src1", "src2", "cmpop", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:compare", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_cmpop, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_cmpop, cmpop, ArgInfo("cmpop", 0)) )
    {
        ERRWRAP2(cv::compare(src1, src2, dst, cmpop));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("compare");

    return NULL;
}

static PyObject* pyopencv_cv_compareHist(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_H1 = NULL;
    Mat H1;
    PyObject* pyobj_H2 = NULL;
    Mat H2;
    PyObject* pyobj_method = NULL;
    int method=0;
    double retval;

    const char* keywords[] = { "H1", "H2", "method", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:compareHist", (char**)keywords, &pyobj_H1, &pyobj_H2, &pyobj_method) &&
        pyopencv_to_safe(pyobj_H1, H1, ArgInfo("H1", 0)) &&
        pyopencv_to_safe(pyobj_H2, H2, ArgInfo("H2", 0)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) )
    {
        ERRWRAP2(retval = cv::compareHist(H1, H2, method));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_H1 = NULL;
    UMat H1;
    PyObject* pyobj_H2 = NULL;
    UMat H2;
    PyObject* pyobj_method = NULL;
    int method=0;
    double retval;

    const char* keywords[] = { "H1", "H2", "method", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:compareHist", (char**)keywords, &pyobj_H1, &pyobj_H2, &pyobj_method) &&
        pyopencv_to_safe(pyobj_H1, H1, ArgInfo("H1", 0)) &&
        pyopencv_to_safe(pyobj_H2, H2, ArgInfo("H2", 0)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) )
    {
        ERRWRAP2(retval = cv::compareHist(H1, H2, method));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("compareHist");

    return NULL;
}

static PyObject* pyopencv_cv_compile_args(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(3);

    {
    PyObject* pyobj_pkg = NULL;
    gapi_GKernelPackage pkg;
    GCompileArgs retval;

    const char* keywords[] = { "pkg", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:compile_args", (char**)keywords, &pyobj_pkg) &&
        pyopencv_to_safe(pyobj_pkg, pkg, ArgInfo("pkg", 0)) )
    {
        ERRWRAP2(retval = cv::compile_args(pkg));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_pkg = NULL;
    gapi_GNetPackage pkg;
    GCompileArgs retval;

    const char* keywords[] = { "pkg", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:compile_args", (char**)keywords, &pyobj_pkg) &&
        pyopencv_to_safe(pyobj_pkg, pkg, ArgInfo("pkg", 0)) )
    {
        ERRWRAP2(retval = cv::compile_args(pkg));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_kernels = NULL;
    gapi_GKernelPackage kernels;
    PyObject* pyobj_nets = NULL;
    gapi_GNetPackage nets;
    GCompileArgs retval;

    const char* keywords[] = { "kernels", "nets", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:compile_args", (char**)keywords, &pyobj_kernels, &pyobj_nets) &&
        pyopencv_to_safe(pyobj_kernels, kernels, ArgInfo("kernels", 0)) &&
        pyopencv_to_safe(pyobj_nets, nets, ArgInfo("nets", 0)) )
    {
        ERRWRAP2(retval = cv::compile_args(kernels, nets));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("compile_args");

    return NULL;
}

static PyObject* pyopencv_cv_completeSymm(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_m = NULL;
    Mat m;
    PyObject* pyobj_lowerToUpper = NULL;
    bool lowerToUpper=false;

    const char* keywords[] = { "m", "lowerToUpper", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:completeSymm", (char**)keywords, &pyobj_m, &pyobj_lowerToUpper) &&
        pyopencv_to_safe(pyobj_m, m, ArgInfo("m", 1)) &&
        pyopencv_to_safe(pyobj_lowerToUpper, lowerToUpper, ArgInfo("lowerToUpper", 0)) )
    {
        ERRWRAP2(cv::completeSymm(m, lowerToUpper));
        return pyopencv_from(m);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_m = NULL;
    UMat m;
    PyObject* pyobj_lowerToUpper = NULL;
    bool lowerToUpper=false;

    const char* keywords[] = { "m", "lowerToUpper", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:completeSymm", (char**)keywords, &pyobj_m, &pyobj_lowerToUpper) &&
        pyopencv_to_safe(pyobj_m, m, ArgInfo("m", 1)) &&
        pyopencv_to_safe(pyobj_lowerToUpper, lowerToUpper, ArgInfo("lowerToUpper", 0)) )
    {
        ERRWRAP2(cv::completeSymm(m, lowerToUpper));
        return pyopencv_from(m);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("completeSymm");

    return NULL;
}

static PyObject* pyopencv_cv_composeRT(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_rvec1 = NULL;
    Mat rvec1;
    PyObject* pyobj_tvec1 = NULL;
    Mat tvec1;
    PyObject* pyobj_rvec2 = NULL;
    Mat rvec2;
    PyObject* pyobj_tvec2 = NULL;
    Mat tvec2;
    PyObject* pyobj_rvec3 = NULL;
    Mat rvec3;
    PyObject* pyobj_tvec3 = NULL;
    Mat tvec3;
    PyObject* pyobj_dr3dr1 = NULL;
    Mat dr3dr1;
    PyObject* pyobj_dr3dt1 = NULL;
    Mat dr3dt1;
    PyObject* pyobj_dr3dr2 = NULL;
    Mat dr3dr2;
    PyObject* pyobj_dr3dt2 = NULL;
    Mat dr3dt2;
    PyObject* pyobj_dt3dr1 = NULL;
    Mat dt3dr1;
    PyObject* pyobj_dt3dt1 = NULL;
    Mat dt3dt1;
    PyObject* pyobj_dt3dr2 = NULL;
    Mat dt3dr2;
    PyObject* pyobj_dt3dt2 = NULL;
    Mat dt3dt2;

    const char* keywords[] = { "rvec1", "tvec1", "rvec2", "tvec2", "rvec3", "tvec3", "dr3dr1", "dr3dt1", "dr3dr2", "dr3dt2", "dt3dr1", "dt3dt1", "dt3dr2", "dt3dt2", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOOOOOOOO:composeRT", (char**)keywords, &pyobj_rvec1, &pyobj_tvec1, &pyobj_rvec2, &pyobj_tvec2, &pyobj_rvec3, &pyobj_tvec3, &pyobj_dr3dr1, &pyobj_dr3dt1, &pyobj_dr3dr2, &pyobj_dr3dt2, &pyobj_dt3dr1, &pyobj_dt3dt1, &pyobj_dt3dr2, &pyobj_dt3dt2) &&
        pyopencv_to_safe(pyobj_rvec1, rvec1, ArgInfo("rvec1", 0)) &&
        pyopencv_to_safe(pyobj_tvec1, tvec1, ArgInfo("tvec1", 0)) &&
        pyopencv_to_safe(pyobj_rvec2, rvec2, ArgInfo("rvec2", 0)) &&
        pyopencv_to_safe(pyobj_tvec2, tvec2, ArgInfo("tvec2", 0)) &&
        pyopencv_to_safe(pyobj_rvec3, rvec3, ArgInfo("rvec3", 1)) &&
        pyopencv_to_safe(pyobj_tvec3, tvec3, ArgInfo("tvec3", 1)) &&
        pyopencv_to_safe(pyobj_dr3dr1, dr3dr1, ArgInfo("dr3dr1", 1)) &&
        pyopencv_to_safe(pyobj_dr3dt1, dr3dt1, ArgInfo("dr3dt1", 1)) &&
        pyopencv_to_safe(pyobj_dr3dr2, dr3dr2, ArgInfo("dr3dr2", 1)) &&
        pyopencv_to_safe(pyobj_dr3dt2, dr3dt2, ArgInfo("dr3dt2", 1)) &&
        pyopencv_to_safe(pyobj_dt3dr1, dt3dr1, ArgInfo("dt3dr1", 1)) &&
        pyopencv_to_safe(pyobj_dt3dt1, dt3dt1, ArgInfo("dt3dt1", 1)) &&
        pyopencv_to_safe(pyobj_dt3dr2, dt3dr2, ArgInfo("dt3dr2", 1)) &&
        pyopencv_to_safe(pyobj_dt3dt2, dt3dt2, ArgInfo("dt3dt2", 1)) )
    {
        ERRWRAP2(cv::composeRT(rvec1, tvec1, rvec2, tvec2, rvec3, tvec3, dr3dr1, dr3dt1, dr3dr2, dr3dt2, dt3dr1, dt3dt1, dt3dr2, dt3dt2));
        return Py_BuildValue("(NNNNNNNNNN)", pyopencv_from(rvec3), pyopencv_from(tvec3), pyopencv_from(dr3dr1), pyopencv_from(dr3dt1), pyopencv_from(dr3dr2), pyopencv_from(dr3dt2), pyopencv_from(dt3dr1), pyopencv_from(dt3dt1), pyopencv_from(dt3dr2), pyopencv_from(dt3dt2));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_rvec1 = NULL;
    UMat rvec1;
    PyObject* pyobj_tvec1 = NULL;
    UMat tvec1;
    PyObject* pyobj_rvec2 = NULL;
    UMat rvec2;
    PyObject* pyobj_tvec2 = NULL;
    UMat tvec2;
    PyObject* pyobj_rvec3 = NULL;
    UMat rvec3;
    PyObject* pyobj_tvec3 = NULL;
    UMat tvec3;
    PyObject* pyobj_dr3dr1 = NULL;
    UMat dr3dr1;
    PyObject* pyobj_dr3dt1 = NULL;
    UMat dr3dt1;
    PyObject* pyobj_dr3dr2 = NULL;
    UMat dr3dr2;
    PyObject* pyobj_dr3dt2 = NULL;
    UMat dr3dt2;
    PyObject* pyobj_dt3dr1 = NULL;
    UMat dt3dr1;
    PyObject* pyobj_dt3dt1 = NULL;
    UMat dt3dt1;
    PyObject* pyobj_dt3dr2 = NULL;
    UMat dt3dr2;
    PyObject* pyobj_dt3dt2 = NULL;
    UMat dt3dt2;

    const char* keywords[] = { "rvec1", "tvec1", "rvec2", "tvec2", "rvec3", "tvec3", "dr3dr1", "dr3dt1", "dr3dr2", "dr3dt2", "dt3dr1", "dt3dt1", "dt3dr2", "dt3dt2", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOOOOOOOO:composeRT", (char**)keywords, &pyobj_rvec1, &pyobj_tvec1, &pyobj_rvec2, &pyobj_tvec2, &pyobj_rvec3, &pyobj_tvec3, &pyobj_dr3dr1, &pyobj_dr3dt1, &pyobj_dr3dr2, &pyobj_dr3dt2, &pyobj_dt3dr1, &pyobj_dt3dt1, &pyobj_dt3dr2, &pyobj_dt3dt2) &&
        pyopencv_to_safe(pyobj_rvec1, rvec1, ArgInfo("rvec1", 0)) &&
        pyopencv_to_safe(pyobj_tvec1, tvec1, ArgInfo("tvec1", 0)) &&
        pyopencv_to_safe(pyobj_rvec2, rvec2, ArgInfo("rvec2", 0)) &&
        pyopencv_to_safe(pyobj_tvec2, tvec2, ArgInfo("tvec2", 0)) &&
        pyopencv_to_safe(pyobj_rvec3, rvec3, ArgInfo("rvec3", 1)) &&
        pyopencv_to_safe(pyobj_tvec3, tvec3, ArgInfo("tvec3", 1)) &&
        pyopencv_to_safe(pyobj_dr3dr1, dr3dr1, ArgInfo("dr3dr1", 1)) &&
        pyopencv_to_safe(pyobj_dr3dt1, dr3dt1, ArgInfo("dr3dt1", 1)) &&
        pyopencv_to_safe(pyobj_dr3dr2, dr3dr2, ArgInfo("dr3dr2", 1)) &&
        pyopencv_to_safe(pyobj_dr3dt2, dr3dt2, ArgInfo("dr3dt2", 1)) &&
        pyopencv_to_safe(pyobj_dt3dr1, dt3dr1, ArgInfo("dt3dr1", 1)) &&
        pyopencv_to_safe(pyobj_dt3dt1, dt3dt1, ArgInfo("dt3dt1", 1)) &&
        pyopencv_to_safe(pyobj_dt3dr2, dt3dr2, ArgInfo("dt3dr2", 1)) &&
        pyopencv_to_safe(pyobj_dt3dt2, dt3dt2, ArgInfo("dt3dt2", 1)) )
    {
        ERRWRAP2(cv::composeRT(rvec1, tvec1, rvec2, tvec2, rvec3, tvec3, dr3dr1, dr3dt1, dr3dr2, dr3dt2, dt3dr1, dt3dt1, dt3dr2, dt3dt2));
        return Py_BuildValue("(NNNNNNNNNN)", pyopencv_from(rvec3), pyopencv_from(tvec3), pyopencv_from(dr3dr1), pyopencv_from(dr3dt1), pyopencv_from(dr3dr2), pyopencv_from(dr3dt2), pyopencv_from(dt3dr1), pyopencv_from(dt3dt1), pyopencv_from(dt3dr2), pyopencv_from(dt3dt2));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("composeRT");

    return NULL;
}

static PyObject* pyopencv_cv_computeCorrespondEpilines(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_points = NULL;
    Mat points;
    PyObject* pyobj_whichImage = NULL;
    int whichImage=0;
    PyObject* pyobj_F = NULL;
    Mat F;
    PyObject* pyobj_lines = NULL;
    Mat lines;

    const char* keywords[] = { "points", "whichImage", "F", "lines", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:computeCorrespondEpilines", (char**)keywords, &pyobj_points, &pyobj_whichImage, &pyobj_F, &pyobj_lines) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) &&
        pyopencv_to_safe(pyobj_whichImage, whichImage, ArgInfo("whichImage", 0)) &&
        pyopencv_to_safe(pyobj_F, F, ArgInfo("F", 0)) &&
        pyopencv_to_safe(pyobj_lines, lines, ArgInfo("lines", 1)) )
    {
        ERRWRAP2(cv::computeCorrespondEpilines(points, whichImage, F, lines));
        return pyopencv_from(lines);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_points = NULL;
    UMat points;
    PyObject* pyobj_whichImage = NULL;
    int whichImage=0;
    PyObject* pyobj_F = NULL;
    UMat F;
    PyObject* pyobj_lines = NULL;
    UMat lines;

    const char* keywords[] = { "points", "whichImage", "F", "lines", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:computeCorrespondEpilines", (char**)keywords, &pyobj_points, &pyobj_whichImage, &pyobj_F, &pyobj_lines) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) &&
        pyopencv_to_safe(pyobj_whichImage, whichImage, ArgInfo("whichImage", 0)) &&
        pyopencv_to_safe(pyobj_F, F, ArgInfo("F", 0)) &&
        pyopencv_to_safe(pyobj_lines, lines, ArgInfo("lines", 1)) )
    {
        ERRWRAP2(cv::computeCorrespondEpilines(points, whichImage, F, lines));
        return pyopencv_from(lines);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("computeCorrespondEpilines");

    return NULL;
}

static PyObject* pyopencv_cv_computeECC(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_templateImage = NULL;
    Mat templateImage;
    PyObject* pyobj_inputImage = NULL;
    Mat inputImage;
    PyObject* pyobj_inputMask = NULL;
    Mat inputMask;
    double retval;

    const char* keywords[] = { "templateImage", "inputImage", "inputMask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:computeECC", (char**)keywords, &pyobj_templateImage, &pyobj_inputImage, &pyobj_inputMask) &&
        pyopencv_to_safe(pyobj_templateImage, templateImage, ArgInfo("templateImage", 0)) &&
        pyopencv_to_safe(pyobj_inputImage, inputImage, ArgInfo("inputImage", 0)) &&
        pyopencv_to_safe(pyobj_inputMask, inputMask, ArgInfo("inputMask", 0)) )
    {
        ERRWRAP2(retval = cv::computeECC(templateImage, inputImage, inputMask));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_templateImage = NULL;
    UMat templateImage;
    PyObject* pyobj_inputImage = NULL;
    UMat inputImage;
    PyObject* pyobj_inputMask = NULL;
    UMat inputMask;
    double retval;

    const char* keywords[] = { "templateImage", "inputImage", "inputMask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:computeECC", (char**)keywords, &pyobj_templateImage, &pyobj_inputImage, &pyobj_inputMask) &&
        pyopencv_to_safe(pyobj_templateImage, templateImage, ArgInfo("templateImage", 0)) &&
        pyopencv_to_safe(pyobj_inputImage, inputImage, ArgInfo("inputImage", 0)) &&
        pyopencv_to_safe(pyobj_inputMask, inputMask, ArgInfo("inputMask", 0)) )
    {
        ERRWRAP2(retval = cv::computeECC(templateImage, inputImage, inputMask));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("computeECC");

    return NULL;
}

static PyObject* pyopencv_cv_connectedComponents(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_labels = NULL;
    Mat labels;
    PyObject* pyobj_connectivity = NULL;
    int connectivity=8;
    PyObject* pyobj_ltype = NULL;
    int ltype=CV_32S;
    int retval;

    const char* keywords[] = { "image", "labels", "connectivity", "ltype", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:connectedComponents", (char**)keywords, &pyobj_image, &pyobj_labels, &pyobj_connectivity, &pyobj_ltype) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_labels, labels, ArgInfo("labels", 1)) &&
        pyopencv_to_safe(pyobj_connectivity, connectivity, ArgInfo("connectivity", 0)) &&
        pyopencv_to_safe(pyobj_ltype, ltype, ArgInfo("ltype", 0)) )
    {
        ERRWRAP2(retval = cv::connectedComponents(image, labels, connectivity, ltype));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(labels));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_labels = NULL;
    UMat labels;
    PyObject* pyobj_connectivity = NULL;
    int connectivity=8;
    PyObject* pyobj_ltype = NULL;
    int ltype=CV_32S;
    int retval;

    const char* keywords[] = { "image", "labels", "connectivity", "ltype", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:connectedComponents", (char**)keywords, &pyobj_image, &pyobj_labels, &pyobj_connectivity, &pyobj_ltype) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_labels, labels, ArgInfo("labels", 1)) &&
        pyopencv_to_safe(pyobj_connectivity, connectivity, ArgInfo("connectivity", 0)) &&
        pyopencv_to_safe(pyobj_ltype, ltype, ArgInfo("ltype", 0)) )
    {
        ERRWRAP2(retval = cv::connectedComponents(image, labels, connectivity, ltype));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(labels));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("connectedComponents");

    return NULL;
}

static PyObject* pyopencv_cv_connectedComponentsWithAlgorithm(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_labels = NULL;
    Mat labels;
    PyObject* pyobj_connectivity = NULL;
    int connectivity=0;
    PyObject* pyobj_ltype = NULL;
    int ltype=0;
    PyObject* pyobj_ccltype = NULL;
    int ccltype=0;
    int retval;

    const char* keywords[] = { "image", "connectivity", "ltype", "ccltype", "labels", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:connectedComponentsWithAlgorithm", (char**)keywords, &pyobj_image, &pyobj_connectivity, &pyobj_ltype, &pyobj_ccltype, &pyobj_labels) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_labels, labels, ArgInfo("labels", 1)) &&
        pyopencv_to_safe(pyobj_connectivity, connectivity, ArgInfo("connectivity", 0)) &&
        pyopencv_to_safe(pyobj_ltype, ltype, ArgInfo("ltype", 0)) &&
        pyopencv_to_safe(pyobj_ccltype, ccltype, ArgInfo("ccltype", 0)) )
    {
        ERRWRAP2(retval = cv::connectedComponents(image, labels, connectivity, ltype, ccltype));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(labels));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_labels = NULL;
    UMat labels;
    PyObject* pyobj_connectivity = NULL;
    int connectivity=0;
    PyObject* pyobj_ltype = NULL;
    int ltype=0;
    PyObject* pyobj_ccltype = NULL;
    int ccltype=0;
    int retval;

    const char* keywords[] = { "image", "connectivity", "ltype", "ccltype", "labels", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:connectedComponentsWithAlgorithm", (char**)keywords, &pyobj_image, &pyobj_connectivity, &pyobj_ltype, &pyobj_ccltype, &pyobj_labels) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_labels, labels, ArgInfo("labels", 1)) &&
        pyopencv_to_safe(pyobj_connectivity, connectivity, ArgInfo("connectivity", 0)) &&
        pyopencv_to_safe(pyobj_ltype, ltype, ArgInfo("ltype", 0)) &&
        pyopencv_to_safe(pyobj_ccltype, ccltype, ArgInfo("ccltype", 0)) )
    {
        ERRWRAP2(retval = cv::connectedComponents(image, labels, connectivity, ltype, ccltype));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(labels));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("connectedComponentsWithAlgorithm");

    return NULL;
}

static PyObject* pyopencv_cv_connectedComponentsWithStats(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_labels = NULL;
    Mat labels;
    PyObject* pyobj_stats = NULL;
    Mat stats;
    PyObject* pyobj_centroids = NULL;
    Mat centroids;
    PyObject* pyobj_connectivity = NULL;
    int connectivity=8;
    PyObject* pyobj_ltype = NULL;
    int ltype=CV_32S;
    int retval;

    const char* keywords[] = { "image", "labels", "stats", "centroids", "connectivity", "ltype", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOOO:connectedComponentsWithStats", (char**)keywords, &pyobj_image, &pyobj_labels, &pyobj_stats, &pyobj_centroids, &pyobj_connectivity, &pyobj_ltype) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_labels, labels, ArgInfo("labels", 1)) &&
        pyopencv_to_safe(pyobj_stats, stats, ArgInfo("stats", 1)) &&
        pyopencv_to_safe(pyobj_centroids, centroids, ArgInfo("centroids", 1)) &&
        pyopencv_to_safe(pyobj_connectivity, connectivity, ArgInfo("connectivity", 0)) &&
        pyopencv_to_safe(pyobj_ltype, ltype, ArgInfo("ltype", 0)) )
    {
        ERRWRAP2(retval = cv::connectedComponentsWithStats(image, labels, stats, centroids, connectivity, ltype));
        return Py_BuildValue("(NNNN)", pyopencv_from(retval), pyopencv_from(labels), pyopencv_from(stats), pyopencv_from(centroids));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_labels = NULL;
    UMat labels;
    PyObject* pyobj_stats = NULL;
    UMat stats;
    PyObject* pyobj_centroids = NULL;
    UMat centroids;
    PyObject* pyobj_connectivity = NULL;
    int connectivity=8;
    PyObject* pyobj_ltype = NULL;
    int ltype=CV_32S;
    int retval;

    const char* keywords[] = { "image", "labels", "stats", "centroids", "connectivity", "ltype", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOOO:connectedComponentsWithStats", (char**)keywords, &pyobj_image, &pyobj_labels, &pyobj_stats, &pyobj_centroids, &pyobj_connectivity, &pyobj_ltype) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_labels, labels, ArgInfo("labels", 1)) &&
        pyopencv_to_safe(pyobj_stats, stats, ArgInfo("stats", 1)) &&
        pyopencv_to_safe(pyobj_centroids, centroids, ArgInfo("centroids", 1)) &&
        pyopencv_to_safe(pyobj_connectivity, connectivity, ArgInfo("connectivity", 0)) &&
        pyopencv_to_safe(pyobj_ltype, ltype, ArgInfo("ltype", 0)) )
    {
        ERRWRAP2(retval = cv::connectedComponentsWithStats(image, labels, stats, centroids, connectivity, ltype));
        return Py_BuildValue("(NNNN)", pyopencv_from(retval), pyopencv_from(labels), pyopencv_from(stats), pyopencv_from(centroids));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("connectedComponentsWithStats");

    return NULL;
}

static PyObject* pyopencv_cv_connectedComponentsWithStatsWithAlgorithm(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_labels = NULL;
    Mat labels;
    PyObject* pyobj_stats = NULL;
    Mat stats;
    PyObject* pyobj_centroids = NULL;
    Mat centroids;
    PyObject* pyobj_connectivity = NULL;
    int connectivity=0;
    PyObject* pyobj_ltype = NULL;
    int ltype=0;
    PyObject* pyobj_ccltype = NULL;
    int ccltype=0;
    int retval;

    const char* keywords[] = { "image", "connectivity", "ltype", "ccltype", "labels", "stats", "centroids", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:connectedComponentsWithStatsWithAlgorithm", (char**)keywords, &pyobj_image, &pyobj_connectivity, &pyobj_ltype, &pyobj_ccltype, &pyobj_labels, &pyobj_stats, &pyobj_centroids) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_labels, labels, ArgInfo("labels", 1)) &&
        pyopencv_to_safe(pyobj_stats, stats, ArgInfo("stats", 1)) &&
        pyopencv_to_safe(pyobj_centroids, centroids, ArgInfo("centroids", 1)) &&
        pyopencv_to_safe(pyobj_connectivity, connectivity, ArgInfo("connectivity", 0)) &&
        pyopencv_to_safe(pyobj_ltype, ltype, ArgInfo("ltype", 0)) &&
        pyopencv_to_safe(pyobj_ccltype, ccltype, ArgInfo("ccltype", 0)) )
    {
        ERRWRAP2(retval = cv::connectedComponentsWithStats(image, labels, stats, centroids, connectivity, ltype, ccltype));
        return Py_BuildValue("(NNNN)", pyopencv_from(retval), pyopencv_from(labels), pyopencv_from(stats), pyopencv_from(centroids));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_labels = NULL;
    UMat labels;
    PyObject* pyobj_stats = NULL;
    UMat stats;
    PyObject* pyobj_centroids = NULL;
    UMat centroids;
    PyObject* pyobj_connectivity = NULL;
    int connectivity=0;
    PyObject* pyobj_ltype = NULL;
    int ltype=0;
    PyObject* pyobj_ccltype = NULL;
    int ccltype=0;
    int retval;

    const char* keywords[] = { "image", "connectivity", "ltype", "ccltype", "labels", "stats", "centroids", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:connectedComponentsWithStatsWithAlgorithm", (char**)keywords, &pyobj_image, &pyobj_connectivity, &pyobj_ltype, &pyobj_ccltype, &pyobj_labels, &pyobj_stats, &pyobj_centroids) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_labels, labels, ArgInfo("labels", 1)) &&
        pyopencv_to_safe(pyobj_stats, stats, ArgInfo("stats", 1)) &&
        pyopencv_to_safe(pyobj_centroids, centroids, ArgInfo("centroids", 1)) &&
        pyopencv_to_safe(pyobj_connectivity, connectivity, ArgInfo("connectivity", 0)) &&
        pyopencv_to_safe(pyobj_ltype, ltype, ArgInfo("ltype", 0)) &&
        pyopencv_to_safe(pyobj_ccltype, ccltype, ArgInfo("ccltype", 0)) )
    {
        ERRWRAP2(retval = cv::connectedComponentsWithStats(image, labels, stats, centroids, connectivity, ltype, ccltype));
        return Py_BuildValue("(NNNN)", pyopencv_from(retval), pyopencv_from(labels), pyopencv_from(stats), pyopencv_from(centroids));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("connectedComponentsWithStatsWithAlgorithm");

    return NULL;
}

static PyObject* pyopencv_cv_contourArea(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_contour = NULL;
    Mat contour;
    PyObject* pyobj_oriented = NULL;
    bool oriented=false;
    double retval;

    const char* keywords[] = { "contour", "oriented", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:contourArea", (char**)keywords, &pyobj_contour, &pyobj_oriented) &&
        pyopencv_to_safe(pyobj_contour, contour, ArgInfo("contour", 0)) &&
        pyopencv_to_safe(pyobj_oriented, oriented, ArgInfo("oriented", 0)) )
    {
        ERRWRAP2(retval = cv::contourArea(contour, oriented));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_contour = NULL;
    UMat contour;
    PyObject* pyobj_oriented = NULL;
    bool oriented=false;
    double retval;

    const char* keywords[] = { "contour", "oriented", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:contourArea", (char**)keywords, &pyobj_contour, &pyobj_oriented) &&
        pyopencv_to_safe(pyobj_contour, contour, ArgInfo("contour", 0)) &&
        pyopencv_to_safe(pyobj_oriented, oriented, ArgInfo("oriented", 0)) )
    {
        ERRWRAP2(retval = cv::contourArea(contour, oriented));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("contourArea");

    return NULL;
}

static PyObject* pyopencv_cv_convertFp16(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:convertFp16", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::convertFp16(src, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:convertFp16", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::convertFp16(src, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("convertFp16");

    return NULL;
}

static PyObject* pyopencv_cv_convertMaps(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_map1 = NULL;
    Mat map1;
    PyObject* pyobj_map2 = NULL;
    Mat map2;
    PyObject* pyobj_dstmap1 = NULL;
    Mat dstmap1;
    PyObject* pyobj_dstmap2 = NULL;
    Mat dstmap2;
    PyObject* pyobj_dstmap1type = NULL;
    int dstmap1type=0;
    PyObject* pyobj_nninterpolation = NULL;
    bool nninterpolation=false;

    const char* keywords[] = { "map1", "map2", "dstmap1type", "dstmap1", "dstmap2", "nninterpolation", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:convertMaps", (char**)keywords, &pyobj_map1, &pyobj_map2, &pyobj_dstmap1type, &pyobj_dstmap1, &pyobj_dstmap2, &pyobj_nninterpolation) &&
        pyopencv_to_safe(pyobj_map1, map1, ArgInfo("map1", 0)) &&
        pyopencv_to_safe(pyobj_map2, map2, ArgInfo("map2", 0)) &&
        pyopencv_to_safe(pyobj_dstmap1, dstmap1, ArgInfo("dstmap1", 1)) &&
        pyopencv_to_safe(pyobj_dstmap2, dstmap2, ArgInfo("dstmap2", 1)) &&
        pyopencv_to_safe(pyobj_dstmap1type, dstmap1type, ArgInfo("dstmap1type", 0)) &&
        pyopencv_to_safe(pyobj_nninterpolation, nninterpolation, ArgInfo("nninterpolation", 0)) )
    {
        ERRWRAP2(cv::convertMaps(map1, map2, dstmap1, dstmap2, dstmap1type, nninterpolation));
        return Py_BuildValue("(NN)", pyopencv_from(dstmap1), pyopencv_from(dstmap2));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_map1 = NULL;
    UMat map1;
    PyObject* pyobj_map2 = NULL;
    UMat map2;
    PyObject* pyobj_dstmap1 = NULL;
    UMat dstmap1;
    PyObject* pyobj_dstmap2 = NULL;
    UMat dstmap2;
    PyObject* pyobj_dstmap1type = NULL;
    int dstmap1type=0;
    PyObject* pyobj_nninterpolation = NULL;
    bool nninterpolation=false;

    const char* keywords[] = { "map1", "map2", "dstmap1type", "dstmap1", "dstmap2", "nninterpolation", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:convertMaps", (char**)keywords, &pyobj_map1, &pyobj_map2, &pyobj_dstmap1type, &pyobj_dstmap1, &pyobj_dstmap2, &pyobj_nninterpolation) &&
        pyopencv_to_safe(pyobj_map1, map1, ArgInfo("map1", 0)) &&
        pyopencv_to_safe(pyobj_map2, map2, ArgInfo("map2", 0)) &&
        pyopencv_to_safe(pyobj_dstmap1, dstmap1, ArgInfo("dstmap1", 1)) &&
        pyopencv_to_safe(pyobj_dstmap2, dstmap2, ArgInfo("dstmap2", 1)) &&
        pyopencv_to_safe(pyobj_dstmap1type, dstmap1type, ArgInfo("dstmap1type", 0)) &&
        pyopencv_to_safe(pyobj_nninterpolation, nninterpolation, ArgInfo("nninterpolation", 0)) )
    {
        ERRWRAP2(cv::convertMaps(map1, map2, dstmap1, dstmap2, dstmap1type, nninterpolation));
        return Py_BuildValue("(NN)", pyopencv_from(dstmap1), pyopencv_from(dstmap2));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("convertMaps");

    return NULL;
}

static PyObject* pyopencv_cv_convertPointsFromHomogeneous(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:convertPointsFromHomogeneous", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::convertPointsFromHomogeneous(src, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:convertPointsFromHomogeneous", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::convertPointsFromHomogeneous(src, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("convertPointsFromHomogeneous");

    return NULL;
}

static PyObject* pyopencv_cv_convertPointsToHomogeneous(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:convertPointsToHomogeneous", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::convertPointsToHomogeneous(src, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:convertPointsToHomogeneous", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::convertPointsToHomogeneous(src, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("convertPointsToHomogeneous");

    return NULL;
}

static PyObject* pyopencv_cv_convertScaleAbs(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_alpha = NULL;
    double alpha=1;
    PyObject* pyobj_beta = NULL;
    double beta=0;

    const char* keywords[] = { "src", "dst", "alpha", "beta", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:convertScaleAbs", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_alpha, &pyobj_beta) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_beta, beta, ArgInfo("beta", 0)) )
    {
        ERRWRAP2(cv::convertScaleAbs(src, dst, alpha, beta));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_alpha = NULL;
    double alpha=1;
    PyObject* pyobj_beta = NULL;
    double beta=0;

    const char* keywords[] = { "src", "dst", "alpha", "beta", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:convertScaleAbs", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_alpha, &pyobj_beta) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_beta, beta, ArgInfo("beta", 0)) )
    {
        ERRWRAP2(cv::convertScaleAbs(src, dst, alpha, beta));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("convertScaleAbs");

    return NULL;
}

static PyObject* pyopencv_cv_convexHull(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_points = NULL;
    Mat points;
    PyObject* pyobj_hull = NULL;
    Mat hull;
    PyObject* pyobj_clockwise = NULL;
    bool clockwise=false;
    PyObject* pyobj_returnPoints = NULL;
    bool returnPoints=true;

    const char* keywords[] = { "points", "hull", "clockwise", "returnPoints", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:convexHull", (char**)keywords, &pyobj_points, &pyobj_hull, &pyobj_clockwise, &pyobj_returnPoints) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) &&
        pyopencv_to_safe(pyobj_hull, hull, ArgInfo("hull", 1)) &&
        pyopencv_to_safe(pyobj_clockwise, clockwise, ArgInfo("clockwise", 0)) &&
        pyopencv_to_safe(pyobj_returnPoints, returnPoints, ArgInfo("returnPoints", 0)) )
    {
        ERRWRAP2(cv::convexHull(points, hull, clockwise, returnPoints));
        return pyopencv_from(hull);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_points = NULL;
    UMat points;
    PyObject* pyobj_hull = NULL;
    UMat hull;
    PyObject* pyobj_clockwise = NULL;
    bool clockwise=false;
    PyObject* pyobj_returnPoints = NULL;
    bool returnPoints=true;

    const char* keywords[] = { "points", "hull", "clockwise", "returnPoints", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:convexHull", (char**)keywords, &pyobj_points, &pyobj_hull, &pyobj_clockwise, &pyobj_returnPoints) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) &&
        pyopencv_to_safe(pyobj_hull, hull, ArgInfo("hull", 1)) &&
        pyopencv_to_safe(pyobj_clockwise, clockwise, ArgInfo("clockwise", 0)) &&
        pyopencv_to_safe(pyobj_returnPoints, returnPoints, ArgInfo("returnPoints", 0)) )
    {
        ERRWRAP2(cv::convexHull(points, hull, clockwise, returnPoints));
        return pyopencv_from(hull);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("convexHull");

    return NULL;
}

static PyObject* pyopencv_cv_convexityDefects(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_contour = NULL;
    Mat contour;
    PyObject* pyobj_convexhull = NULL;
    Mat convexhull;
    PyObject* pyobj_convexityDefects = NULL;
    Mat convexityDefects;

    const char* keywords[] = { "contour", "convexhull", "convexityDefects", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:convexityDefects", (char**)keywords, &pyobj_contour, &pyobj_convexhull, &pyobj_convexityDefects) &&
        pyopencv_to_safe(pyobj_contour, contour, ArgInfo("contour", 0)) &&
        pyopencv_to_safe(pyobj_convexhull, convexhull, ArgInfo("convexhull", 0)) &&
        pyopencv_to_safe(pyobj_convexityDefects, convexityDefects, ArgInfo("convexityDefects", 1)) )
    {
        ERRWRAP2(cv::convexityDefects(contour, convexhull, convexityDefects));
        return pyopencv_from(convexityDefects);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_contour = NULL;
    UMat contour;
    PyObject* pyobj_convexhull = NULL;
    UMat convexhull;
    PyObject* pyobj_convexityDefects = NULL;
    UMat convexityDefects;

    const char* keywords[] = { "contour", "convexhull", "convexityDefects", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:convexityDefects", (char**)keywords, &pyobj_contour, &pyobj_convexhull, &pyobj_convexityDefects) &&
        pyopencv_to_safe(pyobj_contour, contour, ArgInfo("contour", 0)) &&
        pyopencv_to_safe(pyobj_convexhull, convexhull, ArgInfo("convexhull", 0)) &&
        pyopencv_to_safe(pyobj_convexityDefects, convexityDefects, ArgInfo("convexityDefects", 1)) )
    {
        ERRWRAP2(cv::convexityDefects(contour, convexhull, convexityDefects));
        return pyopencv_from(convexityDefects);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("convexityDefects");

    return NULL;
}

static PyObject* pyopencv_cv_copyMakeBorder(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_top = NULL;
    int top=0;
    PyObject* pyobj_bottom = NULL;
    int bottom=0;
    PyObject* pyobj_left = NULL;
    int left=0;
    PyObject* pyobj_right = NULL;
    int right=0;
    PyObject* pyobj_borderType = NULL;
    int borderType=0;
    PyObject* pyobj_value = NULL;
    Scalar value;

    const char* keywords[] = { "src", "top", "bottom", "left", "right", "borderType", "dst", "value", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|OO:copyMakeBorder", (char**)keywords, &pyobj_src, &pyobj_top, &pyobj_bottom, &pyobj_left, &pyobj_right, &pyobj_borderType, &pyobj_dst, &pyobj_value) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_top, top, ArgInfo("top", 0)) &&
        pyopencv_to_safe(pyobj_bottom, bottom, ArgInfo("bottom", 0)) &&
        pyopencv_to_safe(pyobj_left, left, ArgInfo("left", 0)) &&
        pyopencv_to_safe(pyobj_right, right, ArgInfo("right", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) &&
        pyopencv_to_safe(pyobj_value, value, ArgInfo("value", 0)) )
    {
        ERRWRAP2(cv::copyMakeBorder(src, dst, top, bottom, left, right, borderType, value));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_top = NULL;
    int top=0;
    PyObject* pyobj_bottom = NULL;
    int bottom=0;
    PyObject* pyobj_left = NULL;
    int left=0;
    PyObject* pyobj_right = NULL;
    int right=0;
    PyObject* pyobj_borderType = NULL;
    int borderType=0;
    PyObject* pyobj_value = NULL;
    Scalar value;

    const char* keywords[] = { "src", "top", "bottom", "left", "right", "borderType", "dst", "value", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|OO:copyMakeBorder", (char**)keywords, &pyobj_src, &pyobj_top, &pyobj_bottom, &pyobj_left, &pyobj_right, &pyobj_borderType, &pyobj_dst, &pyobj_value) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_top, top, ArgInfo("top", 0)) &&
        pyopencv_to_safe(pyobj_bottom, bottom, ArgInfo("bottom", 0)) &&
        pyopencv_to_safe(pyobj_left, left, ArgInfo("left", 0)) &&
        pyopencv_to_safe(pyobj_right, right, ArgInfo("right", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) &&
        pyopencv_to_safe(pyobj_value, value, ArgInfo("value", 0)) )
    {
        ERRWRAP2(cv::copyMakeBorder(src, dst, top, bottom, left, right, borderType, value));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("copyMakeBorder");

    return NULL;
}

static PyObject* pyopencv_cv_copyTo(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_mask = NULL;
    Mat mask;

    const char* keywords[] = { "src", "mask", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:copyTo", (char**)keywords, &pyobj_src, &pyobj_mask, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::copyTo(src, dst, mask));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_mask = NULL;
    UMat mask;

    const char* keywords[] = { "src", "mask", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:copyTo", (char**)keywords, &pyobj_src, &pyobj_mask, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::copyTo(src, dst, mask));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("copyTo");

    return NULL;
}

static PyObject* pyopencv_cv_cornerEigenValsAndVecs(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_blockSize = NULL;
    int blockSize=0;
    PyObject* pyobj_ksize = NULL;
    int ksize=0;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "blockSize", "ksize", "dst", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:cornerEigenValsAndVecs", (char**)keywords, &pyobj_src, &pyobj_blockSize, &pyobj_ksize, &pyobj_dst, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_blockSize, blockSize, ArgInfo("blockSize", 0)) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::cornerEigenValsAndVecs(src, dst, blockSize, ksize, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_blockSize = NULL;
    int blockSize=0;
    PyObject* pyobj_ksize = NULL;
    int ksize=0;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "blockSize", "ksize", "dst", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:cornerEigenValsAndVecs", (char**)keywords, &pyobj_src, &pyobj_blockSize, &pyobj_ksize, &pyobj_dst, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_blockSize, blockSize, ArgInfo("blockSize", 0)) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::cornerEigenValsAndVecs(src, dst, blockSize, ksize, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("cornerEigenValsAndVecs");

    return NULL;
}

static PyObject* pyopencv_cv_cornerHarris(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_blockSize = NULL;
    int blockSize=0;
    PyObject* pyobj_ksize = NULL;
    int ksize=0;
    PyObject* pyobj_k = NULL;
    double k=0;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "blockSize", "ksize", "k", "dst", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OO:cornerHarris", (char**)keywords, &pyobj_src, &pyobj_blockSize, &pyobj_ksize, &pyobj_k, &pyobj_dst, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_blockSize, blockSize, ArgInfo("blockSize", 0)) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) &&
        pyopencv_to_safe(pyobj_k, k, ArgInfo("k", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::cornerHarris(src, dst, blockSize, ksize, k, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_blockSize = NULL;
    int blockSize=0;
    PyObject* pyobj_ksize = NULL;
    int ksize=0;
    PyObject* pyobj_k = NULL;
    double k=0;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "blockSize", "ksize", "k", "dst", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OO:cornerHarris", (char**)keywords, &pyobj_src, &pyobj_blockSize, &pyobj_ksize, &pyobj_k, &pyobj_dst, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_blockSize, blockSize, ArgInfo("blockSize", 0)) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) &&
        pyopencv_to_safe(pyobj_k, k, ArgInfo("k", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::cornerHarris(src, dst, blockSize, ksize, k, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("cornerHarris");

    return NULL;
}

static PyObject* pyopencv_cv_cornerMinEigenVal(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_blockSize = NULL;
    int blockSize=0;
    PyObject* pyobj_ksize = NULL;
    int ksize=3;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "blockSize", "dst", "ksize", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:cornerMinEigenVal", (char**)keywords, &pyobj_src, &pyobj_blockSize, &pyobj_dst, &pyobj_ksize, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_blockSize, blockSize, ArgInfo("blockSize", 0)) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::cornerMinEigenVal(src, dst, blockSize, ksize, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_blockSize = NULL;
    int blockSize=0;
    PyObject* pyobj_ksize = NULL;
    int ksize=3;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "blockSize", "dst", "ksize", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:cornerMinEigenVal", (char**)keywords, &pyobj_src, &pyobj_blockSize, &pyobj_dst, &pyobj_ksize, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_blockSize, blockSize, ArgInfo("blockSize", 0)) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::cornerMinEigenVal(src, dst, blockSize, ksize, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("cornerMinEigenVal");

    return NULL;
}

static PyObject* pyopencv_cv_cornerSubPix(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_corners = NULL;
    Mat corners;
    PyObject* pyobj_winSize = NULL;
    Size winSize;
    PyObject* pyobj_zeroZone = NULL;
    Size zeroZone;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria;

    const char* keywords[] = { "image", "corners", "winSize", "zeroZone", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO:cornerSubPix", (char**)keywords, &pyobj_image, &pyobj_corners, &pyobj_winSize, &pyobj_zeroZone, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 1)) &&
        pyopencv_to_safe(pyobj_winSize, winSize, ArgInfo("winSize", 0)) &&
        pyopencv_to_safe(pyobj_zeroZone, zeroZone, ArgInfo("zeroZone", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(cv::cornerSubPix(image, corners, winSize, zeroZone, criteria));
        return pyopencv_from(corners);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_corners = NULL;
    UMat corners;
    PyObject* pyobj_winSize = NULL;
    Size winSize;
    PyObject* pyobj_zeroZone = NULL;
    Size zeroZone;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria;

    const char* keywords[] = { "image", "corners", "winSize", "zeroZone", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO:cornerSubPix", (char**)keywords, &pyobj_image, &pyobj_corners, &pyobj_winSize, &pyobj_zeroZone, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 1)) &&
        pyopencv_to_safe(pyobj_winSize, winSize, ArgInfo("winSize", 0)) &&
        pyopencv_to_safe(pyobj_zeroZone, zeroZone, ArgInfo("zeroZone", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(cv::cornerSubPix(image, corners, winSize, zeroZone, criteria));
        return pyopencv_from(corners);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("cornerSubPix");

    return NULL;
}

static PyObject* pyopencv_cv_correctMatches(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_F = NULL;
    Mat F;
    PyObject* pyobj_points1 = NULL;
    Mat points1;
    PyObject* pyobj_points2 = NULL;
    Mat points2;
    PyObject* pyobj_newPoints1 = NULL;
    Mat newPoints1;
    PyObject* pyobj_newPoints2 = NULL;
    Mat newPoints2;

    const char* keywords[] = { "F", "points1", "points2", "newPoints1", "newPoints2", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:correctMatches", (char**)keywords, &pyobj_F, &pyobj_points1, &pyobj_points2, &pyobj_newPoints1, &pyobj_newPoints2) &&
        pyopencv_to_safe(pyobj_F, F, ArgInfo("F", 0)) &&
        pyopencv_to_safe(pyobj_points1, points1, ArgInfo("points1", 0)) &&
        pyopencv_to_safe(pyobj_points2, points2, ArgInfo("points2", 0)) &&
        pyopencv_to_safe(pyobj_newPoints1, newPoints1, ArgInfo("newPoints1", 1)) &&
        pyopencv_to_safe(pyobj_newPoints2, newPoints2, ArgInfo("newPoints2", 1)) )
    {
        ERRWRAP2(cv::correctMatches(F, points1, points2, newPoints1, newPoints2));
        return Py_BuildValue("(NN)", pyopencv_from(newPoints1), pyopencv_from(newPoints2));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_F = NULL;
    UMat F;
    PyObject* pyobj_points1 = NULL;
    UMat points1;
    PyObject* pyobj_points2 = NULL;
    UMat points2;
    PyObject* pyobj_newPoints1 = NULL;
    UMat newPoints1;
    PyObject* pyobj_newPoints2 = NULL;
    UMat newPoints2;

    const char* keywords[] = { "F", "points1", "points2", "newPoints1", "newPoints2", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:correctMatches", (char**)keywords, &pyobj_F, &pyobj_points1, &pyobj_points2, &pyobj_newPoints1, &pyobj_newPoints2) &&
        pyopencv_to_safe(pyobj_F, F, ArgInfo("F", 0)) &&
        pyopencv_to_safe(pyobj_points1, points1, ArgInfo("points1", 0)) &&
        pyopencv_to_safe(pyobj_points2, points2, ArgInfo("points2", 0)) &&
        pyopencv_to_safe(pyobj_newPoints1, newPoints1, ArgInfo("newPoints1", 1)) &&
        pyopencv_to_safe(pyobj_newPoints2, newPoints2, ArgInfo("newPoints2", 1)) )
    {
        ERRWRAP2(cv::correctMatches(F, points1, points2, newPoints1, newPoints2));
        return Py_BuildValue("(NN)", pyopencv_from(newPoints1), pyopencv_from(newPoints2));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("correctMatches");

    return NULL;
}

static PyObject* pyopencv_cv_countNonZero(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    int retval;

    const char* keywords[] = { "src", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:countNonZero", (char**)keywords, &pyobj_src) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) )
    {
        ERRWRAP2(retval = cv::countNonZero(src));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    int retval;

    const char* keywords[] = { "src", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:countNonZero", (char**)keywords, &pyobj_src) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) )
    {
        ERRWRAP2(retval = cv::countNonZero(src));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("countNonZero");

    return NULL;
}

static PyObject* pyopencv_cv_createAffineTransformer(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_fullAffine = NULL;
    bool fullAffine=0;
    Ptr<AffineTransformer> retval;

    const char* keywords[] = { "fullAffine", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:createAffineTransformer", (char**)keywords, &pyobj_fullAffine) &&
        pyopencv_to_safe(pyobj_fullAffine, fullAffine, ArgInfo("fullAffine", 0)) )
    {
        ERRWRAP2(retval = cv::createAffineTransformer(fullAffine));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_createAlignMTB(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_max_bits = NULL;
    int max_bits=6;
    PyObject* pyobj_exclude_range = NULL;
    int exclude_range=4;
    PyObject* pyobj_cut = NULL;
    bool cut=true;
    Ptr<AlignMTB> retval;

    const char* keywords[] = { "max_bits", "exclude_range", "cut", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOO:createAlignMTB", (char**)keywords, &pyobj_max_bits, &pyobj_exclude_range, &pyobj_cut) &&
        pyopencv_to_safe(pyobj_max_bits, max_bits, ArgInfo("max_bits", 0)) &&
        pyopencv_to_safe(pyobj_exclude_range, exclude_range, ArgInfo("exclude_range", 0)) &&
        pyopencv_to_safe(pyobj_cut, cut, ArgInfo("cut", 0)) )
    {
        ERRWRAP2(retval = cv::createAlignMTB(max_bits, exclude_range, cut));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_createBackgroundSubtractorKNN(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_history = NULL;
    int history=500;
    PyObject* pyobj_dist2Threshold = NULL;
    double dist2Threshold=400.0;
    PyObject* pyobj_detectShadows = NULL;
    bool detectShadows=true;
    Ptr<BackgroundSubtractorKNN> retval;

    const char* keywords[] = { "history", "dist2Threshold", "detectShadows", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOO:createBackgroundSubtractorKNN", (char**)keywords, &pyobj_history, &pyobj_dist2Threshold, &pyobj_detectShadows) &&
        pyopencv_to_safe(pyobj_history, history, ArgInfo("history", 0)) &&
        pyopencv_to_safe(pyobj_dist2Threshold, dist2Threshold, ArgInfo("dist2Threshold", 0)) &&
        pyopencv_to_safe(pyobj_detectShadows, detectShadows, ArgInfo("detectShadows", 0)) )
    {
        ERRWRAP2(retval = cv::createBackgroundSubtractorKNN(history, dist2Threshold, detectShadows));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_createBackgroundSubtractorMOG2(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_history = NULL;
    int history=500;
    PyObject* pyobj_varThreshold = NULL;
    double varThreshold=16;
    PyObject* pyobj_detectShadows = NULL;
    bool detectShadows=true;
    Ptr<BackgroundSubtractorMOG2> retval;

    const char* keywords[] = { "history", "varThreshold", "detectShadows", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOO:createBackgroundSubtractorMOG2", (char**)keywords, &pyobj_history, &pyobj_varThreshold, &pyobj_detectShadows) &&
        pyopencv_to_safe(pyobj_history, history, ArgInfo("history", 0)) &&
        pyopencv_to_safe(pyobj_varThreshold, varThreshold, ArgInfo("varThreshold", 0)) &&
        pyopencv_to_safe(pyobj_detectShadows, detectShadows, ArgInfo("detectShadows", 0)) )
    {
        ERRWRAP2(retval = cv::createBackgroundSubtractorMOG2(history, varThreshold, detectShadows));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_createCLAHE(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_clipLimit = NULL;
    double clipLimit=40.0;
    PyObject* pyobj_tileGridSize = NULL;
    Size tileGridSize=Size(8, 8);
    Ptr<CLAHE> retval;

    const char* keywords[] = { "clipLimit", "tileGridSize", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OO:createCLAHE", (char**)keywords, &pyobj_clipLimit, &pyobj_tileGridSize) &&
        pyopencv_to_safe(pyobj_clipLimit, clipLimit, ArgInfo("clipLimit", 0)) &&
        pyopencv_to_safe(pyobj_tileGridSize, tileGridSize, ArgInfo("tileGridSize", 0)) )
    {
        ERRWRAP2(retval = cv::createCLAHE(clipLimit, tileGridSize));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_createCalibrateDebevec(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_samples = NULL;
    int samples=70;
    PyObject* pyobj_lambda = NULL;
    float lambda=10.0f;
    PyObject* pyobj_random = NULL;
    bool random=false;
    Ptr<CalibrateDebevec> retval;

    const char* keywords[] = { "samples", "lambda", "random", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOO:createCalibrateDebevec", (char**)keywords, &pyobj_samples, &pyobj_lambda, &pyobj_random) &&
        pyopencv_to_safe(pyobj_samples, samples, ArgInfo("samples", 0)) &&
        pyopencv_to_safe(pyobj_lambda, lambda, ArgInfo("lambda", 0)) &&
        pyopencv_to_safe(pyobj_random, random, ArgInfo("random", 0)) )
    {
        ERRWRAP2(retval = cv::createCalibrateDebevec(samples, lambda, random));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_createCalibrateRobertson(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_max_iter = NULL;
    int max_iter=30;
    PyObject* pyobj_threshold = NULL;
    float threshold=0.01f;
    Ptr<CalibrateRobertson> retval;

    const char* keywords[] = { "max_iter", "threshold", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OO:createCalibrateRobertson", (char**)keywords, &pyobj_max_iter, &pyobj_threshold) &&
        pyopencv_to_safe(pyobj_max_iter, max_iter, ArgInfo("max_iter", 0)) &&
        pyopencv_to_safe(pyobj_threshold, threshold, ArgInfo("threshold", 0)) )
    {
        ERRWRAP2(retval = cv::createCalibrateRobertson(max_iter, threshold));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_createChiHistogramCostExtractor(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_nDummies = NULL;
    int nDummies=25;
    PyObject* pyobj_defaultCost = NULL;
    float defaultCost=0.2f;
    Ptr<HistogramCostExtractor> retval;

    const char* keywords[] = { "nDummies", "defaultCost", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OO:createChiHistogramCostExtractor", (char**)keywords, &pyobj_nDummies, &pyobj_defaultCost) &&
        pyopencv_to_safe(pyobj_nDummies, nDummies, ArgInfo("nDummies", 0)) &&
        pyopencv_to_safe(pyobj_defaultCost, defaultCost, ArgInfo("defaultCost", 0)) )
    {
        ERRWRAP2(retval = cv::createChiHistogramCostExtractor(nDummies, defaultCost));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_createEMDHistogramCostExtractor(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_flag = NULL;
    int flag=DIST_L2;
    PyObject* pyobj_nDummies = NULL;
    int nDummies=25;
    PyObject* pyobj_defaultCost = NULL;
    float defaultCost=0.2f;
    Ptr<HistogramCostExtractor> retval;

    const char* keywords[] = { "flag", "nDummies", "defaultCost", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOO:createEMDHistogramCostExtractor", (char**)keywords, &pyobj_flag, &pyobj_nDummies, &pyobj_defaultCost) &&
        pyopencv_to_safe(pyobj_flag, flag, ArgInfo("flag", 0)) &&
        pyopencv_to_safe(pyobj_nDummies, nDummies, ArgInfo("nDummies", 0)) &&
        pyopencv_to_safe(pyobj_defaultCost, defaultCost, ArgInfo("defaultCost", 0)) )
    {
        ERRWRAP2(retval = cv::createEMDHistogramCostExtractor(flag, nDummies, defaultCost));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_createEMDL1HistogramCostExtractor(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_nDummies = NULL;
    int nDummies=25;
    PyObject* pyobj_defaultCost = NULL;
    float defaultCost=0.2f;
    Ptr<HistogramCostExtractor> retval;

    const char* keywords[] = { "nDummies", "defaultCost", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OO:createEMDL1HistogramCostExtractor", (char**)keywords, &pyobj_nDummies, &pyobj_defaultCost) &&
        pyopencv_to_safe(pyobj_nDummies, nDummies, ArgInfo("nDummies", 0)) &&
        pyopencv_to_safe(pyobj_defaultCost, defaultCost, ArgInfo("defaultCost", 0)) )
    {
        ERRWRAP2(retval = cv::createEMDL1HistogramCostExtractor(nDummies, defaultCost));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_createGeneralizedHoughBallard(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    Ptr<GeneralizedHoughBallard> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::createGeneralizedHoughBallard());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_createGeneralizedHoughGuil(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    Ptr<GeneralizedHoughGuil> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::createGeneralizedHoughGuil());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_createHanningWindow(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_winSize = NULL;
    Size winSize;
    PyObject* pyobj_type = NULL;
    int type=0;

    const char* keywords[] = { "winSize", "type", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:createHanningWindow", (char**)keywords, &pyobj_winSize, &pyobj_type, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_winSize, winSize, ArgInfo("winSize", 0)) &&
        pyopencv_to_safe(pyobj_type, type, ArgInfo("type", 0)) )
    {
        ERRWRAP2(cv::createHanningWindow(dst, winSize, type));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_winSize = NULL;
    Size winSize;
    PyObject* pyobj_type = NULL;
    int type=0;

    const char* keywords[] = { "winSize", "type", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:createHanningWindow", (char**)keywords, &pyobj_winSize, &pyobj_type, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_winSize, winSize, ArgInfo("winSize", 0)) &&
        pyopencv_to_safe(pyobj_type, type, ArgInfo("type", 0)) )
    {
        ERRWRAP2(cv::createHanningWindow(dst, winSize, type));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("createHanningWindow");

    return NULL;
}

static PyObject* pyopencv_cv_createHausdorffDistanceExtractor(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_distanceFlag = NULL;
    int distanceFlag=cv::NORM_L2;
    PyObject* pyobj_rankProp = NULL;
    float rankProp=0.6f;
    Ptr<HausdorffDistanceExtractor> retval;

    const char* keywords[] = { "distanceFlag", "rankProp", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OO:createHausdorffDistanceExtractor", (char**)keywords, &pyobj_distanceFlag, &pyobj_rankProp) &&
        pyopencv_to_safe(pyobj_distanceFlag, distanceFlag, ArgInfo("distanceFlag", 0)) &&
        pyopencv_to_safe(pyobj_rankProp, rankProp, ArgInfo("rankProp", 0)) )
    {
        ERRWRAP2(retval = cv::createHausdorffDistanceExtractor(distanceFlag, rankProp));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_createLineSegmentDetector(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj__refine = NULL;
    int _refine=LSD_REFINE_STD;
    PyObject* pyobj__scale = NULL;
    double _scale=0.8;
    PyObject* pyobj__sigma_scale = NULL;
    double _sigma_scale=0.6;
    PyObject* pyobj__quant = NULL;
    double _quant=2.0;
    PyObject* pyobj__ang_th = NULL;
    double _ang_th=22.5;
    PyObject* pyobj__log_eps = NULL;
    double _log_eps=0;
    PyObject* pyobj__density_th = NULL;
    double _density_th=0.7;
    PyObject* pyobj__n_bins = NULL;
    int _n_bins=1024;
    Ptr<LineSegmentDetector> retval;

    const char* keywords[] = { "_refine", "_scale", "_sigma_scale", "_quant", "_ang_th", "_log_eps", "_density_th", "_n_bins", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOOOOO:createLineSegmentDetector", (char**)keywords, &pyobj__refine, &pyobj__scale, &pyobj__sigma_scale, &pyobj__quant, &pyobj__ang_th, &pyobj__log_eps, &pyobj__density_th, &pyobj__n_bins) &&
        pyopencv_to_safe(pyobj__refine, _refine, ArgInfo("_refine", 0)) &&
        pyopencv_to_safe(pyobj__scale, _scale, ArgInfo("_scale", 0)) &&
        pyopencv_to_safe(pyobj__sigma_scale, _sigma_scale, ArgInfo("_sigma_scale", 0)) &&
        pyopencv_to_safe(pyobj__quant, _quant, ArgInfo("_quant", 0)) &&
        pyopencv_to_safe(pyobj__ang_th, _ang_th, ArgInfo("_ang_th", 0)) &&
        pyopencv_to_safe(pyobj__log_eps, _log_eps, ArgInfo("_log_eps", 0)) &&
        pyopencv_to_safe(pyobj__density_th, _density_th, ArgInfo("_density_th", 0)) &&
        pyopencv_to_safe(pyobj__n_bins, _n_bins, ArgInfo("_n_bins", 0)) )
    {
        ERRWRAP2(retval = cv::createLineSegmentDetector(_refine, _scale, _sigma_scale, _quant, _ang_th, _log_eps, _density_th, _n_bins));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_createMergeDebevec(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    Ptr<MergeDebevec> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::createMergeDebevec());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_createMergeMertens(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_contrast_weight = NULL;
    float contrast_weight=1.0f;
    PyObject* pyobj_saturation_weight = NULL;
    float saturation_weight=1.0f;
    PyObject* pyobj_exposure_weight = NULL;
    float exposure_weight=0.0f;
    Ptr<MergeMertens> retval;

    const char* keywords[] = { "contrast_weight", "saturation_weight", "exposure_weight", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOO:createMergeMertens", (char**)keywords, &pyobj_contrast_weight, &pyobj_saturation_weight, &pyobj_exposure_weight) &&
        pyopencv_to_safe(pyobj_contrast_weight, contrast_weight, ArgInfo("contrast_weight", 0)) &&
        pyopencv_to_safe(pyobj_saturation_weight, saturation_weight, ArgInfo("saturation_weight", 0)) &&
        pyopencv_to_safe(pyobj_exposure_weight, exposure_weight, ArgInfo("exposure_weight", 0)) )
    {
        ERRWRAP2(retval = cv::createMergeMertens(contrast_weight, saturation_weight, exposure_weight));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_createMergeRobertson(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    Ptr<MergeRobertson> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::createMergeRobertson());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_createNormHistogramCostExtractor(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_flag = NULL;
    int flag=DIST_L2;
    PyObject* pyobj_nDummies = NULL;
    int nDummies=25;
    PyObject* pyobj_defaultCost = NULL;
    float defaultCost=0.2f;
    Ptr<HistogramCostExtractor> retval;

    const char* keywords[] = { "flag", "nDummies", "defaultCost", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOO:createNormHistogramCostExtractor", (char**)keywords, &pyobj_flag, &pyobj_nDummies, &pyobj_defaultCost) &&
        pyopencv_to_safe(pyobj_flag, flag, ArgInfo("flag", 0)) &&
        pyopencv_to_safe(pyobj_nDummies, nDummies, ArgInfo("nDummies", 0)) &&
        pyopencv_to_safe(pyobj_defaultCost, defaultCost, ArgInfo("defaultCost", 0)) )
    {
        ERRWRAP2(retval = cv::createNormHistogramCostExtractor(flag, nDummies, defaultCost));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_createShapeContextDistanceExtractor(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_nAngularBins = NULL;
    int nAngularBins=12;
    PyObject* pyobj_nRadialBins = NULL;
    int nRadialBins=4;
    PyObject* pyobj_innerRadius = NULL;
    float innerRadius=0.2f;
    PyObject* pyobj_outerRadius = NULL;
    float outerRadius=2;
    PyObject* pyobj_iterations = NULL;
    int iterations=3;
    PyObject* pyobj_comparer = NULL;
    Ptr<HistogramCostExtractor> comparer=createChiHistogramCostExtractor();
    PyObject* pyobj_transformer = NULL;
    Ptr<ShapeTransformer> transformer=createThinPlateSplineShapeTransformer();
    Ptr<ShapeContextDistanceExtractor> retval;

    const char* keywords[] = { "nAngularBins", "nRadialBins", "innerRadius", "outerRadius", "iterations", "comparer", "transformer", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOOOO:createShapeContextDistanceExtractor", (char**)keywords, &pyobj_nAngularBins, &pyobj_nRadialBins, &pyobj_innerRadius, &pyobj_outerRadius, &pyobj_iterations, &pyobj_comparer, &pyobj_transformer) &&
        pyopencv_to_safe(pyobj_nAngularBins, nAngularBins, ArgInfo("nAngularBins", 0)) &&
        pyopencv_to_safe(pyobj_nRadialBins, nRadialBins, ArgInfo("nRadialBins", 0)) &&
        pyopencv_to_safe(pyobj_innerRadius, innerRadius, ArgInfo("innerRadius", 0)) &&
        pyopencv_to_safe(pyobj_outerRadius, outerRadius, ArgInfo("outerRadius", 0)) &&
        pyopencv_to_safe(pyobj_iterations, iterations, ArgInfo("iterations", 0)) &&
        pyopencv_to_safe(pyobj_comparer, comparer, ArgInfo("comparer", 0)) &&
        pyopencv_to_safe(pyobj_transformer, transformer, ArgInfo("transformer", 0)) )
    {
        ERRWRAP2(retval = cv::createShapeContextDistanceExtractor(nAngularBins, nRadialBins, innerRadius, outerRadius, iterations, comparer, transformer));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_createThinPlateSplineShapeTransformer(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_regularizationParameter = NULL;
    double regularizationParameter=0;
    Ptr<ThinPlateSplineShapeTransformer> retval;

    const char* keywords[] = { "regularizationParameter", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|O:createThinPlateSplineShapeTransformer", (char**)keywords, &pyobj_regularizationParameter) &&
        pyopencv_to_safe(pyobj_regularizationParameter, regularizationParameter, ArgInfo("regularizationParameter", 0)) )
    {
        ERRWRAP2(retval = cv::createThinPlateSplineShapeTransformer(regularizationParameter));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_createTonemap(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_gamma = NULL;
    float gamma=1.0f;
    Ptr<Tonemap> retval;

    const char* keywords[] = { "gamma", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|O:createTonemap", (char**)keywords, &pyobj_gamma) &&
        pyopencv_to_safe(pyobj_gamma, gamma, ArgInfo("gamma", 0)) )
    {
        ERRWRAP2(retval = cv::createTonemap(gamma));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_createTonemapDrago(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_gamma = NULL;
    float gamma=1.0f;
    PyObject* pyobj_saturation = NULL;
    float saturation=1.0f;
    PyObject* pyobj_bias = NULL;
    float bias=0.85f;
    Ptr<TonemapDrago> retval;

    const char* keywords[] = { "gamma", "saturation", "bias", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOO:createTonemapDrago", (char**)keywords, &pyobj_gamma, &pyobj_saturation, &pyobj_bias) &&
        pyopencv_to_safe(pyobj_gamma, gamma, ArgInfo("gamma", 0)) &&
        pyopencv_to_safe(pyobj_saturation, saturation, ArgInfo("saturation", 0)) &&
        pyopencv_to_safe(pyobj_bias, bias, ArgInfo("bias", 0)) )
    {
        ERRWRAP2(retval = cv::createTonemapDrago(gamma, saturation, bias));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_createTonemapMantiuk(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_gamma = NULL;
    float gamma=1.0f;
    PyObject* pyobj_scale = NULL;
    float scale=0.7f;
    PyObject* pyobj_saturation = NULL;
    float saturation=1.0f;
    Ptr<TonemapMantiuk> retval;

    const char* keywords[] = { "gamma", "scale", "saturation", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOO:createTonemapMantiuk", (char**)keywords, &pyobj_gamma, &pyobj_scale, &pyobj_saturation) &&
        pyopencv_to_safe(pyobj_gamma, gamma, ArgInfo("gamma", 0)) &&
        pyopencv_to_safe(pyobj_scale, scale, ArgInfo("scale", 0)) &&
        pyopencv_to_safe(pyobj_saturation, saturation, ArgInfo("saturation", 0)) )
    {
        ERRWRAP2(retval = cv::createTonemapMantiuk(gamma, scale, saturation));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_createTonemapReinhard(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_gamma = NULL;
    float gamma=1.0f;
    PyObject* pyobj_intensity = NULL;
    float intensity=0.0f;
    PyObject* pyobj_light_adapt = NULL;
    float light_adapt=1.0f;
    PyObject* pyobj_color_adapt = NULL;
    float color_adapt=0.0f;
    Ptr<TonemapReinhard> retval;

    const char* keywords[] = { "gamma", "intensity", "light_adapt", "color_adapt", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOO:createTonemapReinhard", (char**)keywords, &pyobj_gamma, &pyobj_intensity, &pyobj_light_adapt, &pyobj_color_adapt) &&
        pyopencv_to_safe(pyobj_gamma, gamma, ArgInfo("gamma", 0)) &&
        pyopencv_to_safe(pyobj_intensity, intensity, ArgInfo("intensity", 0)) &&
        pyopencv_to_safe(pyobj_light_adapt, light_adapt, ArgInfo("light_adapt", 0)) &&
        pyopencv_to_safe(pyobj_color_adapt, color_adapt, ArgInfo("color_adapt", 0)) )
    {
        ERRWRAP2(retval = cv::createTonemapReinhard(gamma, intensity, light_adapt, color_adapt));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_cubeRoot(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_val = NULL;
    float val=0.f;
    float retval;

    const char* keywords[] = { "val", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:cubeRoot", (char**)keywords, &pyobj_val) &&
        pyopencv_to_safe(pyobj_val, val, ArgInfo("val", 0)) )
    {
        ERRWRAP2(retval = cv::cubeRoot(val));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_cvtColor(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_code = NULL;
    int code=0;
    PyObject* pyobj_dstCn = NULL;
    int dstCn=0;

    const char* keywords[] = { "src", "code", "dst", "dstCn", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:cvtColor", (char**)keywords, &pyobj_src, &pyobj_code, &pyobj_dst, &pyobj_dstCn) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_code, code, ArgInfo("code", 0)) &&
        pyopencv_to_safe(pyobj_dstCn, dstCn, ArgInfo("dstCn", 0)) )
    {
        ERRWRAP2(cv::cvtColor(src, dst, code, dstCn));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_code = NULL;
    int code=0;
    PyObject* pyobj_dstCn = NULL;
    int dstCn=0;

    const char* keywords[] = { "src", "code", "dst", "dstCn", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:cvtColor", (char**)keywords, &pyobj_src, &pyobj_code, &pyobj_dst, &pyobj_dstCn) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_code, code, ArgInfo("code", 0)) &&
        pyopencv_to_safe(pyobj_dstCn, dstCn, ArgInfo("dstCn", 0)) )
    {
        ERRWRAP2(cv::cvtColor(src, dst, code, dstCn));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("cvtColor");

    return NULL;
}

static PyObject* pyopencv_cv_cvtColorTwoPlane(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src1 = NULL;
    Mat src1;
    PyObject* pyobj_src2 = NULL;
    Mat src2;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_code = NULL;
    int code=0;

    const char* keywords[] = { "src1", "src2", "code", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:cvtColorTwoPlane", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_code, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_code, code, ArgInfo("code", 0)) )
    {
        ERRWRAP2(cv::cvtColorTwoPlane(src1, src2, dst, code));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src1 = NULL;
    UMat src1;
    PyObject* pyobj_src2 = NULL;
    UMat src2;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_code = NULL;
    int code=0;

    const char* keywords[] = { "src1", "src2", "code", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:cvtColorTwoPlane", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_code, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_code, code, ArgInfo("code", 0)) )
    {
        ERRWRAP2(cv::cvtColorTwoPlane(src1, src2, dst, code));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("cvtColorTwoPlane");

    return NULL;
}

static PyObject* pyopencv_cv_dct(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_flags = NULL;
    int flags=0;

    const char* keywords[] = { "src", "dst", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:dct", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::dct(src, dst, flags));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_flags = NULL;
    int flags=0;

    const char* keywords[] = { "src", "dst", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:dct", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::dct(src, dst, flags));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("dct");

    return NULL;
}

static PyObject* pyopencv_cv_decolor(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_grayscale = NULL;
    Mat grayscale;
    PyObject* pyobj_color_boost = NULL;
    Mat color_boost;

    const char* keywords[] = { "src", "grayscale", "color_boost", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:decolor", (char**)keywords, &pyobj_src, &pyobj_grayscale, &pyobj_color_boost) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_grayscale, grayscale, ArgInfo("grayscale", 1)) &&
        pyopencv_to_safe(pyobj_color_boost, color_boost, ArgInfo("color_boost", 1)) )
    {
        ERRWRAP2(cv::decolor(src, grayscale, color_boost));
        return Py_BuildValue("(NN)", pyopencv_from(grayscale), pyopencv_from(color_boost));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_grayscale = NULL;
    UMat grayscale;
    PyObject* pyobj_color_boost = NULL;
    UMat color_boost;

    const char* keywords[] = { "src", "grayscale", "color_boost", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:decolor", (char**)keywords, &pyobj_src, &pyobj_grayscale, &pyobj_color_boost) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_grayscale, grayscale, ArgInfo("grayscale", 1)) &&
        pyopencv_to_safe(pyobj_color_boost, color_boost, ArgInfo("color_boost", 1)) )
    {
        ERRWRAP2(cv::decolor(src, grayscale, color_boost));
        return Py_BuildValue("(NN)", pyopencv_from(grayscale), pyopencv_from(color_boost));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("decolor");

    return NULL;
}

static PyObject* pyopencv_cv_decomposeEssentialMat(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_E = NULL;
    Mat E;
    PyObject* pyobj_R1 = NULL;
    Mat R1;
    PyObject* pyobj_R2 = NULL;
    Mat R2;
    PyObject* pyobj_t = NULL;
    Mat t;

    const char* keywords[] = { "E", "R1", "R2", "t", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:decomposeEssentialMat", (char**)keywords, &pyobj_E, &pyobj_R1, &pyobj_R2, &pyobj_t) &&
        pyopencv_to_safe(pyobj_E, E, ArgInfo("E", 0)) &&
        pyopencv_to_safe(pyobj_R1, R1, ArgInfo("R1", 1)) &&
        pyopencv_to_safe(pyobj_R2, R2, ArgInfo("R2", 1)) &&
        pyopencv_to_safe(pyobj_t, t, ArgInfo("t", 1)) )
    {
        ERRWRAP2(cv::decomposeEssentialMat(E, R1, R2, t));
        return Py_BuildValue("(NNN)", pyopencv_from(R1), pyopencv_from(R2), pyopencv_from(t));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_E = NULL;
    UMat E;
    PyObject* pyobj_R1 = NULL;
    UMat R1;
    PyObject* pyobj_R2 = NULL;
    UMat R2;
    PyObject* pyobj_t = NULL;
    UMat t;

    const char* keywords[] = { "E", "R1", "R2", "t", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:decomposeEssentialMat", (char**)keywords, &pyobj_E, &pyobj_R1, &pyobj_R2, &pyobj_t) &&
        pyopencv_to_safe(pyobj_E, E, ArgInfo("E", 0)) &&
        pyopencv_to_safe(pyobj_R1, R1, ArgInfo("R1", 1)) &&
        pyopencv_to_safe(pyobj_R2, R2, ArgInfo("R2", 1)) &&
        pyopencv_to_safe(pyobj_t, t, ArgInfo("t", 1)) )
    {
        ERRWRAP2(cv::decomposeEssentialMat(E, R1, R2, t));
        return Py_BuildValue("(NNN)", pyopencv_from(R1), pyopencv_from(R2), pyopencv_from(t));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("decomposeEssentialMat");

    return NULL;
}

static PyObject* pyopencv_cv_decomposeHomographyMat(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_H = NULL;
    Mat H;
    PyObject* pyobj_K = NULL;
    Mat K;
    PyObject* pyobj_rotations = NULL;
    vector_Mat rotations;
    PyObject* pyobj_translations = NULL;
    vector_Mat translations;
    PyObject* pyobj_normals = NULL;
    vector_Mat normals;
    int retval;

    const char* keywords[] = { "H", "K", "rotations", "translations", "normals", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:decomposeHomographyMat", (char**)keywords, &pyobj_H, &pyobj_K, &pyobj_rotations, &pyobj_translations, &pyobj_normals) &&
        pyopencv_to_safe(pyobj_H, H, ArgInfo("H", 0)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_rotations, rotations, ArgInfo("rotations", 1)) &&
        pyopencv_to_safe(pyobj_translations, translations, ArgInfo("translations", 1)) &&
        pyopencv_to_safe(pyobj_normals, normals, ArgInfo("normals", 1)) )
    {
        ERRWRAP2(retval = cv::decomposeHomographyMat(H, K, rotations, translations, normals));
        return Py_BuildValue("(NNNN)", pyopencv_from(retval), pyopencv_from(rotations), pyopencv_from(translations), pyopencv_from(normals));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_H = NULL;
    UMat H;
    PyObject* pyobj_K = NULL;
    UMat K;
    PyObject* pyobj_rotations = NULL;
    vector_UMat rotations;
    PyObject* pyobj_translations = NULL;
    vector_UMat translations;
    PyObject* pyobj_normals = NULL;
    vector_UMat normals;
    int retval;

    const char* keywords[] = { "H", "K", "rotations", "translations", "normals", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:decomposeHomographyMat", (char**)keywords, &pyobj_H, &pyobj_K, &pyobj_rotations, &pyobj_translations, &pyobj_normals) &&
        pyopencv_to_safe(pyobj_H, H, ArgInfo("H", 0)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_rotations, rotations, ArgInfo("rotations", 1)) &&
        pyopencv_to_safe(pyobj_translations, translations, ArgInfo("translations", 1)) &&
        pyopencv_to_safe(pyobj_normals, normals, ArgInfo("normals", 1)) )
    {
        ERRWRAP2(retval = cv::decomposeHomographyMat(H, K, rotations, translations, normals));
        return Py_BuildValue("(NNNN)", pyopencv_from(retval), pyopencv_from(rotations), pyopencv_from(translations), pyopencv_from(normals));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("decomposeHomographyMat");

    return NULL;
}

static PyObject* pyopencv_cv_decomposeProjectionMatrix(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_projMatrix = NULL;
    Mat projMatrix;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_rotMatrix = NULL;
    Mat rotMatrix;
    PyObject* pyobj_transVect = NULL;
    Mat transVect;
    PyObject* pyobj_rotMatrixX = NULL;
    Mat rotMatrixX;
    PyObject* pyobj_rotMatrixY = NULL;
    Mat rotMatrixY;
    PyObject* pyobj_rotMatrixZ = NULL;
    Mat rotMatrixZ;
    PyObject* pyobj_eulerAngles = NULL;
    Mat eulerAngles;

    const char* keywords[] = { "projMatrix", "cameraMatrix", "rotMatrix", "transVect", "rotMatrixX", "rotMatrixY", "rotMatrixZ", "eulerAngles", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOOOOO:decomposeProjectionMatrix", (char**)keywords, &pyobj_projMatrix, &pyobj_cameraMatrix, &pyobj_rotMatrix, &pyobj_transVect, &pyobj_rotMatrixX, &pyobj_rotMatrixY, &pyobj_rotMatrixZ, &pyobj_eulerAngles) &&
        pyopencv_to_safe(pyobj_projMatrix, projMatrix, ArgInfo("projMatrix", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 1)) &&
        pyopencv_to_safe(pyobj_rotMatrix, rotMatrix, ArgInfo("rotMatrix", 1)) &&
        pyopencv_to_safe(pyobj_transVect, transVect, ArgInfo("transVect", 1)) &&
        pyopencv_to_safe(pyobj_rotMatrixX, rotMatrixX, ArgInfo("rotMatrixX", 1)) &&
        pyopencv_to_safe(pyobj_rotMatrixY, rotMatrixY, ArgInfo("rotMatrixY", 1)) &&
        pyopencv_to_safe(pyobj_rotMatrixZ, rotMatrixZ, ArgInfo("rotMatrixZ", 1)) &&
        pyopencv_to_safe(pyobj_eulerAngles, eulerAngles, ArgInfo("eulerAngles", 1)) )
    {
        ERRWRAP2(cv::decomposeProjectionMatrix(projMatrix, cameraMatrix, rotMatrix, transVect, rotMatrixX, rotMatrixY, rotMatrixZ, eulerAngles));
        return Py_BuildValue("(NNNNNNN)", pyopencv_from(cameraMatrix), pyopencv_from(rotMatrix), pyopencv_from(transVect), pyopencv_from(rotMatrixX), pyopencv_from(rotMatrixY), pyopencv_from(rotMatrixZ), pyopencv_from(eulerAngles));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_projMatrix = NULL;
    UMat projMatrix;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_rotMatrix = NULL;
    UMat rotMatrix;
    PyObject* pyobj_transVect = NULL;
    UMat transVect;
    PyObject* pyobj_rotMatrixX = NULL;
    UMat rotMatrixX;
    PyObject* pyobj_rotMatrixY = NULL;
    UMat rotMatrixY;
    PyObject* pyobj_rotMatrixZ = NULL;
    UMat rotMatrixZ;
    PyObject* pyobj_eulerAngles = NULL;
    UMat eulerAngles;

    const char* keywords[] = { "projMatrix", "cameraMatrix", "rotMatrix", "transVect", "rotMatrixX", "rotMatrixY", "rotMatrixZ", "eulerAngles", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOOOOO:decomposeProjectionMatrix", (char**)keywords, &pyobj_projMatrix, &pyobj_cameraMatrix, &pyobj_rotMatrix, &pyobj_transVect, &pyobj_rotMatrixX, &pyobj_rotMatrixY, &pyobj_rotMatrixZ, &pyobj_eulerAngles) &&
        pyopencv_to_safe(pyobj_projMatrix, projMatrix, ArgInfo("projMatrix", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 1)) &&
        pyopencv_to_safe(pyobj_rotMatrix, rotMatrix, ArgInfo("rotMatrix", 1)) &&
        pyopencv_to_safe(pyobj_transVect, transVect, ArgInfo("transVect", 1)) &&
        pyopencv_to_safe(pyobj_rotMatrixX, rotMatrixX, ArgInfo("rotMatrixX", 1)) &&
        pyopencv_to_safe(pyobj_rotMatrixY, rotMatrixY, ArgInfo("rotMatrixY", 1)) &&
        pyopencv_to_safe(pyobj_rotMatrixZ, rotMatrixZ, ArgInfo("rotMatrixZ", 1)) &&
        pyopencv_to_safe(pyobj_eulerAngles, eulerAngles, ArgInfo("eulerAngles", 1)) )
    {
        ERRWRAP2(cv::decomposeProjectionMatrix(projMatrix, cameraMatrix, rotMatrix, transVect, rotMatrixX, rotMatrixY, rotMatrixZ, eulerAngles));
        return Py_BuildValue("(NNNNNNN)", pyopencv_from(cameraMatrix), pyopencv_from(rotMatrix), pyopencv_from(transVect), pyopencv_from(rotMatrixX), pyopencv_from(rotMatrixY), pyopencv_from(rotMatrixZ), pyopencv_from(eulerAngles));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("decomposeProjectionMatrix");

    return NULL;
}

static PyObject* pyopencv_cv_demosaicing(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_code = NULL;
    int code=0;
    PyObject* pyobj_dstCn = NULL;
    int dstCn=0;

    const char* keywords[] = { "src", "code", "dst", "dstCn", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:demosaicing", (char**)keywords, &pyobj_src, &pyobj_code, &pyobj_dst, &pyobj_dstCn) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_code, code, ArgInfo("code", 0)) &&
        pyopencv_to_safe(pyobj_dstCn, dstCn, ArgInfo("dstCn", 0)) )
    {
        ERRWRAP2(cv::demosaicing(src, dst, code, dstCn));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_code = NULL;
    int code=0;
    PyObject* pyobj_dstCn = NULL;
    int dstCn=0;

    const char* keywords[] = { "src", "code", "dst", "dstCn", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:demosaicing", (char**)keywords, &pyobj_src, &pyobj_code, &pyobj_dst, &pyobj_dstCn) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_code, code, ArgInfo("code", 0)) &&
        pyopencv_to_safe(pyobj_dstCn, dstCn, ArgInfo("dstCn", 0)) )
    {
        ERRWRAP2(cv::demosaicing(src, dst, code, dstCn));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("demosaicing");

    return NULL;
}

static PyObject* pyopencv_cv_denoise_TVL1(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_observations = NULL;
    vector_Mat observations;
    PyObject* pyobj_result = NULL;
    Mat result;
    PyObject* pyobj_lambda = NULL;
    double lambda=1.0;
    PyObject* pyobj_niters = NULL;
    int niters=30;

    const char* keywords[] = { "observations", "result", "lambda", "niters", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:denoise_TVL1", (char**)keywords, &pyobj_observations, &pyobj_result, &pyobj_lambda, &pyobj_niters) &&
        pyopencv_to_safe(pyobj_observations, observations, ArgInfo("observations", 0)) &&
        pyopencv_to_safe(pyobj_result, result, ArgInfo("result", 0)) &&
        pyopencv_to_safe(pyobj_lambda, lambda, ArgInfo("lambda", 0)) &&
        pyopencv_to_safe(pyobj_niters, niters, ArgInfo("niters", 0)) )
    {
        ERRWRAP2(cv::denoise_TVL1(observations, result, lambda, niters));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_observations = NULL;
    vector_Mat observations;
    PyObject* pyobj_result = NULL;
    Mat result;
    PyObject* pyobj_lambda = NULL;
    double lambda=1.0;
    PyObject* pyobj_niters = NULL;
    int niters=30;

    const char* keywords[] = { "observations", "result", "lambda", "niters", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:denoise_TVL1", (char**)keywords, &pyobj_observations, &pyobj_result, &pyobj_lambda, &pyobj_niters) &&
        pyopencv_to_safe(pyobj_observations, observations, ArgInfo("observations", 0)) &&
        pyopencv_to_safe(pyobj_result, result, ArgInfo("result", 0)) &&
        pyopencv_to_safe(pyobj_lambda, lambda, ArgInfo("lambda", 0)) &&
        pyopencv_to_safe(pyobj_niters, niters, ArgInfo("niters", 0)) )
    {
        ERRWRAP2(cv::denoise_TVL1(observations, result, lambda, niters));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("denoise_TVL1");

    return NULL;
}

static PyObject* pyopencv_cv_destroyAllWindows(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;


    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(cv::destroyAllWindows());
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_destroyWindow(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_winname = NULL;
    String winname;

    const char* keywords[] = { "winname", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:destroyWindow", (char**)keywords, &pyobj_winname) &&
        pyopencv_to_safe(pyobj_winname, winname, ArgInfo("winname", 0)) )
    {
        ERRWRAP2(cv::destroyWindow(winname));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_detailEnhance(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_sigma_s = NULL;
    float sigma_s=10;
    PyObject* pyobj_sigma_r = NULL;
    float sigma_r=0.15f;

    const char* keywords[] = { "src", "dst", "sigma_s", "sigma_r", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:detailEnhance", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_sigma_s, &pyobj_sigma_r) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_sigma_s, sigma_s, ArgInfo("sigma_s", 0)) &&
        pyopencv_to_safe(pyobj_sigma_r, sigma_r, ArgInfo("sigma_r", 0)) )
    {
        ERRWRAP2(cv::detailEnhance(src, dst, sigma_s, sigma_r));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_sigma_s = NULL;
    float sigma_s=10;
    PyObject* pyobj_sigma_r = NULL;
    float sigma_r=0.15f;

    const char* keywords[] = { "src", "dst", "sigma_s", "sigma_r", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:detailEnhance", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_sigma_s, &pyobj_sigma_r) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_sigma_s, sigma_s, ArgInfo("sigma_s", 0)) &&
        pyopencv_to_safe(pyobj_sigma_r, sigma_r, ArgInfo("sigma_r", 0)) )
    {
        ERRWRAP2(cv::detailEnhance(src, dst, sigma_s, sigma_r));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("detailEnhance");

    return NULL;
}

static PyObject* pyopencv_cv_determinant(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_mtx = NULL;
    Mat mtx;
    double retval;

    const char* keywords[] = { "mtx", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:determinant", (char**)keywords, &pyobj_mtx) &&
        pyopencv_to_safe(pyobj_mtx, mtx, ArgInfo("mtx", 0)) )
    {
        ERRWRAP2(retval = cv::determinant(mtx));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_mtx = NULL;
    UMat mtx;
    double retval;

    const char* keywords[] = { "mtx", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:determinant", (char**)keywords, &pyobj_mtx) &&
        pyopencv_to_safe(pyobj_mtx, mtx, ArgInfo("mtx", 0)) )
    {
        ERRWRAP2(retval = cv::determinant(mtx));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("determinant");

    return NULL;
}

static PyObject* pyopencv_cv_dft(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_nonzeroRows = NULL;
    int nonzeroRows=0;

    const char* keywords[] = { "src", "dst", "flags", "nonzeroRows", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:dft", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_flags, &pyobj_nonzeroRows) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_nonzeroRows, nonzeroRows, ArgInfo("nonzeroRows", 0)) )
    {
        ERRWRAP2(cv::dft(src, dst, flags, nonzeroRows));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_nonzeroRows = NULL;
    int nonzeroRows=0;

    const char* keywords[] = { "src", "dst", "flags", "nonzeroRows", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:dft", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_flags, &pyobj_nonzeroRows) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_nonzeroRows, nonzeroRows, ArgInfo("nonzeroRows", 0)) )
    {
        ERRWRAP2(cv::dft(src, dst, flags, nonzeroRows));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("dft");

    return NULL;
}

static PyObject* pyopencv_cv_dilate(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_kernel = NULL;
    Mat kernel;
    PyObject* pyobj_anchor = NULL;
    Point anchor=Point(-1,-1);
    PyObject* pyobj_iterations = NULL;
    int iterations=1;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_CONSTANT;
    PyObject* pyobj_borderValue = NULL;
    Scalar borderValue=morphologyDefaultBorderValue();

    const char* keywords[] = { "src", "kernel", "dst", "anchor", "iterations", "borderType", "borderValue", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOOO:dilate", (char**)keywords, &pyobj_src, &pyobj_kernel, &pyobj_dst, &pyobj_anchor, &pyobj_iterations, &pyobj_borderType, &pyobj_borderValue) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_kernel, kernel, ArgInfo("kernel", 0)) &&
        pyopencv_to_safe(pyobj_anchor, anchor, ArgInfo("anchor", 0)) &&
        pyopencv_to_safe(pyobj_iterations, iterations, ArgInfo("iterations", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) &&
        pyopencv_to_safe(pyobj_borderValue, borderValue, ArgInfo("borderValue", 0)) )
    {
        ERRWRAP2(cv::dilate(src, dst, kernel, anchor, iterations, borderType, borderValue));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_kernel = NULL;
    UMat kernel;
    PyObject* pyobj_anchor = NULL;
    Point anchor=Point(-1,-1);
    PyObject* pyobj_iterations = NULL;
    int iterations=1;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_CONSTANT;
    PyObject* pyobj_borderValue = NULL;
    Scalar borderValue=morphologyDefaultBorderValue();

    const char* keywords[] = { "src", "kernel", "dst", "anchor", "iterations", "borderType", "borderValue", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOOO:dilate", (char**)keywords, &pyobj_src, &pyobj_kernel, &pyobj_dst, &pyobj_anchor, &pyobj_iterations, &pyobj_borderType, &pyobj_borderValue) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_kernel, kernel, ArgInfo("kernel", 0)) &&
        pyopencv_to_safe(pyobj_anchor, anchor, ArgInfo("anchor", 0)) &&
        pyopencv_to_safe(pyobj_iterations, iterations, ArgInfo("iterations", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) &&
        pyopencv_to_safe(pyobj_borderValue, borderValue, ArgInfo("borderValue", 0)) )
    {
        ERRWRAP2(cv::dilate(src, dst, kernel, anchor, iterations, borderType, borderValue));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("dilate");

    return NULL;
}

static PyObject* pyopencv_cv_displayOverlay(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_winname = NULL;
    String winname;
    PyObject* pyobj_text = NULL;
    String text;
    PyObject* pyobj_delayms = NULL;
    int delayms=0;

    const char* keywords[] = { "winname", "text", "delayms", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:displayOverlay", (char**)keywords, &pyobj_winname, &pyobj_text, &pyobj_delayms) &&
        pyopencv_to_safe(pyobj_winname, winname, ArgInfo("winname", 0)) &&
        pyopencv_to_safe(pyobj_text, text, ArgInfo("text", 0)) &&
        pyopencv_to_safe(pyobj_delayms, delayms, ArgInfo("delayms", 0)) )
    {
        ERRWRAP2(cv::displayOverlay(winname, text, delayms));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_displayStatusBar(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_winname = NULL;
    String winname;
    PyObject* pyobj_text = NULL;
    String text;
    PyObject* pyobj_delayms = NULL;
    int delayms=0;

    const char* keywords[] = { "winname", "text", "delayms", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:displayStatusBar", (char**)keywords, &pyobj_winname, &pyobj_text, &pyobj_delayms) &&
        pyopencv_to_safe(pyobj_winname, winname, ArgInfo("winname", 0)) &&
        pyopencv_to_safe(pyobj_text, text, ArgInfo("text", 0)) &&
        pyopencv_to_safe(pyobj_delayms, delayms, ArgInfo("delayms", 0)) )
    {
        ERRWRAP2(cv::displayStatusBar(winname, text, delayms));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_distanceTransform(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_distanceType = NULL;
    int distanceType=0;
    PyObject* pyobj_maskSize = NULL;
    int maskSize=0;
    PyObject* pyobj_dstType = NULL;
    int dstType=CV_32F;

    const char* keywords[] = { "src", "distanceType", "maskSize", "dst", "dstType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:distanceTransform", (char**)keywords, &pyobj_src, &pyobj_distanceType, &pyobj_maskSize, &pyobj_dst, &pyobj_dstType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_distanceType, distanceType, ArgInfo("distanceType", 0)) &&
        pyopencv_to_safe(pyobj_maskSize, maskSize, ArgInfo("maskSize", 0)) &&
        pyopencv_to_safe(pyobj_dstType, dstType, ArgInfo("dstType", 0)) )
    {
        ERRWRAP2(cv::distanceTransform(src, dst, distanceType, maskSize, dstType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_distanceType = NULL;
    int distanceType=0;
    PyObject* pyobj_maskSize = NULL;
    int maskSize=0;
    PyObject* pyobj_dstType = NULL;
    int dstType=CV_32F;

    const char* keywords[] = { "src", "distanceType", "maskSize", "dst", "dstType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:distanceTransform", (char**)keywords, &pyobj_src, &pyobj_distanceType, &pyobj_maskSize, &pyobj_dst, &pyobj_dstType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_distanceType, distanceType, ArgInfo("distanceType", 0)) &&
        pyopencv_to_safe(pyobj_maskSize, maskSize, ArgInfo("maskSize", 0)) &&
        pyopencv_to_safe(pyobj_dstType, dstType, ArgInfo("dstType", 0)) )
    {
        ERRWRAP2(cv::distanceTransform(src, dst, distanceType, maskSize, dstType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("distanceTransform");

    return NULL;
}

static PyObject* pyopencv_cv_distanceTransformWithLabels(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_labels = NULL;
    Mat labels;
    PyObject* pyobj_distanceType = NULL;
    int distanceType=0;
    PyObject* pyobj_maskSize = NULL;
    int maskSize=0;
    PyObject* pyobj_labelType = NULL;
    int labelType=DIST_LABEL_CCOMP;

    const char* keywords[] = { "src", "distanceType", "maskSize", "dst", "labels", "labelType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:distanceTransformWithLabels", (char**)keywords, &pyobj_src, &pyobj_distanceType, &pyobj_maskSize, &pyobj_dst, &pyobj_labels, &pyobj_labelType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_labels, labels, ArgInfo("labels", 1)) &&
        pyopencv_to_safe(pyobj_distanceType, distanceType, ArgInfo("distanceType", 0)) &&
        pyopencv_to_safe(pyobj_maskSize, maskSize, ArgInfo("maskSize", 0)) &&
        pyopencv_to_safe(pyobj_labelType, labelType, ArgInfo("labelType", 0)) )
    {
        ERRWRAP2(cv::distanceTransform(src, dst, labels, distanceType, maskSize, labelType));
        return Py_BuildValue("(NN)", pyopencv_from(dst), pyopencv_from(labels));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_labels = NULL;
    UMat labels;
    PyObject* pyobj_distanceType = NULL;
    int distanceType=0;
    PyObject* pyobj_maskSize = NULL;
    int maskSize=0;
    PyObject* pyobj_labelType = NULL;
    int labelType=DIST_LABEL_CCOMP;

    const char* keywords[] = { "src", "distanceType", "maskSize", "dst", "labels", "labelType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:distanceTransformWithLabels", (char**)keywords, &pyobj_src, &pyobj_distanceType, &pyobj_maskSize, &pyobj_dst, &pyobj_labels, &pyobj_labelType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_labels, labels, ArgInfo("labels", 1)) &&
        pyopencv_to_safe(pyobj_distanceType, distanceType, ArgInfo("distanceType", 0)) &&
        pyopencv_to_safe(pyobj_maskSize, maskSize, ArgInfo("maskSize", 0)) &&
        pyopencv_to_safe(pyobj_labelType, labelType, ArgInfo("labelType", 0)) )
    {
        ERRWRAP2(cv::distanceTransform(src, dst, labels, distanceType, maskSize, labelType));
        return Py_BuildValue("(NN)", pyopencv_from(dst), pyopencv_from(labels));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("distanceTransformWithLabels");

    return NULL;
}

static PyObject* pyopencv_cv_divide(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(4);

    {
    PyObject* pyobj_src1 = NULL;
    Mat src1;
    PyObject* pyobj_src2 = NULL;
    Mat src2;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_scale = NULL;
    double scale=1;
    PyObject* pyobj_dtype = NULL;
    int dtype=-1;

    const char* keywords[] = { "src1", "src2", "dst", "scale", "dtype", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:divide", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_dst, &pyobj_scale, &pyobj_dtype) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_scale, scale, ArgInfo("scale", 0)) &&
        pyopencv_to_safe(pyobj_dtype, dtype, ArgInfo("dtype", 0)) )
    {
        ERRWRAP2(cv::divide(src1, src2, dst, scale, dtype));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src1 = NULL;
    UMat src1;
    PyObject* pyobj_src2 = NULL;
    UMat src2;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_scale = NULL;
    double scale=1;
    PyObject* pyobj_dtype = NULL;
    int dtype=-1;

    const char* keywords[] = { "src1", "src2", "dst", "scale", "dtype", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:divide", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_dst, &pyobj_scale, &pyobj_dtype) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_scale, scale, ArgInfo("scale", 0)) &&
        pyopencv_to_safe(pyobj_dtype, dtype, ArgInfo("dtype", 0)) )
    {
        ERRWRAP2(cv::divide(src1, src2, dst, scale, dtype));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_scale = NULL;
    double scale=0;
    PyObject* pyobj_src2 = NULL;
    Mat src2;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_dtype = NULL;
    int dtype=-1;

    const char* keywords[] = { "scale", "src2", "dst", "dtype", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:divide", (char**)keywords, &pyobj_scale, &pyobj_src2, &pyobj_dst, &pyobj_dtype) &&
        pyopencv_to_safe(pyobj_scale, scale, ArgInfo("scale", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_dtype, dtype, ArgInfo("dtype", 0)) )
    {
        ERRWRAP2(cv::divide(scale, src2, dst, dtype));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_scale = NULL;
    double scale=0;
    PyObject* pyobj_src2 = NULL;
    UMat src2;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_dtype = NULL;
    int dtype=-1;

    const char* keywords[] = { "scale", "src2", "dst", "dtype", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:divide", (char**)keywords, &pyobj_scale, &pyobj_src2, &pyobj_dst, &pyobj_dtype) &&
        pyopencv_to_safe(pyobj_scale, scale, ArgInfo("scale", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_dtype, dtype, ArgInfo("dtype", 0)) )
    {
        ERRWRAP2(cv::divide(scale, src2, dst, dtype));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("divide");

    return NULL;
}

static PyObject* pyopencv_cv_drawChessboardCorners(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_patternSize = NULL;
    Size patternSize;
    PyObject* pyobj_corners = NULL;
    Mat corners;
    PyObject* pyobj_patternWasFound = NULL;
    bool patternWasFound=0;

    const char* keywords[] = { "image", "patternSize", "corners", "patternWasFound", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO:drawChessboardCorners", (char**)keywords, &pyobj_image, &pyobj_patternSize, &pyobj_corners, &pyobj_patternWasFound) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 1)) &&
        pyopencv_to_safe(pyobj_patternSize, patternSize, ArgInfo("patternSize", 0)) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 0)) &&
        pyopencv_to_safe(pyobj_patternWasFound, patternWasFound, ArgInfo("patternWasFound", 0)) )
    {
        ERRWRAP2(cv::drawChessboardCorners(image, patternSize, corners, patternWasFound));
        return pyopencv_from(image);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_patternSize = NULL;
    Size patternSize;
    PyObject* pyobj_corners = NULL;
    UMat corners;
    PyObject* pyobj_patternWasFound = NULL;
    bool patternWasFound=0;

    const char* keywords[] = { "image", "patternSize", "corners", "patternWasFound", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO:drawChessboardCorners", (char**)keywords, &pyobj_image, &pyobj_patternSize, &pyobj_corners, &pyobj_patternWasFound) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 1)) &&
        pyopencv_to_safe(pyobj_patternSize, patternSize, ArgInfo("patternSize", 0)) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 0)) &&
        pyopencv_to_safe(pyobj_patternWasFound, patternWasFound, ArgInfo("patternWasFound", 0)) )
    {
        ERRWRAP2(cv::drawChessboardCorners(image, patternSize, corners, patternWasFound));
        return pyopencv_from(image);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("drawChessboardCorners");

    return NULL;
}

static PyObject* pyopencv_cv_drawContours(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_contours = NULL;
    vector_Mat contours;
    PyObject* pyobj_contourIdx = NULL;
    int contourIdx=0;
    PyObject* pyobj_color = NULL;
    Scalar color;
    PyObject* pyobj_thickness = NULL;
    int thickness=1;
    PyObject* pyobj_lineType = NULL;
    int lineType=LINE_8;
    PyObject* pyobj_hierarchy = NULL;
    Mat hierarchy;
    PyObject* pyobj_maxLevel = NULL;
    int maxLevel=INT_MAX;
    PyObject* pyobj_offset = NULL;
    Point offset;

    const char* keywords[] = { "image", "contours", "contourIdx", "color", "thickness", "lineType", "hierarchy", "maxLevel", "offset", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOOO:drawContours", (char**)keywords, &pyobj_image, &pyobj_contours, &pyobj_contourIdx, &pyobj_color, &pyobj_thickness, &pyobj_lineType, &pyobj_hierarchy, &pyobj_maxLevel, &pyobj_offset) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 1)) &&
        pyopencv_to_safe(pyobj_contours, contours, ArgInfo("contours", 0)) &&
        pyopencv_to_safe(pyobj_contourIdx, contourIdx, ArgInfo("contourIdx", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_thickness, thickness, ArgInfo("thickness", 0)) &&
        pyopencv_to_safe(pyobj_lineType, lineType, ArgInfo("lineType", 0)) &&
        pyopencv_to_safe(pyobj_hierarchy, hierarchy, ArgInfo("hierarchy", 0)) &&
        pyopencv_to_safe(pyobj_maxLevel, maxLevel, ArgInfo("maxLevel", 0)) &&
        pyopencv_to_safe(pyobj_offset, offset, ArgInfo("offset", 0)) )
    {
        ERRWRAP2(cv::drawContours(image, contours, contourIdx, color, thickness, lineType, hierarchy, maxLevel, offset));
        return pyopencv_from(image);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_contours = NULL;
    vector_UMat contours;
    PyObject* pyobj_contourIdx = NULL;
    int contourIdx=0;
    PyObject* pyobj_color = NULL;
    Scalar color;
    PyObject* pyobj_thickness = NULL;
    int thickness=1;
    PyObject* pyobj_lineType = NULL;
    int lineType=LINE_8;
    PyObject* pyobj_hierarchy = NULL;
    UMat hierarchy;
    PyObject* pyobj_maxLevel = NULL;
    int maxLevel=INT_MAX;
    PyObject* pyobj_offset = NULL;
    Point offset;

    const char* keywords[] = { "image", "contours", "contourIdx", "color", "thickness", "lineType", "hierarchy", "maxLevel", "offset", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOOO:drawContours", (char**)keywords, &pyobj_image, &pyobj_contours, &pyobj_contourIdx, &pyobj_color, &pyobj_thickness, &pyobj_lineType, &pyobj_hierarchy, &pyobj_maxLevel, &pyobj_offset) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 1)) &&
        pyopencv_to_safe(pyobj_contours, contours, ArgInfo("contours", 0)) &&
        pyopencv_to_safe(pyobj_contourIdx, contourIdx, ArgInfo("contourIdx", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_thickness, thickness, ArgInfo("thickness", 0)) &&
        pyopencv_to_safe(pyobj_lineType, lineType, ArgInfo("lineType", 0)) &&
        pyopencv_to_safe(pyobj_hierarchy, hierarchy, ArgInfo("hierarchy", 0)) &&
        pyopencv_to_safe(pyobj_maxLevel, maxLevel, ArgInfo("maxLevel", 0)) &&
        pyopencv_to_safe(pyobj_offset, offset, ArgInfo("offset", 0)) )
    {
        ERRWRAP2(cv::drawContours(image, contours, contourIdx, color, thickness, lineType, hierarchy, maxLevel, offset));
        return pyopencv_from(image);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("drawContours");

    return NULL;
}

static PyObject* pyopencv_cv_drawFrameAxes(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    Mat distCoeffs;
    PyObject* pyobj_rvec = NULL;
    Mat rvec;
    PyObject* pyobj_tvec = NULL;
    Mat tvec;
    PyObject* pyobj_length = NULL;
    float length=0.f;
    PyObject* pyobj_thickness = NULL;
    int thickness=3;

    const char* keywords[] = { "image", "cameraMatrix", "distCoeffs", "rvec", "tvec", "length", "thickness", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|O:drawFrameAxes", (char**)keywords, &pyobj_image, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvec, &pyobj_tvec, &pyobj_length, &pyobj_thickness) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 1)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 0)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 0)) &&
        pyopencv_to_safe(pyobj_length, length, ArgInfo("length", 0)) &&
        pyopencv_to_safe(pyobj_thickness, thickness, ArgInfo("thickness", 0)) )
    {
        ERRWRAP2(cv::drawFrameAxes(image, cameraMatrix, distCoeffs, rvec, tvec, length, thickness));
        return pyopencv_from(image);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    UMat distCoeffs;
    PyObject* pyobj_rvec = NULL;
    UMat rvec;
    PyObject* pyobj_tvec = NULL;
    UMat tvec;
    PyObject* pyobj_length = NULL;
    float length=0.f;
    PyObject* pyobj_thickness = NULL;
    int thickness=3;

    const char* keywords[] = { "image", "cameraMatrix", "distCoeffs", "rvec", "tvec", "length", "thickness", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|O:drawFrameAxes", (char**)keywords, &pyobj_image, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvec, &pyobj_tvec, &pyobj_length, &pyobj_thickness) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 1)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 0)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 0)) &&
        pyopencv_to_safe(pyobj_length, length, ArgInfo("length", 0)) &&
        pyopencv_to_safe(pyobj_thickness, thickness, ArgInfo("thickness", 0)) )
    {
        ERRWRAP2(cv::drawFrameAxes(image, cameraMatrix, distCoeffs, rvec, tvec, length, thickness));
        return pyopencv_from(image);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("drawFrameAxes");

    return NULL;
}

static PyObject* pyopencv_cv_drawKeypoints(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_keypoints = NULL;
    vector_KeyPoint keypoints;
    PyObject* pyobj_outImage = NULL;
    Mat outImage;
    PyObject* pyobj_color = NULL;
    Scalar color=Scalar::all(-1);
    PyObject* pyobj_flags = NULL;
    DrawMatchesFlags flags=DrawMatchesFlags::DEFAULT;

    const char* keywords[] = { "image", "keypoints", "outImage", "color", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:drawKeypoints", (char**)keywords, &pyobj_image, &pyobj_keypoints, &pyobj_outImage, &pyobj_color, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_keypoints, keypoints, ArgInfo("keypoints", 0)) &&
        pyopencv_to_safe(pyobj_outImage, outImage, ArgInfo("outImage", 1)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::drawKeypoints(image, keypoints, outImage, color, flags));
        return pyopencv_from(outImage);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_keypoints = NULL;
    vector_KeyPoint keypoints;
    PyObject* pyobj_outImage = NULL;
    UMat outImage;
    PyObject* pyobj_color = NULL;
    Scalar color=Scalar::all(-1);
    PyObject* pyobj_flags = NULL;
    DrawMatchesFlags flags=DrawMatchesFlags::DEFAULT;

    const char* keywords[] = { "image", "keypoints", "outImage", "color", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:drawKeypoints", (char**)keywords, &pyobj_image, &pyobj_keypoints, &pyobj_outImage, &pyobj_color, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_keypoints, keypoints, ArgInfo("keypoints", 0)) &&
        pyopencv_to_safe(pyobj_outImage, outImage, ArgInfo("outImage", 1)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::drawKeypoints(image, keypoints, outImage, color, flags));
        return pyopencv_from(outImage);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("drawKeypoints");

    return NULL;
}

static PyObject* pyopencv_cv_drawMarker(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_position = NULL;
    Point position;
    PyObject* pyobj_color = NULL;
    Scalar color;
    PyObject* pyobj_markerType = NULL;
    int markerType=MARKER_CROSS;
    PyObject* pyobj_markerSize = NULL;
    int markerSize=20;
    PyObject* pyobj_thickness = NULL;
    int thickness=1;
    PyObject* pyobj_line_type = NULL;
    int line_type=8;

    const char* keywords[] = { "img", "position", "color", "markerType", "markerSize", "thickness", "line_type", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOO:drawMarker", (char**)keywords, &pyobj_img, &pyobj_position, &pyobj_color, &pyobj_markerType, &pyobj_markerSize, &pyobj_thickness, &pyobj_line_type) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_position, position, ArgInfo("position", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_markerType, markerType, ArgInfo("markerType", 0)) &&
        pyopencv_to_safe(pyobj_markerSize, markerSize, ArgInfo("markerSize", 0)) &&
        pyopencv_to_safe(pyobj_thickness, thickness, ArgInfo("thickness", 0)) &&
        pyopencv_to_safe(pyobj_line_type, line_type, ArgInfo("line_type", 0)) )
    {
        ERRWRAP2(cv::drawMarker(img, position, color, markerType, markerSize, thickness, line_type));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_position = NULL;
    Point position;
    PyObject* pyobj_color = NULL;
    Scalar color;
    PyObject* pyobj_markerType = NULL;
    int markerType=MARKER_CROSS;
    PyObject* pyobj_markerSize = NULL;
    int markerSize=20;
    PyObject* pyobj_thickness = NULL;
    int thickness=1;
    PyObject* pyobj_line_type = NULL;
    int line_type=8;

    const char* keywords[] = { "img", "position", "color", "markerType", "markerSize", "thickness", "line_type", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOO:drawMarker", (char**)keywords, &pyobj_img, &pyobj_position, &pyobj_color, &pyobj_markerType, &pyobj_markerSize, &pyobj_thickness, &pyobj_line_type) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_position, position, ArgInfo("position", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_markerType, markerType, ArgInfo("markerType", 0)) &&
        pyopencv_to_safe(pyobj_markerSize, markerSize, ArgInfo("markerSize", 0)) &&
        pyopencv_to_safe(pyobj_thickness, thickness, ArgInfo("thickness", 0)) &&
        pyopencv_to_safe(pyobj_line_type, line_type, ArgInfo("line_type", 0)) )
    {
        ERRWRAP2(cv::drawMarker(img, position, color, markerType, markerSize, thickness, line_type));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("drawMarker");

    return NULL;
}

static PyObject* pyopencv_cv_drawMatches(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_img1 = NULL;
    Mat img1;
    PyObject* pyobj_keypoints1 = NULL;
    vector_KeyPoint keypoints1;
    PyObject* pyobj_img2 = NULL;
    Mat img2;
    PyObject* pyobj_keypoints2 = NULL;
    vector_KeyPoint keypoints2;
    PyObject* pyobj_matches1to2 = NULL;
    vector_DMatch matches1to2;
    PyObject* pyobj_outImg = NULL;
    Mat outImg;
    PyObject* pyobj_matchColor = NULL;
    Scalar matchColor=Scalar::all(-1);
    PyObject* pyobj_singlePointColor = NULL;
    Scalar singlePointColor=Scalar::all(-1);
    PyObject* pyobj_matchesMask = NULL;
    vector_char matchesMask=std::vector<char>();
    PyObject* pyobj_flags = NULL;
    DrawMatchesFlags flags=DrawMatchesFlags::DEFAULT;

    const char* keywords[] = { "img1", "keypoints1", "img2", "keypoints2", "matches1to2", "outImg", "matchColor", "singlePointColor", "matchesMask", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|OOOO:drawMatches", (char**)keywords, &pyobj_img1, &pyobj_keypoints1, &pyobj_img2, &pyobj_keypoints2, &pyobj_matches1to2, &pyobj_outImg, &pyobj_matchColor, &pyobj_singlePointColor, &pyobj_matchesMask, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_img1, img1, ArgInfo("img1", 0)) &&
        pyopencv_to_safe(pyobj_keypoints1, keypoints1, ArgInfo("keypoints1", 0)) &&
        pyopencv_to_safe(pyobj_img2, img2, ArgInfo("img2", 0)) &&
        pyopencv_to_safe(pyobj_keypoints2, keypoints2, ArgInfo("keypoints2", 0)) &&
        pyopencv_to_safe(pyobj_matches1to2, matches1to2, ArgInfo("matches1to2", 0)) &&
        pyopencv_to_safe(pyobj_outImg, outImg, ArgInfo("outImg", 1)) &&
        pyopencv_to_safe(pyobj_matchColor, matchColor, ArgInfo("matchColor", 0)) &&
        pyopencv_to_safe(pyobj_singlePointColor, singlePointColor, ArgInfo("singlePointColor", 0)) &&
        pyopencv_to_safe(pyobj_matchesMask, matchesMask, ArgInfo("matchesMask", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::drawMatches(img1, keypoints1, img2, keypoints2, matches1to2, outImg, matchColor, singlePointColor, matchesMask, flags));
        return pyopencv_from(outImg);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img1 = NULL;
    UMat img1;
    PyObject* pyobj_keypoints1 = NULL;
    vector_KeyPoint keypoints1;
    PyObject* pyobj_img2 = NULL;
    UMat img2;
    PyObject* pyobj_keypoints2 = NULL;
    vector_KeyPoint keypoints2;
    PyObject* pyobj_matches1to2 = NULL;
    vector_DMatch matches1to2;
    PyObject* pyobj_outImg = NULL;
    UMat outImg;
    PyObject* pyobj_matchColor = NULL;
    Scalar matchColor=Scalar::all(-1);
    PyObject* pyobj_singlePointColor = NULL;
    Scalar singlePointColor=Scalar::all(-1);
    PyObject* pyobj_matchesMask = NULL;
    vector_char matchesMask=std::vector<char>();
    PyObject* pyobj_flags = NULL;
    DrawMatchesFlags flags=DrawMatchesFlags::DEFAULT;

    const char* keywords[] = { "img1", "keypoints1", "img2", "keypoints2", "matches1to2", "outImg", "matchColor", "singlePointColor", "matchesMask", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|OOOO:drawMatches", (char**)keywords, &pyobj_img1, &pyobj_keypoints1, &pyobj_img2, &pyobj_keypoints2, &pyobj_matches1to2, &pyobj_outImg, &pyobj_matchColor, &pyobj_singlePointColor, &pyobj_matchesMask, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_img1, img1, ArgInfo("img1", 0)) &&
        pyopencv_to_safe(pyobj_keypoints1, keypoints1, ArgInfo("keypoints1", 0)) &&
        pyopencv_to_safe(pyobj_img2, img2, ArgInfo("img2", 0)) &&
        pyopencv_to_safe(pyobj_keypoints2, keypoints2, ArgInfo("keypoints2", 0)) &&
        pyopencv_to_safe(pyobj_matches1to2, matches1to2, ArgInfo("matches1to2", 0)) &&
        pyopencv_to_safe(pyobj_outImg, outImg, ArgInfo("outImg", 1)) &&
        pyopencv_to_safe(pyobj_matchColor, matchColor, ArgInfo("matchColor", 0)) &&
        pyopencv_to_safe(pyobj_singlePointColor, singlePointColor, ArgInfo("singlePointColor", 0)) &&
        pyopencv_to_safe(pyobj_matchesMask, matchesMask, ArgInfo("matchesMask", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::drawMatches(img1, keypoints1, img2, keypoints2, matches1to2, outImg, matchColor, singlePointColor, matchesMask, flags));
        return pyopencv_from(outImg);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("drawMatches");

    return NULL;
}

static PyObject* pyopencv_cv_drawMatchesKnn(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_img1 = NULL;
    Mat img1;
    PyObject* pyobj_keypoints1 = NULL;
    vector_KeyPoint keypoints1;
    PyObject* pyobj_img2 = NULL;
    Mat img2;
    PyObject* pyobj_keypoints2 = NULL;
    vector_KeyPoint keypoints2;
    PyObject* pyobj_matches1to2 = NULL;
    vector_vector_DMatch matches1to2;
    PyObject* pyobj_outImg = NULL;
    Mat outImg;
    PyObject* pyobj_matchColor = NULL;
    Scalar matchColor=Scalar::all(-1);
    PyObject* pyobj_singlePointColor = NULL;
    Scalar singlePointColor=Scalar::all(-1);
    PyObject* pyobj_matchesMask = NULL;
    vector_vector_char matchesMask=std::vector<std::vector<char> >();
    PyObject* pyobj_flags = NULL;
    DrawMatchesFlags flags=DrawMatchesFlags::DEFAULT;

    const char* keywords[] = { "img1", "keypoints1", "img2", "keypoints2", "matches1to2", "outImg", "matchColor", "singlePointColor", "matchesMask", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|OOOO:drawMatchesKnn", (char**)keywords, &pyobj_img1, &pyobj_keypoints1, &pyobj_img2, &pyobj_keypoints2, &pyobj_matches1to2, &pyobj_outImg, &pyobj_matchColor, &pyobj_singlePointColor, &pyobj_matchesMask, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_img1, img1, ArgInfo("img1", 0)) &&
        pyopencv_to_safe(pyobj_keypoints1, keypoints1, ArgInfo("keypoints1", 0)) &&
        pyopencv_to_safe(pyobj_img2, img2, ArgInfo("img2", 0)) &&
        pyopencv_to_safe(pyobj_keypoints2, keypoints2, ArgInfo("keypoints2", 0)) &&
        pyopencv_to_safe(pyobj_matches1to2, matches1to2, ArgInfo("matches1to2", 0)) &&
        pyopencv_to_safe(pyobj_outImg, outImg, ArgInfo("outImg", 1)) &&
        pyopencv_to_safe(pyobj_matchColor, matchColor, ArgInfo("matchColor", 0)) &&
        pyopencv_to_safe(pyobj_singlePointColor, singlePointColor, ArgInfo("singlePointColor", 0)) &&
        pyopencv_to_safe(pyobj_matchesMask, matchesMask, ArgInfo("matchesMask", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::drawMatches(img1, keypoints1, img2, keypoints2, matches1to2, outImg, matchColor, singlePointColor, matchesMask, flags));
        return pyopencv_from(outImg);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img1 = NULL;
    UMat img1;
    PyObject* pyobj_keypoints1 = NULL;
    vector_KeyPoint keypoints1;
    PyObject* pyobj_img2 = NULL;
    UMat img2;
    PyObject* pyobj_keypoints2 = NULL;
    vector_KeyPoint keypoints2;
    PyObject* pyobj_matches1to2 = NULL;
    vector_vector_DMatch matches1to2;
    PyObject* pyobj_outImg = NULL;
    UMat outImg;
    PyObject* pyobj_matchColor = NULL;
    Scalar matchColor=Scalar::all(-1);
    PyObject* pyobj_singlePointColor = NULL;
    Scalar singlePointColor=Scalar::all(-1);
    PyObject* pyobj_matchesMask = NULL;
    vector_vector_char matchesMask=std::vector<std::vector<char> >();
    PyObject* pyobj_flags = NULL;
    DrawMatchesFlags flags=DrawMatchesFlags::DEFAULT;

    const char* keywords[] = { "img1", "keypoints1", "img2", "keypoints2", "matches1to2", "outImg", "matchColor", "singlePointColor", "matchesMask", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|OOOO:drawMatchesKnn", (char**)keywords, &pyobj_img1, &pyobj_keypoints1, &pyobj_img2, &pyobj_keypoints2, &pyobj_matches1to2, &pyobj_outImg, &pyobj_matchColor, &pyobj_singlePointColor, &pyobj_matchesMask, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_img1, img1, ArgInfo("img1", 0)) &&
        pyopencv_to_safe(pyobj_keypoints1, keypoints1, ArgInfo("keypoints1", 0)) &&
        pyopencv_to_safe(pyobj_img2, img2, ArgInfo("img2", 0)) &&
        pyopencv_to_safe(pyobj_keypoints2, keypoints2, ArgInfo("keypoints2", 0)) &&
        pyopencv_to_safe(pyobj_matches1to2, matches1to2, ArgInfo("matches1to2", 0)) &&
        pyopencv_to_safe(pyobj_outImg, outImg, ArgInfo("outImg", 1)) &&
        pyopencv_to_safe(pyobj_matchColor, matchColor, ArgInfo("matchColor", 0)) &&
        pyopencv_to_safe(pyobj_singlePointColor, singlePointColor, ArgInfo("singlePointColor", 0)) &&
        pyopencv_to_safe(pyobj_matchesMask, matchesMask, ArgInfo("matchesMask", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::drawMatches(img1, keypoints1, img2, keypoints2, matches1to2, outImg, matchColor, singlePointColor, matchesMask, flags));
        return pyopencv_from(outImg);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("drawMatchesKnn");

    return NULL;
}

static PyObject* pyopencv_cv_edgePreservingFilter(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_flags = NULL;
    int flags=1;
    PyObject* pyobj_sigma_s = NULL;
    float sigma_s=60;
    PyObject* pyobj_sigma_r = NULL;
    float sigma_r=0.4f;

    const char* keywords[] = { "src", "dst", "flags", "sigma_s", "sigma_r", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOO:edgePreservingFilter", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_flags, &pyobj_sigma_s, &pyobj_sigma_r) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_sigma_s, sigma_s, ArgInfo("sigma_s", 0)) &&
        pyopencv_to_safe(pyobj_sigma_r, sigma_r, ArgInfo("sigma_r", 0)) )
    {
        ERRWRAP2(cv::edgePreservingFilter(src, dst, flags, sigma_s, sigma_r));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_flags = NULL;
    int flags=1;
    PyObject* pyobj_sigma_s = NULL;
    float sigma_s=60;
    PyObject* pyobj_sigma_r = NULL;
    float sigma_r=0.4f;

    const char* keywords[] = { "src", "dst", "flags", "sigma_s", "sigma_r", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOO:edgePreservingFilter", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_flags, &pyobj_sigma_s, &pyobj_sigma_r) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_sigma_s, sigma_s, ArgInfo("sigma_s", 0)) &&
        pyopencv_to_safe(pyobj_sigma_r, sigma_r, ArgInfo("sigma_r", 0)) )
    {
        ERRWRAP2(cv::edgePreservingFilter(src, dst, flags, sigma_s, sigma_r));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("edgePreservingFilter");

    return NULL;
}

static PyObject* pyopencv_cv_eigen(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_eigenvalues = NULL;
    Mat eigenvalues;
    PyObject* pyobj_eigenvectors = NULL;
    Mat eigenvectors;
    bool retval;

    const char* keywords[] = { "src", "eigenvalues", "eigenvectors", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:eigen", (char**)keywords, &pyobj_src, &pyobj_eigenvalues, &pyobj_eigenvectors) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_eigenvalues, eigenvalues, ArgInfo("eigenvalues", 1)) &&
        pyopencv_to_safe(pyobj_eigenvectors, eigenvectors, ArgInfo("eigenvectors", 1)) )
    {
        ERRWRAP2(retval = cv::eigen(src, eigenvalues, eigenvectors));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(eigenvalues), pyopencv_from(eigenvectors));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_eigenvalues = NULL;
    UMat eigenvalues;
    PyObject* pyobj_eigenvectors = NULL;
    UMat eigenvectors;
    bool retval;

    const char* keywords[] = { "src", "eigenvalues", "eigenvectors", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:eigen", (char**)keywords, &pyobj_src, &pyobj_eigenvalues, &pyobj_eigenvectors) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_eigenvalues, eigenvalues, ArgInfo("eigenvalues", 1)) &&
        pyopencv_to_safe(pyobj_eigenvectors, eigenvectors, ArgInfo("eigenvectors", 1)) )
    {
        ERRWRAP2(retval = cv::eigen(src, eigenvalues, eigenvectors));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(eigenvalues), pyopencv_from(eigenvectors));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("eigen");

    return NULL;
}

static PyObject* pyopencv_cv_eigenNonSymmetric(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_eigenvalues = NULL;
    Mat eigenvalues;
    PyObject* pyobj_eigenvectors = NULL;
    Mat eigenvectors;

    const char* keywords[] = { "src", "eigenvalues", "eigenvectors", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:eigenNonSymmetric", (char**)keywords, &pyobj_src, &pyobj_eigenvalues, &pyobj_eigenvectors) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_eigenvalues, eigenvalues, ArgInfo("eigenvalues", 1)) &&
        pyopencv_to_safe(pyobj_eigenvectors, eigenvectors, ArgInfo("eigenvectors", 1)) )
    {
        ERRWRAP2(cv::eigenNonSymmetric(src, eigenvalues, eigenvectors));
        return Py_BuildValue("(NN)", pyopencv_from(eigenvalues), pyopencv_from(eigenvectors));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_eigenvalues = NULL;
    UMat eigenvalues;
    PyObject* pyobj_eigenvectors = NULL;
    UMat eigenvectors;

    const char* keywords[] = { "src", "eigenvalues", "eigenvectors", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:eigenNonSymmetric", (char**)keywords, &pyobj_src, &pyobj_eigenvalues, &pyobj_eigenvectors) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_eigenvalues, eigenvalues, ArgInfo("eigenvalues", 1)) &&
        pyopencv_to_safe(pyobj_eigenvectors, eigenvectors, ArgInfo("eigenvectors", 1)) )
    {
        ERRWRAP2(cv::eigenNonSymmetric(src, eigenvalues, eigenvectors));
        return Py_BuildValue("(NN)", pyopencv_from(eigenvalues), pyopencv_from(eigenvectors));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("eigenNonSymmetric");

    return NULL;
}

static PyObject* pyopencv_cv_ellipse(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(4);

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_center = NULL;
    Point center;
    PyObject* pyobj_axes = NULL;
    Size axes;
    PyObject* pyobj_angle = NULL;
    double angle=0;
    PyObject* pyobj_startAngle = NULL;
    double startAngle=0;
    PyObject* pyobj_endAngle = NULL;
    double endAngle=0;
    PyObject* pyobj_color = NULL;
    Scalar color;
    PyObject* pyobj_thickness = NULL;
    int thickness=1;
    PyObject* pyobj_lineType = NULL;
    int lineType=LINE_8;
    PyObject* pyobj_shift = NULL;
    int shift=0;

    const char* keywords[] = { "img", "center", "axes", "angle", "startAngle", "endAngle", "color", "thickness", "lineType", "shift", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOO|OOO:ellipse", (char**)keywords, &pyobj_img, &pyobj_center, &pyobj_axes, &pyobj_angle, &pyobj_startAngle, &pyobj_endAngle, &pyobj_color, &pyobj_thickness, &pyobj_lineType, &pyobj_shift) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_center, center, ArgInfo("center", 0)) &&
        pyopencv_to_safe(pyobj_axes, axes, ArgInfo("axes", 0)) &&
        pyopencv_to_safe(pyobj_angle, angle, ArgInfo("angle", 0)) &&
        pyopencv_to_safe(pyobj_startAngle, startAngle, ArgInfo("startAngle", 0)) &&
        pyopencv_to_safe(pyobj_endAngle, endAngle, ArgInfo("endAngle", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_thickness, thickness, ArgInfo("thickness", 0)) &&
        pyopencv_to_safe(pyobj_lineType, lineType, ArgInfo("lineType", 0)) &&
        pyopencv_to_safe(pyobj_shift, shift, ArgInfo("shift", 0)) )
    {
        ERRWRAP2(cv::ellipse(img, center, axes, angle, startAngle, endAngle, color, thickness, lineType, shift));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_center = NULL;
    Point center;
    PyObject* pyobj_axes = NULL;
    Size axes;
    PyObject* pyobj_angle = NULL;
    double angle=0;
    PyObject* pyobj_startAngle = NULL;
    double startAngle=0;
    PyObject* pyobj_endAngle = NULL;
    double endAngle=0;
    PyObject* pyobj_color = NULL;
    Scalar color;
    PyObject* pyobj_thickness = NULL;
    int thickness=1;
    PyObject* pyobj_lineType = NULL;
    int lineType=LINE_8;
    PyObject* pyobj_shift = NULL;
    int shift=0;

    const char* keywords[] = { "img", "center", "axes", "angle", "startAngle", "endAngle", "color", "thickness", "lineType", "shift", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOO|OOO:ellipse", (char**)keywords, &pyobj_img, &pyobj_center, &pyobj_axes, &pyobj_angle, &pyobj_startAngle, &pyobj_endAngle, &pyobj_color, &pyobj_thickness, &pyobj_lineType, &pyobj_shift) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_center, center, ArgInfo("center", 0)) &&
        pyopencv_to_safe(pyobj_axes, axes, ArgInfo("axes", 0)) &&
        pyopencv_to_safe(pyobj_angle, angle, ArgInfo("angle", 0)) &&
        pyopencv_to_safe(pyobj_startAngle, startAngle, ArgInfo("startAngle", 0)) &&
        pyopencv_to_safe(pyobj_endAngle, endAngle, ArgInfo("endAngle", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_thickness, thickness, ArgInfo("thickness", 0)) &&
        pyopencv_to_safe(pyobj_lineType, lineType, ArgInfo("lineType", 0)) &&
        pyopencv_to_safe(pyobj_shift, shift, ArgInfo("shift", 0)) )
    {
        ERRWRAP2(cv::ellipse(img, center, axes, angle, startAngle, endAngle, color, thickness, lineType, shift));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_box = NULL;
    RotatedRect box;
    PyObject* pyobj_color = NULL;
    Scalar color;
    PyObject* pyobj_thickness = NULL;
    int thickness=1;
    PyObject* pyobj_lineType = NULL;
    int lineType=LINE_8;

    const char* keywords[] = { "img", "box", "color", "thickness", "lineType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:ellipse", (char**)keywords, &pyobj_img, &pyobj_box, &pyobj_color, &pyobj_thickness, &pyobj_lineType) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_box, box, ArgInfo("box", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_thickness, thickness, ArgInfo("thickness", 0)) &&
        pyopencv_to_safe(pyobj_lineType, lineType, ArgInfo("lineType", 0)) )
    {
        ERRWRAP2(cv::ellipse(img, box, color, thickness, lineType));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_box = NULL;
    RotatedRect box;
    PyObject* pyobj_color = NULL;
    Scalar color;
    PyObject* pyobj_thickness = NULL;
    int thickness=1;
    PyObject* pyobj_lineType = NULL;
    int lineType=LINE_8;

    const char* keywords[] = { "img", "box", "color", "thickness", "lineType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:ellipse", (char**)keywords, &pyobj_img, &pyobj_box, &pyobj_color, &pyobj_thickness, &pyobj_lineType) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_box, box, ArgInfo("box", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_thickness, thickness, ArgInfo("thickness", 0)) &&
        pyopencv_to_safe(pyobj_lineType, lineType, ArgInfo("lineType", 0)) )
    {
        ERRWRAP2(cv::ellipse(img, box, color, thickness, lineType));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("ellipse");

    return NULL;
}

static PyObject* pyopencv_cv_ellipse2Poly(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_center = NULL;
    Point center;
    PyObject* pyobj_axes = NULL;
    Size axes;
    PyObject* pyobj_angle = NULL;
    int angle=0;
    PyObject* pyobj_arcStart = NULL;
    int arcStart=0;
    PyObject* pyobj_arcEnd = NULL;
    int arcEnd=0;
    PyObject* pyobj_delta = NULL;
    int delta=0;
    vector_Point pts;

    const char* keywords[] = { "center", "axes", "angle", "arcStart", "arcEnd", "delta", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO:ellipse2Poly", (char**)keywords, &pyobj_center, &pyobj_axes, &pyobj_angle, &pyobj_arcStart, &pyobj_arcEnd, &pyobj_delta) &&
        pyopencv_to_safe(pyobj_center, center, ArgInfo("center", 0)) &&
        pyopencv_to_safe(pyobj_axes, axes, ArgInfo("axes", 0)) &&
        pyopencv_to_safe(pyobj_angle, angle, ArgInfo("angle", 0)) &&
        pyopencv_to_safe(pyobj_arcStart, arcStart, ArgInfo("arcStart", 0)) &&
        pyopencv_to_safe(pyobj_arcEnd, arcEnd, ArgInfo("arcEnd", 0)) &&
        pyopencv_to_safe(pyobj_delta, delta, ArgInfo("delta", 0)) )
    {
        ERRWRAP2(cv::ellipse2Poly(center, axes, angle, arcStart, arcEnd, delta, pts));
        return pyopencv_from(pts);
    }

    return NULL;
}

static PyObject* pyopencv_cv_empty_array_desc(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    GArrayDesc retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::empty_array_desc());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_empty_gopaque_desc(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    GOpaqueDesc retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::empty_gopaque_desc());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_empty_scalar_desc(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    GScalarDesc retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::empty_scalar_desc());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_equalizeHist(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:equalizeHist", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::equalizeHist(src, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:equalizeHist", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::equalizeHist(src, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("equalizeHist");

    return NULL;
}

static PyObject* pyopencv_cv_erode(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_kernel = NULL;
    Mat kernel;
    PyObject* pyobj_anchor = NULL;
    Point anchor=Point(-1,-1);
    PyObject* pyobj_iterations = NULL;
    int iterations=1;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_CONSTANT;
    PyObject* pyobj_borderValue = NULL;
    Scalar borderValue=morphologyDefaultBorderValue();

    const char* keywords[] = { "src", "kernel", "dst", "anchor", "iterations", "borderType", "borderValue", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOOO:erode", (char**)keywords, &pyobj_src, &pyobj_kernel, &pyobj_dst, &pyobj_anchor, &pyobj_iterations, &pyobj_borderType, &pyobj_borderValue) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_kernel, kernel, ArgInfo("kernel", 0)) &&
        pyopencv_to_safe(pyobj_anchor, anchor, ArgInfo("anchor", 0)) &&
        pyopencv_to_safe(pyobj_iterations, iterations, ArgInfo("iterations", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) &&
        pyopencv_to_safe(pyobj_borderValue, borderValue, ArgInfo("borderValue", 0)) )
    {
        ERRWRAP2(cv::erode(src, dst, kernel, anchor, iterations, borderType, borderValue));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_kernel = NULL;
    UMat kernel;
    PyObject* pyobj_anchor = NULL;
    Point anchor=Point(-1,-1);
    PyObject* pyobj_iterations = NULL;
    int iterations=1;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_CONSTANT;
    PyObject* pyobj_borderValue = NULL;
    Scalar borderValue=morphologyDefaultBorderValue();

    const char* keywords[] = { "src", "kernel", "dst", "anchor", "iterations", "borderType", "borderValue", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOOO:erode", (char**)keywords, &pyobj_src, &pyobj_kernel, &pyobj_dst, &pyobj_anchor, &pyobj_iterations, &pyobj_borderType, &pyobj_borderValue) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_kernel, kernel, ArgInfo("kernel", 0)) &&
        pyopencv_to_safe(pyobj_anchor, anchor, ArgInfo("anchor", 0)) &&
        pyopencv_to_safe(pyobj_iterations, iterations, ArgInfo("iterations", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) &&
        pyopencv_to_safe(pyobj_borderValue, borderValue, ArgInfo("borderValue", 0)) )
    {
        ERRWRAP2(cv::erode(src, dst, kernel, anchor, iterations, borderType, borderValue));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("erode");

    return NULL;
}

static PyObject* pyopencv_cv_estimateAffine2D(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(4);

    {
    PyObject* pyobj_from = NULL;
    Mat from;
    PyObject* pyobj_to = NULL;
    Mat to;
    PyObject* pyobj_inliers = NULL;
    Mat inliers;
    PyObject* pyobj_method = NULL;
    int method=RANSAC;
    PyObject* pyobj_ransacReprojThreshold = NULL;
    double ransacReprojThreshold=3;
    PyObject* pyobj_maxIters = NULL;
    size_t maxIters=2000;
    PyObject* pyobj_confidence = NULL;
    double confidence=0.99;
    PyObject* pyobj_refineIters = NULL;
    size_t refineIters=10;
    cv::Mat retval;

    const char* keywords[] = { "from", "to", "inliers", "method", "ransacReprojThreshold", "maxIters", "confidence", "refineIters", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOOOO:estimateAffine2D", (char**)keywords, &pyobj_from, &pyobj_to, &pyobj_inliers, &pyobj_method, &pyobj_ransacReprojThreshold, &pyobj_maxIters, &pyobj_confidence, &pyobj_refineIters) &&
        pyopencv_to_safe(pyobj_from, from, ArgInfo("from", 0)) &&
        pyopencv_to_safe(pyobj_to, to, ArgInfo("to", 0)) &&
        pyopencv_to_safe(pyobj_inliers, inliers, ArgInfo("inliers", 1)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) &&
        pyopencv_to_safe(pyobj_ransacReprojThreshold, ransacReprojThreshold, ArgInfo("ransacReprojThreshold", 0)) &&
        pyopencv_to_safe(pyobj_maxIters, maxIters, ArgInfo("maxIters", 0)) &&
        pyopencv_to_safe(pyobj_confidence, confidence, ArgInfo("confidence", 0)) &&
        pyopencv_to_safe(pyobj_refineIters, refineIters, ArgInfo("refineIters", 0)) )
    {
        ERRWRAP2(retval = cv::estimateAffine2D(from, to, inliers, method, ransacReprojThreshold, maxIters, confidence, refineIters));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(inliers));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_from = NULL;
    UMat from;
    PyObject* pyobj_to = NULL;
    UMat to;
    PyObject* pyobj_inliers = NULL;
    UMat inliers;
    PyObject* pyobj_method = NULL;
    int method=RANSAC;
    PyObject* pyobj_ransacReprojThreshold = NULL;
    double ransacReprojThreshold=3;
    PyObject* pyobj_maxIters = NULL;
    size_t maxIters=2000;
    PyObject* pyobj_confidence = NULL;
    double confidence=0.99;
    PyObject* pyobj_refineIters = NULL;
    size_t refineIters=10;
    cv::Mat retval;

    const char* keywords[] = { "from", "to", "inliers", "method", "ransacReprojThreshold", "maxIters", "confidence", "refineIters", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOOOO:estimateAffine2D", (char**)keywords, &pyobj_from, &pyobj_to, &pyobj_inliers, &pyobj_method, &pyobj_ransacReprojThreshold, &pyobj_maxIters, &pyobj_confidence, &pyobj_refineIters) &&
        pyopencv_to_safe(pyobj_from, from, ArgInfo("from", 0)) &&
        pyopencv_to_safe(pyobj_to, to, ArgInfo("to", 0)) &&
        pyopencv_to_safe(pyobj_inliers, inliers, ArgInfo("inliers", 1)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) &&
        pyopencv_to_safe(pyobj_ransacReprojThreshold, ransacReprojThreshold, ArgInfo("ransacReprojThreshold", 0)) &&
        pyopencv_to_safe(pyobj_maxIters, maxIters, ArgInfo("maxIters", 0)) &&
        pyopencv_to_safe(pyobj_confidence, confidence, ArgInfo("confidence", 0)) &&
        pyopencv_to_safe(pyobj_refineIters, refineIters, ArgInfo("refineIters", 0)) )
    {
        ERRWRAP2(retval = cv::estimateAffine2D(from, to, inliers, method, ransacReprojThreshold, maxIters, confidence, refineIters));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(inliers));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_pts1 = NULL;
    Mat pts1;
    PyObject* pyobj_pts2 = NULL;
    Mat pts2;
    PyObject* pyobj_inliers = NULL;
    Mat inliers;
    PyObject* pyobj_params = NULL;
    UsacParams params;
    cv::Mat retval;

    const char* keywords[] = { "pts1", "pts2", "params", "inliers", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:estimateAffine2D", (char**)keywords, &pyobj_pts1, &pyobj_pts2, &pyobj_params, &pyobj_inliers) &&
        pyopencv_to_safe(pyobj_pts1, pts1, ArgInfo("pts1", 0)) &&
        pyopencv_to_safe(pyobj_pts2, pts2, ArgInfo("pts2", 0)) &&
        pyopencv_to_safe(pyobj_inliers, inliers, ArgInfo("inliers", 1)) &&
        pyopencv_to_safe(pyobj_params, params, ArgInfo("params", 0)) )
    {
        ERRWRAP2(retval = cv::estimateAffine2D(pts1, pts2, inliers, params));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(inliers));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_pts1 = NULL;
    UMat pts1;
    PyObject* pyobj_pts2 = NULL;
    UMat pts2;
    PyObject* pyobj_inliers = NULL;
    UMat inliers;
    PyObject* pyobj_params = NULL;
    UsacParams params;
    cv::Mat retval;

    const char* keywords[] = { "pts1", "pts2", "params", "inliers", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:estimateAffine2D", (char**)keywords, &pyobj_pts1, &pyobj_pts2, &pyobj_params, &pyobj_inliers) &&
        pyopencv_to_safe(pyobj_pts1, pts1, ArgInfo("pts1", 0)) &&
        pyopencv_to_safe(pyobj_pts2, pts2, ArgInfo("pts2", 0)) &&
        pyopencv_to_safe(pyobj_inliers, inliers, ArgInfo("inliers", 1)) &&
        pyopencv_to_safe(pyobj_params, params, ArgInfo("params", 0)) )
    {
        ERRWRAP2(retval = cv::estimateAffine2D(pts1, pts2, inliers, params));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(inliers));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("estimateAffine2D");

    return NULL;
}

static PyObject* pyopencv_cv_estimateAffine3D(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_out = NULL;
    Mat out;
    PyObject* pyobj_inliers = NULL;
    Mat inliers;
    PyObject* pyobj_ransacThreshold = NULL;
    double ransacThreshold=3;
    PyObject* pyobj_confidence = NULL;
    double confidence=0.99;
    int retval;

    const char* keywords[] = { "src", "dst", "out", "inliers", "ransacThreshold", "confidence", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOO:estimateAffine3D", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_out, &pyobj_inliers, &pyobj_ransacThreshold, &pyobj_confidence) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 0)) &&
        pyopencv_to_safe(pyobj_out, out, ArgInfo("out", 1)) &&
        pyopencv_to_safe(pyobj_inliers, inliers, ArgInfo("inliers", 1)) &&
        pyopencv_to_safe(pyobj_ransacThreshold, ransacThreshold, ArgInfo("ransacThreshold", 0)) &&
        pyopencv_to_safe(pyobj_confidence, confidence, ArgInfo("confidence", 0)) )
    {
        ERRWRAP2(retval = cv::estimateAffine3D(src, dst, out, inliers, ransacThreshold, confidence));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(out), pyopencv_from(inliers));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_out = NULL;
    UMat out;
    PyObject* pyobj_inliers = NULL;
    UMat inliers;
    PyObject* pyobj_ransacThreshold = NULL;
    double ransacThreshold=3;
    PyObject* pyobj_confidence = NULL;
    double confidence=0.99;
    int retval;

    const char* keywords[] = { "src", "dst", "out", "inliers", "ransacThreshold", "confidence", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOO:estimateAffine3D", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_out, &pyobj_inliers, &pyobj_ransacThreshold, &pyobj_confidence) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 0)) &&
        pyopencv_to_safe(pyobj_out, out, ArgInfo("out", 1)) &&
        pyopencv_to_safe(pyobj_inliers, inliers, ArgInfo("inliers", 1)) &&
        pyopencv_to_safe(pyobj_ransacThreshold, ransacThreshold, ArgInfo("ransacThreshold", 0)) &&
        pyopencv_to_safe(pyobj_confidence, confidence, ArgInfo("confidence", 0)) )
    {
        ERRWRAP2(retval = cv::estimateAffine3D(src, dst, out, inliers, ransacThreshold, confidence));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(out), pyopencv_from(inliers));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("estimateAffine3D");

    return NULL;
}

static PyObject* pyopencv_cv_estimateAffinePartial2D(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_from = NULL;
    Mat from;
    PyObject* pyobj_to = NULL;
    Mat to;
    PyObject* pyobj_inliers = NULL;
    Mat inliers;
    PyObject* pyobj_method = NULL;
    int method=RANSAC;
    PyObject* pyobj_ransacReprojThreshold = NULL;
    double ransacReprojThreshold=3;
    PyObject* pyobj_maxIters = NULL;
    size_t maxIters=2000;
    PyObject* pyobj_confidence = NULL;
    double confidence=0.99;
    PyObject* pyobj_refineIters = NULL;
    size_t refineIters=10;
    cv::Mat retval;

    const char* keywords[] = { "from", "to", "inliers", "method", "ransacReprojThreshold", "maxIters", "confidence", "refineIters", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOOOO:estimateAffinePartial2D", (char**)keywords, &pyobj_from, &pyobj_to, &pyobj_inliers, &pyobj_method, &pyobj_ransacReprojThreshold, &pyobj_maxIters, &pyobj_confidence, &pyobj_refineIters) &&
        pyopencv_to_safe(pyobj_from, from, ArgInfo("from", 0)) &&
        pyopencv_to_safe(pyobj_to, to, ArgInfo("to", 0)) &&
        pyopencv_to_safe(pyobj_inliers, inliers, ArgInfo("inliers", 1)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) &&
        pyopencv_to_safe(pyobj_ransacReprojThreshold, ransacReprojThreshold, ArgInfo("ransacReprojThreshold", 0)) &&
        pyopencv_to_safe(pyobj_maxIters, maxIters, ArgInfo("maxIters", 0)) &&
        pyopencv_to_safe(pyobj_confidence, confidence, ArgInfo("confidence", 0)) &&
        pyopencv_to_safe(pyobj_refineIters, refineIters, ArgInfo("refineIters", 0)) )
    {
        ERRWRAP2(retval = cv::estimateAffinePartial2D(from, to, inliers, method, ransacReprojThreshold, maxIters, confidence, refineIters));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(inliers));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_from = NULL;
    UMat from;
    PyObject* pyobj_to = NULL;
    UMat to;
    PyObject* pyobj_inliers = NULL;
    UMat inliers;
    PyObject* pyobj_method = NULL;
    int method=RANSAC;
    PyObject* pyobj_ransacReprojThreshold = NULL;
    double ransacReprojThreshold=3;
    PyObject* pyobj_maxIters = NULL;
    size_t maxIters=2000;
    PyObject* pyobj_confidence = NULL;
    double confidence=0.99;
    PyObject* pyobj_refineIters = NULL;
    size_t refineIters=10;
    cv::Mat retval;

    const char* keywords[] = { "from", "to", "inliers", "method", "ransacReprojThreshold", "maxIters", "confidence", "refineIters", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOOOO:estimateAffinePartial2D", (char**)keywords, &pyobj_from, &pyobj_to, &pyobj_inliers, &pyobj_method, &pyobj_ransacReprojThreshold, &pyobj_maxIters, &pyobj_confidence, &pyobj_refineIters) &&
        pyopencv_to_safe(pyobj_from, from, ArgInfo("from", 0)) &&
        pyopencv_to_safe(pyobj_to, to, ArgInfo("to", 0)) &&
        pyopencv_to_safe(pyobj_inliers, inliers, ArgInfo("inliers", 1)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) &&
        pyopencv_to_safe(pyobj_ransacReprojThreshold, ransacReprojThreshold, ArgInfo("ransacReprojThreshold", 0)) &&
        pyopencv_to_safe(pyobj_maxIters, maxIters, ArgInfo("maxIters", 0)) &&
        pyopencv_to_safe(pyobj_confidence, confidence, ArgInfo("confidence", 0)) &&
        pyopencv_to_safe(pyobj_refineIters, refineIters, ArgInfo("refineIters", 0)) )
    {
        ERRWRAP2(retval = cv::estimateAffinePartial2D(from, to, inliers, method, ransacReprojThreshold, maxIters, confidence, refineIters));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(inliers));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("estimateAffinePartial2D");

    return NULL;
}

static PyObject* pyopencv_cv_estimateChessboardSharpness(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_patternSize = NULL;
    Size patternSize;
    PyObject* pyobj_corners = NULL;
    Mat corners;
    PyObject* pyobj_rise_distance = NULL;
    float rise_distance=0.8F;
    PyObject* pyobj_vertical = NULL;
    bool vertical=false;
    PyObject* pyobj_sharpness = NULL;
    Mat sharpness;
    Scalar retval;

    const char* keywords[] = { "image", "patternSize", "corners", "rise_distance", "vertical", "sharpness", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:estimateChessboardSharpness", (char**)keywords, &pyobj_image, &pyobj_patternSize, &pyobj_corners, &pyobj_rise_distance, &pyobj_vertical, &pyobj_sharpness) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_patternSize, patternSize, ArgInfo("patternSize", 0)) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 0)) &&
        pyopencv_to_safe(pyobj_rise_distance, rise_distance, ArgInfo("rise_distance", 0)) &&
        pyopencv_to_safe(pyobj_vertical, vertical, ArgInfo("vertical", 0)) &&
        pyopencv_to_safe(pyobj_sharpness, sharpness, ArgInfo("sharpness", 1)) )
    {
        ERRWRAP2(retval = cv::estimateChessboardSharpness(image, patternSize, corners, rise_distance, vertical, sharpness));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(sharpness));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_patternSize = NULL;
    Size patternSize;
    PyObject* pyobj_corners = NULL;
    UMat corners;
    PyObject* pyobj_rise_distance = NULL;
    float rise_distance=0.8F;
    PyObject* pyobj_vertical = NULL;
    bool vertical=false;
    PyObject* pyobj_sharpness = NULL;
    UMat sharpness;
    Scalar retval;

    const char* keywords[] = { "image", "patternSize", "corners", "rise_distance", "vertical", "sharpness", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:estimateChessboardSharpness", (char**)keywords, &pyobj_image, &pyobj_patternSize, &pyobj_corners, &pyobj_rise_distance, &pyobj_vertical, &pyobj_sharpness) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_patternSize, patternSize, ArgInfo("patternSize", 0)) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 0)) &&
        pyopencv_to_safe(pyobj_rise_distance, rise_distance, ArgInfo("rise_distance", 0)) &&
        pyopencv_to_safe(pyobj_vertical, vertical, ArgInfo("vertical", 0)) &&
        pyopencv_to_safe(pyobj_sharpness, sharpness, ArgInfo("sharpness", 1)) )
    {
        ERRWRAP2(retval = cv::estimateChessboardSharpness(image, patternSize, corners, rise_distance, vertical, sharpness));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(sharpness));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("estimateChessboardSharpness");

    return NULL;
}

static PyObject* pyopencv_cv_estimateTranslation3D(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_out = NULL;
    Mat out;
    PyObject* pyobj_inliers = NULL;
    Mat inliers;
    PyObject* pyobj_ransacThreshold = NULL;
    double ransacThreshold=3;
    PyObject* pyobj_confidence = NULL;
    double confidence=0.99;
    int retval;

    const char* keywords[] = { "src", "dst", "out", "inliers", "ransacThreshold", "confidence", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOO:estimateTranslation3D", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_out, &pyobj_inliers, &pyobj_ransacThreshold, &pyobj_confidence) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 0)) &&
        pyopencv_to_safe(pyobj_out, out, ArgInfo("out", 1)) &&
        pyopencv_to_safe(pyobj_inliers, inliers, ArgInfo("inliers", 1)) &&
        pyopencv_to_safe(pyobj_ransacThreshold, ransacThreshold, ArgInfo("ransacThreshold", 0)) &&
        pyopencv_to_safe(pyobj_confidence, confidence, ArgInfo("confidence", 0)) )
    {
        ERRWRAP2(retval = cv::estimateTranslation3D(src, dst, out, inliers, ransacThreshold, confidence));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(out), pyopencv_from(inliers));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_out = NULL;
    UMat out;
    PyObject* pyobj_inliers = NULL;
    UMat inliers;
    PyObject* pyobj_ransacThreshold = NULL;
    double ransacThreshold=3;
    PyObject* pyobj_confidence = NULL;
    double confidence=0.99;
    int retval;

    const char* keywords[] = { "src", "dst", "out", "inliers", "ransacThreshold", "confidence", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOO:estimateTranslation3D", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_out, &pyobj_inliers, &pyobj_ransacThreshold, &pyobj_confidence) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 0)) &&
        pyopencv_to_safe(pyobj_out, out, ArgInfo("out", 1)) &&
        pyopencv_to_safe(pyobj_inliers, inliers, ArgInfo("inliers", 1)) &&
        pyopencv_to_safe(pyobj_ransacThreshold, ransacThreshold, ArgInfo("ransacThreshold", 0)) &&
        pyopencv_to_safe(pyobj_confidence, confidence, ArgInfo("confidence", 0)) )
    {
        ERRWRAP2(retval = cv::estimateTranslation3D(src, dst, out, inliers, ransacThreshold, confidence));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(out), pyopencv_from(inliers));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("estimateTranslation3D");

    return NULL;
}

static PyObject* pyopencv_cv_exp(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:exp", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::exp(src, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:exp", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::exp(src, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("exp");

    return NULL;
}

static PyObject* pyopencv_cv_extractChannel(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_coi = NULL;
    int coi=0;

    const char* keywords[] = { "src", "coi", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:extractChannel", (char**)keywords, &pyobj_src, &pyobj_coi, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_coi, coi, ArgInfo("coi", 0)) )
    {
        ERRWRAP2(cv::extractChannel(src, dst, coi));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_coi = NULL;
    int coi=0;

    const char* keywords[] = { "src", "coi", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:extractChannel", (char**)keywords, &pyobj_src, &pyobj_coi, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_coi, coi, ArgInfo("coi", 0)) )
    {
        ERRWRAP2(cv::extractChannel(src, dst, coi));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("extractChannel");

    return NULL;
}

static PyObject* pyopencv_cv_fastAtan2(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_y = NULL;
    float y=0.f;
    PyObject* pyobj_x = NULL;
    float x=0.f;
    float retval;

    const char* keywords[] = { "y", "x", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:fastAtan2", (char**)keywords, &pyobj_y, &pyobj_x) &&
        pyopencv_to_safe(pyobj_y, y, ArgInfo("y", 0)) &&
        pyopencv_to_safe(pyobj_x, x, ArgInfo("x", 0)) )
    {
        ERRWRAP2(retval = cv::fastAtan2(y, x));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_fastNlMeansDenoising(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(4);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_h = NULL;
    float h=3;
    PyObject* pyobj_templateWindowSize = NULL;
    int templateWindowSize=7;
    PyObject* pyobj_searchWindowSize = NULL;
    int searchWindowSize=21;

    const char* keywords[] = { "src", "dst", "h", "templateWindowSize", "searchWindowSize", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOO:fastNlMeansDenoising", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_h, &pyobj_templateWindowSize, &pyobj_searchWindowSize) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_h, h, ArgInfo("h", 0)) &&
        pyopencv_to_safe(pyobj_templateWindowSize, templateWindowSize, ArgInfo("templateWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_searchWindowSize, searchWindowSize, ArgInfo("searchWindowSize", 0)) )
    {
        ERRWRAP2(cv::fastNlMeansDenoising(src, dst, h, templateWindowSize, searchWindowSize));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_h = NULL;
    float h=3;
    PyObject* pyobj_templateWindowSize = NULL;
    int templateWindowSize=7;
    PyObject* pyobj_searchWindowSize = NULL;
    int searchWindowSize=21;

    const char* keywords[] = { "src", "dst", "h", "templateWindowSize", "searchWindowSize", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOO:fastNlMeansDenoising", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_h, &pyobj_templateWindowSize, &pyobj_searchWindowSize) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_h, h, ArgInfo("h", 0)) &&
        pyopencv_to_safe(pyobj_templateWindowSize, templateWindowSize, ArgInfo("templateWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_searchWindowSize, searchWindowSize, ArgInfo("searchWindowSize", 0)) )
    {
        ERRWRAP2(cv::fastNlMeansDenoising(src, dst, h, templateWindowSize, searchWindowSize));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_h = NULL;
    vector_float h;
    PyObject* pyobj_templateWindowSize = NULL;
    int templateWindowSize=7;
    PyObject* pyobj_searchWindowSize = NULL;
    int searchWindowSize=21;
    PyObject* pyobj_normType = NULL;
    int normType=NORM_L2;

    const char* keywords[] = { "src", "h", "dst", "templateWindowSize", "searchWindowSize", "normType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOO:fastNlMeansDenoising", (char**)keywords, &pyobj_src, &pyobj_h, &pyobj_dst, &pyobj_templateWindowSize, &pyobj_searchWindowSize, &pyobj_normType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_h, h, ArgInfo("h", 0)) &&
        pyopencv_to_safe(pyobj_templateWindowSize, templateWindowSize, ArgInfo("templateWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_searchWindowSize, searchWindowSize, ArgInfo("searchWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_normType, normType, ArgInfo("normType", 0)) )
    {
        ERRWRAP2(cv::fastNlMeansDenoising(src, dst, h, templateWindowSize, searchWindowSize, normType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_h = NULL;
    vector_float h;
    PyObject* pyobj_templateWindowSize = NULL;
    int templateWindowSize=7;
    PyObject* pyobj_searchWindowSize = NULL;
    int searchWindowSize=21;
    PyObject* pyobj_normType = NULL;
    int normType=NORM_L2;

    const char* keywords[] = { "src", "h", "dst", "templateWindowSize", "searchWindowSize", "normType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOO:fastNlMeansDenoising", (char**)keywords, &pyobj_src, &pyobj_h, &pyobj_dst, &pyobj_templateWindowSize, &pyobj_searchWindowSize, &pyobj_normType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_h, h, ArgInfo("h", 0)) &&
        pyopencv_to_safe(pyobj_templateWindowSize, templateWindowSize, ArgInfo("templateWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_searchWindowSize, searchWindowSize, ArgInfo("searchWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_normType, normType, ArgInfo("normType", 0)) )
    {
        ERRWRAP2(cv::fastNlMeansDenoising(src, dst, h, templateWindowSize, searchWindowSize, normType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("fastNlMeansDenoising");

    return NULL;
}

static PyObject* pyopencv_cv_fastNlMeansDenoisingColored(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_h = NULL;
    float h=3;
    PyObject* pyobj_hColor = NULL;
    float hColor=3;
    PyObject* pyobj_templateWindowSize = NULL;
    int templateWindowSize=7;
    PyObject* pyobj_searchWindowSize = NULL;
    int searchWindowSize=21;

    const char* keywords[] = { "src", "dst", "h", "hColor", "templateWindowSize", "searchWindowSize", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOOO:fastNlMeansDenoisingColored", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_h, &pyobj_hColor, &pyobj_templateWindowSize, &pyobj_searchWindowSize) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_h, h, ArgInfo("h", 0)) &&
        pyopencv_to_safe(pyobj_hColor, hColor, ArgInfo("hColor", 0)) &&
        pyopencv_to_safe(pyobj_templateWindowSize, templateWindowSize, ArgInfo("templateWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_searchWindowSize, searchWindowSize, ArgInfo("searchWindowSize", 0)) )
    {
        ERRWRAP2(cv::fastNlMeansDenoisingColored(src, dst, h, hColor, templateWindowSize, searchWindowSize));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_h = NULL;
    float h=3;
    PyObject* pyobj_hColor = NULL;
    float hColor=3;
    PyObject* pyobj_templateWindowSize = NULL;
    int templateWindowSize=7;
    PyObject* pyobj_searchWindowSize = NULL;
    int searchWindowSize=21;

    const char* keywords[] = { "src", "dst", "h", "hColor", "templateWindowSize", "searchWindowSize", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOOO:fastNlMeansDenoisingColored", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_h, &pyobj_hColor, &pyobj_templateWindowSize, &pyobj_searchWindowSize) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_h, h, ArgInfo("h", 0)) &&
        pyopencv_to_safe(pyobj_hColor, hColor, ArgInfo("hColor", 0)) &&
        pyopencv_to_safe(pyobj_templateWindowSize, templateWindowSize, ArgInfo("templateWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_searchWindowSize, searchWindowSize, ArgInfo("searchWindowSize", 0)) )
    {
        ERRWRAP2(cv::fastNlMeansDenoisingColored(src, dst, h, hColor, templateWindowSize, searchWindowSize));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("fastNlMeansDenoisingColored");

    return NULL;
}

static PyObject* pyopencv_cv_fastNlMeansDenoisingColoredMulti(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_srcImgs = NULL;
    vector_Mat srcImgs;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_imgToDenoiseIndex = NULL;
    int imgToDenoiseIndex=0;
    PyObject* pyobj_temporalWindowSize = NULL;
    int temporalWindowSize=0;
    PyObject* pyobj_h = NULL;
    float h=3;
    PyObject* pyobj_hColor = NULL;
    float hColor=3;
    PyObject* pyobj_templateWindowSize = NULL;
    int templateWindowSize=7;
    PyObject* pyobj_searchWindowSize = NULL;
    int searchWindowSize=21;

    const char* keywords[] = { "srcImgs", "imgToDenoiseIndex", "temporalWindowSize", "dst", "h", "hColor", "templateWindowSize", "searchWindowSize", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOOO:fastNlMeansDenoisingColoredMulti", (char**)keywords, &pyobj_srcImgs, &pyobj_imgToDenoiseIndex, &pyobj_temporalWindowSize, &pyobj_dst, &pyobj_h, &pyobj_hColor, &pyobj_templateWindowSize, &pyobj_searchWindowSize) &&
        pyopencv_to_safe(pyobj_srcImgs, srcImgs, ArgInfo("srcImgs", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_imgToDenoiseIndex, imgToDenoiseIndex, ArgInfo("imgToDenoiseIndex", 0)) &&
        pyopencv_to_safe(pyobj_temporalWindowSize, temporalWindowSize, ArgInfo("temporalWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_h, h, ArgInfo("h", 0)) &&
        pyopencv_to_safe(pyobj_hColor, hColor, ArgInfo("hColor", 0)) &&
        pyopencv_to_safe(pyobj_templateWindowSize, templateWindowSize, ArgInfo("templateWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_searchWindowSize, searchWindowSize, ArgInfo("searchWindowSize", 0)) )
    {
        ERRWRAP2(cv::fastNlMeansDenoisingColoredMulti(srcImgs, dst, imgToDenoiseIndex, temporalWindowSize, h, hColor, templateWindowSize, searchWindowSize));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_srcImgs = NULL;
    vector_UMat srcImgs;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_imgToDenoiseIndex = NULL;
    int imgToDenoiseIndex=0;
    PyObject* pyobj_temporalWindowSize = NULL;
    int temporalWindowSize=0;
    PyObject* pyobj_h = NULL;
    float h=3;
    PyObject* pyobj_hColor = NULL;
    float hColor=3;
    PyObject* pyobj_templateWindowSize = NULL;
    int templateWindowSize=7;
    PyObject* pyobj_searchWindowSize = NULL;
    int searchWindowSize=21;

    const char* keywords[] = { "srcImgs", "imgToDenoiseIndex", "temporalWindowSize", "dst", "h", "hColor", "templateWindowSize", "searchWindowSize", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOOO:fastNlMeansDenoisingColoredMulti", (char**)keywords, &pyobj_srcImgs, &pyobj_imgToDenoiseIndex, &pyobj_temporalWindowSize, &pyobj_dst, &pyobj_h, &pyobj_hColor, &pyobj_templateWindowSize, &pyobj_searchWindowSize) &&
        pyopencv_to_safe(pyobj_srcImgs, srcImgs, ArgInfo("srcImgs", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_imgToDenoiseIndex, imgToDenoiseIndex, ArgInfo("imgToDenoiseIndex", 0)) &&
        pyopencv_to_safe(pyobj_temporalWindowSize, temporalWindowSize, ArgInfo("temporalWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_h, h, ArgInfo("h", 0)) &&
        pyopencv_to_safe(pyobj_hColor, hColor, ArgInfo("hColor", 0)) &&
        pyopencv_to_safe(pyobj_templateWindowSize, templateWindowSize, ArgInfo("templateWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_searchWindowSize, searchWindowSize, ArgInfo("searchWindowSize", 0)) )
    {
        ERRWRAP2(cv::fastNlMeansDenoisingColoredMulti(srcImgs, dst, imgToDenoiseIndex, temporalWindowSize, h, hColor, templateWindowSize, searchWindowSize));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("fastNlMeansDenoisingColoredMulti");

    return NULL;
}

static PyObject* pyopencv_cv_fastNlMeansDenoisingMulti(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(4);

    {
    PyObject* pyobj_srcImgs = NULL;
    vector_Mat srcImgs;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_imgToDenoiseIndex = NULL;
    int imgToDenoiseIndex=0;
    PyObject* pyobj_temporalWindowSize = NULL;
    int temporalWindowSize=0;
    PyObject* pyobj_h = NULL;
    float h=3;
    PyObject* pyobj_templateWindowSize = NULL;
    int templateWindowSize=7;
    PyObject* pyobj_searchWindowSize = NULL;
    int searchWindowSize=21;

    const char* keywords[] = { "srcImgs", "imgToDenoiseIndex", "temporalWindowSize", "dst", "h", "templateWindowSize", "searchWindowSize", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOO:fastNlMeansDenoisingMulti", (char**)keywords, &pyobj_srcImgs, &pyobj_imgToDenoiseIndex, &pyobj_temporalWindowSize, &pyobj_dst, &pyobj_h, &pyobj_templateWindowSize, &pyobj_searchWindowSize) &&
        pyopencv_to_safe(pyobj_srcImgs, srcImgs, ArgInfo("srcImgs", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_imgToDenoiseIndex, imgToDenoiseIndex, ArgInfo("imgToDenoiseIndex", 0)) &&
        pyopencv_to_safe(pyobj_temporalWindowSize, temporalWindowSize, ArgInfo("temporalWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_h, h, ArgInfo("h", 0)) &&
        pyopencv_to_safe(pyobj_templateWindowSize, templateWindowSize, ArgInfo("templateWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_searchWindowSize, searchWindowSize, ArgInfo("searchWindowSize", 0)) )
    {
        ERRWRAP2(cv::fastNlMeansDenoisingMulti(srcImgs, dst, imgToDenoiseIndex, temporalWindowSize, h, templateWindowSize, searchWindowSize));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_srcImgs = NULL;
    vector_UMat srcImgs;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_imgToDenoiseIndex = NULL;
    int imgToDenoiseIndex=0;
    PyObject* pyobj_temporalWindowSize = NULL;
    int temporalWindowSize=0;
    PyObject* pyobj_h = NULL;
    float h=3;
    PyObject* pyobj_templateWindowSize = NULL;
    int templateWindowSize=7;
    PyObject* pyobj_searchWindowSize = NULL;
    int searchWindowSize=21;

    const char* keywords[] = { "srcImgs", "imgToDenoiseIndex", "temporalWindowSize", "dst", "h", "templateWindowSize", "searchWindowSize", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOO:fastNlMeansDenoisingMulti", (char**)keywords, &pyobj_srcImgs, &pyobj_imgToDenoiseIndex, &pyobj_temporalWindowSize, &pyobj_dst, &pyobj_h, &pyobj_templateWindowSize, &pyobj_searchWindowSize) &&
        pyopencv_to_safe(pyobj_srcImgs, srcImgs, ArgInfo("srcImgs", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_imgToDenoiseIndex, imgToDenoiseIndex, ArgInfo("imgToDenoiseIndex", 0)) &&
        pyopencv_to_safe(pyobj_temporalWindowSize, temporalWindowSize, ArgInfo("temporalWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_h, h, ArgInfo("h", 0)) &&
        pyopencv_to_safe(pyobj_templateWindowSize, templateWindowSize, ArgInfo("templateWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_searchWindowSize, searchWindowSize, ArgInfo("searchWindowSize", 0)) )
    {
        ERRWRAP2(cv::fastNlMeansDenoisingMulti(srcImgs, dst, imgToDenoiseIndex, temporalWindowSize, h, templateWindowSize, searchWindowSize));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_srcImgs = NULL;
    vector_Mat srcImgs;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_imgToDenoiseIndex = NULL;
    int imgToDenoiseIndex=0;
    PyObject* pyobj_temporalWindowSize = NULL;
    int temporalWindowSize=0;
    PyObject* pyobj_h = NULL;
    vector_float h;
    PyObject* pyobj_templateWindowSize = NULL;
    int templateWindowSize=7;
    PyObject* pyobj_searchWindowSize = NULL;
    int searchWindowSize=21;
    PyObject* pyobj_normType = NULL;
    int normType=NORM_L2;

    const char* keywords[] = { "srcImgs", "imgToDenoiseIndex", "temporalWindowSize", "h", "dst", "templateWindowSize", "searchWindowSize", "normType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOO:fastNlMeansDenoisingMulti", (char**)keywords, &pyobj_srcImgs, &pyobj_imgToDenoiseIndex, &pyobj_temporalWindowSize, &pyobj_h, &pyobj_dst, &pyobj_templateWindowSize, &pyobj_searchWindowSize, &pyobj_normType) &&
        pyopencv_to_safe(pyobj_srcImgs, srcImgs, ArgInfo("srcImgs", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_imgToDenoiseIndex, imgToDenoiseIndex, ArgInfo("imgToDenoiseIndex", 0)) &&
        pyopencv_to_safe(pyobj_temporalWindowSize, temporalWindowSize, ArgInfo("temporalWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_h, h, ArgInfo("h", 0)) &&
        pyopencv_to_safe(pyobj_templateWindowSize, templateWindowSize, ArgInfo("templateWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_searchWindowSize, searchWindowSize, ArgInfo("searchWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_normType, normType, ArgInfo("normType", 0)) )
    {
        ERRWRAP2(cv::fastNlMeansDenoisingMulti(srcImgs, dst, imgToDenoiseIndex, temporalWindowSize, h, templateWindowSize, searchWindowSize, normType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_srcImgs = NULL;
    vector_UMat srcImgs;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_imgToDenoiseIndex = NULL;
    int imgToDenoiseIndex=0;
    PyObject* pyobj_temporalWindowSize = NULL;
    int temporalWindowSize=0;
    PyObject* pyobj_h = NULL;
    vector_float h;
    PyObject* pyobj_templateWindowSize = NULL;
    int templateWindowSize=7;
    PyObject* pyobj_searchWindowSize = NULL;
    int searchWindowSize=21;
    PyObject* pyobj_normType = NULL;
    int normType=NORM_L2;

    const char* keywords[] = { "srcImgs", "imgToDenoiseIndex", "temporalWindowSize", "h", "dst", "templateWindowSize", "searchWindowSize", "normType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOO:fastNlMeansDenoisingMulti", (char**)keywords, &pyobj_srcImgs, &pyobj_imgToDenoiseIndex, &pyobj_temporalWindowSize, &pyobj_h, &pyobj_dst, &pyobj_templateWindowSize, &pyobj_searchWindowSize, &pyobj_normType) &&
        pyopencv_to_safe(pyobj_srcImgs, srcImgs, ArgInfo("srcImgs", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_imgToDenoiseIndex, imgToDenoiseIndex, ArgInfo("imgToDenoiseIndex", 0)) &&
        pyopencv_to_safe(pyobj_temporalWindowSize, temporalWindowSize, ArgInfo("temporalWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_h, h, ArgInfo("h", 0)) &&
        pyopencv_to_safe(pyobj_templateWindowSize, templateWindowSize, ArgInfo("templateWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_searchWindowSize, searchWindowSize, ArgInfo("searchWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_normType, normType, ArgInfo("normType", 0)) )
    {
        ERRWRAP2(cv::fastNlMeansDenoisingMulti(srcImgs, dst, imgToDenoiseIndex, temporalWindowSize, h, templateWindowSize, searchWindowSize, normType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("fastNlMeansDenoisingMulti");

    return NULL;
}

static PyObject* pyopencv_cv_fillConvexPoly(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_points = NULL;
    Mat points;
    PyObject* pyobj_color = NULL;
    Scalar color;
    PyObject* pyobj_lineType = NULL;
    int lineType=LINE_8;
    PyObject* pyobj_shift = NULL;
    int shift=0;

    const char* keywords[] = { "img", "points", "color", "lineType", "shift", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:fillConvexPoly", (char**)keywords, &pyobj_img, &pyobj_points, &pyobj_color, &pyobj_lineType, &pyobj_shift) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_lineType, lineType, ArgInfo("lineType", 0)) &&
        pyopencv_to_safe(pyobj_shift, shift, ArgInfo("shift", 0)) )
    {
        ERRWRAP2(cv::fillConvexPoly(img, points, color, lineType, shift));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_points = NULL;
    UMat points;
    PyObject* pyobj_color = NULL;
    Scalar color;
    PyObject* pyobj_lineType = NULL;
    int lineType=LINE_8;
    PyObject* pyobj_shift = NULL;
    int shift=0;

    const char* keywords[] = { "img", "points", "color", "lineType", "shift", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:fillConvexPoly", (char**)keywords, &pyobj_img, &pyobj_points, &pyobj_color, &pyobj_lineType, &pyobj_shift) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_lineType, lineType, ArgInfo("lineType", 0)) &&
        pyopencv_to_safe(pyobj_shift, shift, ArgInfo("shift", 0)) )
    {
        ERRWRAP2(cv::fillConvexPoly(img, points, color, lineType, shift));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("fillConvexPoly");

    return NULL;
}

static PyObject* pyopencv_cv_fillPoly(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_pts = NULL;
    vector_Mat pts;
    PyObject* pyobj_color = NULL;
    Scalar color;
    PyObject* pyobj_lineType = NULL;
    int lineType=LINE_8;
    PyObject* pyobj_shift = NULL;
    int shift=0;
    PyObject* pyobj_offset = NULL;
    Point offset;

    const char* keywords[] = { "img", "pts", "color", "lineType", "shift", "offset", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:fillPoly", (char**)keywords, &pyobj_img, &pyobj_pts, &pyobj_color, &pyobj_lineType, &pyobj_shift, &pyobj_offset) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_pts, pts, ArgInfo("pts", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_lineType, lineType, ArgInfo("lineType", 0)) &&
        pyopencv_to_safe(pyobj_shift, shift, ArgInfo("shift", 0)) &&
        pyopencv_to_safe(pyobj_offset, offset, ArgInfo("offset", 0)) )
    {
        ERRWRAP2(cv::fillPoly(img, pts, color, lineType, shift, offset));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_pts = NULL;
    vector_UMat pts;
    PyObject* pyobj_color = NULL;
    Scalar color;
    PyObject* pyobj_lineType = NULL;
    int lineType=LINE_8;
    PyObject* pyobj_shift = NULL;
    int shift=0;
    PyObject* pyobj_offset = NULL;
    Point offset;

    const char* keywords[] = { "img", "pts", "color", "lineType", "shift", "offset", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:fillPoly", (char**)keywords, &pyobj_img, &pyobj_pts, &pyobj_color, &pyobj_lineType, &pyobj_shift, &pyobj_offset) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_pts, pts, ArgInfo("pts", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_lineType, lineType, ArgInfo("lineType", 0)) &&
        pyopencv_to_safe(pyobj_shift, shift, ArgInfo("shift", 0)) &&
        pyopencv_to_safe(pyobj_offset, offset, ArgInfo("offset", 0)) )
    {
        ERRWRAP2(cv::fillPoly(img, pts, color, lineType, shift, offset));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("fillPoly");

    return NULL;
}

static PyObject* pyopencv_cv_filter2D(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_ddepth = NULL;
    int ddepth=0;
    PyObject* pyobj_kernel = NULL;
    Mat kernel;
    PyObject* pyobj_anchor = NULL;
    Point anchor=Point(-1,-1);
    PyObject* pyobj_delta = NULL;
    double delta=0;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "ddepth", "kernel", "dst", "anchor", "delta", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOO:filter2D", (char**)keywords, &pyobj_src, &pyobj_ddepth, &pyobj_kernel, &pyobj_dst, &pyobj_anchor, &pyobj_delta, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_ddepth, ddepth, ArgInfo("ddepth", 0)) &&
        pyopencv_to_safe(pyobj_kernel, kernel, ArgInfo("kernel", 0)) &&
        pyopencv_to_safe(pyobj_anchor, anchor, ArgInfo("anchor", 0)) &&
        pyopencv_to_safe(pyobj_delta, delta, ArgInfo("delta", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::filter2D(src, dst, ddepth, kernel, anchor, delta, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_ddepth = NULL;
    int ddepth=0;
    PyObject* pyobj_kernel = NULL;
    UMat kernel;
    PyObject* pyobj_anchor = NULL;
    Point anchor=Point(-1,-1);
    PyObject* pyobj_delta = NULL;
    double delta=0;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "ddepth", "kernel", "dst", "anchor", "delta", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOO:filter2D", (char**)keywords, &pyobj_src, &pyobj_ddepth, &pyobj_kernel, &pyobj_dst, &pyobj_anchor, &pyobj_delta, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_ddepth, ddepth, ArgInfo("ddepth", 0)) &&
        pyopencv_to_safe(pyobj_kernel, kernel, ArgInfo("kernel", 0)) &&
        pyopencv_to_safe(pyobj_anchor, anchor, ArgInfo("anchor", 0)) &&
        pyopencv_to_safe(pyobj_delta, delta, ArgInfo("delta", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::filter2D(src, dst, ddepth, kernel, anchor, delta, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("filter2D");

    return NULL;
}

static PyObject* pyopencv_cv_filterHomographyDecompByVisibleRefpoints(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_rotations = NULL;
    vector_Mat rotations;
    PyObject* pyobj_normals = NULL;
    vector_Mat normals;
    PyObject* pyobj_beforePoints = NULL;
    Mat beforePoints;
    PyObject* pyobj_afterPoints = NULL;
    Mat afterPoints;
    PyObject* pyobj_possibleSolutions = NULL;
    Mat possibleSolutions;
    PyObject* pyobj_pointsMask = NULL;
    Mat pointsMask;

    const char* keywords[] = { "rotations", "normals", "beforePoints", "afterPoints", "possibleSolutions", "pointsMask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OO:filterHomographyDecompByVisibleRefpoints", (char**)keywords, &pyobj_rotations, &pyobj_normals, &pyobj_beforePoints, &pyobj_afterPoints, &pyobj_possibleSolutions, &pyobj_pointsMask) &&
        pyopencv_to_safe(pyobj_rotations, rotations, ArgInfo("rotations", 0)) &&
        pyopencv_to_safe(pyobj_normals, normals, ArgInfo("normals", 0)) &&
        pyopencv_to_safe(pyobj_beforePoints, beforePoints, ArgInfo("beforePoints", 0)) &&
        pyopencv_to_safe(pyobj_afterPoints, afterPoints, ArgInfo("afterPoints", 0)) &&
        pyopencv_to_safe(pyobj_possibleSolutions, possibleSolutions, ArgInfo("possibleSolutions", 1)) &&
        pyopencv_to_safe(pyobj_pointsMask, pointsMask, ArgInfo("pointsMask", 0)) )
    {
        ERRWRAP2(cv::filterHomographyDecompByVisibleRefpoints(rotations, normals, beforePoints, afterPoints, possibleSolutions, pointsMask));
        return pyopencv_from(possibleSolutions);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_rotations = NULL;
    vector_UMat rotations;
    PyObject* pyobj_normals = NULL;
    vector_UMat normals;
    PyObject* pyobj_beforePoints = NULL;
    UMat beforePoints;
    PyObject* pyobj_afterPoints = NULL;
    UMat afterPoints;
    PyObject* pyobj_possibleSolutions = NULL;
    UMat possibleSolutions;
    PyObject* pyobj_pointsMask = NULL;
    UMat pointsMask;

    const char* keywords[] = { "rotations", "normals", "beforePoints", "afterPoints", "possibleSolutions", "pointsMask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OO:filterHomographyDecompByVisibleRefpoints", (char**)keywords, &pyobj_rotations, &pyobj_normals, &pyobj_beforePoints, &pyobj_afterPoints, &pyobj_possibleSolutions, &pyobj_pointsMask) &&
        pyopencv_to_safe(pyobj_rotations, rotations, ArgInfo("rotations", 0)) &&
        pyopencv_to_safe(pyobj_normals, normals, ArgInfo("normals", 0)) &&
        pyopencv_to_safe(pyobj_beforePoints, beforePoints, ArgInfo("beforePoints", 0)) &&
        pyopencv_to_safe(pyobj_afterPoints, afterPoints, ArgInfo("afterPoints", 0)) &&
        pyopencv_to_safe(pyobj_possibleSolutions, possibleSolutions, ArgInfo("possibleSolutions", 1)) &&
        pyopencv_to_safe(pyobj_pointsMask, pointsMask, ArgInfo("pointsMask", 0)) )
    {
        ERRWRAP2(cv::filterHomographyDecompByVisibleRefpoints(rotations, normals, beforePoints, afterPoints, possibleSolutions, pointsMask));
        return pyopencv_from(possibleSolutions);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("filterHomographyDecompByVisibleRefpoints");

    return NULL;
}

static PyObject* pyopencv_cv_filterSpeckles(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_newVal = NULL;
    double newVal=0;
    PyObject* pyobj_maxSpeckleSize = NULL;
    int maxSpeckleSize=0;
    PyObject* pyobj_maxDiff = NULL;
    double maxDiff=0;
    PyObject* pyobj_buf = NULL;
    Mat buf;

    const char* keywords[] = { "img", "newVal", "maxSpeckleSize", "maxDiff", "buf", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:filterSpeckles", (char**)keywords, &pyobj_img, &pyobj_newVal, &pyobj_maxSpeckleSize, &pyobj_maxDiff, &pyobj_buf) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_newVal, newVal, ArgInfo("newVal", 0)) &&
        pyopencv_to_safe(pyobj_maxSpeckleSize, maxSpeckleSize, ArgInfo("maxSpeckleSize", 0)) &&
        pyopencv_to_safe(pyobj_maxDiff, maxDiff, ArgInfo("maxDiff", 0)) &&
        pyopencv_to_safe(pyobj_buf, buf, ArgInfo("buf", 1)) )
    {
        ERRWRAP2(cv::filterSpeckles(img, newVal, maxSpeckleSize, maxDiff, buf));
        return Py_BuildValue("(NN)", pyopencv_from(img), pyopencv_from(buf));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_newVal = NULL;
    double newVal=0;
    PyObject* pyobj_maxSpeckleSize = NULL;
    int maxSpeckleSize=0;
    PyObject* pyobj_maxDiff = NULL;
    double maxDiff=0;
    PyObject* pyobj_buf = NULL;
    UMat buf;

    const char* keywords[] = { "img", "newVal", "maxSpeckleSize", "maxDiff", "buf", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:filterSpeckles", (char**)keywords, &pyobj_img, &pyobj_newVal, &pyobj_maxSpeckleSize, &pyobj_maxDiff, &pyobj_buf) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_newVal, newVal, ArgInfo("newVal", 0)) &&
        pyopencv_to_safe(pyobj_maxSpeckleSize, maxSpeckleSize, ArgInfo("maxSpeckleSize", 0)) &&
        pyopencv_to_safe(pyobj_maxDiff, maxDiff, ArgInfo("maxDiff", 0)) &&
        pyopencv_to_safe(pyobj_buf, buf, ArgInfo("buf", 1)) )
    {
        ERRWRAP2(cv::filterSpeckles(img, newVal, maxSpeckleSize, maxDiff, buf));
        return Py_BuildValue("(NN)", pyopencv_from(img), pyopencv_from(buf));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("filterSpeckles");

    return NULL;
}

static PyObject* pyopencv_cv_find4QuadCornerSubpix(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_corners = NULL;
    Mat corners;
    PyObject* pyobj_region_size = NULL;
    Size region_size;
    bool retval;

    const char* keywords[] = { "img", "corners", "region_size", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:find4QuadCornerSubpix", (char**)keywords, &pyobj_img, &pyobj_corners, &pyobj_region_size) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 1)) &&
        pyopencv_to_safe(pyobj_region_size, region_size, ArgInfo("region_size", 0)) )
    {
        ERRWRAP2(retval = cv::find4QuadCornerSubpix(img, corners, region_size));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(corners));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_corners = NULL;
    UMat corners;
    PyObject* pyobj_region_size = NULL;
    Size region_size;
    bool retval;

    const char* keywords[] = { "img", "corners", "region_size", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:find4QuadCornerSubpix", (char**)keywords, &pyobj_img, &pyobj_corners, &pyobj_region_size) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 1)) &&
        pyopencv_to_safe(pyobj_region_size, region_size, ArgInfo("region_size", 0)) )
    {
        ERRWRAP2(retval = cv::find4QuadCornerSubpix(img, corners, region_size));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(corners));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("find4QuadCornerSubpix");

    return NULL;
}

static PyObject* pyopencv_cv_findChessboardCorners(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_patternSize = NULL;
    Size patternSize;
    PyObject* pyobj_corners = NULL;
    Mat corners;
    PyObject* pyobj_flags = NULL;
    int flags=CALIB_CB_ADAPTIVE_THRESH + CALIB_CB_NORMALIZE_IMAGE;
    bool retval;

    const char* keywords[] = { "image", "patternSize", "corners", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:findChessboardCorners", (char**)keywords, &pyobj_image, &pyobj_patternSize, &pyobj_corners, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_patternSize, patternSize, ArgInfo("patternSize", 0)) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(retval = cv::findChessboardCorners(image, patternSize, corners, flags));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(corners));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_patternSize = NULL;
    Size patternSize;
    PyObject* pyobj_corners = NULL;
    UMat corners;
    PyObject* pyobj_flags = NULL;
    int flags=CALIB_CB_ADAPTIVE_THRESH + CALIB_CB_NORMALIZE_IMAGE;
    bool retval;

    const char* keywords[] = { "image", "patternSize", "corners", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:findChessboardCorners", (char**)keywords, &pyobj_image, &pyobj_patternSize, &pyobj_corners, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_patternSize, patternSize, ArgInfo("patternSize", 0)) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(retval = cv::findChessboardCorners(image, patternSize, corners, flags));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(corners));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("findChessboardCorners");

    return NULL;
}

static PyObject* pyopencv_cv_findChessboardCornersSB(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_patternSize = NULL;
    Size patternSize;
    PyObject* pyobj_corners = NULL;
    Mat corners;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    bool retval;

    const char* keywords[] = { "image", "patternSize", "corners", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:findChessboardCornersSB", (char**)keywords, &pyobj_image, &pyobj_patternSize, &pyobj_corners, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_patternSize, patternSize, ArgInfo("patternSize", 0)) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(retval = cv::findChessboardCornersSB(image, patternSize, corners, flags));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(corners));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_patternSize = NULL;
    Size patternSize;
    PyObject* pyobj_corners = NULL;
    UMat corners;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    bool retval;

    const char* keywords[] = { "image", "patternSize", "corners", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:findChessboardCornersSB", (char**)keywords, &pyobj_image, &pyobj_patternSize, &pyobj_corners, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_patternSize, patternSize, ArgInfo("patternSize", 0)) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(retval = cv::findChessboardCornersSB(image, patternSize, corners, flags));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(corners));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("findChessboardCornersSB");

    return NULL;
}

static PyObject* pyopencv_cv_findChessboardCornersSBWithMeta(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_patternSize = NULL;
    Size patternSize;
    PyObject* pyobj_corners = NULL;
    Mat corners;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_meta = NULL;
    Mat meta;
    bool retval;

    const char* keywords[] = { "image", "patternSize", "flags", "corners", "meta", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:findChessboardCornersSBWithMeta", (char**)keywords, &pyobj_image, &pyobj_patternSize, &pyobj_flags, &pyobj_corners, &pyobj_meta) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_patternSize, patternSize, ArgInfo("patternSize", 0)) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_meta, meta, ArgInfo("meta", 1)) )
    {
        ERRWRAP2(retval = cv::findChessboardCornersSB(image, patternSize, corners, flags, meta));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(corners), pyopencv_from(meta));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_patternSize = NULL;
    Size patternSize;
    PyObject* pyobj_corners = NULL;
    UMat corners;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_meta = NULL;
    UMat meta;
    bool retval;

    const char* keywords[] = { "image", "patternSize", "flags", "corners", "meta", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:findChessboardCornersSBWithMeta", (char**)keywords, &pyobj_image, &pyobj_patternSize, &pyobj_flags, &pyobj_corners, &pyobj_meta) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_patternSize, patternSize, ArgInfo("patternSize", 0)) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_meta, meta, ArgInfo("meta", 1)) )
    {
        ERRWRAP2(retval = cv::findChessboardCornersSB(image, patternSize, corners, flags, meta));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(corners), pyopencv_from(meta));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("findChessboardCornersSBWithMeta");

    return NULL;
}

static PyObject* pyopencv_cv_findCirclesGrid(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(4);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_patternSize = NULL;
    Size patternSize;
    PyObject* pyobj_centers = NULL;
    Mat centers;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_blobDetector = NULL;
    Ptr<FeatureDetector> blobDetector;
    PyObject* pyobj_parameters = NULL;
    CirclesGridFinderParameters parameters;
    bool retval;

    const char* keywords[] = { "image", "patternSize", "flags", "blobDetector", "parameters", "centers", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|O:findCirclesGrid", (char**)keywords, &pyobj_image, &pyobj_patternSize, &pyobj_flags, &pyobj_blobDetector, &pyobj_parameters, &pyobj_centers) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_patternSize, patternSize, ArgInfo("patternSize", 0)) &&
        pyopencv_to_safe(pyobj_centers, centers, ArgInfo("centers", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_blobDetector, blobDetector, ArgInfo("blobDetector", 0)) &&
        pyopencv_to_safe(pyobj_parameters, parameters, ArgInfo("parameters", 0)) )
    {
        ERRWRAP2(retval = cv::findCirclesGrid(image, patternSize, centers, flags, blobDetector, parameters));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(centers));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_patternSize = NULL;
    Size patternSize;
    PyObject* pyobj_centers = NULL;
    UMat centers;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_blobDetector = NULL;
    Ptr<FeatureDetector> blobDetector;
    PyObject* pyobj_parameters = NULL;
    CirclesGridFinderParameters parameters;
    bool retval;

    const char* keywords[] = { "image", "patternSize", "flags", "blobDetector", "parameters", "centers", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|O:findCirclesGrid", (char**)keywords, &pyobj_image, &pyobj_patternSize, &pyobj_flags, &pyobj_blobDetector, &pyobj_parameters, &pyobj_centers) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_patternSize, patternSize, ArgInfo("patternSize", 0)) &&
        pyopencv_to_safe(pyobj_centers, centers, ArgInfo("centers", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_blobDetector, blobDetector, ArgInfo("blobDetector", 0)) &&
        pyopencv_to_safe(pyobj_parameters, parameters, ArgInfo("parameters", 0)) )
    {
        ERRWRAP2(retval = cv::findCirclesGrid(image, patternSize, centers, flags, blobDetector, parameters));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(centers));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_patternSize = NULL;
    Size patternSize;
    PyObject* pyobj_centers = NULL;
    Mat centers;
    PyObject* pyobj_flags = NULL;
    int flags=CALIB_CB_SYMMETRIC_GRID;
    PyObject* pyobj_blobDetector = NULL;
    Ptr<FeatureDetector> blobDetector=SimpleBlobDetector::create();
    bool retval;

    const char* keywords[] = { "image", "patternSize", "centers", "flags", "blobDetector", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:findCirclesGrid", (char**)keywords, &pyobj_image, &pyobj_patternSize, &pyobj_centers, &pyobj_flags, &pyobj_blobDetector) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_patternSize, patternSize, ArgInfo("patternSize", 0)) &&
        pyopencv_to_safe(pyobj_centers, centers, ArgInfo("centers", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_blobDetector, blobDetector, ArgInfo("blobDetector", 0)) )
    {
        ERRWRAP2(retval = cv::findCirclesGrid(image, patternSize, centers, flags, blobDetector));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(centers));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_patternSize = NULL;
    Size patternSize;
    PyObject* pyobj_centers = NULL;
    UMat centers;
    PyObject* pyobj_flags = NULL;
    int flags=CALIB_CB_SYMMETRIC_GRID;
    PyObject* pyobj_blobDetector = NULL;
    Ptr<FeatureDetector> blobDetector=SimpleBlobDetector::create();
    bool retval;

    const char* keywords[] = { "image", "patternSize", "centers", "flags", "blobDetector", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:findCirclesGrid", (char**)keywords, &pyobj_image, &pyobj_patternSize, &pyobj_centers, &pyobj_flags, &pyobj_blobDetector) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_patternSize, patternSize, ArgInfo("patternSize", 0)) &&
        pyopencv_to_safe(pyobj_centers, centers, ArgInfo("centers", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_blobDetector, blobDetector, ArgInfo("blobDetector", 0)) )
    {
        ERRWRAP2(retval = cv::findCirclesGrid(image, patternSize, centers, flags, blobDetector));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(centers));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("findCirclesGrid");

    return NULL;
}

static PyObject* pyopencv_cv_findContours(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_contours = NULL;
    vector_Mat contours;
    PyObject* pyobj_hierarchy = NULL;
    Mat hierarchy;
    PyObject* pyobj_mode = NULL;
    int mode=0;
    PyObject* pyobj_method = NULL;
    int method=0;
    PyObject* pyobj_offset = NULL;
    Point offset;

    const char* keywords[] = { "image", "mode", "method", "contours", "hierarchy", "offset", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:findContours", (char**)keywords, &pyobj_image, &pyobj_mode, &pyobj_method, &pyobj_contours, &pyobj_hierarchy, &pyobj_offset) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_contours, contours, ArgInfo("contours", 1)) &&
        pyopencv_to_safe(pyobj_hierarchy, hierarchy, ArgInfo("hierarchy", 1)) &&
        pyopencv_to_safe(pyobj_mode, mode, ArgInfo("mode", 0)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) &&
        pyopencv_to_safe(pyobj_offset, offset, ArgInfo("offset", 0)) )
    {
        ERRWRAP2(cv::findContours(image, contours, hierarchy, mode, method, offset));
        return Py_BuildValue("(NN)", pyopencv_from(contours), pyopencv_from(hierarchy));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_contours = NULL;
    vector_UMat contours;
    PyObject* pyobj_hierarchy = NULL;
    UMat hierarchy;
    PyObject* pyobj_mode = NULL;
    int mode=0;
    PyObject* pyobj_method = NULL;
    int method=0;
    PyObject* pyobj_offset = NULL;
    Point offset;

    const char* keywords[] = { "image", "mode", "method", "contours", "hierarchy", "offset", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:findContours", (char**)keywords, &pyobj_image, &pyobj_mode, &pyobj_method, &pyobj_contours, &pyobj_hierarchy, &pyobj_offset) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_contours, contours, ArgInfo("contours", 1)) &&
        pyopencv_to_safe(pyobj_hierarchy, hierarchy, ArgInfo("hierarchy", 1)) &&
        pyopencv_to_safe(pyobj_mode, mode, ArgInfo("mode", 0)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) &&
        pyopencv_to_safe(pyobj_offset, offset, ArgInfo("offset", 0)) )
    {
        ERRWRAP2(cv::findContours(image, contours, hierarchy, mode, method, offset));
        return Py_BuildValue("(NN)", pyopencv_from(contours), pyopencv_from(hierarchy));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("findContours");

    return NULL;
}

static PyObject* pyopencv_cv_findEssentialMat(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(8);

    {
    PyObject* pyobj_points1 = NULL;
    Mat points1;
    PyObject* pyobj_points2 = NULL;
    Mat points2;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_method = NULL;
    int method=RANSAC;
    PyObject* pyobj_prob = NULL;
    double prob=0.999;
    PyObject* pyobj_threshold = NULL;
    double threshold=1.0;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    Mat retval;

    const char* keywords[] = { "points1", "points2", "cameraMatrix", "method", "prob", "threshold", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOO:findEssentialMat", (char**)keywords, &pyobj_points1, &pyobj_points2, &pyobj_cameraMatrix, &pyobj_method, &pyobj_prob, &pyobj_threshold, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_points1, points1, ArgInfo("points1", 0)) &&
        pyopencv_to_safe(pyobj_points2, points2, ArgInfo("points2", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) &&
        pyopencv_to_safe(pyobj_prob, prob, ArgInfo("prob", 0)) &&
        pyopencv_to_safe(pyobj_threshold, threshold, ArgInfo("threshold", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 1)) )
    {
        ERRWRAP2(retval = cv::findEssentialMat(points1, points2, cameraMatrix, method, prob, threshold, mask));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(mask));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_points1 = NULL;
    UMat points1;
    PyObject* pyobj_points2 = NULL;
    UMat points2;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_method = NULL;
    int method=RANSAC;
    PyObject* pyobj_prob = NULL;
    double prob=0.999;
    PyObject* pyobj_threshold = NULL;
    double threshold=1.0;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    Mat retval;

    const char* keywords[] = { "points1", "points2", "cameraMatrix", "method", "prob", "threshold", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOO:findEssentialMat", (char**)keywords, &pyobj_points1, &pyobj_points2, &pyobj_cameraMatrix, &pyobj_method, &pyobj_prob, &pyobj_threshold, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_points1, points1, ArgInfo("points1", 0)) &&
        pyopencv_to_safe(pyobj_points2, points2, ArgInfo("points2", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) &&
        pyopencv_to_safe(pyobj_prob, prob, ArgInfo("prob", 0)) &&
        pyopencv_to_safe(pyobj_threshold, threshold, ArgInfo("threshold", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 1)) )
    {
        ERRWRAP2(retval = cv::findEssentialMat(points1, points2, cameraMatrix, method, prob, threshold, mask));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(mask));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_points1 = NULL;
    Mat points1;
    PyObject* pyobj_points2 = NULL;
    Mat points2;
    PyObject* pyobj_focal = NULL;
    double focal=1.0;
    PyObject* pyobj_pp = NULL;
    Point2d pp=Point2d(0, 0);
    PyObject* pyobj_method = NULL;
    int method=RANSAC;
    PyObject* pyobj_prob = NULL;
    double prob=0.999;
    PyObject* pyobj_threshold = NULL;
    double threshold=1.0;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    Mat retval;

    const char* keywords[] = { "points1", "points2", "focal", "pp", "method", "prob", "threshold", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOOOO:findEssentialMat", (char**)keywords, &pyobj_points1, &pyobj_points2, &pyobj_focal, &pyobj_pp, &pyobj_method, &pyobj_prob, &pyobj_threshold, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_points1, points1, ArgInfo("points1", 0)) &&
        pyopencv_to_safe(pyobj_points2, points2, ArgInfo("points2", 0)) &&
        pyopencv_to_safe(pyobj_focal, focal, ArgInfo("focal", 0)) &&
        pyopencv_to_safe(pyobj_pp, pp, ArgInfo("pp", 0)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) &&
        pyopencv_to_safe(pyobj_prob, prob, ArgInfo("prob", 0)) &&
        pyopencv_to_safe(pyobj_threshold, threshold, ArgInfo("threshold", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 1)) )
    {
        ERRWRAP2(retval = cv::findEssentialMat(points1, points2, focal, pp, method, prob, threshold, mask));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(mask));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_points1 = NULL;
    UMat points1;
    PyObject* pyobj_points2 = NULL;
    UMat points2;
    PyObject* pyobj_focal = NULL;
    double focal=1.0;
    PyObject* pyobj_pp = NULL;
    Point2d pp=Point2d(0, 0);
    PyObject* pyobj_method = NULL;
    int method=RANSAC;
    PyObject* pyobj_prob = NULL;
    double prob=0.999;
    PyObject* pyobj_threshold = NULL;
    double threshold=1.0;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    Mat retval;

    const char* keywords[] = { "points1", "points2", "focal", "pp", "method", "prob", "threshold", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOOOO:findEssentialMat", (char**)keywords, &pyobj_points1, &pyobj_points2, &pyobj_focal, &pyobj_pp, &pyobj_method, &pyobj_prob, &pyobj_threshold, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_points1, points1, ArgInfo("points1", 0)) &&
        pyopencv_to_safe(pyobj_points2, points2, ArgInfo("points2", 0)) &&
        pyopencv_to_safe(pyobj_focal, focal, ArgInfo("focal", 0)) &&
        pyopencv_to_safe(pyobj_pp, pp, ArgInfo("pp", 0)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) &&
        pyopencv_to_safe(pyobj_prob, prob, ArgInfo("prob", 0)) &&
        pyopencv_to_safe(pyobj_threshold, threshold, ArgInfo("threshold", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 1)) )
    {
        ERRWRAP2(retval = cv::findEssentialMat(points1, points2, focal, pp, method, prob, threshold, mask));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(mask));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_points1 = NULL;
    Mat points1;
    PyObject* pyobj_points2 = NULL;
    Mat points2;
    PyObject* pyobj_cameraMatrix1 = NULL;
    Mat cameraMatrix1;
    PyObject* pyobj_distCoeffs1 = NULL;
    Mat distCoeffs1;
    PyObject* pyobj_cameraMatrix2 = NULL;
    Mat cameraMatrix2;
    PyObject* pyobj_distCoeffs2 = NULL;
    Mat distCoeffs2;
    PyObject* pyobj_method = NULL;
    int method=RANSAC;
    PyObject* pyobj_prob = NULL;
    double prob=0.999;
    PyObject* pyobj_threshold = NULL;
    double threshold=1.0;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    Mat retval;

    const char* keywords[] = { "points1", "points2", "cameraMatrix1", "distCoeffs1", "cameraMatrix2", "distCoeffs2", "method", "prob", "threshold", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|OOOO:findEssentialMat", (char**)keywords, &pyobj_points1, &pyobj_points2, &pyobj_cameraMatrix1, &pyobj_distCoeffs1, &pyobj_cameraMatrix2, &pyobj_distCoeffs2, &pyobj_method, &pyobj_prob, &pyobj_threshold, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_points1, points1, ArgInfo("points1", 0)) &&
        pyopencv_to_safe(pyobj_points2, points2, ArgInfo("points2", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix1, cameraMatrix1, ArgInfo("cameraMatrix1", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs1, distCoeffs1, ArgInfo("distCoeffs1", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix2, cameraMatrix2, ArgInfo("cameraMatrix2", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs2, distCoeffs2, ArgInfo("distCoeffs2", 0)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) &&
        pyopencv_to_safe(pyobj_prob, prob, ArgInfo("prob", 0)) &&
        pyopencv_to_safe(pyobj_threshold, threshold, ArgInfo("threshold", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 1)) )
    {
        ERRWRAP2(retval = cv::findEssentialMat(points1, points2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, method, prob, threshold, mask));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(mask));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_points1 = NULL;
    UMat points1;
    PyObject* pyobj_points2 = NULL;
    UMat points2;
    PyObject* pyobj_cameraMatrix1 = NULL;
    UMat cameraMatrix1;
    PyObject* pyobj_distCoeffs1 = NULL;
    UMat distCoeffs1;
    PyObject* pyobj_cameraMatrix2 = NULL;
    UMat cameraMatrix2;
    PyObject* pyobj_distCoeffs2 = NULL;
    UMat distCoeffs2;
    PyObject* pyobj_method = NULL;
    int method=RANSAC;
    PyObject* pyobj_prob = NULL;
    double prob=0.999;
    PyObject* pyobj_threshold = NULL;
    double threshold=1.0;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    Mat retval;

    const char* keywords[] = { "points1", "points2", "cameraMatrix1", "distCoeffs1", "cameraMatrix2", "distCoeffs2", "method", "prob", "threshold", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|OOOO:findEssentialMat", (char**)keywords, &pyobj_points1, &pyobj_points2, &pyobj_cameraMatrix1, &pyobj_distCoeffs1, &pyobj_cameraMatrix2, &pyobj_distCoeffs2, &pyobj_method, &pyobj_prob, &pyobj_threshold, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_points1, points1, ArgInfo("points1", 0)) &&
        pyopencv_to_safe(pyobj_points2, points2, ArgInfo("points2", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix1, cameraMatrix1, ArgInfo("cameraMatrix1", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs1, distCoeffs1, ArgInfo("distCoeffs1", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix2, cameraMatrix2, ArgInfo("cameraMatrix2", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs2, distCoeffs2, ArgInfo("distCoeffs2", 0)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) &&
        pyopencv_to_safe(pyobj_prob, prob, ArgInfo("prob", 0)) &&
        pyopencv_to_safe(pyobj_threshold, threshold, ArgInfo("threshold", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 1)) )
    {
        ERRWRAP2(retval = cv::findEssentialMat(points1, points2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, method, prob, threshold, mask));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(mask));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_points1 = NULL;
    Mat points1;
    PyObject* pyobj_points2 = NULL;
    Mat points2;
    PyObject* pyobj_cameraMatrix1 = NULL;
    Mat cameraMatrix1;
    PyObject* pyobj_cameraMatrix2 = NULL;
    Mat cameraMatrix2;
    PyObject* pyobj_dist_coeff1 = NULL;
    Mat dist_coeff1;
    PyObject* pyobj_dist_coeff2 = NULL;
    Mat dist_coeff2;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_params = NULL;
    UsacParams params;
    Mat retval;

    const char* keywords[] = { "points1", "points2", "cameraMatrix1", "cameraMatrix2", "dist_coeff1", "dist_coeff2", "params", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOO|O:findEssentialMat", (char**)keywords, &pyobj_points1, &pyobj_points2, &pyobj_cameraMatrix1, &pyobj_cameraMatrix2, &pyobj_dist_coeff1, &pyobj_dist_coeff2, &pyobj_params, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_points1, points1, ArgInfo("points1", 0)) &&
        pyopencv_to_safe(pyobj_points2, points2, ArgInfo("points2", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix1, cameraMatrix1, ArgInfo("cameraMatrix1", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix2, cameraMatrix2, ArgInfo("cameraMatrix2", 0)) &&
        pyopencv_to_safe(pyobj_dist_coeff1, dist_coeff1, ArgInfo("dist_coeff1", 0)) &&
        pyopencv_to_safe(pyobj_dist_coeff2, dist_coeff2, ArgInfo("dist_coeff2", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 1)) &&
        pyopencv_to_safe(pyobj_params, params, ArgInfo("params", 0)) )
    {
        ERRWRAP2(retval = cv::findEssentialMat(points1, points2, cameraMatrix1, cameraMatrix2, dist_coeff1, dist_coeff2, mask, params));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(mask));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_points1 = NULL;
    UMat points1;
    PyObject* pyobj_points2 = NULL;
    UMat points2;
    PyObject* pyobj_cameraMatrix1 = NULL;
    UMat cameraMatrix1;
    PyObject* pyobj_cameraMatrix2 = NULL;
    UMat cameraMatrix2;
    PyObject* pyobj_dist_coeff1 = NULL;
    UMat dist_coeff1;
    PyObject* pyobj_dist_coeff2 = NULL;
    UMat dist_coeff2;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    PyObject* pyobj_params = NULL;
    UsacParams params;
    Mat retval;

    const char* keywords[] = { "points1", "points2", "cameraMatrix1", "cameraMatrix2", "dist_coeff1", "dist_coeff2", "params", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOO|O:findEssentialMat", (char**)keywords, &pyobj_points1, &pyobj_points2, &pyobj_cameraMatrix1, &pyobj_cameraMatrix2, &pyobj_dist_coeff1, &pyobj_dist_coeff2, &pyobj_params, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_points1, points1, ArgInfo("points1", 0)) &&
        pyopencv_to_safe(pyobj_points2, points2, ArgInfo("points2", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix1, cameraMatrix1, ArgInfo("cameraMatrix1", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix2, cameraMatrix2, ArgInfo("cameraMatrix2", 0)) &&
        pyopencv_to_safe(pyobj_dist_coeff1, dist_coeff1, ArgInfo("dist_coeff1", 0)) &&
        pyopencv_to_safe(pyobj_dist_coeff2, dist_coeff2, ArgInfo("dist_coeff2", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 1)) &&
        pyopencv_to_safe(pyobj_params, params, ArgInfo("params", 0)) )
    {
        ERRWRAP2(retval = cv::findEssentialMat(points1, points2, cameraMatrix1, cameraMatrix2, dist_coeff1, dist_coeff2, mask, params));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(mask));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("findEssentialMat");

    return NULL;
}

static PyObject* pyopencv_cv_findFundamentalMat(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(6);

    {
    PyObject* pyobj_points1 = NULL;
    Mat points1;
    PyObject* pyobj_points2 = NULL;
    Mat points2;
    PyObject* pyobj_method = NULL;
    int method=0;
    PyObject* pyobj_ransacReprojThreshold = NULL;
    double ransacReprojThreshold=0;
    PyObject* pyobj_confidence = NULL;
    double confidence=0;
    PyObject* pyobj_maxIters = NULL;
    int maxIters=0;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    Mat retval;

    const char* keywords[] = { "points1", "points2", "method", "ransacReprojThreshold", "confidence", "maxIters", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|O:findFundamentalMat", (char**)keywords, &pyobj_points1, &pyobj_points2, &pyobj_method, &pyobj_ransacReprojThreshold, &pyobj_confidence, &pyobj_maxIters, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_points1, points1, ArgInfo("points1", 0)) &&
        pyopencv_to_safe(pyobj_points2, points2, ArgInfo("points2", 0)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) &&
        pyopencv_to_safe(pyobj_ransacReprojThreshold, ransacReprojThreshold, ArgInfo("ransacReprojThreshold", 0)) &&
        pyopencv_to_safe(pyobj_confidence, confidence, ArgInfo("confidence", 0)) &&
        pyopencv_to_safe(pyobj_maxIters, maxIters, ArgInfo("maxIters", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 1)) )
    {
        ERRWRAP2(retval = cv::findFundamentalMat(points1, points2, method, ransacReprojThreshold, confidence, maxIters, mask));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(mask));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_points1 = NULL;
    UMat points1;
    PyObject* pyobj_points2 = NULL;
    UMat points2;
    PyObject* pyobj_method = NULL;
    int method=0;
    PyObject* pyobj_ransacReprojThreshold = NULL;
    double ransacReprojThreshold=0;
    PyObject* pyobj_confidence = NULL;
    double confidence=0;
    PyObject* pyobj_maxIters = NULL;
    int maxIters=0;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    Mat retval;

    const char* keywords[] = { "points1", "points2", "method", "ransacReprojThreshold", "confidence", "maxIters", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|O:findFundamentalMat", (char**)keywords, &pyobj_points1, &pyobj_points2, &pyobj_method, &pyobj_ransacReprojThreshold, &pyobj_confidence, &pyobj_maxIters, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_points1, points1, ArgInfo("points1", 0)) &&
        pyopencv_to_safe(pyobj_points2, points2, ArgInfo("points2", 0)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) &&
        pyopencv_to_safe(pyobj_ransacReprojThreshold, ransacReprojThreshold, ArgInfo("ransacReprojThreshold", 0)) &&
        pyopencv_to_safe(pyobj_confidence, confidence, ArgInfo("confidence", 0)) &&
        pyopencv_to_safe(pyobj_maxIters, maxIters, ArgInfo("maxIters", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 1)) )
    {
        ERRWRAP2(retval = cv::findFundamentalMat(points1, points2, method, ransacReprojThreshold, confidence, maxIters, mask));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(mask));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_points1 = NULL;
    Mat points1;
    PyObject* pyobj_points2 = NULL;
    Mat points2;
    PyObject* pyobj_method = NULL;
    int method=FM_RANSAC;
    PyObject* pyobj_ransacReprojThreshold = NULL;
    double ransacReprojThreshold=3.;
    PyObject* pyobj_confidence = NULL;
    double confidence=0.99;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    Mat retval;

    const char* keywords[] = { "points1", "points2", "method", "ransacReprojThreshold", "confidence", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOO:findFundamentalMat", (char**)keywords, &pyobj_points1, &pyobj_points2, &pyobj_method, &pyobj_ransacReprojThreshold, &pyobj_confidence, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_points1, points1, ArgInfo("points1", 0)) &&
        pyopencv_to_safe(pyobj_points2, points2, ArgInfo("points2", 0)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) &&
        pyopencv_to_safe(pyobj_ransacReprojThreshold, ransacReprojThreshold, ArgInfo("ransacReprojThreshold", 0)) &&
        pyopencv_to_safe(pyobj_confidence, confidence, ArgInfo("confidence", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 1)) )
    {
        ERRWRAP2(retval = cv::findFundamentalMat(points1, points2, method, ransacReprojThreshold, confidence, mask));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(mask));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_points1 = NULL;
    UMat points1;
    PyObject* pyobj_points2 = NULL;
    UMat points2;
    PyObject* pyobj_method = NULL;
    int method=FM_RANSAC;
    PyObject* pyobj_ransacReprojThreshold = NULL;
    double ransacReprojThreshold=3.;
    PyObject* pyobj_confidence = NULL;
    double confidence=0.99;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    Mat retval;

    const char* keywords[] = { "points1", "points2", "method", "ransacReprojThreshold", "confidence", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOO:findFundamentalMat", (char**)keywords, &pyobj_points1, &pyobj_points2, &pyobj_method, &pyobj_ransacReprojThreshold, &pyobj_confidence, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_points1, points1, ArgInfo("points1", 0)) &&
        pyopencv_to_safe(pyobj_points2, points2, ArgInfo("points2", 0)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) &&
        pyopencv_to_safe(pyobj_ransacReprojThreshold, ransacReprojThreshold, ArgInfo("ransacReprojThreshold", 0)) &&
        pyopencv_to_safe(pyobj_confidence, confidence, ArgInfo("confidence", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 1)) )
    {
        ERRWRAP2(retval = cv::findFundamentalMat(points1, points2, method, ransacReprojThreshold, confidence, mask));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(mask));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_points1 = NULL;
    Mat points1;
    PyObject* pyobj_points2 = NULL;
    Mat points2;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_params = NULL;
    UsacParams params;
    Mat retval;

    const char* keywords[] = { "points1", "points2", "params", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:findFundamentalMat", (char**)keywords, &pyobj_points1, &pyobj_points2, &pyobj_params, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_points1, points1, ArgInfo("points1", 0)) &&
        pyopencv_to_safe(pyobj_points2, points2, ArgInfo("points2", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 1)) &&
        pyopencv_to_safe(pyobj_params, params, ArgInfo("params", 0)) )
    {
        ERRWRAP2(retval = cv::findFundamentalMat(points1, points2, mask, params));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(mask));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_points1 = NULL;
    UMat points1;
    PyObject* pyobj_points2 = NULL;
    UMat points2;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    PyObject* pyobj_params = NULL;
    UsacParams params;
    Mat retval;

    const char* keywords[] = { "points1", "points2", "params", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:findFundamentalMat", (char**)keywords, &pyobj_points1, &pyobj_points2, &pyobj_params, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_points1, points1, ArgInfo("points1", 0)) &&
        pyopencv_to_safe(pyobj_points2, points2, ArgInfo("points2", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 1)) &&
        pyopencv_to_safe(pyobj_params, params, ArgInfo("params", 0)) )
    {
        ERRWRAP2(retval = cv::findFundamentalMat(points1, points2, mask, params));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(mask));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("findFundamentalMat");

    return NULL;
}

static PyObject* pyopencv_cv_findHomography(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(4);

    {
    PyObject* pyobj_srcPoints = NULL;
    Mat srcPoints;
    PyObject* pyobj_dstPoints = NULL;
    Mat dstPoints;
    PyObject* pyobj_method = NULL;
    int method=0;
    PyObject* pyobj_ransacReprojThreshold = NULL;
    double ransacReprojThreshold=3;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_maxIters = NULL;
    int maxIters=2000;
    PyObject* pyobj_confidence = NULL;
    double confidence=0.995;
    Mat retval;

    const char* keywords[] = { "srcPoints", "dstPoints", "method", "ransacReprojThreshold", "mask", "maxIters", "confidence", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOOO:findHomography", (char**)keywords, &pyobj_srcPoints, &pyobj_dstPoints, &pyobj_method, &pyobj_ransacReprojThreshold, &pyobj_mask, &pyobj_maxIters, &pyobj_confidence) &&
        pyopencv_to_safe(pyobj_srcPoints, srcPoints, ArgInfo("srcPoints", 0)) &&
        pyopencv_to_safe(pyobj_dstPoints, dstPoints, ArgInfo("dstPoints", 0)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) &&
        pyopencv_to_safe(pyobj_ransacReprojThreshold, ransacReprojThreshold, ArgInfo("ransacReprojThreshold", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 1)) &&
        pyopencv_to_safe(pyobj_maxIters, maxIters, ArgInfo("maxIters", 0)) &&
        pyopencv_to_safe(pyobj_confidence, confidence, ArgInfo("confidence", 0)) )
    {
        ERRWRAP2(retval = cv::findHomography(srcPoints, dstPoints, method, ransacReprojThreshold, mask, maxIters, confidence));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(mask));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_srcPoints = NULL;
    UMat srcPoints;
    PyObject* pyobj_dstPoints = NULL;
    UMat dstPoints;
    PyObject* pyobj_method = NULL;
    int method=0;
    PyObject* pyobj_ransacReprojThreshold = NULL;
    double ransacReprojThreshold=3;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    PyObject* pyobj_maxIters = NULL;
    int maxIters=2000;
    PyObject* pyobj_confidence = NULL;
    double confidence=0.995;
    Mat retval;

    const char* keywords[] = { "srcPoints", "dstPoints", "method", "ransacReprojThreshold", "mask", "maxIters", "confidence", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOOO:findHomography", (char**)keywords, &pyobj_srcPoints, &pyobj_dstPoints, &pyobj_method, &pyobj_ransacReprojThreshold, &pyobj_mask, &pyobj_maxIters, &pyobj_confidence) &&
        pyopencv_to_safe(pyobj_srcPoints, srcPoints, ArgInfo("srcPoints", 0)) &&
        pyopencv_to_safe(pyobj_dstPoints, dstPoints, ArgInfo("dstPoints", 0)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) &&
        pyopencv_to_safe(pyobj_ransacReprojThreshold, ransacReprojThreshold, ArgInfo("ransacReprojThreshold", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 1)) &&
        pyopencv_to_safe(pyobj_maxIters, maxIters, ArgInfo("maxIters", 0)) &&
        pyopencv_to_safe(pyobj_confidence, confidence, ArgInfo("confidence", 0)) )
    {
        ERRWRAP2(retval = cv::findHomography(srcPoints, dstPoints, method, ransacReprojThreshold, mask, maxIters, confidence));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(mask));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_srcPoints = NULL;
    Mat srcPoints;
    PyObject* pyobj_dstPoints = NULL;
    Mat dstPoints;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_params = NULL;
    UsacParams params;
    Mat retval;

    const char* keywords[] = { "srcPoints", "dstPoints", "params", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:findHomography", (char**)keywords, &pyobj_srcPoints, &pyobj_dstPoints, &pyobj_params, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_srcPoints, srcPoints, ArgInfo("srcPoints", 0)) &&
        pyopencv_to_safe(pyobj_dstPoints, dstPoints, ArgInfo("dstPoints", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 1)) &&
        pyopencv_to_safe(pyobj_params, params, ArgInfo("params", 0)) )
    {
        ERRWRAP2(retval = cv::findHomography(srcPoints, dstPoints, mask, params));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(mask));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_srcPoints = NULL;
    UMat srcPoints;
    PyObject* pyobj_dstPoints = NULL;
    UMat dstPoints;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    PyObject* pyobj_params = NULL;
    UsacParams params;
    Mat retval;

    const char* keywords[] = { "srcPoints", "dstPoints", "params", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:findHomography", (char**)keywords, &pyobj_srcPoints, &pyobj_dstPoints, &pyobj_params, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_srcPoints, srcPoints, ArgInfo("srcPoints", 0)) &&
        pyopencv_to_safe(pyobj_dstPoints, dstPoints, ArgInfo("dstPoints", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 1)) &&
        pyopencv_to_safe(pyobj_params, params, ArgInfo("params", 0)) )
    {
        ERRWRAP2(retval = cv::findHomography(srcPoints, dstPoints, mask, params));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(mask));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("findHomography");

    return NULL;
}

static PyObject* pyopencv_cv_findNonZero(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_idx = NULL;
    Mat idx;

    const char* keywords[] = { "src", "idx", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:findNonZero", (char**)keywords, &pyobj_src, &pyobj_idx) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_idx, idx, ArgInfo("idx", 1)) )
    {
        ERRWRAP2(cv::findNonZero(src, idx));
        return pyopencv_from(idx);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_idx = NULL;
    UMat idx;

    const char* keywords[] = { "src", "idx", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:findNonZero", (char**)keywords, &pyobj_src, &pyobj_idx) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_idx, idx, ArgInfo("idx", 1)) )
    {
        ERRWRAP2(cv::findNonZero(src, idx));
        return pyopencv_from(idx);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("findNonZero");

    return NULL;
}

static PyObject* pyopencv_cv_findTransformECC(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(4);

    {
    PyObject* pyobj_templateImage = NULL;
    Mat templateImage;
    PyObject* pyobj_inputImage = NULL;
    Mat inputImage;
    PyObject* pyobj_warpMatrix = NULL;
    Mat warpMatrix;
    PyObject* pyobj_motionType = NULL;
    int motionType=0;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria;
    PyObject* pyobj_inputMask = NULL;
    Mat inputMask;
    PyObject* pyobj_gaussFiltSize = NULL;
    int gaussFiltSize=0;
    double retval;

    const char* keywords[] = { "templateImage", "inputImage", "warpMatrix", "motionType", "criteria", "inputMask", "gaussFiltSize", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOO:findTransformECC", (char**)keywords, &pyobj_templateImage, &pyobj_inputImage, &pyobj_warpMatrix, &pyobj_motionType, &pyobj_criteria, &pyobj_inputMask, &pyobj_gaussFiltSize) &&
        pyopencv_to_safe(pyobj_templateImage, templateImage, ArgInfo("templateImage", 0)) &&
        pyopencv_to_safe(pyobj_inputImage, inputImage, ArgInfo("inputImage", 0)) &&
        pyopencv_to_safe(pyobj_warpMatrix, warpMatrix, ArgInfo("warpMatrix", 1)) &&
        pyopencv_to_safe(pyobj_motionType, motionType, ArgInfo("motionType", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) &&
        pyopencv_to_safe(pyobj_inputMask, inputMask, ArgInfo("inputMask", 0)) &&
        pyopencv_to_safe(pyobj_gaussFiltSize, gaussFiltSize, ArgInfo("gaussFiltSize", 0)) )
    {
        ERRWRAP2(retval = cv::findTransformECC(templateImage, inputImage, warpMatrix, motionType, criteria, inputMask, gaussFiltSize));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(warpMatrix));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_templateImage = NULL;
    UMat templateImage;
    PyObject* pyobj_inputImage = NULL;
    UMat inputImage;
    PyObject* pyobj_warpMatrix = NULL;
    UMat warpMatrix;
    PyObject* pyobj_motionType = NULL;
    int motionType=0;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria;
    PyObject* pyobj_inputMask = NULL;
    UMat inputMask;
    PyObject* pyobj_gaussFiltSize = NULL;
    int gaussFiltSize=0;
    double retval;

    const char* keywords[] = { "templateImage", "inputImage", "warpMatrix", "motionType", "criteria", "inputMask", "gaussFiltSize", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOO:findTransformECC", (char**)keywords, &pyobj_templateImage, &pyobj_inputImage, &pyobj_warpMatrix, &pyobj_motionType, &pyobj_criteria, &pyobj_inputMask, &pyobj_gaussFiltSize) &&
        pyopencv_to_safe(pyobj_templateImage, templateImage, ArgInfo("templateImage", 0)) &&
        pyopencv_to_safe(pyobj_inputImage, inputImage, ArgInfo("inputImage", 0)) &&
        pyopencv_to_safe(pyobj_warpMatrix, warpMatrix, ArgInfo("warpMatrix", 1)) &&
        pyopencv_to_safe(pyobj_motionType, motionType, ArgInfo("motionType", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) &&
        pyopencv_to_safe(pyobj_inputMask, inputMask, ArgInfo("inputMask", 0)) &&
        pyopencv_to_safe(pyobj_gaussFiltSize, gaussFiltSize, ArgInfo("gaussFiltSize", 0)) )
    {
        ERRWRAP2(retval = cv::findTransformECC(templateImage, inputImage, warpMatrix, motionType, criteria, inputMask, gaussFiltSize));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(warpMatrix));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_templateImage = NULL;
    Mat templateImage;
    PyObject* pyobj_inputImage = NULL;
    Mat inputImage;
    PyObject* pyobj_warpMatrix = NULL;
    Mat warpMatrix;
    PyObject* pyobj_motionType = NULL;
    int motionType=MOTION_AFFINE;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 50, 0.001);
    PyObject* pyobj_inputMask = NULL;
    Mat inputMask;
    double retval;

    const char* keywords[] = { "templateImage", "inputImage", "warpMatrix", "motionType", "criteria", "inputMask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:findTransformECC", (char**)keywords, &pyobj_templateImage, &pyobj_inputImage, &pyobj_warpMatrix, &pyobj_motionType, &pyobj_criteria, &pyobj_inputMask) &&
        pyopencv_to_safe(pyobj_templateImage, templateImage, ArgInfo("templateImage", 0)) &&
        pyopencv_to_safe(pyobj_inputImage, inputImage, ArgInfo("inputImage", 0)) &&
        pyopencv_to_safe(pyobj_warpMatrix, warpMatrix, ArgInfo("warpMatrix", 1)) &&
        pyopencv_to_safe(pyobj_motionType, motionType, ArgInfo("motionType", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) &&
        pyopencv_to_safe(pyobj_inputMask, inputMask, ArgInfo("inputMask", 0)) )
    {
        ERRWRAP2(retval = cv::findTransformECC(templateImage, inputImage, warpMatrix, motionType, criteria, inputMask));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(warpMatrix));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_templateImage = NULL;
    UMat templateImage;
    PyObject* pyobj_inputImage = NULL;
    UMat inputImage;
    PyObject* pyobj_warpMatrix = NULL;
    UMat warpMatrix;
    PyObject* pyobj_motionType = NULL;
    int motionType=MOTION_AFFINE;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 50, 0.001);
    PyObject* pyobj_inputMask = NULL;
    UMat inputMask;
    double retval;

    const char* keywords[] = { "templateImage", "inputImage", "warpMatrix", "motionType", "criteria", "inputMask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:findTransformECC", (char**)keywords, &pyobj_templateImage, &pyobj_inputImage, &pyobj_warpMatrix, &pyobj_motionType, &pyobj_criteria, &pyobj_inputMask) &&
        pyopencv_to_safe(pyobj_templateImage, templateImage, ArgInfo("templateImage", 0)) &&
        pyopencv_to_safe(pyobj_inputImage, inputImage, ArgInfo("inputImage", 0)) &&
        pyopencv_to_safe(pyobj_warpMatrix, warpMatrix, ArgInfo("warpMatrix", 1)) &&
        pyopencv_to_safe(pyobj_motionType, motionType, ArgInfo("motionType", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) &&
        pyopencv_to_safe(pyobj_inputMask, inputMask, ArgInfo("inputMask", 0)) )
    {
        ERRWRAP2(retval = cv::findTransformECC(templateImage, inputImage, warpMatrix, motionType, criteria, inputMask));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(warpMatrix));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("findTransformECC");

    return NULL;
}

static PyObject* pyopencv_cv_fitEllipse(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_points = NULL;
    Mat points;
    RotatedRect retval;

    const char* keywords[] = { "points", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:fitEllipse", (char**)keywords, &pyobj_points) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) )
    {
        ERRWRAP2(retval = cv::fitEllipse(points));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_points = NULL;
    UMat points;
    RotatedRect retval;

    const char* keywords[] = { "points", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:fitEllipse", (char**)keywords, &pyobj_points) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) )
    {
        ERRWRAP2(retval = cv::fitEllipse(points));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("fitEllipse");

    return NULL;
}

static PyObject* pyopencv_cv_fitEllipseAMS(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_points = NULL;
    Mat points;
    RotatedRect retval;

    const char* keywords[] = { "points", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:fitEllipseAMS", (char**)keywords, &pyobj_points) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) )
    {
        ERRWRAP2(retval = cv::fitEllipseAMS(points));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_points = NULL;
    UMat points;
    RotatedRect retval;

    const char* keywords[] = { "points", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:fitEllipseAMS", (char**)keywords, &pyobj_points) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) )
    {
        ERRWRAP2(retval = cv::fitEllipseAMS(points));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("fitEllipseAMS");

    return NULL;
}

static PyObject* pyopencv_cv_fitEllipseDirect(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_points = NULL;
    Mat points;
    RotatedRect retval;

    const char* keywords[] = { "points", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:fitEllipseDirect", (char**)keywords, &pyobj_points) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) )
    {
        ERRWRAP2(retval = cv::fitEllipseDirect(points));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_points = NULL;
    UMat points;
    RotatedRect retval;

    const char* keywords[] = { "points", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:fitEllipseDirect", (char**)keywords, &pyobj_points) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) )
    {
        ERRWRAP2(retval = cv::fitEllipseDirect(points));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("fitEllipseDirect");

    return NULL;
}

static PyObject* pyopencv_cv_fitLine(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_points = NULL;
    Mat points;
    PyObject* pyobj_line = NULL;
    Mat line;
    PyObject* pyobj_distType = NULL;
    int distType=0;
    PyObject* pyobj_param = NULL;
    double param=0;
    PyObject* pyobj_reps = NULL;
    double reps=0;
    PyObject* pyobj_aeps = NULL;
    double aeps=0;

    const char* keywords[] = { "points", "distType", "param", "reps", "aeps", "line", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|O:fitLine", (char**)keywords, &pyobj_points, &pyobj_distType, &pyobj_param, &pyobj_reps, &pyobj_aeps, &pyobj_line) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) &&
        pyopencv_to_safe(pyobj_line, line, ArgInfo("line", 1)) &&
        pyopencv_to_safe(pyobj_distType, distType, ArgInfo("distType", 0)) &&
        pyopencv_to_safe(pyobj_param, param, ArgInfo("param", 0)) &&
        pyopencv_to_safe(pyobj_reps, reps, ArgInfo("reps", 0)) &&
        pyopencv_to_safe(pyobj_aeps, aeps, ArgInfo("aeps", 0)) )
    {
        ERRWRAP2(cv::fitLine(points, line, distType, param, reps, aeps));
        return pyopencv_from(line);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_points = NULL;
    UMat points;
    PyObject* pyobj_line = NULL;
    UMat line;
    PyObject* pyobj_distType = NULL;
    int distType=0;
    PyObject* pyobj_param = NULL;
    double param=0;
    PyObject* pyobj_reps = NULL;
    double reps=0;
    PyObject* pyobj_aeps = NULL;
    double aeps=0;

    const char* keywords[] = { "points", "distType", "param", "reps", "aeps", "line", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|O:fitLine", (char**)keywords, &pyobj_points, &pyobj_distType, &pyobj_param, &pyobj_reps, &pyobj_aeps, &pyobj_line) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) &&
        pyopencv_to_safe(pyobj_line, line, ArgInfo("line", 1)) &&
        pyopencv_to_safe(pyobj_distType, distType, ArgInfo("distType", 0)) &&
        pyopencv_to_safe(pyobj_param, param, ArgInfo("param", 0)) &&
        pyopencv_to_safe(pyobj_reps, reps, ArgInfo("reps", 0)) &&
        pyopencv_to_safe(pyobj_aeps, aeps, ArgInfo("aeps", 0)) )
    {
        ERRWRAP2(cv::fitLine(points, line, distType, param, reps, aeps));
        return pyopencv_from(line);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("fitLine");

    return NULL;
}

static PyObject* pyopencv_cv_flip(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_flipCode = NULL;
    int flipCode=0;

    const char* keywords[] = { "src", "flipCode", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:flip", (char**)keywords, &pyobj_src, &pyobj_flipCode, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_flipCode, flipCode, ArgInfo("flipCode", 0)) )
    {
        ERRWRAP2(cv::flip(src, dst, flipCode));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_flipCode = NULL;
    int flipCode=0;

    const char* keywords[] = { "src", "flipCode", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:flip", (char**)keywords, &pyobj_src, &pyobj_flipCode, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_flipCode, flipCode, ArgInfo("flipCode", 0)) )
    {
        ERRWRAP2(cv::flip(src, dst, flipCode));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("flip");

    return NULL;
}

static PyObject* pyopencv_cv_floodFill(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_seedPoint = NULL;
    Point seedPoint;
    PyObject* pyobj_newVal = NULL;
    Scalar newVal;
    Rect rect;
    PyObject* pyobj_loDiff = NULL;
    Scalar loDiff;
    PyObject* pyobj_upDiff = NULL;
    Scalar upDiff;
    PyObject* pyobj_flags = NULL;
    int flags=4;
    int retval;

    const char* keywords[] = { "image", "mask", "seedPoint", "newVal", "loDiff", "upDiff", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:floodFill", (char**)keywords, &pyobj_image, &pyobj_mask, &pyobj_seedPoint, &pyobj_newVal, &pyobj_loDiff, &pyobj_upDiff, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 1)) &&
        pyopencv_to_safe(pyobj_seedPoint, seedPoint, ArgInfo("seedPoint", 0)) &&
        pyopencv_to_safe(pyobj_newVal, newVal, ArgInfo("newVal", 0)) &&
        pyopencv_to_safe(pyobj_loDiff, loDiff, ArgInfo("loDiff", 0)) &&
        pyopencv_to_safe(pyobj_upDiff, upDiff, ArgInfo("upDiff", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(retval = cv::floodFill(image, mask, seedPoint, newVal, &rect, loDiff, upDiff, flags));
        return Py_BuildValue("(NNNN)", pyopencv_from(retval), pyopencv_from(image), pyopencv_from(mask), pyopencv_from(rect));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    PyObject* pyobj_seedPoint = NULL;
    Point seedPoint;
    PyObject* pyobj_newVal = NULL;
    Scalar newVal;
    Rect rect;
    PyObject* pyobj_loDiff = NULL;
    Scalar loDiff;
    PyObject* pyobj_upDiff = NULL;
    Scalar upDiff;
    PyObject* pyobj_flags = NULL;
    int flags=4;
    int retval;

    const char* keywords[] = { "image", "mask", "seedPoint", "newVal", "loDiff", "upDiff", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:floodFill", (char**)keywords, &pyobj_image, &pyobj_mask, &pyobj_seedPoint, &pyobj_newVal, &pyobj_loDiff, &pyobj_upDiff, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 1)) &&
        pyopencv_to_safe(pyobj_seedPoint, seedPoint, ArgInfo("seedPoint", 0)) &&
        pyopencv_to_safe(pyobj_newVal, newVal, ArgInfo("newVal", 0)) &&
        pyopencv_to_safe(pyobj_loDiff, loDiff, ArgInfo("loDiff", 0)) &&
        pyopencv_to_safe(pyobj_upDiff, upDiff, ArgInfo("upDiff", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(retval = cv::floodFill(image, mask, seedPoint, newVal, &rect, loDiff, upDiff, flags));
        return Py_BuildValue("(NNNN)", pyopencv_from(retval), pyopencv_from(image), pyopencv_from(mask), pyopencv_from(rect));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("floodFill");

    return NULL;
}

static PyObject* pyopencv_cv_gemm(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src1 = NULL;
    Mat src1;
    PyObject* pyobj_src2 = NULL;
    Mat src2;
    PyObject* pyobj_alpha = NULL;
    double alpha=0;
    PyObject* pyobj_src3 = NULL;
    Mat src3;
    PyObject* pyobj_beta = NULL;
    double beta=0;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_flags = NULL;
    int flags=0;

    const char* keywords[] = { "src1", "src2", "alpha", "src3", "beta", "dst", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OO:gemm", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_alpha, &pyobj_src3, &pyobj_beta, &pyobj_dst, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_src3, src3, ArgInfo("src3", 0)) &&
        pyopencv_to_safe(pyobj_beta, beta, ArgInfo("beta", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::gemm(src1, src2, alpha, src3, beta, dst, flags));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src1 = NULL;
    UMat src1;
    PyObject* pyobj_src2 = NULL;
    UMat src2;
    PyObject* pyobj_alpha = NULL;
    double alpha=0;
    PyObject* pyobj_src3 = NULL;
    UMat src3;
    PyObject* pyobj_beta = NULL;
    double beta=0;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_flags = NULL;
    int flags=0;

    const char* keywords[] = { "src1", "src2", "alpha", "src3", "beta", "dst", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OO:gemm", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_alpha, &pyobj_src3, &pyobj_beta, &pyobj_dst, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_src3, src3, ArgInfo("src3", 0)) &&
        pyopencv_to_safe(pyobj_beta, beta, ArgInfo("beta", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::gemm(src1, src2, alpha, src3, beta, dst, flags));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("gemm");

    return NULL;
}

static PyObject* pyopencv_cv_getAffineTransform(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    Mat retval;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:getAffineTransform", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 0)) )
    {
        ERRWRAP2(retval = cv::getAffineTransform(src, dst));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    Mat retval;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:getAffineTransform", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 0)) )
    {
        ERRWRAP2(retval = cv::getAffineTransform(src, dst));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("getAffineTransform");

    return NULL;
}

static PyObject* pyopencv_cv_getBuildInformation(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    String retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::getBuildInformation());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_getCPUFeaturesLine(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    std::string retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::getCPUFeaturesLine());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_getCPUTickCount(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    int64 retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::getCPUTickCount());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_getDefaultNewCameraMatrix(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_imgsize = NULL;
    Size imgsize;
    PyObject* pyobj_centerPrincipalPoint = NULL;
    bool centerPrincipalPoint=false;
    Mat retval;

    const char* keywords[] = { "cameraMatrix", "imgsize", "centerPrincipalPoint", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:getDefaultNewCameraMatrix", (char**)keywords, &pyobj_cameraMatrix, &pyobj_imgsize, &pyobj_centerPrincipalPoint) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_imgsize, imgsize, ArgInfo("imgsize", 0)) &&
        pyopencv_to_safe(pyobj_centerPrincipalPoint, centerPrincipalPoint, ArgInfo("centerPrincipalPoint", 0)) )
    {
        ERRWRAP2(retval = cv::getDefaultNewCameraMatrix(cameraMatrix, imgsize, centerPrincipalPoint));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_imgsize = NULL;
    Size imgsize;
    PyObject* pyobj_centerPrincipalPoint = NULL;
    bool centerPrincipalPoint=false;
    Mat retval;

    const char* keywords[] = { "cameraMatrix", "imgsize", "centerPrincipalPoint", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:getDefaultNewCameraMatrix", (char**)keywords, &pyobj_cameraMatrix, &pyobj_imgsize, &pyobj_centerPrincipalPoint) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_imgsize, imgsize, ArgInfo("imgsize", 0)) &&
        pyopencv_to_safe(pyobj_centerPrincipalPoint, centerPrincipalPoint, ArgInfo("centerPrincipalPoint", 0)) )
    {
        ERRWRAP2(retval = cv::getDefaultNewCameraMatrix(cameraMatrix, imgsize, centerPrincipalPoint));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("getDefaultNewCameraMatrix");

    return NULL;
}

static PyObject* pyopencv_cv_getDerivKernels(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_kx = NULL;
    Mat kx;
    PyObject* pyobj_ky = NULL;
    Mat ky;
    PyObject* pyobj_dx = NULL;
    int dx=0;
    PyObject* pyobj_dy = NULL;
    int dy=0;
    PyObject* pyobj_ksize = NULL;
    int ksize=0;
    PyObject* pyobj_normalize = NULL;
    bool normalize=false;
    PyObject* pyobj_ktype = NULL;
    int ktype=CV_32F;

    const char* keywords[] = { "dx", "dy", "ksize", "kx", "ky", "normalize", "ktype", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOO:getDerivKernels", (char**)keywords, &pyobj_dx, &pyobj_dy, &pyobj_ksize, &pyobj_kx, &pyobj_ky, &pyobj_normalize, &pyobj_ktype) &&
        pyopencv_to_safe(pyobj_kx, kx, ArgInfo("kx", 1)) &&
        pyopencv_to_safe(pyobj_ky, ky, ArgInfo("ky", 1)) &&
        pyopencv_to_safe(pyobj_dx, dx, ArgInfo("dx", 0)) &&
        pyopencv_to_safe(pyobj_dy, dy, ArgInfo("dy", 0)) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) &&
        pyopencv_to_safe(pyobj_normalize, normalize, ArgInfo("normalize", 0)) &&
        pyopencv_to_safe(pyobj_ktype, ktype, ArgInfo("ktype", 0)) )
    {
        ERRWRAP2(cv::getDerivKernels(kx, ky, dx, dy, ksize, normalize, ktype));
        return Py_BuildValue("(NN)", pyopencv_from(kx), pyopencv_from(ky));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_kx = NULL;
    UMat kx;
    PyObject* pyobj_ky = NULL;
    UMat ky;
    PyObject* pyobj_dx = NULL;
    int dx=0;
    PyObject* pyobj_dy = NULL;
    int dy=0;
    PyObject* pyobj_ksize = NULL;
    int ksize=0;
    PyObject* pyobj_normalize = NULL;
    bool normalize=false;
    PyObject* pyobj_ktype = NULL;
    int ktype=CV_32F;

    const char* keywords[] = { "dx", "dy", "ksize", "kx", "ky", "normalize", "ktype", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOO:getDerivKernels", (char**)keywords, &pyobj_dx, &pyobj_dy, &pyobj_ksize, &pyobj_kx, &pyobj_ky, &pyobj_normalize, &pyobj_ktype) &&
        pyopencv_to_safe(pyobj_kx, kx, ArgInfo("kx", 1)) &&
        pyopencv_to_safe(pyobj_ky, ky, ArgInfo("ky", 1)) &&
        pyopencv_to_safe(pyobj_dx, dx, ArgInfo("dx", 0)) &&
        pyopencv_to_safe(pyobj_dy, dy, ArgInfo("dy", 0)) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) &&
        pyopencv_to_safe(pyobj_normalize, normalize, ArgInfo("normalize", 0)) &&
        pyopencv_to_safe(pyobj_ktype, ktype, ArgInfo("ktype", 0)) )
    {
        ERRWRAP2(cv::getDerivKernels(kx, ky, dx, dy, ksize, normalize, ktype));
        return Py_BuildValue("(NN)", pyopencv_from(kx), pyopencv_from(ky));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("getDerivKernels");

    return NULL;
}

static PyObject* pyopencv_cv_getFontScaleFromHeight(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_fontFace = NULL;
    int fontFace=0;
    PyObject* pyobj_pixelHeight = NULL;
    int pixelHeight=0;
    PyObject* pyobj_thickness = NULL;
    int thickness=1;
    double retval;

    const char* keywords[] = { "fontFace", "pixelHeight", "thickness", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:getFontScaleFromHeight", (char**)keywords, &pyobj_fontFace, &pyobj_pixelHeight, &pyobj_thickness) &&
        pyopencv_to_safe(pyobj_fontFace, fontFace, ArgInfo("fontFace", 0)) &&
        pyopencv_to_safe(pyobj_pixelHeight, pixelHeight, ArgInfo("pixelHeight", 0)) &&
        pyopencv_to_safe(pyobj_thickness, thickness, ArgInfo("thickness", 0)) )
    {
        ERRWRAP2(retval = cv::getFontScaleFromHeight(fontFace, pixelHeight, thickness));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_getGaborKernel(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_ksize = NULL;
    Size ksize;
    PyObject* pyobj_sigma = NULL;
    double sigma=0;
    PyObject* pyobj_theta = NULL;
    double theta=0;
    PyObject* pyobj_lambd = NULL;
    double lambd=0;
    PyObject* pyobj_gamma = NULL;
    double gamma=0;
    PyObject* pyobj_psi = NULL;
    double psi=CV_PI*0.5;
    PyObject* pyobj_ktype = NULL;
    int ktype=CV_64F;
    Mat retval;

    const char* keywords[] = { "ksize", "sigma", "theta", "lambd", "gamma", "psi", "ktype", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OO:getGaborKernel", (char**)keywords, &pyobj_ksize, &pyobj_sigma, &pyobj_theta, &pyobj_lambd, &pyobj_gamma, &pyobj_psi, &pyobj_ktype) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) &&
        pyopencv_to_safe(pyobj_sigma, sigma, ArgInfo("sigma", 0)) &&
        pyopencv_to_safe(pyobj_theta, theta, ArgInfo("theta", 0)) &&
        pyopencv_to_safe(pyobj_lambd, lambd, ArgInfo("lambd", 0)) &&
        pyopencv_to_safe(pyobj_gamma, gamma, ArgInfo("gamma", 0)) &&
        pyopencv_to_safe(pyobj_psi, psi, ArgInfo("psi", 0)) &&
        pyopencv_to_safe(pyobj_ktype, ktype, ArgInfo("ktype", 0)) )
    {
        ERRWRAP2(retval = cv::getGaborKernel(ksize, sigma, theta, lambd, gamma, psi, ktype));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_getGaussianKernel(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_ksize = NULL;
    int ksize=0;
    PyObject* pyobj_sigma = NULL;
    double sigma=0;
    PyObject* pyobj_ktype = NULL;
    int ktype=CV_64F;
    Mat retval;

    const char* keywords[] = { "ksize", "sigma", "ktype", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:getGaussianKernel", (char**)keywords, &pyobj_ksize, &pyobj_sigma, &pyobj_ktype) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) &&
        pyopencv_to_safe(pyobj_sigma, sigma, ArgInfo("sigma", 0)) &&
        pyopencv_to_safe(pyobj_ktype, ktype, ArgInfo("ktype", 0)) )
    {
        ERRWRAP2(retval = cv::getGaussianKernel(ksize, sigma, ktype));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_getHardwareFeatureName(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_feature = NULL;
    int feature=0;
    String retval;

    const char* keywords[] = { "feature", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:getHardwareFeatureName", (char**)keywords, &pyobj_feature) &&
        pyopencv_to_safe(pyobj_feature, feature, ArgInfo("feature", 0)) )
    {
        ERRWRAP2(retval = cv::getHardwareFeatureName(feature));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_getLogLevel(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    int retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::getLogLevel());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_getNumThreads(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    int retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::getNumThreads());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_getNumberOfCPUs(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    int retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::getNumberOfCPUs());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_getOptimalDFTSize(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_vecsize = NULL;
    int vecsize=0;
    int retval;

    const char* keywords[] = { "vecsize", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:getOptimalDFTSize", (char**)keywords, &pyobj_vecsize) &&
        pyopencv_to_safe(pyobj_vecsize, vecsize, ArgInfo("vecsize", 0)) )
    {
        ERRWRAP2(retval = cv::getOptimalDFTSize(vecsize));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_getOptimalNewCameraMatrix(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    Mat distCoeffs;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_alpha = NULL;
    double alpha=0;
    PyObject* pyobj_newImgSize = NULL;
    Size newImgSize;
    Rect validPixROI;
    PyObject* pyobj_centerPrincipalPoint = NULL;
    bool centerPrincipalPoint=false;
    Mat retval;

    const char* keywords[] = { "cameraMatrix", "distCoeffs", "imageSize", "alpha", "newImgSize", "centerPrincipalPoint", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OO:getOptimalNewCameraMatrix", (char**)keywords, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_imageSize, &pyobj_alpha, &pyobj_newImgSize, &pyobj_centerPrincipalPoint) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_newImgSize, newImgSize, ArgInfo("newImgSize", 0)) &&
        pyopencv_to_safe(pyobj_centerPrincipalPoint, centerPrincipalPoint, ArgInfo("centerPrincipalPoint", 0)) )
    {
        ERRWRAP2(retval = cv::getOptimalNewCameraMatrix(cameraMatrix, distCoeffs, imageSize, alpha, newImgSize, &validPixROI, centerPrincipalPoint));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(validPixROI));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    UMat distCoeffs;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_alpha = NULL;
    double alpha=0;
    PyObject* pyobj_newImgSize = NULL;
    Size newImgSize;
    Rect validPixROI;
    PyObject* pyobj_centerPrincipalPoint = NULL;
    bool centerPrincipalPoint=false;
    Mat retval;

    const char* keywords[] = { "cameraMatrix", "distCoeffs", "imageSize", "alpha", "newImgSize", "centerPrincipalPoint", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OO:getOptimalNewCameraMatrix", (char**)keywords, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_imageSize, &pyobj_alpha, &pyobj_newImgSize, &pyobj_centerPrincipalPoint) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_newImgSize, newImgSize, ArgInfo("newImgSize", 0)) &&
        pyopencv_to_safe(pyobj_centerPrincipalPoint, centerPrincipalPoint, ArgInfo("centerPrincipalPoint", 0)) )
    {
        ERRWRAP2(retval = cv::getOptimalNewCameraMatrix(cameraMatrix, distCoeffs, imageSize, alpha, newImgSize, &validPixROI, centerPrincipalPoint));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(validPixROI));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("getOptimalNewCameraMatrix");

    return NULL;
}

static PyObject* pyopencv_cv_getPerspectiveTransform(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_solveMethod = NULL;
    int solveMethod=DECOMP_LU;
    Mat retval;

    const char* keywords[] = { "src", "dst", "solveMethod", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:getPerspectiveTransform", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_solveMethod) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 0)) &&
        pyopencv_to_safe(pyobj_solveMethod, solveMethod, ArgInfo("solveMethod", 0)) )
    {
        ERRWRAP2(retval = cv::getPerspectiveTransform(src, dst, solveMethod));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_solveMethod = NULL;
    int solveMethod=DECOMP_LU;
    Mat retval;

    const char* keywords[] = { "src", "dst", "solveMethod", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:getPerspectiveTransform", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_solveMethod) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 0)) &&
        pyopencv_to_safe(pyobj_solveMethod, solveMethod, ArgInfo("solveMethod", 0)) )
    {
        ERRWRAP2(retval = cv::getPerspectiveTransform(src, dst, solveMethod));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("getPerspectiveTransform");

    return NULL;
}

static PyObject* pyopencv_cv_getRectSubPix(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_patchSize = NULL;
    Size patchSize;
    PyObject* pyobj_center = NULL;
    Point2f center;
    PyObject* pyobj_patch = NULL;
    Mat patch;
    PyObject* pyobj_patchType = NULL;
    int patchType=-1;

    const char* keywords[] = { "image", "patchSize", "center", "patch", "patchType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:getRectSubPix", (char**)keywords, &pyobj_image, &pyobj_patchSize, &pyobj_center, &pyobj_patch, &pyobj_patchType) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_patchSize, patchSize, ArgInfo("patchSize", 0)) &&
        pyopencv_to_safe(pyobj_center, center, ArgInfo("center", 0)) &&
        pyopencv_to_safe(pyobj_patch, patch, ArgInfo("patch", 1)) &&
        pyopencv_to_safe(pyobj_patchType, patchType, ArgInfo("patchType", 0)) )
    {
        ERRWRAP2(cv::getRectSubPix(image, patchSize, center, patch, patchType));
        return pyopencv_from(patch);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_patchSize = NULL;
    Size patchSize;
    PyObject* pyobj_center = NULL;
    Point2f center;
    PyObject* pyobj_patch = NULL;
    UMat patch;
    PyObject* pyobj_patchType = NULL;
    int patchType=-1;

    const char* keywords[] = { "image", "patchSize", "center", "patch", "patchType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:getRectSubPix", (char**)keywords, &pyobj_image, &pyobj_patchSize, &pyobj_center, &pyobj_patch, &pyobj_patchType) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_patchSize, patchSize, ArgInfo("patchSize", 0)) &&
        pyopencv_to_safe(pyobj_center, center, ArgInfo("center", 0)) &&
        pyopencv_to_safe(pyobj_patch, patch, ArgInfo("patch", 1)) &&
        pyopencv_to_safe(pyobj_patchType, patchType, ArgInfo("patchType", 0)) )
    {
        ERRWRAP2(cv::getRectSubPix(image, patchSize, center, patch, patchType));
        return pyopencv_from(patch);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("getRectSubPix");

    return NULL;
}

static PyObject* pyopencv_cv_getRotationMatrix2D(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_center = NULL;
    Point2f center;
    PyObject* pyobj_angle = NULL;
    double angle=0;
    PyObject* pyobj_scale = NULL;
    double scale=0;
    Mat retval;

    const char* keywords[] = { "center", "angle", "scale", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:getRotationMatrix2D", (char**)keywords, &pyobj_center, &pyobj_angle, &pyobj_scale) &&
        pyopencv_to_safe(pyobj_center, center, ArgInfo("center", 0)) &&
        pyopencv_to_safe(pyobj_angle, angle, ArgInfo("angle", 0)) &&
        pyopencv_to_safe(pyobj_scale, scale, ArgInfo("scale", 0)) )
    {
        ERRWRAP2(retval = cv::getRotationMatrix2D(center, angle, scale));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_getStructuringElement(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_shape = NULL;
    int shape=0;
    PyObject* pyobj_ksize = NULL;
    Size ksize;
    PyObject* pyobj_anchor = NULL;
    Point anchor=Point(-1,-1);
    Mat retval;

    const char* keywords[] = { "shape", "ksize", "anchor", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:getStructuringElement", (char**)keywords, &pyobj_shape, &pyobj_ksize, &pyobj_anchor) &&
        pyopencv_to_safe(pyobj_shape, shape, ArgInfo("shape", 0)) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) &&
        pyopencv_to_safe(pyobj_anchor, anchor, ArgInfo("anchor", 0)) )
    {
        ERRWRAP2(retval = cv::getStructuringElement(shape, ksize, anchor));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_getTextSize(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_text = NULL;
    String text;
    PyObject* pyobj_fontFace = NULL;
    int fontFace=0;
    PyObject* pyobj_fontScale = NULL;
    double fontScale=0;
    PyObject* pyobj_thickness = NULL;
    int thickness=0;
    int baseLine;
    Size retval;

    const char* keywords[] = { "text", "fontFace", "fontScale", "thickness", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO:getTextSize", (char**)keywords, &pyobj_text, &pyobj_fontFace, &pyobj_fontScale, &pyobj_thickness) &&
        pyopencv_to_safe(pyobj_text, text, ArgInfo("text", 0)) &&
        pyopencv_to_safe(pyobj_fontFace, fontFace, ArgInfo("fontFace", 0)) &&
        pyopencv_to_safe(pyobj_fontScale, fontScale, ArgInfo("fontScale", 0)) &&
        pyopencv_to_safe(pyobj_thickness, thickness, ArgInfo("thickness", 0)) )
    {
        ERRWRAP2(retval = cv::getTextSize(text, fontFace, fontScale, thickness, &baseLine));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(baseLine));
    }

    return NULL;
}

static PyObject* pyopencv_cv_getThreadNum(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    int retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::getThreadNum());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_getTickCount(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    int64 retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::getTickCount());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_getTickFrequency(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    double retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::getTickFrequency());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_getTrackbarPos(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_trackbarname = NULL;
    String trackbarname;
    PyObject* pyobj_winname = NULL;
    String winname;
    int retval;

    const char* keywords[] = { "trackbarname", "winname", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:getTrackbarPos", (char**)keywords, &pyobj_trackbarname, &pyobj_winname) &&
        pyopencv_to_safe(pyobj_trackbarname, trackbarname, ArgInfo("trackbarname", 0)) &&
        pyopencv_to_safe(pyobj_winname, winname, ArgInfo("winname", 0)) )
    {
        ERRWRAP2(retval = cv::getTrackbarPos(trackbarname, winname));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_getValidDisparityROI(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_roi1 = NULL;
    Rect roi1;
    PyObject* pyobj_roi2 = NULL;
    Rect roi2;
    PyObject* pyobj_minDisparity = NULL;
    int minDisparity=0;
    PyObject* pyobj_numberOfDisparities = NULL;
    int numberOfDisparities=0;
    PyObject* pyobj_blockSize = NULL;
    int blockSize=0;
    Rect retval;

    const char* keywords[] = { "roi1", "roi2", "minDisparity", "numberOfDisparities", "blockSize", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO:getValidDisparityROI", (char**)keywords, &pyobj_roi1, &pyobj_roi2, &pyobj_minDisparity, &pyobj_numberOfDisparities, &pyobj_blockSize) &&
        pyopencv_to_safe(pyobj_roi1, roi1, ArgInfo("roi1", 0)) &&
        pyopencv_to_safe(pyobj_roi2, roi2, ArgInfo("roi2", 0)) &&
        pyopencv_to_safe(pyobj_minDisparity, minDisparity, ArgInfo("minDisparity", 0)) &&
        pyopencv_to_safe(pyobj_numberOfDisparities, numberOfDisparities, ArgInfo("numberOfDisparities", 0)) &&
        pyopencv_to_safe(pyobj_blockSize, blockSize, ArgInfo("blockSize", 0)) )
    {
        ERRWRAP2(retval = cv::getValidDisparityROI(roi1, roi2, minDisparity, numberOfDisparities, blockSize));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_getVersionMajor(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    int retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::getVersionMajor());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_getVersionMinor(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    int retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::getVersionMinor());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_getVersionRevision(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    int retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::getVersionRevision());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_getVersionString(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    String retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::getVersionString());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_getWindowImageRect(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_winname = NULL;
    String winname;
    Rect retval;

    const char* keywords[] = { "winname", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:getWindowImageRect", (char**)keywords, &pyobj_winname) &&
        pyopencv_to_safe(pyobj_winname, winname, ArgInfo("winname", 0)) )
    {
        ERRWRAP2(retval = cv::getWindowImageRect(winname));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_getWindowProperty(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_winname = NULL;
    String winname;
    PyObject* pyobj_prop_id = NULL;
    int prop_id=0;
    double retval;

    const char* keywords[] = { "winname", "prop_id", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:getWindowProperty", (char**)keywords, &pyobj_winname, &pyobj_prop_id) &&
        pyopencv_to_safe(pyobj_winname, winname, ArgInfo("winname", 0)) &&
        pyopencv_to_safe(pyobj_prop_id, prop_id, ArgInfo("prop_id", 0)) )
    {
        ERRWRAP2(retval = cv::getWindowProperty(winname, prop_id));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_goodFeaturesToTrack(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(4);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_corners = NULL;
    Mat corners;
    PyObject* pyobj_maxCorners = NULL;
    int maxCorners=0;
    PyObject* pyobj_qualityLevel = NULL;
    double qualityLevel=0;
    PyObject* pyobj_minDistance = NULL;
    double minDistance=0;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_blockSize = NULL;
    int blockSize=3;
    PyObject* pyobj_useHarrisDetector = NULL;
    bool useHarrisDetector=false;
    PyObject* pyobj_k = NULL;
    double k=0.04;

    const char* keywords[] = { "image", "maxCorners", "qualityLevel", "minDistance", "corners", "mask", "blockSize", "useHarrisDetector", "k", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOOO:goodFeaturesToTrack", (char**)keywords, &pyobj_image, &pyobj_maxCorners, &pyobj_qualityLevel, &pyobj_minDistance, &pyobj_corners, &pyobj_mask, &pyobj_blockSize, &pyobj_useHarrisDetector, &pyobj_k) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 1)) &&
        pyopencv_to_safe(pyobj_maxCorners, maxCorners, ArgInfo("maxCorners", 0)) &&
        pyopencv_to_safe(pyobj_qualityLevel, qualityLevel, ArgInfo("qualityLevel", 0)) &&
        pyopencv_to_safe(pyobj_minDistance, minDistance, ArgInfo("minDistance", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_blockSize, blockSize, ArgInfo("blockSize", 0)) &&
        pyopencv_to_safe(pyobj_useHarrisDetector, useHarrisDetector, ArgInfo("useHarrisDetector", 0)) &&
        pyopencv_to_safe(pyobj_k, k, ArgInfo("k", 0)) )
    {
        ERRWRAP2(cv::goodFeaturesToTrack(image, corners, maxCorners, qualityLevel, minDistance, mask, blockSize, useHarrisDetector, k));
        return pyopencv_from(corners);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_corners = NULL;
    UMat corners;
    PyObject* pyobj_maxCorners = NULL;
    int maxCorners=0;
    PyObject* pyobj_qualityLevel = NULL;
    double qualityLevel=0;
    PyObject* pyobj_minDistance = NULL;
    double minDistance=0;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    PyObject* pyobj_blockSize = NULL;
    int blockSize=3;
    PyObject* pyobj_useHarrisDetector = NULL;
    bool useHarrisDetector=false;
    PyObject* pyobj_k = NULL;
    double k=0.04;

    const char* keywords[] = { "image", "maxCorners", "qualityLevel", "minDistance", "corners", "mask", "blockSize", "useHarrisDetector", "k", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOOO:goodFeaturesToTrack", (char**)keywords, &pyobj_image, &pyobj_maxCorners, &pyobj_qualityLevel, &pyobj_minDistance, &pyobj_corners, &pyobj_mask, &pyobj_blockSize, &pyobj_useHarrisDetector, &pyobj_k) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 1)) &&
        pyopencv_to_safe(pyobj_maxCorners, maxCorners, ArgInfo("maxCorners", 0)) &&
        pyopencv_to_safe(pyobj_qualityLevel, qualityLevel, ArgInfo("qualityLevel", 0)) &&
        pyopencv_to_safe(pyobj_minDistance, minDistance, ArgInfo("minDistance", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_blockSize, blockSize, ArgInfo("blockSize", 0)) &&
        pyopencv_to_safe(pyobj_useHarrisDetector, useHarrisDetector, ArgInfo("useHarrisDetector", 0)) &&
        pyopencv_to_safe(pyobj_k, k, ArgInfo("k", 0)) )
    {
        ERRWRAP2(cv::goodFeaturesToTrack(image, corners, maxCorners, qualityLevel, minDistance, mask, blockSize, useHarrisDetector, k));
        return pyopencv_from(corners);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_corners = NULL;
    Mat corners;
    PyObject* pyobj_maxCorners = NULL;
    int maxCorners=0;
    PyObject* pyobj_qualityLevel = NULL;
    double qualityLevel=0;
    PyObject* pyobj_minDistance = NULL;
    double minDistance=0;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_blockSize = NULL;
    int blockSize=0;
    PyObject* pyobj_gradientSize = NULL;
    int gradientSize=0;
    PyObject* pyobj_useHarrisDetector = NULL;
    bool useHarrisDetector=false;
    PyObject* pyobj_k = NULL;
    double k=0.04;

    const char* keywords[] = { "image", "maxCorners", "qualityLevel", "minDistance", "mask", "blockSize", "gradientSize", "corners", "useHarrisDetector", "k", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOO|OOO:goodFeaturesToTrack", (char**)keywords, &pyobj_image, &pyobj_maxCorners, &pyobj_qualityLevel, &pyobj_minDistance, &pyobj_mask, &pyobj_blockSize, &pyobj_gradientSize, &pyobj_corners, &pyobj_useHarrisDetector, &pyobj_k) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 1)) &&
        pyopencv_to_safe(pyobj_maxCorners, maxCorners, ArgInfo("maxCorners", 0)) &&
        pyopencv_to_safe(pyobj_qualityLevel, qualityLevel, ArgInfo("qualityLevel", 0)) &&
        pyopencv_to_safe(pyobj_minDistance, minDistance, ArgInfo("minDistance", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_blockSize, blockSize, ArgInfo("blockSize", 0)) &&
        pyopencv_to_safe(pyobj_gradientSize, gradientSize, ArgInfo("gradientSize", 0)) &&
        pyopencv_to_safe(pyobj_useHarrisDetector, useHarrisDetector, ArgInfo("useHarrisDetector", 0)) &&
        pyopencv_to_safe(pyobj_k, k, ArgInfo("k", 0)) )
    {
        ERRWRAP2(cv::goodFeaturesToTrack(image, corners, maxCorners, qualityLevel, minDistance, mask, blockSize, gradientSize, useHarrisDetector, k));
        return pyopencv_from(corners);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_corners = NULL;
    UMat corners;
    PyObject* pyobj_maxCorners = NULL;
    int maxCorners=0;
    PyObject* pyobj_qualityLevel = NULL;
    double qualityLevel=0;
    PyObject* pyobj_minDistance = NULL;
    double minDistance=0;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    PyObject* pyobj_blockSize = NULL;
    int blockSize=0;
    PyObject* pyobj_gradientSize = NULL;
    int gradientSize=0;
    PyObject* pyobj_useHarrisDetector = NULL;
    bool useHarrisDetector=false;
    PyObject* pyobj_k = NULL;
    double k=0.04;

    const char* keywords[] = { "image", "maxCorners", "qualityLevel", "minDistance", "mask", "blockSize", "gradientSize", "corners", "useHarrisDetector", "k", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOO|OOO:goodFeaturesToTrack", (char**)keywords, &pyobj_image, &pyobj_maxCorners, &pyobj_qualityLevel, &pyobj_minDistance, &pyobj_mask, &pyobj_blockSize, &pyobj_gradientSize, &pyobj_corners, &pyobj_useHarrisDetector, &pyobj_k) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 1)) &&
        pyopencv_to_safe(pyobj_maxCorners, maxCorners, ArgInfo("maxCorners", 0)) &&
        pyopencv_to_safe(pyobj_qualityLevel, qualityLevel, ArgInfo("qualityLevel", 0)) &&
        pyopencv_to_safe(pyobj_minDistance, minDistance, ArgInfo("minDistance", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_blockSize, blockSize, ArgInfo("blockSize", 0)) &&
        pyopencv_to_safe(pyobj_gradientSize, gradientSize, ArgInfo("gradientSize", 0)) &&
        pyopencv_to_safe(pyobj_useHarrisDetector, useHarrisDetector, ArgInfo("useHarrisDetector", 0)) &&
        pyopencv_to_safe(pyobj_k, k, ArgInfo("k", 0)) )
    {
        ERRWRAP2(cv::goodFeaturesToTrack(image, corners, maxCorners, qualityLevel, minDistance, mask, blockSize, gradientSize, useHarrisDetector, k));
        return pyopencv_from(corners);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("goodFeaturesToTrack");

    return NULL;
}

static PyObject* pyopencv_cv_goodFeaturesToTrackWithQuality(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_corners = NULL;
    Mat corners;
    PyObject* pyobj_maxCorners = NULL;
    int maxCorners=0;
    PyObject* pyobj_qualityLevel = NULL;
    double qualityLevel=0;
    PyObject* pyobj_minDistance = NULL;
    double minDistance=0;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_cornersQuality = NULL;
    Mat cornersQuality;
    PyObject* pyobj_blockSize = NULL;
    int blockSize=3;
    PyObject* pyobj_gradientSize = NULL;
    int gradientSize=3;
    PyObject* pyobj_useHarrisDetector = NULL;
    bool useHarrisDetector=false;
    PyObject* pyobj_k = NULL;
    double k=0.04;

    const char* keywords[] = { "image", "maxCorners", "qualityLevel", "minDistance", "mask", "corners", "cornersQuality", "blockSize", "gradientSize", "useHarrisDetector", "k", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OOOOOO:goodFeaturesToTrackWithQuality", (char**)keywords, &pyobj_image, &pyobj_maxCorners, &pyobj_qualityLevel, &pyobj_minDistance, &pyobj_mask, &pyobj_corners, &pyobj_cornersQuality, &pyobj_blockSize, &pyobj_gradientSize, &pyobj_useHarrisDetector, &pyobj_k) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 1)) &&
        pyopencv_to_safe(pyobj_maxCorners, maxCorners, ArgInfo("maxCorners", 0)) &&
        pyopencv_to_safe(pyobj_qualityLevel, qualityLevel, ArgInfo("qualityLevel", 0)) &&
        pyopencv_to_safe(pyobj_minDistance, minDistance, ArgInfo("minDistance", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_cornersQuality, cornersQuality, ArgInfo("cornersQuality", 1)) &&
        pyopencv_to_safe(pyobj_blockSize, blockSize, ArgInfo("blockSize", 0)) &&
        pyopencv_to_safe(pyobj_gradientSize, gradientSize, ArgInfo("gradientSize", 0)) &&
        pyopencv_to_safe(pyobj_useHarrisDetector, useHarrisDetector, ArgInfo("useHarrisDetector", 0)) &&
        pyopencv_to_safe(pyobj_k, k, ArgInfo("k", 0)) )
    {
        ERRWRAP2(cv::goodFeaturesToTrack(image, corners, maxCorners, qualityLevel, minDistance, mask, cornersQuality, blockSize, gradientSize, useHarrisDetector, k));
        return Py_BuildValue("(NN)", pyopencv_from(corners), pyopencv_from(cornersQuality));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_corners = NULL;
    UMat corners;
    PyObject* pyobj_maxCorners = NULL;
    int maxCorners=0;
    PyObject* pyobj_qualityLevel = NULL;
    double qualityLevel=0;
    PyObject* pyobj_minDistance = NULL;
    double minDistance=0;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    PyObject* pyobj_cornersQuality = NULL;
    UMat cornersQuality;
    PyObject* pyobj_blockSize = NULL;
    int blockSize=3;
    PyObject* pyobj_gradientSize = NULL;
    int gradientSize=3;
    PyObject* pyobj_useHarrisDetector = NULL;
    bool useHarrisDetector=false;
    PyObject* pyobj_k = NULL;
    double k=0.04;

    const char* keywords[] = { "image", "maxCorners", "qualityLevel", "minDistance", "mask", "corners", "cornersQuality", "blockSize", "gradientSize", "useHarrisDetector", "k", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OOOOOO:goodFeaturesToTrackWithQuality", (char**)keywords, &pyobj_image, &pyobj_maxCorners, &pyobj_qualityLevel, &pyobj_minDistance, &pyobj_mask, &pyobj_corners, &pyobj_cornersQuality, &pyobj_blockSize, &pyobj_gradientSize, &pyobj_useHarrisDetector, &pyobj_k) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 1)) &&
        pyopencv_to_safe(pyobj_maxCorners, maxCorners, ArgInfo("maxCorners", 0)) &&
        pyopencv_to_safe(pyobj_qualityLevel, qualityLevel, ArgInfo("qualityLevel", 0)) &&
        pyopencv_to_safe(pyobj_minDistance, minDistance, ArgInfo("minDistance", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_cornersQuality, cornersQuality, ArgInfo("cornersQuality", 1)) &&
        pyopencv_to_safe(pyobj_blockSize, blockSize, ArgInfo("blockSize", 0)) &&
        pyopencv_to_safe(pyobj_gradientSize, gradientSize, ArgInfo("gradientSize", 0)) &&
        pyopencv_to_safe(pyobj_useHarrisDetector, useHarrisDetector, ArgInfo("useHarrisDetector", 0)) &&
        pyopencv_to_safe(pyobj_k, k, ArgInfo("k", 0)) )
    {
        ERRWRAP2(cv::goodFeaturesToTrack(image, corners, maxCorners, qualityLevel, minDistance, mask, cornersQuality, blockSize, gradientSize, useHarrisDetector, k));
        return Py_BuildValue("(NN)", pyopencv_from(corners), pyopencv_from(cornersQuality));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("goodFeaturesToTrackWithQuality");

    return NULL;
}

static PyObject* pyopencv_cv_grabCut(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_rect = NULL;
    Rect rect;
    PyObject* pyobj_bgdModel = NULL;
    Mat bgdModel;
    PyObject* pyobj_fgdModel = NULL;
    Mat fgdModel;
    PyObject* pyobj_iterCount = NULL;
    int iterCount=0;
    PyObject* pyobj_mode = NULL;
    int mode=GC_EVAL;

    const char* keywords[] = { "img", "mask", "rect", "bgdModel", "fgdModel", "iterCount", "mode", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|O:grabCut", (char**)keywords, &pyobj_img, &pyobj_mask, &pyobj_rect, &pyobj_bgdModel, &pyobj_fgdModel, &pyobj_iterCount, &pyobj_mode) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 1)) &&
        pyopencv_to_safe(pyobj_rect, rect, ArgInfo("rect", 0)) &&
        pyopencv_to_safe(pyobj_bgdModel, bgdModel, ArgInfo("bgdModel", 1)) &&
        pyopencv_to_safe(pyobj_fgdModel, fgdModel, ArgInfo("fgdModel", 1)) &&
        pyopencv_to_safe(pyobj_iterCount, iterCount, ArgInfo("iterCount", 0)) &&
        pyopencv_to_safe(pyobj_mode, mode, ArgInfo("mode", 0)) )
    {
        ERRWRAP2(cv::grabCut(img, mask, rect, bgdModel, fgdModel, iterCount, mode));
        return Py_BuildValue("(NNN)", pyopencv_from(mask), pyopencv_from(bgdModel), pyopencv_from(fgdModel));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    PyObject* pyobj_rect = NULL;
    Rect rect;
    PyObject* pyobj_bgdModel = NULL;
    UMat bgdModel;
    PyObject* pyobj_fgdModel = NULL;
    UMat fgdModel;
    PyObject* pyobj_iterCount = NULL;
    int iterCount=0;
    PyObject* pyobj_mode = NULL;
    int mode=GC_EVAL;

    const char* keywords[] = { "img", "mask", "rect", "bgdModel", "fgdModel", "iterCount", "mode", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|O:grabCut", (char**)keywords, &pyobj_img, &pyobj_mask, &pyobj_rect, &pyobj_bgdModel, &pyobj_fgdModel, &pyobj_iterCount, &pyobj_mode) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 1)) &&
        pyopencv_to_safe(pyobj_rect, rect, ArgInfo("rect", 0)) &&
        pyopencv_to_safe(pyobj_bgdModel, bgdModel, ArgInfo("bgdModel", 1)) &&
        pyopencv_to_safe(pyobj_fgdModel, fgdModel, ArgInfo("fgdModel", 1)) &&
        pyopencv_to_safe(pyobj_iterCount, iterCount, ArgInfo("iterCount", 0)) &&
        pyopencv_to_safe(pyobj_mode, mode, ArgInfo("mode", 0)) )
    {
        ERRWRAP2(cv::grabCut(img, mask, rect, bgdModel, fgdModel, iterCount, mode));
        return Py_BuildValue("(NNN)", pyopencv_from(mask), pyopencv_from(bgdModel), pyopencv_from(fgdModel));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("grabCut");

    return NULL;
}

static PyObject* pyopencv_cv_groupRectangles(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_rectList = NULL;
    vector_Rect rectList;
    vector_int weights;
    PyObject* pyobj_groupThreshold = NULL;
    int groupThreshold=0;
    PyObject* pyobj_eps = NULL;
    double eps=0.2;

    const char* keywords[] = { "rectList", "groupThreshold", "eps", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:groupRectangles", (char**)keywords, &pyobj_rectList, &pyobj_groupThreshold, &pyobj_eps) &&
        pyopencv_to_safe(pyobj_rectList, rectList, ArgInfo("rectList", 1)) &&
        pyopencv_to_safe(pyobj_groupThreshold, groupThreshold, ArgInfo("groupThreshold", 0)) &&
        pyopencv_to_safe(pyobj_eps, eps, ArgInfo("eps", 0)) )
    {
        ERRWRAP2(cv::groupRectangles(rectList, weights, groupThreshold, eps));
        return Py_BuildValue("(NN)", pyopencv_from(rectList), pyopencv_from(weights));
    }

    return NULL;
}

static PyObject* pyopencv_cv_haveImageReader(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_filename = NULL;
    String filename;
    bool retval;

    const char* keywords[] = { "filename", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:haveImageReader", (char**)keywords, &pyobj_filename) &&
        pyopencv_to_safe(pyobj_filename, filename, ArgInfo("filename", 0)) )
    {
        ERRWRAP2(retval = cv::haveImageReader(filename));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_haveImageWriter(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_filename = NULL;
    String filename;
    bool retval;

    const char* keywords[] = { "filename", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:haveImageWriter", (char**)keywords, &pyobj_filename) &&
        pyopencv_to_safe(pyobj_filename, filename, ArgInfo("filename", 0)) )
    {
        ERRWRAP2(retval = cv::haveImageWriter(filename));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_haveOpenVX(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    bool retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::haveOpenVX());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_hconcat(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    vector_Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:hconcat", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::hconcat(src, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    vector_UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:hconcat", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::hconcat(src, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("hconcat");

    return NULL;
}

static PyObject* pyopencv_cv_idct(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_flags = NULL;
    int flags=0;

    const char* keywords[] = { "src", "dst", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:idct", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::idct(src, dst, flags));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_flags = NULL;
    int flags=0;

    const char* keywords[] = { "src", "dst", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:idct", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::idct(src, dst, flags));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("idct");

    return NULL;
}

static PyObject* pyopencv_cv_idft(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_nonzeroRows = NULL;
    int nonzeroRows=0;

    const char* keywords[] = { "src", "dst", "flags", "nonzeroRows", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:idft", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_flags, &pyobj_nonzeroRows) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_nonzeroRows, nonzeroRows, ArgInfo("nonzeroRows", 0)) )
    {
        ERRWRAP2(cv::idft(src, dst, flags, nonzeroRows));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_nonzeroRows = NULL;
    int nonzeroRows=0;

    const char* keywords[] = { "src", "dst", "flags", "nonzeroRows", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:idft", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_flags, &pyobj_nonzeroRows) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_nonzeroRows, nonzeroRows, ArgInfo("nonzeroRows", 0)) )
    {
        ERRWRAP2(cv::idft(src, dst, flags, nonzeroRows));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("idft");

    return NULL;
}

static PyObject* pyopencv_cv_illuminationChange(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_alpha = NULL;
    float alpha=0.2f;
    PyObject* pyobj_beta = NULL;
    float beta=0.4f;

    const char* keywords[] = { "src", "mask", "dst", "alpha", "beta", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:illuminationChange", (char**)keywords, &pyobj_src, &pyobj_mask, &pyobj_dst, &pyobj_alpha, &pyobj_beta) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_beta, beta, ArgInfo("beta", 0)) )
    {
        ERRWRAP2(cv::illuminationChange(src, mask, dst, alpha, beta));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_alpha = NULL;
    float alpha=0.2f;
    PyObject* pyobj_beta = NULL;
    float beta=0.4f;

    const char* keywords[] = { "src", "mask", "dst", "alpha", "beta", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:illuminationChange", (char**)keywords, &pyobj_src, &pyobj_mask, &pyobj_dst, &pyobj_alpha, &pyobj_beta) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_beta, beta, ArgInfo("beta", 0)) )
    {
        ERRWRAP2(cv::illuminationChange(src, mask, dst, alpha, beta));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("illuminationChange");

    return NULL;
}

static PyObject* pyopencv_cv_imdecode(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_buf = NULL;
    Mat buf;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    Mat retval;

    const char* keywords[] = { "buf", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:imdecode", (char**)keywords, &pyobj_buf, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_buf, buf, ArgInfo("buf", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(retval = cv::imdecode(buf, flags));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_buf = NULL;
    UMat buf;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    Mat retval;

    const char* keywords[] = { "buf", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:imdecode", (char**)keywords, &pyobj_buf, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_buf, buf, ArgInfo("buf", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(retval = cv::imdecode(buf, flags));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("imdecode");

    return NULL;
}

static PyObject* pyopencv_cv_imencode(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_ext = NULL;
    String ext;
    PyObject* pyobj_img = NULL;
    Mat img;
    vector_uchar buf;
    PyObject* pyobj_params = NULL;
    vector_int params=std::vector<int>();
    bool retval;

    const char* keywords[] = { "ext", "img", "params", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:imencode", (char**)keywords, &pyobj_ext, &pyobj_img, &pyobj_params) &&
        pyopencv_to_safe(pyobj_ext, ext, ArgInfo("ext", 0)) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_params, params, ArgInfo("params", 0)) )
    {
        ERRWRAP2(retval = cv::imencode(ext, img, buf, params));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(buf));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_ext = NULL;
    String ext;
    PyObject* pyobj_img = NULL;
    UMat img;
    vector_uchar buf;
    PyObject* pyobj_params = NULL;
    vector_int params=std::vector<int>();
    bool retval;

    const char* keywords[] = { "ext", "img", "params", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:imencode", (char**)keywords, &pyobj_ext, &pyobj_img, &pyobj_params) &&
        pyopencv_to_safe(pyobj_ext, ext, ArgInfo("ext", 0)) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_params, params, ArgInfo("params", 0)) )
    {
        ERRWRAP2(retval = cv::imencode(ext, img, buf, params));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(buf));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("imencode");

    return NULL;
}

static PyObject* pyopencv_cv_imread(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_filename = NULL;
    String filename;
    PyObject* pyobj_flags = NULL;
    int flags=IMREAD_COLOR;
    Mat retval;

    const char* keywords[] = { "filename", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:imread", (char**)keywords, &pyobj_filename, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_filename, filename, ArgInfo("filename", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(retval = cv::imread(filename, flags));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_imreadmulti(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_filename = NULL;
    String filename;
    PyObject* pyobj_mats = NULL;
    vector_Mat mats;
    PyObject* pyobj_flags = NULL;
    int flags=IMREAD_ANYCOLOR;
    bool retval;

    const char* keywords[] = { "filename", "mats", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:imreadmulti", (char**)keywords, &pyobj_filename, &pyobj_mats, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_filename, filename, ArgInfo("filename", 0)) &&
        pyopencv_to_safe(pyobj_mats, mats, ArgInfo("mats", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(retval = cv::imreadmulti(filename, mats, flags));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(mats));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_filename = NULL;
    String filename;
    PyObject* pyobj_mats = NULL;
    vector_Mat mats;
    PyObject* pyobj_flags = NULL;
    int flags=IMREAD_ANYCOLOR;
    bool retval;

    const char* keywords[] = { "filename", "mats", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:imreadmulti", (char**)keywords, &pyobj_filename, &pyobj_mats, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_filename, filename, ArgInfo("filename", 0)) &&
        pyopencv_to_safe(pyobj_mats, mats, ArgInfo("mats", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(retval = cv::imreadmulti(filename, mats, flags));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(mats));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("imreadmulti");

    return NULL;
}

static PyObject* pyopencv_cv_imshow(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(3);

    {
    PyObject* pyobj_winname = NULL;
    String winname;
    PyObject* pyobj_mat = NULL;
    Mat mat;

    const char* keywords[] = { "winname", "mat", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:imshow", (char**)keywords, &pyobj_winname, &pyobj_mat) &&
        pyopencv_to_safe(pyobj_winname, winname, ArgInfo("winname", 0)) &&
        pyopencv_to_safe(pyobj_mat, mat, ArgInfo("mat", 0)) )
    {
        ERRWRAP2(cv::imshow(winname, mat));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_winname = NULL;
    String winname;
    PyObject* pyobj_mat = NULL;
    cuda::GpuMat mat;

    const char* keywords[] = { "winname", "mat", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:imshow", (char**)keywords, &pyobj_winname, &pyobj_mat) &&
        pyopencv_to_safe(pyobj_winname, winname, ArgInfo("winname", 0)) &&
        pyopencv_to_safe(pyobj_mat, mat, ArgInfo("mat", 0)) )
    {
        ERRWRAP2(cv::imshow(winname, mat));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_winname = NULL;
    String winname;
    PyObject* pyobj_mat = NULL;
    UMat mat;

    const char* keywords[] = { "winname", "mat", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:imshow", (char**)keywords, &pyobj_winname, &pyobj_mat) &&
        pyopencv_to_safe(pyobj_winname, winname, ArgInfo("winname", 0)) &&
        pyopencv_to_safe(pyobj_mat, mat, ArgInfo("mat", 0)) )
    {
        ERRWRAP2(cv::imshow(winname, mat));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("imshow");

    return NULL;
}

static PyObject* pyopencv_cv_imwrite(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_filename = NULL;
    String filename;
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_params = NULL;
    vector_int params=std::vector<int>();
    bool retval;

    const char* keywords[] = { "filename", "img", "params", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:imwrite", (char**)keywords, &pyobj_filename, &pyobj_img, &pyobj_params) &&
        pyopencv_to_safe(pyobj_filename, filename, ArgInfo("filename", 0)) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_params, params, ArgInfo("params", 0)) )
    {
        ERRWRAP2(retval = cv::imwrite(filename, img, params));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_filename = NULL;
    String filename;
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_params = NULL;
    vector_int params=std::vector<int>();
    bool retval;

    const char* keywords[] = { "filename", "img", "params", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:imwrite", (char**)keywords, &pyobj_filename, &pyobj_img, &pyobj_params) &&
        pyopencv_to_safe(pyobj_filename, filename, ArgInfo("filename", 0)) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_params, params, ArgInfo("params", 0)) )
    {
        ERRWRAP2(retval = cv::imwrite(filename, img, params));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("imwrite");

    return NULL;
}

static PyObject* pyopencv_cv_imwritemulti(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_filename = NULL;
    String filename;
    PyObject* pyobj_img = NULL;
    vector_Mat img;
    PyObject* pyobj_params = NULL;
    vector_int params=std::vector<int>();
    bool retval;

    const char* keywords[] = { "filename", "img", "params", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:imwritemulti", (char**)keywords, &pyobj_filename, &pyobj_img, &pyobj_params) &&
        pyopencv_to_safe(pyobj_filename, filename, ArgInfo("filename", 0)) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_params, params, ArgInfo("params", 0)) )
    {
        ERRWRAP2(retval = cv::imwritemulti(filename, img, params));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_filename = NULL;
    String filename;
    PyObject* pyobj_img = NULL;
    vector_UMat img;
    PyObject* pyobj_params = NULL;
    vector_int params=std::vector<int>();
    bool retval;

    const char* keywords[] = { "filename", "img", "params", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:imwritemulti", (char**)keywords, &pyobj_filename, &pyobj_img, &pyobj_params) &&
        pyopencv_to_safe(pyobj_filename, filename, ArgInfo("filename", 0)) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_params, params, ArgInfo("params", 0)) )
    {
        ERRWRAP2(retval = cv::imwritemulti(filename, img, params));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("imwritemulti");

    return NULL;
}

static PyObject* pyopencv_cv_inRange(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_lowerb = NULL;
    Mat lowerb;
    PyObject* pyobj_upperb = NULL;
    Mat upperb;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src", "lowerb", "upperb", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:inRange", (char**)keywords, &pyobj_src, &pyobj_lowerb, &pyobj_upperb, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_lowerb, lowerb, ArgInfo("lowerb", 0)) &&
        pyopencv_to_safe(pyobj_upperb, upperb, ArgInfo("upperb", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::inRange(src, lowerb, upperb, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_lowerb = NULL;
    UMat lowerb;
    PyObject* pyobj_upperb = NULL;
    UMat upperb;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "src", "lowerb", "upperb", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:inRange", (char**)keywords, &pyobj_src, &pyobj_lowerb, &pyobj_upperb, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_lowerb, lowerb, ArgInfo("lowerb", 0)) &&
        pyopencv_to_safe(pyobj_upperb, upperb, ArgInfo("upperb", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::inRange(src, lowerb, upperb, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("inRange");

    return NULL;
}

static PyObject* pyopencv_cv_initCameraMatrix2D(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_objectPoints = NULL;
    vector_Mat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    vector_Mat imagePoints;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_aspectRatio = NULL;
    double aspectRatio=1.0;
    Mat retval;

    const char* keywords[] = { "objectPoints", "imagePoints", "imageSize", "aspectRatio", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:initCameraMatrix2D", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints, &pyobj_imageSize, &pyobj_aspectRatio) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 0)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_aspectRatio, aspectRatio, ArgInfo("aspectRatio", 0)) )
    {
        ERRWRAP2(retval = cv::initCameraMatrix2D(objectPoints, imagePoints, imageSize, aspectRatio));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_objectPoints = NULL;
    vector_UMat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    vector_UMat imagePoints;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_aspectRatio = NULL;
    double aspectRatio=1.0;
    Mat retval;

    const char* keywords[] = { "objectPoints", "imagePoints", "imageSize", "aspectRatio", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:initCameraMatrix2D", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints, &pyobj_imageSize, &pyobj_aspectRatio) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 0)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_aspectRatio, aspectRatio, ArgInfo("aspectRatio", 0)) )
    {
        ERRWRAP2(retval = cv::initCameraMatrix2D(objectPoints, imagePoints, imageSize, aspectRatio));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("initCameraMatrix2D");

    return NULL;
}

static PyObject* pyopencv_cv_initUndistortRectifyMap(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    Mat distCoeffs;
    PyObject* pyobj_R = NULL;
    Mat R;
    PyObject* pyobj_newCameraMatrix = NULL;
    Mat newCameraMatrix;
    PyObject* pyobj_size = NULL;
    Size size;
    PyObject* pyobj_m1type = NULL;
    int m1type=0;
    PyObject* pyobj_map1 = NULL;
    Mat map1;
    PyObject* pyobj_map2 = NULL;
    Mat map2;

    const char* keywords[] = { "cameraMatrix", "distCoeffs", "R", "newCameraMatrix", "size", "m1type", "map1", "map2", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|OO:initUndistortRectifyMap", (char**)keywords, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_R, &pyobj_newCameraMatrix, &pyobj_size, &pyobj_m1type, &pyobj_map1, &pyobj_map2) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) &&
        pyopencv_to_safe(pyobj_newCameraMatrix, newCameraMatrix, ArgInfo("newCameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_size, size, ArgInfo("size", 0)) &&
        pyopencv_to_safe(pyobj_m1type, m1type, ArgInfo("m1type", 0)) &&
        pyopencv_to_safe(pyobj_map1, map1, ArgInfo("map1", 1)) &&
        pyopencv_to_safe(pyobj_map2, map2, ArgInfo("map2", 1)) )
    {
        ERRWRAP2(cv::initUndistortRectifyMap(cameraMatrix, distCoeffs, R, newCameraMatrix, size, m1type, map1, map2));
        return Py_BuildValue("(NN)", pyopencv_from(map1), pyopencv_from(map2));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    UMat distCoeffs;
    PyObject* pyobj_R = NULL;
    UMat R;
    PyObject* pyobj_newCameraMatrix = NULL;
    UMat newCameraMatrix;
    PyObject* pyobj_size = NULL;
    Size size;
    PyObject* pyobj_m1type = NULL;
    int m1type=0;
    PyObject* pyobj_map1 = NULL;
    UMat map1;
    PyObject* pyobj_map2 = NULL;
    UMat map2;

    const char* keywords[] = { "cameraMatrix", "distCoeffs", "R", "newCameraMatrix", "size", "m1type", "map1", "map2", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|OO:initUndistortRectifyMap", (char**)keywords, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_R, &pyobj_newCameraMatrix, &pyobj_size, &pyobj_m1type, &pyobj_map1, &pyobj_map2) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) &&
        pyopencv_to_safe(pyobj_newCameraMatrix, newCameraMatrix, ArgInfo("newCameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_size, size, ArgInfo("size", 0)) &&
        pyopencv_to_safe(pyobj_m1type, m1type, ArgInfo("m1type", 0)) &&
        pyopencv_to_safe(pyobj_map1, map1, ArgInfo("map1", 1)) &&
        pyopencv_to_safe(pyobj_map2, map2, ArgInfo("map2", 1)) )
    {
        ERRWRAP2(cv::initUndistortRectifyMap(cameraMatrix, distCoeffs, R, newCameraMatrix, size, m1type, map1, map2));
        return Py_BuildValue("(NN)", pyopencv_from(map1), pyopencv_from(map2));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("initUndistortRectifyMap");

    return NULL;
}

static PyObject* pyopencv_cv_inpaint(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_inpaintMask = NULL;
    Mat inpaintMask;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_inpaintRadius = NULL;
    double inpaintRadius=0;
    PyObject* pyobj_flags = NULL;
    int flags=0;

    const char* keywords[] = { "src", "inpaintMask", "inpaintRadius", "flags", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:inpaint", (char**)keywords, &pyobj_src, &pyobj_inpaintMask, &pyobj_inpaintRadius, &pyobj_flags, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_inpaintMask, inpaintMask, ArgInfo("inpaintMask", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_inpaintRadius, inpaintRadius, ArgInfo("inpaintRadius", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::inpaint(src, inpaintMask, dst, inpaintRadius, flags));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_inpaintMask = NULL;
    UMat inpaintMask;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_inpaintRadius = NULL;
    double inpaintRadius=0;
    PyObject* pyobj_flags = NULL;
    int flags=0;

    const char* keywords[] = { "src", "inpaintMask", "inpaintRadius", "flags", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:inpaint", (char**)keywords, &pyobj_src, &pyobj_inpaintMask, &pyobj_inpaintRadius, &pyobj_flags, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_inpaintMask, inpaintMask, ArgInfo("inpaintMask", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_inpaintRadius, inpaintRadius, ArgInfo("inpaintRadius", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::inpaint(src, inpaintMask, dst, inpaintRadius, flags));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("inpaint");

    return NULL;
}

static PyObject* pyopencv_cv_insertChannel(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_coi = NULL;
    int coi=0;

    const char* keywords[] = { "src", "dst", "coi", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:insertChannel", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_coi) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_coi, coi, ArgInfo("coi", 0)) )
    {
        ERRWRAP2(cv::insertChannel(src, dst, coi));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_coi = NULL;
    int coi=0;

    const char* keywords[] = { "src", "dst", "coi", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:insertChannel", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_coi) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_coi, coi, ArgInfo("coi", 0)) )
    {
        ERRWRAP2(cv::insertChannel(src, dst, coi));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("insertChannel");

    return NULL;
}

static PyObject* pyopencv_cv_integral(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_sum = NULL;
    Mat sum;
    PyObject* pyobj_sdepth = NULL;
    int sdepth=-1;

    const char* keywords[] = { "src", "sum", "sdepth", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:integral", (char**)keywords, &pyobj_src, &pyobj_sum, &pyobj_sdepth) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_sum, sum, ArgInfo("sum", 1)) &&
        pyopencv_to_safe(pyobj_sdepth, sdepth, ArgInfo("sdepth", 0)) )
    {
        ERRWRAP2(cv::integral(src, sum, sdepth));
        return pyopencv_from(sum);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_sum = NULL;
    UMat sum;
    PyObject* pyobj_sdepth = NULL;
    int sdepth=-1;

    const char* keywords[] = { "src", "sum", "sdepth", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:integral", (char**)keywords, &pyobj_src, &pyobj_sum, &pyobj_sdepth) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_sum, sum, ArgInfo("sum", 1)) &&
        pyopencv_to_safe(pyobj_sdepth, sdepth, ArgInfo("sdepth", 0)) )
    {
        ERRWRAP2(cv::integral(src, sum, sdepth));
        return pyopencv_from(sum);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("integral");

    return NULL;
}

static PyObject* pyopencv_cv_integral2(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_sum = NULL;
    Mat sum;
    PyObject* pyobj_sqsum = NULL;
    Mat sqsum;
    PyObject* pyobj_sdepth = NULL;
    int sdepth=-1;
    PyObject* pyobj_sqdepth = NULL;
    int sqdepth=-1;

    const char* keywords[] = { "src", "sum", "sqsum", "sdepth", "sqdepth", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOO:integral2", (char**)keywords, &pyobj_src, &pyobj_sum, &pyobj_sqsum, &pyobj_sdepth, &pyobj_sqdepth) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_sum, sum, ArgInfo("sum", 1)) &&
        pyopencv_to_safe(pyobj_sqsum, sqsum, ArgInfo("sqsum", 1)) &&
        pyopencv_to_safe(pyobj_sdepth, sdepth, ArgInfo("sdepth", 0)) &&
        pyopencv_to_safe(pyobj_sqdepth, sqdepth, ArgInfo("sqdepth", 0)) )
    {
        ERRWRAP2(cv::integral(src, sum, sqsum, sdepth, sqdepth));
        return Py_BuildValue("(NN)", pyopencv_from(sum), pyopencv_from(sqsum));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_sum = NULL;
    UMat sum;
    PyObject* pyobj_sqsum = NULL;
    UMat sqsum;
    PyObject* pyobj_sdepth = NULL;
    int sdepth=-1;
    PyObject* pyobj_sqdepth = NULL;
    int sqdepth=-1;

    const char* keywords[] = { "src", "sum", "sqsum", "sdepth", "sqdepth", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOO:integral2", (char**)keywords, &pyobj_src, &pyobj_sum, &pyobj_sqsum, &pyobj_sdepth, &pyobj_sqdepth) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_sum, sum, ArgInfo("sum", 1)) &&
        pyopencv_to_safe(pyobj_sqsum, sqsum, ArgInfo("sqsum", 1)) &&
        pyopencv_to_safe(pyobj_sdepth, sdepth, ArgInfo("sdepth", 0)) &&
        pyopencv_to_safe(pyobj_sqdepth, sqdepth, ArgInfo("sqdepth", 0)) )
    {
        ERRWRAP2(cv::integral(src, sum, sqsum, sdepth, sqdepth));
        return Py_BuildValue("(NN)", pyopencv_from(sum), pyopencv_from(sqsum));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("integral2");

    return NULL;
}

static PyObject* pyopencv_cv_integral3(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_sum = NULL;
    Mat sum;
    PyObject* pyobj_sqsum = NULL;
    Mat sqsum;
    PyObject* pyobj_tilted = NULL;
    Mat tilted;
    PyObject* pyobj_sdepth = NULL;
    int sdepth=-1;
    PyObject* pyobj_sqdepth = NULL;
    int sqdepth=-1;

    const char* keywords[] = { "src", "sum", "sqsum", "tilted", "sdepth", "sqdepth", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOOO:integral3", (char**)keywords, &pyobj_src, &pyobj_sum, &pyobj_sqsum, &pyobj_tilted, &pyobj_sdepth, &pyobj_sqdepth) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_sum, sum, ArgInfo("sum", 1)) &&
        pyopencv_to_safe(pyobj_sqsum, sqsum, ArgInfo("sqsum", 1)) &&
        pyopencv_to_safe(pyobj_tilted, tilted, ArgInfo("tilted", 1)) &&
        pyopencv_to_safe(pyobj_sdepth, sdepth, ArgInfo("sdepth", 0)) &&
        pyopencv_to_safe(pyobj_sqdepth, sqdepth, ArgInfo("sqdepth", 0)) )
    {
        ERRWRAP2(cv::integral(src, sum, sqsum, tilted, sdepth, sqdepth));
        return Py_BuildValue("(NNN)", pyopencv_from(sum), pyopencv_from(sqsum), pyopencv_from(tilted));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_sum = NULL;
    UMat sum;
    PyObject* pyobj_sqsum = NULL;
    UMat sqsum;
    PyObject* pyobj_tilted = NULL;
    UMat tilted;
    PyObject* pyobj_sdepth = NULL;
    int sdepth=-1;
    PyObject* pyobj_sqdepth = NULL;
    int sqdepth=-1;

    const char* keywords[] = { "src", "sum", "sqsum", "tilted", "sdepth", "sqdepth", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOOO:integral3", (char**)keywords, &pyobj_src, &pyobj_sum, &pyobj_sqsum, &pyobj_tilted, &pyobj_sdepth, &pyobj_sqdepth) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_sum, sum, ArgInfo("sum", 1)) &&
        pyopencv_to_safe(pyobj_sqsum, sqsum, ArgInfo("sqsum", 1)) &&
        pyopencv_to_safe(pyobj_tilted, tilted, ArgInfo("tilted", 1)) &&
        pyopencv_to_safe(pyobj_sdepth, sdepth, ArgInfo("sdepth", 0)) &&
        pyopencv_to_safe(pyobj_sqdepth, sqdepth, ArgInfo("sqdepth", 0)) )
    {
        ERRWRAP2(cv::integral(src, sum, sqsum, tilted, sdepth, sqdepth));
        return Py_BuildValue("(NNN)", pyopencv_from(sum), pyopencv_from(sqsum), pyopencv_from(tilted));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("integral3");

    return NULL;
}

static PyObject* pyopencv_cv_intersectConvexConvex(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj__p1 = NULL;
    Mat _p1;
    PyObject* pyobj__p2 = NULL;
    Mat _p2;
    PyObject* pyobj__p12 = NULL;
    Mat _p12;
    PyObject* pyobj_handleNested = NULL;
    bool handleNested=true;
    float retval;

    const char* keywords[] = { "_p1", "_p2", "_p12", "handleNested", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:intersectConvexConvex", (char**)keywords, &pyobj__p1, &pyobj__p2, &pyobj__p12, &pyobj_handleNested) &&
        pyopencv_to_safe(pyobj__p1, _p1, ArgInfo("_p1", 0)) &&
        pyopencv_to_safe(pyobj__p2, _p2, ArgInfo("_p2", 0)) &&
        pyopencv_to_safe(pyobj__p12, _p12, ArgInfo("_p12", 1)) &&
        pyopencv_to_safe(pyobj_handleNested, handleNested, ArgInfo("handleNested", 0)) )
    {
        ERRWRAP2(retval = cv::intersectConvexConvex(_p1, _p2, _p12, handleNested));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(_p12));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj__p1 = NULL;
    UMat _p1;
    PyObject* pyobj__p2 = NULL;
    UMat _p2;
    PyObject* pyobj__p12 = NULL;
    UMat _p12;
    PyObject* pyobj_handleNested = NULL;
    bool handleNested=true;
    float retval;

    const char* keywords[] = { "_p1", "_p2", "_p12", "handleNested", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:intersectConvexConvex", (char**)keywords, &pyobj__p1, &pyobj__p2, &pyobj__p12, &pyobj_handleNested) &&
        pyopencv_to_safe(pyobj__p1, _p1, ArgInfo("_p1", 0)) &&
        pyopencv_to_safe(pyobj__p2, _p2, ArgInfo("_p2", 0)) &&
        pyopencv_to_safe(pyobj__p12, _p12, ArgInfo("_p12", 1)) &&
        pyopencv_to_safe(pyobj_handleNested, handleNested, ArgInfo("handleNested", 0)) )
    {
        ERRWRAP2(retval = cv::intersectConvexConvex(_p1, _p2, _p12, handleNested));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(_p12));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("intersectConvexConvex");

    return NULL;
}

static PyObject* pyopencv_cv_invert(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_flags = NULL;
    int flags=DECOMP_LU;
    double retval;

    const char* keywords[] = { "src", "dst", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:invert", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(retval = cv::invert(src, dst, flags));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(dst));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_flags = NULL;
    int flags=DECOMP_LU;
    double retval;

    const char* keywords[] = { "src", "dst", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:invert", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(retval = cv::invert(src, dst, flags));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(dst));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("invert");

    return NULL;
}

static PyObject* pyopencv_cv_invertAffineTransform(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_M = NULL;
    Mat M;
    PyObject* pyobj_iM = NULL;
    Mat iM;

    const char* keywords[] = { "M", "iM", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:invertAffineTransform", (char**)keywords, &pyobj_M, &pyobj_iM) &&
        pyopencv_to_safe(pyobj_M, M, ArgInfo("M", 0)) &&
        pyopencv_to_safe(pyobj_iM, iM, ArgInfo("iM", 1)) )
    {
        ERRWRAP2(cv::invertAffineTransform(M, iM));
        return pyopencv_from(iM);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_M = NULL;
    UMat M;
    PyObject* pyobj_iM = NULL;
    UMat iM;

    const char* keywords[] = { "M", "iM", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:invertAffineTransform", (char**)keywords, &pyobj_M, &pyobj_iM) &&
        pyopencv_to_safe(pyobj_M, M, ArgInfo("M", 0)) &&
        pyopencv_to_safe(pyobj_iM, iM, ArgInfo("iM", 1)) )
    {
        ERRWRAP2(cv::invertAffineTransform(M, iM));
        return pyopencv_from(iM);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("invertAffineTransform");

    return NULL;
}

static PyObject* pyopencv_cv_isContourConvex(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_contour = NULL;
    Mat contour;
    bool retval;

    const char* keywords[] = { "contour", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:isContourConvex", (char**)keywords, &pyobj_contour) &&
        pyopencv_to_safe(pyobj_contour, contour, ArgInfo("contour", 0)) )
    {
        ERRWRAP2(retval = cv::isContourConvex(contour));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_contour = NULL;
    UMat contour;
    bool retval;

    const char* keywords[] = { "contour", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:isContourConvex", (char**)keywords, &pyobj_contour) &&
        pyopencv_to_safe(pyobj_contour, contour, ArgInfo("contour", 0)) )
    {
        ERRWRAP2(retval = cv::isContourConvex(contour));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("isContourConvex");

    return NULL;
}

static PyObject* pyopencv_cv_kmeans(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_data = NULL;
    Mat data;
    PyObject* pyobj_K = NULL;
    int K=0;
    PyObject* pyobj_bestLabels = NULL;
    Mat bestLabels;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria;
    PyObject* pyobj_attempts = NULL;
    int attempts=0;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_centers = NULL;
    Mat centers;
    double retval;

    const char* keywords[] = { "data", "K", "bestLabels", "criteria", "attempts", "flags", "centers", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|O:kmeans", (char**)keywords, &pyobj_data, &pyobj_K, &pyobj_bestLabels, &pyobj_criteria, &pyobj_attempts, &pyobj_flags, &pyobj_centers) &&
        pyopencv_to_safe(pyobj_data, data, ArgInfo("data", 0)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_bestLabels, bestLabels, ArgInfo("bestLabels", 1)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) &&
        pyopencv_to_safe(pyobj_attempts, attempts, ArgInfo("attempts", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_centers, centers, ArgInfo("centers", 1)) )
    {
        ERRWRAP2(retval = cv::kmeans(data, K, bestLabels, criteria, attempts, flags, centers));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(bestLabels), pyopencv_from(centers));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_data = NULL;
    UMat data;
    PyObject* pyobj_K = NULL;
    int K=0;
    PyObject* pyobj_bestLabels = NULL;
    UMat bestLabels;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria;
    PyObject* pyobj_attempts = NULL;
    int attempts=0;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_centers = NULL;
    UMat centers;
    double retval;

    const char* keywords[] = { "data", "K", "bestLabels", "criteria", "attempts", "flags", "centers", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|O:kmeans", (char**)keywords, &pyobj_data, &pyobj_K, &pyobj_bestLabels, &pyobj_criteria, &pyobj_attempts, &pyobj_flags, &pyobj_centers) &&
        pyopencv_to_safe(pyobj_data, data, ArgInfo("data", 0)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_bestLabels, bestLabels, ArgInfo("bestLabels", 1)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) &&
        pyopencv_to_safe(pyobj_attempts, attempts, ArgInfo("attempts", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_centers, centers, ArgInfo("centers", 1)) )
    {
        ERRWRAP2(retval = cv::kmeans(data, K, bestLabels, criteria, attempts, flags, centers));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(bestLabels), pyopencv_from(centers));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("kmeans");

    return NULL;
}

static PyObject* pyopencv_cv_line(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_pt1 = NULL;
    Point pt1;
    PyObject* pyobj_pt2 = NULL;
    Point pt2;
    PyObject* pyobj_color = NULL;
    Scalar color;
    PyObject* pyobj_thickness = NULL;
    int thickness=1;
    PyObject* pyobj_lineType = NULL;
    int lineType=LINE_8;
    PyObject* pyobj_shift = NULL;
    int shift=0;

    const char* keywords[] = { "img", "pt1", "pt2", "color", "thickness", "lineType", "shift", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:line", (char**)keywords, &pyobj_img, &pyobj_pt1, &pyobj_pt2, &pyobj_color, &pyobj_thickness, &pyobj_lineType, &pyobj_shift) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_pt1, pt1, ArgInfo("pt1", 0)) &&
        pyopencv_to_safe(pyobj_pt2, pt2, ArgInfo("pt2", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_thickness, thickness, ArgInfo("thickness", 0)) &&
        pyopencv_to_safe(pyobj_lineType, lineType, ArgInfo("lineType", 0)) &&
        pyopencv_to_safe(pyobj_shift, shift, ArgInfo("shift", 0)) )
    {
        ERRWRAP2(cv::line(img, pt1, pt2, color, thickness, lineType, shift));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_pt1 = NULL;
    Point pt1;
    PyObject* pyobj_pt2 = NULL;
    Point pt2;
    PyObject* pyobj_color = NULL;
    Scalar color;
    PyObject* pyobj_thickness = NULL;
    int thickness=1;
    PyObject* pyobj_lineType = NULL;
    int lineType=LINE_8;
    PyObject* pyobj_shift = NULL;
    int shift=0;

    const char* keywords[] = { "img", "pt1", "pt2", "color", "thickness", "lineType", "shift", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:line", (char**)keywords, &pyobj_img, &pyobj_pt1, &pyobj_pt2, &pyobj_color, &pyobj_thickness, &pyobj_lineType, &pyobj_shift) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_pt1, pt1, ArgInfo("pt1", 0)) &&
        pyopencv_to_safe(pyobj_pt2, pt2, ArgInfo("pt2", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_thickness, thickness, ArgInfo("thickness", 0)) &&
        pyopencv_to_safe(pyobj_lineType, lineType, ArgInfo("lineType", 0)) &&
        pyopencv_to_safe(pyobj_shift, shift, ArgInfo("shift", 0)) )
    {
        ERRWRAP2(cv::line(img, pt1, pt2, color, thickness, lineType, shift));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("line");

    return NULL;
}

static PyObject* pyopencv_cv_linearPolar(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_center = NULL;
    Point2f center;
    PyObject* pyobj_maxRadius = NULL;
    double maxRadius=0;
    PyObject* pyobj_flags = NULL;
    int flags=0;

    const char* keywords[] = { "src", "center", "maxRadius", "flags", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:linearPolar", (char**)keywords, &pyobj_src, &pyobj_center, &pyobj_maxRadius, &pyobj_flags, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_center, center, ArgInfo("center", 0)) &&
        pyopencv_to_safe(pyobj_maxRadius, maxRadius, ArgInfo("maxRadius", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::linearPolar(src, dst, center, maxRadius, flags));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_center = NULL;
    Point2f center;
    PyObject* pyobj_maxRadius = NULL;
    double maxRadius=0;
    PyObject* pyobj_flags = NULL;
    int flags=0;

    const char* keywords[] = { "src", "center", "maxRadius", "flags", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:linearPolar", (char**)keywords, &pyobj_src, &pyobj_center, &pyobj_maxRadius, &pyobj_flags, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_center, center, ArgInfo("center", 0)) &&
        pyopencv_to_safe(pyobj_maxRadius, maxRadius, ArgInfo("maxRadius", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::linearPolar(src, dst, center, maxRadius, flags));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("linearPolar");

    return NULL;
}

static PyObject* pyopencv_cv_log(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:log", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::log(src, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:log", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::log(src, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("log");

    return NULL;
}

static PyObject* pyopencv_cv_logPolar(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_center = NULL;
    Point2f center;
    PyObject* pyobj_M = NULL;
    double M=0;
    PyObject* pyobj_flags = NULL;
    int flags=0;

    const char* keywords[] = { "src", "center", "M", "flags", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:logPolar", (char**)keywords, &pyobj_src, &pyobj_center, &pyobj_M, &pyobj_flags, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_center, center, ArgInfo("center", 0)) &&
        pyopencv_to_safe(pyobj_M, M, ArgInfo("M", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::logPolar(src, dst, center, M, flags));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_center = NULL;
    Point2f center;
    PyObject* pyobj_M = NULL;
    double M=0;
    PyObject* pyobj_flags = NULL;
    int flags=0;

    const char* keywords[] = { "src", "center", "M", "flags", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:logPolar", (char**)keywords, &pyobj_src, &pyobj_center, &pyobj_M, &pyobj_flags, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_center, center, ArgInfo("center", 0)) &&
        pyopencv_to_safe(pyobj_M, M, ArgInfo("M", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::logPolar(src, dst, center, M, flags));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("logPolar");

    return NULL;
}

static PyObject* pyopencv_cv_magnitude(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_x = NULL;
    Mat x;
    PyObject* pyobj_y = NULL;
    Mat y;
    PyObject* pyobj_magnitude = NULL;
    Mat magnitude;

    const char* keywords[] = { "x", "y", "magnitude", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:magnitude", (char**)keywords, &pyobj_x, &pyobj_y, &pyobj_magnitude) &&
        pyopencv_to_safe(pyobj_x, x, ArgInfo("x", 0)) &&
        pyopencv_to_safe(pyobj_y, y, ArgInfo("y", 0)) &&
        pyopencv_to_safe(pyobj_magnitude, magnitude, ArgInfo("magnitude", 1)) )
    {
        ERRWRAP2(cv::magnitude(x, y, magnitude));
        return pyopencv_from(magnitude);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_x = NULL;
    UMat x;
    PyObject* pyobj_y = NULL;
    UMat y;
    PyObject* pyobj_magnitude = NULL;
    UMat magnitude;

    const char* keywords[] = { "x", "y", "magnitude", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:magnitude", (char**)keywords, &pyobj_x, &pyobj_y, &pyobj_magnitude) &&
        pyopencv_to_safe(pyobj_x, x, ArgInfo("x", 0)) &&
        pyopencv_to_safe(pyobj_y, y, ArgInfo("y", 0)) &&
        pyopencv_to_safe(pyobj_magnitude, magnitude, ArgInfo("magnitude", 1)) )
    {
        ERRWRAP2(cv::magnitude(x, y, magnitude));
        return pyopencv_from(magnitude);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("magnitude");

    return NULL;
}

static PyObject* pyopencv_cv_matMulDeriv(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_A = NULL;
    Mat A;
    PyObject* pyobj_B = NULL;
    Mat B;
    PyObject* pyobj_dABdA = NULL;
    Mat dABdA;
    PyObject* pyobj_dABdB = NULL;
    Mat dABdB;

    const char* keywords[] = { "A", "B", "dABdA", "dABdB", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:matMulDeriv", (char**)keywords, &pyobj_A, &pyobj_B, &pyobj_dABdA, &pyobj_dABdB) &&
        pyopencv_to_safe(pyobj_A, A, ArgInfo("A", 0)) &&
        pyopencv_to_safe(pyobj_B, B, ArgInfo("B", 0)) &&
        pyopencv_to_safe(pyobj_dABdA, dABdA, ArgInfo("dABdA", 1)) &&
        pyopencv_to_safe(pyobj_dABdB, dABdB, ArgInfo("dABdB", 1)) )
    {
        ERRWRAP2(cv::matMulDeriv(A, B, dABdA, dABdB));
        return Py_BuildValue("(NN)", pyopencv_from(dABdA), pyopencv_from(dABdB));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_A = NULL;
    UMat A;
    PyObject* pyobj_B = NULL;
    UMat B;
    PyObject* pyobj_dABdA = NULL;
    UMat dABdA;
    PyObject* pyobj_dABdB = NULL;
    UMat dABdB;

    const char* keywords[] = { "A", "B", "dABdA", "dABdB", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:matMulDeriv", (char**)keywords, &pyobj_A, &pyobj_B, &pyobj_dABdA, &pyobj_dABdB) &&
        pyopencv_to_safe(pyobj_A, A, ArgInfo("A", 0)) &&
        pyopencv_to_safe(pyobj_B, B, ArgInfo("B", 0)) &&
        pyopencv_to_safe(pyobj_dABdA, dABdA, ArgInfo("dABdA", 1)) &&
        pyopencv_to_safe(pyobj_dABdB, dABdB, ArgInfo("dABdB", 1)) )
    {
        ERRWRAP2(cv::matMulDeriv(A, B, dABdA, dABdB));
        return Py_BuildValue("(NN)", pyopencv_from(dABdA), pyopencv_from(dABdB));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("matMulDeriv");

    return NULL;
}

static PyObject* pyopencv_cv_matchShapes(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_contour1 = NULL;
    Mat contour1;
    PyObject* pyobj_contour2 = NULL;
    Mat contour2;
    PyObject* pyobj_method = NULL;
    int method=0;
    PyObject* pyobj_parameter = NULL;
    double parameter=0;
    double retval;

    const char* keywords[] = { "contour1", "contour2", "method", "parameter", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO:matchShapes", (char**)keywords, &pyobj_contour1, &pyobj_contour2, &pyobj_method, &pyobj_parameter) &&
        pyopencv_to_safe(pyobj_contour1, contour1, ArgInfo("contour1", 0)) &&
        pyopencv_to_safe(pyobj_contour2, contour2, ArgInfo("contour2", 0)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) &&
        pyopencv_to_safe(pyobj_parameter, parameter, ArgInfo("parameter", 0)) )
    {
        ERRWRAP2(retval = cv::matchShapes(contour1, contour2, method, parameter));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_contour1 = NULL;
    UMat contour1;
    PyObject* pyobj_contour2 = NULL;
    UMat contour2;
    PyObject* pyobj_method = NULL;
    int method=0;
    PyObject* pyobj_parameter = NULL;
    double parameter=0;
    double retval;

    const char* keywords[] = { "contour1", "contour2", "method", "parameter", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO:matchShapes", (char**)keywords, &pyobj_contour1, &pyobj_contour2, &pyobj_method, &pyobj_parameter) &&
        pyopencv_to_safe(pyobj_contour1, contour1, ArgInfo("contour1", 0)) &&
        pyopencv_to_safe(pyobj_contour2, contour2, ArgInfo("contour2", 0)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) &&
        pyopencv_to_safe(pyobj_parameter, parameter, ArgInfo("parameter", 0)) )
    {
        ERRWRAP2(retval = cv::matchShapes(contour1, contour2, method, parameter));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("matchShapes");

    return NULL;
}

static PyObject* pyopencv_cv_matchTemplate(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_templ = NULL;
    Mat templ;
    PyObject* pyobj_result = NULL;
    Mat result;
    PyObject* pyobj_method = NULL;
    int method=0;
    PyObject* pyobj_mask = NULL;
    Mat mask;

    const char* keywords[] = { "image", "templ", "method", "result", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:matchTemplate", (char**)keywords, &pyobj_image, &pyobj_templ, &pyobj_method, &pyobj_result, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_templ, templ, ArgInfo("templ", 0)) &&
        pyopencv_to_safe(pyobj_result, result, ArgInfo("result", 1)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::matchTemplate(image, templ, result, method, mask));
        return pyopencv_from(result);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_templ = NULL;
    UMat templ;
    PyObject* pyobj_result = NULL;
    UMat result;
    PyObject* pyobj_method = NULL;
    int method=0;
    PyObject* pyobj_mask = NULL;
    UMat mask;

    const char* keywords[] = { "image", "templ", "method", "result", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:matchTemplate", (char**)keywords, &pyobj_image, &pyobj_templ, &pyobj_method, &pyobj_result, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_templ, templ, ArgInfo("templ", 0)) &&
        pyopencv_to_safe(pyobj_result, result, ArgInfo("result", 1)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::matchTemplate(image, templ, result, method, mask));
        return pyopencv_from(result);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("matchTemplate");

    return NULL;
}

static PyObject* pyopencv_cv_max(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src1 = NULL;
    Mat src1;
    PyObject* pyobj_src2 = NULL;
    Mat src2;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src1", "src2", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:max", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::max(src1, src2, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src1 = NULL;
    UMat src1;
    PyObject* pyobj_src2 = NULL;
    UMat src2;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "src1", "src2", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:max", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::max(src1, src2, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("max");

    return NULL;
}

static PyObject* pyopencv_cv_mean(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    Scalar retval;

    const char* keywords[] = { "src", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:mean", (char**)keywords, &pyobj_src, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(retval = cv::mean(src, mask));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    Scalar retval;

    const char* keywords[] = { "src", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:mean", (char**)keywords, &pyobj_src, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(retval = cv::mean(src, mask));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("mean");

    return NULL;
}

static PyObject* pyopencv_cv_meanShift(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_probImage = NULL;
    Mat probImage;
    PyObject* pyobj_window = NULL;
    Rect window;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria;
    int retval;

    const char* keywords[] = { "probImage", "window", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:meanShift", (char**)keywords, &pyobj_probImage, &pyobj_window, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_probImage, probImage, ArgInfo("probImage", 0)) &&
        pyopencv_to_safe(pyobj_window, window, ArgInfo("window", 1)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(retval = cv::meanShift(probImage, window, criteria));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(window));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_probImage = NULL;
    UMat probImage;
    PyObject* pyobj_window = NULL;
    Rect window;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria;
    int retval;

    const char* keywords[] = { "probImage", "window", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:meanShift", (char**)keywords, &pyobj_probImage, &pyobj_window, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_probImage, probImage, ArgInfo("probImage", 0)) &&
        pyopencv_to_safe(pyobj_window, window, ArgInfo("window", 1)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(retval = cv::meanShift(probImage, window, criteria));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(window));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("meanShift");

    return NULL;
}

static PyObject* pyopencv_cv_meanStdDev(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_mean = NULL;
    Mat mean;
    PyObject* pyobj_stddev = NULL;
    Mat stddev;
    PyObject* pyobj_mask = NULL;
    Mat mask;

    const char* keywords[] = { "src", "mean", "stddev", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:meanStdDev", (char**)keywords, &pyobj_src, &pyobj_mean, &pyobj_stddev, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_mean, mean, ArgInfo("mean", 1)) &&
        pyopencv_to_safe(pyobj_stddev, stddev, ArgInfo("stddev", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::meanStdDev(src, mean, stddev, mask));
        return Py_BuildValue("(NN)", pyopencv_from(mean), pyopencv_from(stddev));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_mean = NULL;
    UMat mean;
    PyObject* pyobj_stddev = NULL;
    UMat stddev;
    PyObject* pyobj_mask = NULL;
    UMat mask;

    const char* keywords[] = { "src", "mean", "stddev", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:meanStdDev", (char**)keywords, &pyobj_src, &pyobj_mean, &pyobj_stddev, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_mean, mean, ArgInfo("mean", 1)) &&
        pyopencv_to_safe(pyobj_stddev, stddev, ArgInfo("stddev", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::meanStdDev(src, mean, stddev, mask));
        return Py_BuildValue("(NN)", pyopencv_from(mean), pyopencv_from(stddev));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("meanStdDev");

    return NULL;
}

static PyObject* pyopencv_cv_medianBlur(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_ksize = NULL;
    int ksize=0;

    const char* keywords[] = { "src", "ksize", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:medianBlur", (char**)keywords, &pyobj_src, &pyobj_ksize, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) )
    {
        ERRWRAP2(cv::medianBlur(src, dst, ksize));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_ksize = NULL;
    int ksize=0;

    const char* keywords[] = { "src", "ksize", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:medianBlur", (char**)keywords, &pyobj_src, &pyobj_ksize, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) )
    {
        ERRWRAP2(cv::medianBlur(src, dst, ksize));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("medianBlur");

    return NULL;
}

static PyObject* pyopencv_cv_merge(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_mv = NULL;
    vector_Mat mv;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "mv", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:merge", (char**)keywords, &pyobj_mv, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_mv, mv, ArgInfo("mv", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::merge(mv, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_mv = NULL;
    vector_UMat mv;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "mv", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:merge", (char**)keywords, &pyobj_mv, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_mv, mv, ArgInfo("mv", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::merge(mv, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("merge");

    return NULL;
}

static PyObject* pyopencv_cv_min(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src1 = NULL;
    Mat src1;
    PyObject* pyobj_src2 = NULL;
    Mat src2;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src1", "src2", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:min", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::min(src1, src2, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src1 = NULL;
    UMat src1;
    PyObject* pyobj_src2 = NULL;
    UMat src2;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "src1", "src2", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:min", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::min(src1, src2, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("min");

    return NULL;
}

static PyObject* pyopencv_cv_minAreaRect(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_points = NULL;
    Mat points;
    RotatedRect retval;

    const char* keywords[] = { "points", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:minAreaRect", (char**)keywords, &pyobj_points) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) )
    {
        ERRWRAP2(retval = cv::minAreaRect(points));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_points = NULL;
    UMat points;
    RotatedRect retval;

    const char* keywords[] = { "points", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:minAreaRect", (char**)keywords, &pyobj_points) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) )
    {
        ERRWRAP2(retval = cv::minAreaRect(points));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("minAreaRect");

    return NULL;
}

static PyObject* pyopencv_cv_minEnclosingCircle(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_points = NULL;
    Mat points;
    Point2f center;
    float radius;

    const char* keywords[] = { "points", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:minEnclosingCircle", (char**)keywords, &pyobj_points) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) )
    {
        ERRWRAP2(cv::minEnclosingCircle(points, center, radius));
        return Py_BuildValue("(NN)", pyopencv_from(center), pyopencv_from(radius));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_points = NULL;
    UMat points;
    Point2f center;
    float radius;

    const char* keywords[] = { "points", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:minEnclosingCircle", (char**)keywords, &pyobj_points) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) )
    {
        ERRWRAP2(cv::minEnclosingCircle(points, center, radius));
        return Py_BuildValue("(NN)", pyopencv_from(center), pyopencv_from(radius));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("minEnclosingCircle");

    return NULL;
}

static PyObject* pyopencv_cv_minEnclosingTriangle(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_points = NULL;
    Mat points;
    PyObject* pyobj_triangle = NULL;
    Mat triangle;
    double retval;

    const char* keywords[] = { "points", "triangle", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:minEnclosingTriangle", (char**)keywords, &pyobj_points, &pyobj_triangle) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) &&
        pyopencv_to_safe(pyobj_triangle, triangle, ArgInfo("triangle", 1)) )
    {
        ERRWRAP2(retval = cv::minEnclosingTriangle(points, triangle));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(triangle));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_points = NULL;
    UMat points;
    PyObject* pyobj_triangle = NULL;
    UMat triangle;
    double retval;

    const char* keywords[] = { "points", "triangle", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:minEnclosingTriangle", (char**)keywords, &pyobj_points, &pyobj_triangle) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) &&
        pyopencv_to_safe(pyobj_triangle, triangle, ArgInfo("triangle", 1)) )
    {
        ERRWRAP2(retval = cv::minEnclosingTriangle(points, triangle));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(triangle));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("minEnclosingTriangle");

    return NULL;
}

static PyObject* pyopencv_cv_minMaxLoc(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    double minVal;
    double maxVal;
    Point minLoc;
    Point maxLoc;
    PyObject* pyobj_mask = NULL;
    Mat mask;

    const char* keywords[] = { "src", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:minMaxLoc", (char**)keywords, &pyobj_src, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::minMaxLoc(src, &minVal, &maxVal, &minLoc, &maxLoc, mask));
        return Py_BuildValue("(NNNN)", pyopencv_from(minVal), pyopencv_from(maxVal), pyopencv_from(minLoc), pyopencv_from(maxLoc));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    double minVal;
    double maxVal;
    Point minLoc;
    Point maxLoc;
    PyObject* pyobj_mask = NULL;
    UMat mask;

    const char* keywords[] = { "src", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:minMaxLoc", (char**)keywords, &pyobj_src, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::minMaxLoc(src, &minVal, &maxVal, &minLoc, &maxLoc, mask));
        return Py_BuildValue("(NNNN)", pyopencv_from(minVal), pyopencv_from(maxVal), pyopencv_from(minLoc), pyopencv_from(maxLoc));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("minMaxLoc");

    return NULL;
}

static PyObject* pyopencv_cv_mixChannels(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    vector_Mat src;
    PyObject* pyobj_dst = NULL;
    vector_Mat dst;
    PyObject* pyobj_fromTo = NULL;
    vector_int fromTo;

    const char* keywords[] = { "src", "dst", "fromTo", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:mixChannels", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_fromTo) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_fromTo, fromTo, ArgInfo("fromTo", 0)) )
    {
        ERRWRAP2(cv::mixChannels(src, dst, fromTo));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    vector_UMat src;
    PyObject* pyobj_dst = NULL;
    vector_UMat dst;
    PyObject* pyobj_fromTo = NULL;
    vector_int fromTo;

    const char* keywords[] = { "src", "dst", "fromTo", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:mixChannels", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_fromTo) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_fromTo, fromTo, ArgInfo("fromTo", 0)) )
    {
        ERRWRAP2(cv::mixChannels(src, dst, fromTo));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("mixChannels");

    return NULL;
}

static PyObject* pyopencv_cv_moments(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_array = NULL;
    Mat array;
    PyObject* pyobj_binaryImage = NULL;
    bool binaryImage=false;
    Moments retval;

    const char* keywords[] = { "array", "binaryImage", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:moments", (char**)keywords, &pyobj_array, &pyobj_binaryImage) &&
        pyopencv_to_safe(pyobj_array, array, ArgInfo("array", 0)) &&
        pyopencv_to_safe(pyobj_binaryImage, binaryImage, ArgInfo("binaryImage", 0)) )
    {
        ERRWRAP2(retval = cv::moments(array, binaryImage));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_array = NULL;
    UMat array;
    PyObject* pyobj_binaryImage = NULL;
    bool binaryImage=false;
    Moments retval;

    const char* keywords[] = { "array", "binaryImage", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:moments", (char**)keywords, &pyobj_array, &pyobj_binaryImage) &&
        pyopencv_to_safe(pyobj_array, array, ArgInfo("array", 0)) &&
        pyopencv_to_safe(pyobj_binaryImage, binaryImage, ArgInfo("binaryImage", 0)) )
    {
        ERRWRAP2(retval = cv::moments(array, binaryImage));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("moments");

    return NULL;
}

static PyObject* pyopencv_cv_morphologyEx(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_op = NULL;
    int op=0;
    PyObject* pyobj_kernel = NULL;
    Mat kernel;
    PyObject* pyobj_anchor = NULL;
    Point anchor=Point(-1,-1);
    PyObject* pyobj_iterations = NULL;
    int iterations=1;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_CONSTANT;
    PyObject* pyobj_borderValue = NULL;
    Scalar borderValue=morphologyDefaultBorderValue();

    const char* keywords[] = { "src", "op", "kernel", "dst", "anchor", "iterations", "borderType", "borderValue", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOOO:morphologyEx", (char**)keywords, &pyobj_src, &pyobj_op, &pyobj_kernel, &pyobj_dst, &pyobj_anchor, &pyobj_iterations, &pyobj_borderType, &pyobj_borderValue) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_op, op, ArgInfo("op", 0)) &&
        pyopencv_to_safe(pyobj_kernel, kernel, ArgInfo("kernel", 0)) &&
        pyopencv_to_safe(pyobj_anchor, anchor, ArgInfo("anchor", 0)) &&
        pyopencv_to_safe(pyobj_iterations, iterations, ArgInfo("iterations", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) &&
        pyopencv_to_safe(pyobj_borderValue, borderValue, ArgInfo("borderValue", 0)) )
    {
        ERRWRAP2(cv::morphologyEx(src, dst, op, kernel, anchor, iterations, borderType, borderValue));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_op = NULL;
    int op=0;
    PyObject* pyobj_kernel = NULL;
    UMat kernel;
    PyObject* pyobj_anchor = NULL;
    Point anchor=Point(-1,-1);
    PyObject* pyobj_iterations = NULL;
    int iterations=1;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_CONSTANT;
    PyObject* pyobj_borderValue = NULL;
    Scalar borderValue=morphologyDefaultBorderValue();

    const char* keywords[] = { "src", "op", "kernel", "dst", "anchor", "iterations", "borderType", "borderValue", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOOO:morphologyEx", (char**)keywords, &pyobj_src, &pyobj_op, &pyobj_kernel, &pyobj_dst, &pyobj_anchor, &pyobj_iterations, &pyobj_borderType, &pyobj_borderValue) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_op, op, ArgInfo("op", 0)) &&
        pyopencv_to_safe(pyobj_kernel, kernel, ArgInfo("kernel", 0)) &&
        pyopencv_to_safe(pyobj_anchor, anchor, ArgInfo("anchor", 0)) &&
        pyopencv_to_safe(pyobj_iterations, iterations, ArgInfo("iterations", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) &&
        pyopencv_to_safe(pyobj_borderValue, borderValue, ArgInfo("borderValue", 0)) )
    {
        ERRWRAP2(cv::morphologyEx(src, dst, op, kernel, anchor, iterations, borderType, borderValue));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("morphologyEx");

    return NULL;
}

static PyObject* pyopencv_cv_moveWindow(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_winname = NULL;
    String winname;
    PyObject* pyobj_x = NULL;
    int x=0;
    PyObject* pyobj_y = NULL;
    int y=0;

    const char* keywords[] = { "winname", "x", "y", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:moveWindow", (char**)keywords, &pyobj_winname, &pyobj_x, &pyobj_y) &&
        pyopencv_to_safe(pyobj_winname, winname, ArgInfo("winname", 0)) &&
        pyopencv_to_safe(pyobj_x, x, ArgInfo("x", 0)) &&
        pyopencv_to_safe(pyobj_y, y, ArgInfo("y", 0)) )
    {
        ERRWRAP2(cv::moveWindow(winname, x, y));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_mulSpectrums(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_a = NULL;
    Mat a;
    PyObject* pyobj_b = NULL;
    Mat b;
    PyObject* pyobj_c = NULL;
    Mat c;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_conjB = NULL;
    bool conjB=false;

    const char* keywords[] = { "a", "b", "flags", "c", "conjB", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:mulSpectrums", (char**)keywords, &pyobj_a, &pyobj_b, &pyobj_flags, &pyobj_c, &pyobj_conjB) &&
        pyopencv_to_safe(pyobj_a, a, ArgInfo("a", 0)) &&
        pyopencv_to_safe(pyobj_b, b, ArgInfo("b", 0)) &&
        pyopencv_to_safe(pyobj_c, c, ArgInfo("c", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_conjB, conjB, ArgInfo("conjB", 0)) )
    {
        ERRWRAP2(cv::mulSpectrums(a, b, c, flags, conjB));
        return pyopencv_from(c);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_a = NULL;
    UMat a;
    PyObject* pyobj_b = NULL;
    UMat b;
    PyObject* pyobj_c = NULL;
    UMat c;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_conjB = NULL;
    bool conjB=false;

    const char* keywords[] = { "a", "b", "flags", "c", "conjB", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:mulSpectrums", (char**)keywords, &pyobj_a, &pyobj_b, &pyobj_flags, &pyobj_c, &pyobj_conjB) &&
        pyopencv_to_safe(pyobj_a, a, ArgInfo("a", 0)) &&
        pyopencv_to_safe(pyobj_b, b, ArgInfo("b", 0)) &&
        pyopencv_to_safe(pyobj_c, c, ArgInfo("c", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_conjB, conjB, ArgInfo("conjB", 0)) )
    {
        ERRWRAP2(cv::mulSpectrums(a, b, c, flags, conjB));
        return pyopencv_from(c);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("mulSpectrums");

    return NULL;
}

static PyObject* pyopencv_cv_mulTransposed(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_aTa = NULL;
    bool aTa=0;
    PyObject* pyobj_delta = NULL;
    Mat delta;
    PyObject* pyobj_scale = NULL;
    double scale=1;
    PyObject* pyobj_dtype = NULL;
    int dtype=-1;

    const char* keywords[] = { "src", "aTa", "dst", "delta", "scale", "dtype", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOO:mulTransposed", (char**)keywords, &pyobj_src, &pyobj_aTa, &pyobj_dst, &pyobj_delta, &pyobj_scale, &pyobj_dtype) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_aTa, aTa, ArgInfo("aTa", 0)) &&
        pyopencv_to_safe(pyobj_delta, delta, ArgInfo("delta", 0)) &&
        pyopencv_to_safe(pyobj_scale, scale, ArgInfo("scale", 0)) &&
        pyopencv_to_safe(pyobj_dtype, dtype, ArgInfo("dtype", 0)) )
    {
        ERRWRAP2(cv::mulTransposed(src, dst, aTa, delta, scale, dtype));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_aTa = NULL;
    bool aTa=0;
    PyObject* pyobj_delta = NULL;
    UMat delta;
    PyObject* pyobj_scale = NULL;
    double scale=1;
    PyObject* pyobj_dtype = NULL;
    int dtype=-1;

    const char* keywords[] = { "src", "aTa", "dst", "delta", "scale", "dtype", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOO:mulTransposed", (char**)keywords, &pyobj_src, &pyobj_aTa, &pyobj_dst, &pyobj_delta, &pyobj_scale, &pyobj_dtype) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_aTa, aTa, ArgInfo("aTa", 0)) &&
        pyopencv_to_safe(pyobj_delta, delta, ArgInfo("delta", 0)) &&
        pyopencv_to_safe(pyobj_scale, scale, ArgInfo("scale", 0)) &&
        pyopencv_to_safe(pyobj_dtype, dtype, ArgInfo("dtype", 0)) )
    {
        ERRWRAP2(cv::mulTransposed(src, dst, aTa, delta, scale, dtype));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("mulTransposed");

    return NULL;
}

static PyObject* pyopencv_cv_multiply(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src1 = NULL;
    Mat src1;
    PyObject* pyobj_src2 = NULL;
    Mat src2;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_scale = NULL;
    double scale=1;
    PyObject* pyobj_dtype = NULL;
    int dtype=-1;

    const char* keywords[] = { "src1", "src2", "dst", "scale", "dtype", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:multiply", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_dst, &pyobj_scale, &pyobj_dtype) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_scale, scale, ArgInfo("scale", 0)) &&
        pyopencv_to_safe(pyobj_dtype, dtype, ArgInfo("dtype", 0)) )
    {
        ERRWRAP2(cv::multiply(src1, src2, dst, scale, dtype));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src1 = NULL;
    UMat src1;
    PyObject* pyobj_src2 = NULL;
    UMat src2;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_scale = NULL;
    double scale=1;
    PyObject* pyobj_dtype = NULL;
    int dtype=-1;

    const char* keywords[] = { "src1", "src2", "dst", "scale", "dtype", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:multiply", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_dst, &pyobj_scale, &pyobj_dtype) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_scale, scale, ArgInfo("scale", 0)) &&
        pyopencv_to_safe(pyobj_dtype, dtype, ArgInfo("dtype", 0)) )
    {
        ERRWRAP2(cv::multiply(src1, src2, dst, scale, dtype));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("multiply");

    return NULL;
}

static PyObject* pyopencv_cv_namedWindow(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_winname = NULL;
    String winname;
    PyObject* pyobj_flags = NULL;
    int flags=WINDOW_AUTOSIZE;

    const char* keywords[] = { "winname", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:namedWindow", (char**)keywords, &pyobj_winname, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_winname, winname, ArgInfo("winname", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::namedWindow(winname, flags));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_norm(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(4);

    {
    PyObject* pyobj_src1 = NULL;
    Mat src1;
    PyObject* pyobj_normType = NULL;
    int normType=NORM_L2;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    double retval;

    const char* keywords[] = { "src1", "normType", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:norm", (char**)keywords, &pyobj_src1, &pyobj_normType, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_normType, normType, ArgInfo("normType", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(retval = cv::norm(src1, normType, mask));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src1 = NULL;
    UMat src1;
    PyObject* pyobj_normType = NULL;
    int normType=NORM_L2;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    double retval;

    const char* keywords[] = { "src1", "normType", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:norm", (char**)keywords, &pyobj_src1, &pyobj_normType, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_normType, normType, ArgInfo("normType", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(retval = cv::norm(src1, normType, mask));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src1 = NULL;
    Mat src1;
    PyObject* pyobj_src2 = NULL;
    Mat src2;
    PyObject* pyobj_normType = NULL;
    int normType=NORM_L2;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    double retval;

    const char* keywords[] = { "src1", "src2", "normType", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:norm", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_normType, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_normType, normType, ArgInfo("normType", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(retval = cv::norm(src1, src2, normType, mask));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src1 = NULL;
    UMat src1;
    PyObject* pyobj_src2 = NULL;
    UMat src2;
    PyObject* pyobj_normType = NULL;
    int normType=NORM_L2;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    double retval;

    const char* keywords[] = { "src1", "src2", "normType", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:norm", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_normType, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_normType, normType, ArgInfo("normType", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(retval = cv::norm(src1, src2, normType, mask));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("norm");

    return NULL;
}

static PyObject* pyopencv_cv_normalize(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_alpha = NULL;
    double alpha=1;
    PyObject* pyobj_beta = NULL;
    double beta=0;
    PyObject* pyobj_norm_type = NULL;
    int norm_type=NORM_L2;
    PyObject* pyobj_dtype = NULL;
    int dtype=-1;
    PyObject* pyobj_mask = NULL;
    Mat mask;

    const char* keywords[] = { "src", "dst", "alpha", "beta", "norm_type", "dtype", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOOO:normalize", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_alpha, &pyobj_beta, &pyobj_norm_type, &pyobj_dtype, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_beta, beta, ArgInfo("beta", 0)) &&
        pyopencv_to_safe(pyobj_norm_type, norm_type, ArgInfo("norm_type", 0)) &&
        pyopencv_to_safe(pyobj_dtype, dtype, ArgInfo("dtype", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::normalize(src, dst, alpha, beta, norm_type, dtype, mask));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_alpha = NULL;
    double alpha=1;
    PyObject* pyobj_beta = NULL;
    double beta=0;
    PyObject* pyobj_norm_type = NULL;
    int norm_type=NORM_L2;
    PyObject* pyobj_dtype = NULL;
    int dtype=-1;
    PyObject* pyobj_mask = NULL;
    UMat mask;

    const char* keywords[] = { "src", "dst", "alpha", "beta", "norm_type", "dtype", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOOO:normalize", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_alpha, &pyobj_beta, &pyobj_norm_type, &pyobj_dtype, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_beta, beta, ArgInfo("beta", 0)) &&
        pyopencv_to_safe(pyobj_norm_type, norm_type, ArgInfo("norm_type", 0)) &&
        pyopencv_to_safe(pyobj_dtype, dtype, ArgInfo("dtype", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::normalize(src, dst, alpha, beta, norm_type, dtype, mask));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("normalize");

    return NULL;
}

static PyObject* pyopencv_cv_patchNaNs(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_a = NULL;
    Mat a;
    PyObject* pyobj_val = NULL;
    double val=0;

    const char* keywords[] = { "a", "val", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:patchNaNs", (char**)keywords, &pyobj_a, &pyobj_val) &&
        pyopencv_to_safe(pyobj_a, a, ArgInfo("a", 1)) &&
        pyopencv_to_safe(pyobj_val, val, ArgInfo("val", 0)) )
    {
        ERRWRAP2(cv::patchNaNs(a, val));
        return pyopencv_from(a);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_a = NULL;
    UMat a;
    PyObject* pyobj_val = NULL;
    double val=0;

    const char* keywords[] = { "a", "val", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:patchNaNs", (char**)keywords, &pyobj_a, &pyobj_val) &&
        pyopencv_to_safe(pyobj_a, a, ArgInfo("a", 1)) &&
        pyopencv_to_safe(pyobj_val, val, ArgInfo("val", 0)) )
    {
        ERRWRAP2(cv::patchNaNs(a, val));
        return pyopencv_from(a);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("patchNaNs");

    return NULL;
}

static PyObject* pyopencv_cv_pencilSketch(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst1 = NULL;
    Mat dst1;
    PyObject* pyobj_dst2 = NULL;
    Mat dst2;
    PyObject* pyobj_sigma_s = NULL;
    float sigma_s=60;
    PyObject* pyobj_sigma_r = NULL;
    float sigma_r=0.07f;
    PyObject* pyobj_shade_factor = NULL;
    float shade_factor=0.02f;

    const char* keywords[] = { "src", "dst1", "dst2", "sigma_s", "sigma_r", "shade_factor", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOOO:pencilSketch", (char**)keywords, &pyobj_src, &pyobj_dst1, &pyobj_dst2, &pyobj_sigma_s, &pyobj_sigma_r, &pyobj_shade_factor) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst1, dst1, ArgInfo("dst1", 1)) &&
        pyopencv_to_safe(pyobj_dst2, dst2, ArgInfo("dst2", 1)) &&
        pyopencv_to_safe(pyobj_sigma_s, sigma_s, ArgInfo("sigma_s", 0)) &&
        pyopencv_to_safe(pyobj_sigma_r, sigma_r, ArgInfo("sigma_r", 0)) &&
        pyopencv_to_safe(pyobj_shade_factor, shade_factor, ArgInfo("shade_factor", 0)) )
    {
        ERRWRAP2(cv::pencilSketch(src, dst1, dst2, sigma_s, sigma_r, shade_factor));
        return Py_BuildValue("(NN)", pyopencv_from(dst1), pyopencv_from(dst2));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst1 = NULL;
    UMat dst1;
    PyObject* pyobj_dst2 = NULL;
    UMat dst2;
    PyObject* pyobj_sigma_s = NULL;
    float sigma_s=60;
    PyObject* pyobj_sigma_r = NULL;
    float sigma_r=0.07f;
    PyObject* pyobj_shade_factor = NULL;
    float shade_factor=0.02f;

    const char* keywords[] = { "src", "dst1", "dst2", "sigma_s", "sigma_r", "shade_factor", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOOO:pencilSketch", (char**)keywords, &pyobj_src, &pyobj_dst1, &pyobj_dst2, &pyobj_sigma_s, &pyobj_sigma_r, &pyobj_shade_factor) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst1, dst1, ArgInfo("dst1", 1)) &&
        pyopencv_to_safe(pyobj_dst2, dst2, ArgInfo("dst2", 1)) &&
        pyopencv_to_safe(pyobj_sigma_s, sigma_s, ArgInfo("sigma_s", 0)) &&
        pyopencv_to_safe(pyobj_sigma_r, sigma_r, ArgInfo("sigma_r", 0)) &&
        pyopencv_to_safe(pyobj_shade_factor, shade_factor, ArgInfo("shade_factor", 0)) )
    {
        ERRWRAP2(cv::pencilSketch(src, dst1, dst2, sigma_s, sigma_r, shade_factor));
        return Py_BuildValue("(NN)", pyopencv_from(dst1), pyopencv_from(dst2));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("pencilSketch");

    return NULL;
}

static PyObject* pyopencv_cv_perspectiveTransform(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_m = NULL;
    Mat m;

    const char* keywords[] = { "src", "m", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:perspectiveTransform", (char**)keywords, &pyobj_src, &pyobj_m, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_m, m, ArgInfo("m", 0)) )
    {
        ERRWRAP2(cv::perspectiveTransform(src, dst, m));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_m = NULL;
    UMat m;

    const char* keywords[] = { "src", "m", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:perspectiveTransform", (char**)keywords, &pyobj_src, &pyobj_m, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_m, m, ArgInfo("m", 0)) )
    {
        ERRWRAP2(cv::perspectiveTransform(src, dst, m));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("perspectiveTransform");

    return NULL;
}

static PyObject* pyopencv_cv_phase(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_x = NULL;
    Mat x;
    PyObject* pyobj_y = NULL;
    Mat y;
    PyObject* pyobj_angle = NULL;
    Mat angle;
    PyObject* pyobj_angleInDegrees = NULL;
    bool angleInDegrees=false;

    const char* keywords[] = { "x", "y", "angle", "angleInDegrees", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:phase", (char**)keywords, &pyobj_x, &pyobj_y, &pyobj_angle, &pyobj_angleInDegrees) &&
        pyopencv_to_safe(pyobj_x, x, ArgInfo("x", 0)) &&
        pyopencv_to_safe(pyobj_y, y, ArgInfo("y", 0)) &&
        pyopencv_to_safe(pyobj_angle, angle, ArgInfo("angle", 1)) &&
        pyopencv_to_safe(pyobj_angleInDegrees, angleInDegrees, ArgInfo("angleInDegrees", 0)) )
    {
        ERRWRAP2(cv::phase(x, y, angle, angleInDegrees));
        return pyopencv_from(angle);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_x = NULL;
    UMat x;
    PyObject* pyobj_y = NULL;
    UMat y;
    PyObject* pyobj_angle = NULL;
    UMat angle;
    PyObject* pyobj_angleInDegrees = NULL;
    bool angleInDegrees=false;

    const char* keywords[] = { "x", "y", "angle", "angleInDegrees", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:phase", (char**)keywords, &pyobj_x, &pyobj_y, &pyobj_angle, &pyobj_angleInDegrees) &&
        pyopencv_to_safe(pyobj_x, x, ArgInfo("x", 0)) &&
        pyopencv_to_safe(pyobj_y, y, ArgInfo("y", 0)) &&
        pyopencv_to_safe(pyobj_angle, angle, ArgInfo("angle", 1)) &&
        pyopencv_to_safe(pyobj_angleInDegrees, angleInDegrees, ArgInfo("angleInDegrees", 0)) )
    {
        ERRWRAP2(cv::phase(x, y, angle, angleInDegrees));
        return pyopencv_from(angle);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("phase");

    return NULL;
}

static PyObject* pyopencv_cv_phaseCorrelate(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src1 = NULL;
    Mat src1;
    PyObject* pyobj_src2 = NULL;
    Mat src2;
    PyObject* pyobj_window = NULL;
    Mat window;
    double response;
    Point2d retval;

    const char* keywords[] = { "src1", "src2", "window", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:phaseCorrelate", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_window) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_window, window, ArgInfo("window", 0)) )
    {
        ERRWRAP2(retval = cv::phaseCorrelate(src1, src2, window, &response));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(response));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src1 = NULL;
    UMat src1;
    PyObject* pyobj_src2 = NULL;
    UMat src2;
    PyObject* pyobj_window = NULL;
    UMat window;
    double response;
    Point2d retval;

    const char* keywords[] = { "src1", "src2", "window", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:phaseCorrelate", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_window) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_window, window, ArgInfo("window", 0)) )
    {
        ERRWRAP2(retval = cv::phaseCorrelate(src1, src2, window, &response));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(response));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("phaseCorrelate");

    return NULL;
}

static PyObject* pyopencv_cv_pointPolygonTest(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_contour = NULL;
    Mat contour;
    PyObject* pyobj_pt = NULL;
    Point2f pt;
    PyObject* pyobj_measureDist = NULL;
    bool measureDist=0;
    double retval;

    const char* keywords[] = { "contour", "pt", "measureDist", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:pointPolygonTest", (char**)keywords, &pyobj_contour, &pyobj_pt, &pyobj_measureDist) &&
        pyopencv_to_safe(pyobj_contour, contour, ArgInfo("contour", 0)) &&
        pyopencv_to_safe(pyobj_pt, pt, ArgInfo("pt", 0)) &&
        pyopencv_to_safe(pyobj_measureDist, measureDist, ArgInfo("measureDist", 0)) )
    {
        ERRWRAP2(retval = cv::pointPolygonTest(contour, pt, measureDist));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_contour = NULL;
    UMat contour;
    PyObject* pyobj_pt = NULL;
    Point2f pt;
    PyObject* pyobj_measureDist = NULL;
    bool measureDist=0;
    double retval;

    const char* keywords[] = { "contour", "pt", "measureDist", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:pointPolygonTest", (char**)keywords, &pyobj_contour, &pyobj_pt, &pyobj_measureDist) &&
        pyopencv_to_safe(pyobj_contour, contour, ArgInfo("contour", 0)) &&
        pyopencv_to_safe(pyobj_pt, pt, ArgInfo("pt", 0)) &&
        pyopencv_to_safe(pyobj_measureDist, measureDist, ArgInfo("measureDist", 0)) )
    {
        ERRWRAP2(retval = cv::pointPolygonTest(contour, pt, measureDist));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("pointPolygonTest");

    return NULL;
}

static PyObject* pyopencv_cv_polarToCart(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_magnitude = NULL;
    Mat magnitude;
    PyObject* pyobj_angle = NULL;
    Mat angle;
    PyObject* pyobj_x = NULL;
    Mat x;
    PyObject* pyobj_y = NULL;
    Mat y;
    PyObject* pyobj_angleInDegrees = NULL;
    bool angleInDegrees=false;

    const char* keywords[] = { "magnitude", "angle", "x", "y", "angleInDegrees", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:polarToCart", (char**)keywords, &pyobj_magnitude, &pyobj_angle, &pyobj_x, &pyobj_y, &pyobj_angleInDegrees) &&
        pyopencv_to_safe(pyobj_magnitude, magnitude, ArgInfo("magnitude", 0)) &&
        pyopencv_to_safe(pyobj_angle, angle, ArgInfo("angle", 0)) &&
        pyopencv_to_safe(pyobj_x, x, ArgInfo("x", 1)) &&
        pyopencv_to_safe(pyobj_y, y, ArgInfo("y", 1)) &&
        pyopencv_to_safe(pyobj_angleInDegrees, angleInDegrees, ArgInfo("angleInDegrees", 0)) )
    {
        ERRWRAP2(cv::polarToCart(magnitude, angle, x, y, angleInDegrees));
        return Py_BuildValue("(NN)", pyopencv_from(x), pyopencv_from(y));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_magnitude = NULL;
    UMat magnitude;
    PyObject* pyobj_angle = NULL;
    UMat angle;
    PyObject* pyobj_x = NULL;
    UMat x;
    PyObject* pyobj_y = NULL;
    UMat y;
    PyObject* pyobj_angleInDegrees = NULL;
    bool angleInDegrees=false;

    const char* keywords[] = { "magnitude", "angle", "x", "y", "angleInDegrees", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:polarToCart", (char**)keywords, &pyobj_magnitude, &pyobj_angle, &pyobj_x, &pyobj_y, &pyobj_angleInDegrees) &&
        pyopencv_to_safe(pyobj_magnitude, magnitude, ArgInfo("magnitude", 0)) &&
        pyopencv_to_safe(pyobj_angle, angle, ArgInfo("angle", 0)) &&
        pyopencv_to_safe(pyobj_x, x, ArgInfo("x", 1)) &&
        pyopencv_to_safe(pyobj_y, y, ArgInfo("y", 1)) &&
        pyopencv_to_safe(pyobj_angleInDegrees, angleInDegrees, ArgInfo("angleInDegrees", 0)) )
    {
        ERRWRAP2(cv::polarToCart(magnitude, angle, x, y, angleInDegrees));
        return Py_BuildValue("(NN)", pyopencv_from(x), pyopencv_from(y));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("polarToCart");

    return NULL;
}

static PyObject* pyopencv_cv_pollKey(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    int retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::pollKey());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_polylines(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_pts = NULL;
    vector_Mat pts;
    PyObject* pyobj_isClosed = NULL;
    bool isClosed=0;
    PyObject* pyobj_color = NULL;
    Scalar color;
    PyObject* pyobj_thickness = NULL;
    int thickness=1;
    PyObject* pyobj_lineType = NULL;
    int lineType=LINE_8;
    PyObject* pyobj_shift = NULL;
    int shift=0;

    const char* keywords[] = { "img", "pts", "isClosed", "color", "thickness", "lineType", "shift", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:polylines", (char**)keywords, &pyobj_img, &pyobj_pts, &pyobj_isClosed, &pyobj_color, &pyobj_thickness, &pyobj_lineType, &pyobj_shift) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_pts, pts, ArgInfo("pts", 0)) &&
        pyopencv_to_safe(pyobj_isClosed, isClosed, ArgInfo("isClosed", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_thickness, thickness, ArgInfo("thickness", 0)) &&
        pyopencv_to_safe(pyobj_lineType, lineType, ArgInfo("lineType", 0)) &&
        pyopencv_to_safe(pyobj_shift, shift, ArgInfo("shift", 0)) )
    {
        ERRWRAP2(cv::polylines(img, pts, isClosed, color, thickness, lineType, shift));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_pts = NULL;
    vector_UMat pts;
    PyObject* pyobj_isClosed = NULL;
    bool isClosed=0;
    PyObject* pyobj_color = NULL;
    Scalar color;
    PyObject* pyobj_thickness = NULL;
    int thickness=1;
    PyObject* pyobj_lineType = NULL;
    int lineType=LINE_8;
    PyObject* pyobj_shift = NULL;
    int shift=0;

    const char* keywords[] = { "img", "pts", "isClosed", "color", "thickness", "lineType", "shift", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:polylines", (char**)keywords, &pyobj_img, &pyobj_pts, &pyobj_isClosed, &pyobj_color, &pyobj_thickness, &pyobj_lineType, &pyobj_shift) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_pts, pts, ArgInfo("pts", 0)) &&
        pyopencv_to_safe(pyobj_isClosed, isClosed, ArgInfo("isClosed", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_thickness, thickness, ArgInfo("thickness", 0)) &&
        pyopencv_to_safe(pyobj_lineType, lineType, ArgInfo("lineType", 0)) &&
        pyopencv_to_safe(pyobj_shift, shift, ArgInfo("shift", 0)) )
    {
        ERRWRAP2(cv::polylines(img, pts, isClosed, color, thickness, lineType, shift));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("polylines");

    return NULL;
}

static PyObject* pyopencv_cv_pow(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_power = NULL;
    double power=0;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src", "power", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:pow", (char**)keywords, &pyobj_src, &pyobj_power, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_power, power, ArgInfo("power", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::pow(src, power, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_power = NULL;
    double power=0;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "src", "power", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:pow", (char**)keywords, &pyobj_src, &pyobj_power, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_power, power, ArgInfo("power", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::pow(src, power, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("pow");

    return NULL;
}

static PyObject* pyopencv_cv_preCornerDetect(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_ksize = NULL;
    int ksize=0;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "ksize", "dst", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:preCornerDetect", (char**)keywords, &pyobj_src, &pyobj_ksize, &pyobj_dst, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::preCornerDetect(src, dst, ksize, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_ksize = NULL;
    int ksize=0;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "ksize", "dst", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:preCornerDetect", (char**)keywords, &pyobj_src, &pyobj_ksize, &pyobj_dst, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::preCornerDetect(src, dst, ksize, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("preCornerDetect");

    return NULL;
}

static PyObject* pyopencv_cv_projectPoints(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_objectPoints = NULL;
    Mat objectPoints;
    PyObject* pyobj_rvec = NULL;
    Mat rvec;
    PyObject* pyobj_tvec = NULL;
    Mat tvec;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    Mat distCoeffs;
    PyObject* pyobj_imagePoints = NULL;
    Mat imagePoints;
    PyObject* pyobj_jacobian = NULL;
    Mat jacobian;
    PyObject* pyobj_aspectRatio = NULL;
    double aspectRatio=0;

    const char* keywords[] = { "objectPoints", "rvec", "tvec", "cameraMatrix", "distCoeffs", "imagePoints", "jacobian", "aspectRatio", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OOO:projectPoints", (char**)keywords, &pyobj_objectPoints, &pyobj_rvec, &pyobj_tvec, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_imagePoints, &pyobj_jacobian, &pyobj_aspectRatio) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 0)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 1)) &&
        pyopencv_to_safe(pyobj_jacobian, jacobian, ArgInfo("jacobian", 1)) &&
        pyopencv_to_safe(pyobj_aspectRatio, aspectRatio, ArgInfo("aspectRatio", 0)) )
    {
        ERRWRAP2(cv::projectPoints(objectPoints, rvec, tvec, cameraMatrix, distCoeffs, imagePoints, jacobian, aspectRatio));
        return Py_BuildValue("(NN)", pyopencv_from(imagePoints), pyopencv_from(jacobian));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_objectPoints = NULL;
    UMat objectPoints;
    PyObject* pyobj_rvec = NULL;
    UMat rvec;
    PyObject* pyobj_tvec = NULL;
    UMat tvec;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    UMat distCoeffs;
    PyObject* pyobj_imagePoints = NULL;
    UMat imagePoints;
    PyObject* pyobj_jacobian = NULL;
    UMat jacobian;
    PyObject* pyobj_aspectRatio = NULL;
    double aspectRatio=0;

    const char* keywords[] = { "objectPoints", "rvec", "tvec", "cameraMatrix", "distCoeffs", "imagePoints", "jacobian", "aspectRatio", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OOO:projectPoints", (char**)keywords, &pyobj_objectPoints, &pyobj_rvec, &pyobj_tvec, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_imagePoints, &pyobj_jacobian, &pyobj_aspectRatio) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 0)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 1)) &&
        pyopencv_to_safe(pyobj_jacobian, jacobian, ArgInfo("jacobian", 1)) &&
        pyopencv_to_safe(pyobj_aspectRatio, aspectRatio, ArgInfo("aspectRatio", 0)) )
    {
        ERRWRAP2(cv::projectPoints(objectPoints, rvec, tvec, cameraMatrix, distCoeffs, imagePoints, jacobian, aspectRatio));
        return Py_BuildValue("(NN)", pyopencv_from(imagePoints), pyopencv_from(jacobian));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("projectPoints");

    return NULL;
}

static PyObject* pyopencv_cv_putText(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_text = NULL;
    String text;
    PyObject* pyobj_org = NULL;
    Point org;
    PyObject* pyobj_fontFace = NULL;
    int fontFace=0;
    PyObject* pyobj_fontScale = NULL;
    double fontScale=0;
    PyObject* pyobj_color = NULL;
    Scalar color;
    PyObject* pyobj_thickness = NULL;
    int thickness=1;
    PyObject* pyobj_lineType = NULL;
    int lineType=LINE_8;
    PyObject* pyobj_bottomLeftOrigin = NULL;
    bool bottomLeftOrigin=false;

    const char* keywords[] = { "img", "text", "org", "fontFace", "fontScale", "color", "thickness", "lineType", "bottomLeftOrigin", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|OOO:putText", (char**)keywords, &pyobj_img, &pyobj_text, &pyobj_org, &pyobj_fontFace, &pyobj_fontScale, &pyobj_color, &pyobj_thickness, &pyobj_lineType, &pyobj_bottomLeftOrigin) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_text, text, ArgInfo("text", 0)) &&
        pyopencv_to_safe(pyobj_org, org, ArgInfo("org", 0)) &&
        pyopencv_to_safe(pyobj_fontFace, fontFace, ArgInfo("fontFace", 0)) &&
        pyopencv_to_safe(pyobj_fontScale, fontScale, ArgInfo("fontScale", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_thickness, thickness, ArgInfo("thickness", 0)) &&
        pyopencv_to_safe(pyobj_lineType, lineType, ArgInfo("lineType", 0)) &&
        pyopencv_to_safe(pyobj_bottomLeftOrigin, bottomLeftOrigin, ArgInfo("bottomLeftOrigin", 0)) )
    {
        ERRWRAP2(cv::putText(img, text, org, fontFace, fontScale, color, thickness, lineType, bottomLeftOrigin));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_text = NULL;
    String text;
    PyObject* pyobj_org = NULL;
    Point org;
    PyObject* pyobj_fontFace = NULL;
    int fontFace=0;
    PyObject* pyobj_fontScale = NULL;
    double fontScale=0;
    PyObject* pyobj_color = NULL;
    Scalar color;
    PyObject* pyobj_thickness = NULL;
    int thickness=1;
    PyObject* pyobj_lineType = NULL;
    int lineType=LINE_8;
    PyObject* pyobj_bottomLeftOrigin = NULL;
    bool bottomLeftOrigin=false;

    const char* keywords[] = { "img", "text", "org", "fontFace", "fontScale", "color", "thickness", "lineType", "bottomLeftOrigin", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|OOO:putText", (char**)keywords, &pyobj_img, &pyobj_text, &pyobj_org, &pyobj_fontFace, &pyobj_fontScale, &pyobj_color, &pyobj_thickness, &pyobj_lineType, &pyobj_bottomLeftOrigin) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_text, text, ArgInfo("text", 0)) &&
        pyopencv_to_safe(pyobj_org, org, ArgInfo("org", 0)) &&
        pyopencv_to_safe(pyobj_fontFace, fontFace, ArgInfo("fontFace", 0)) &&
        pyopencv_to_safe(pyobj_fontScale, fontScale, ArgInfo("fontScale", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_thickness, thickness, ArgInfo("thickness", 0)) &&
        pyopencv_to_safe(pyobj_lineType, lineType, ArgInfo("lineType", 0)) &&
        pyopencv_to_safe(pyobj_bottomLeftOrigin, bottomLeftOrigin, ArgInfo("bottomLeftOrigin", 0)) )
    {
        ERRWRAP2(cv::putText(img, text, org, fontFace, fontScale, color, thickness, lineType, bottomLeftOrigin));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("putText");

    return NULL;
}

static PyObject* pyopencv_cv_pyrDown(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_dstsize = NULL;
    Size dstsize;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "dst", "dstsize", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:pyrDown", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_dstsize, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_dstsize, dstsize, ArgInfo("dstsize", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::pyrDown(src, dst, dstsize, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_dstsize = NULL;
    Size dstsize;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "dst", "dstsize", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:pyrDown", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_dstsize, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_dstsize, dstsize, ArgInfo("dstsize", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::pyrDown(src, dst, dstsize, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("pyrDown");

    return NULL;
}

static PyObject* pyopencv_cv_pyrMeanShiftFiltering(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_sp = NULL;
    double sp=0;
    PyObject* pyobj_sr = NULL;
    double sr=0;
    PyObject* pyobj_maxLevel = NULL;
    int maxLevel=1;
    PyObject* pyobj_termcrit = NULL;
    TermCriteria termcrit=TermCriteria(TermCriteria::MAX_ITER+TermCriteria::EPS,5,1);

    const char* keywords[] = { "src", "sp", "sr", "dst", "maxLevel", "termcrit", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:pyrMeanShiftFiltering", (char**)keywords, &pyobj_src, &pyobj_sp, &pyobj_sr, &pyobj_dst, &pyobj_maxLevel, &pyobj_termcrit) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_sp, sp, ArgInfo("sp", 0)) &&
        pyopencv_to_safe(pyobj_sr, sr, ArgInfo("sr", 0)) &&
        pyopencv_to_safe(pyobj_maxLevel, maxLevel, ArgInfo("maxLevel", 0)) &&
        pyopencv_to_safe(pyobj_termcrit, termcrit, ArgInfo("termcrit", 0)) )
    {
        ERRWRAP2(cv::pyrMeanShiftFiltering(src, dst, sp, sr, maxLevel, termcrit));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_sp = NULL;
    double sp=0;
    PyObject* pyobj_sr = NULL;
    double sr=0;
    PyObject* pyobj_maxLevel = NULL;
    int maxLevel=1;
    PyObject* pyobj_termcrit = NULL;
    TermCriteria termcrit=TermCriteria(TermCriteria::MAX_ITER+TermCriteria::EPS,5,1);

    const char* keywords[] = { "src", "sp", "sr", "dst", "maxLevel", "termcrit", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:pyrMeanShiftFiltering", (char**)keywords, &pyobj_src, &pyobj_sp, &pyobj_sr, &pyobj_dst, &pyobj_maxLevel, &pyobj_termcrit) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_sp, sp, ArgInfo("sp", 0)) &&
        pyopencv_to_safe(pyobj_sr, sr, ArgInfo("sr", 0)) &&
        pyopencv_to_safe(pyobj_maxLevel, maxLevel, ArgInfo("maxLevel", 0)) &&
        pyopencv_to_safe(pyobj_termcrit, termcrit, ArgInfo("termcrit", 0)) )
    {
        ERRWRAP2(cv::pyrMeanShiftFiltering(src, dst, sp, sr, maxLevel, termcrit));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("pyrMeanShiftFiltering");

    return NULL;
}

static PyObject* pyopencv_cv_pyrUp(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_dstsize = NULL;
    Size dstsize;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "dst", "dstsize", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:pyrUp", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_dstsize, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_dstsize, dstsize, ArgInfo("dstsize", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::pyrUp(src, dst, dstsize, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_dstsize = NULL;
    Size dstsize;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "dst", "dstsize", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:pyrUp", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_dstsize, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_dstsize, dstsize, ArgInfo("dstsize", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::pyrUp(src, dst, dstsize, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("pyrUp");

    return NULL;
}

static PyObject* pyopencv_cv_randShuffle(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_iterFactor = NULL;
    double iterFactor=1.;

    const char* keywords[] = { "dst", "iterFactor", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:randShuffle", (char**)keywords, &pyobj_dst, &pyobj_iterFactor) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_iterFactor, iterFactor, ArgInfo("iterFactor", 0)) )
    {
        ERRWRAP2(cv::randShuffle(dst, iterFactor, 0));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_iterFactor = NULL;
    double iterFactor=1.;

    const char* keywords[] = { "dst", "iterFactor", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:randShuffle", (char**)keywords, &pyobj_dst, &pyobj_iterFactor) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_iterFactor, iterFactor, ArgInfo("iterFactor", 0)) )
    {
        ERRWRAP2(cv::randShuffle(dst, iterFactor, 0));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("randShuffle");

    return NULL;
}

static PyObject* pyopencv_cv_randn(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_mean = NULL;
    Mat mean;
    PyObject* pyobj_stddev = NULL;
    Mat stddev;

    const char* keywords[] = { "dst", "mean", "stddev", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:randn", (char**)keywords, &pyobj_dst, &pyobj_mean, &pyobj_stddev) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_mean, mean, ArgInfo("mean", 0)) &&
        pyopencv_to_safe(pyobj_stddev, stddev, ArgInfo("stddev", 0)) )
    {
        ERRWRAP2(cv::randn(dst, mean, stddev));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_mean = NULL;
    UMat mean;
    PyObject* pyobj_stddev = NULL;
    UMat stddev;

    const char* keywords[] = { "dst", "mean", "stddev", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:randn", (char**)keywords, &pyobj_dst, &pyobj_mean, &pyobj_stddev) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_mean, mean, ArgInfo("mean", 0)) &&
        pyopencv_to_safe(pyobj_stddev, stddev, ArgInfo("stddev", 0)) )
    {
        ERRWRAP2(cv::randn(dst, mean, stddev));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("randn");

    return NULL;
}

static PyObject* pyopencv_cv_randu(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_low = NULL;
    Mat low;
    PyObject* pyobj_high = NULL;
    Mat high;

    const char* keywords[] = { "dst", "low", "high", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:randu", (char**)keywords, &pyobj_dst, &pyobj_low, &pyobj_high) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_low, low, ArgInfo("low", 0)) &&
        pyopencv_to_safe(pyobj_high, high, ArgInfo("high", 0)) )
    {
        ERRWRAP2(cv::randu(dst, low, high));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_low = NULL;
    UMat low;
    PyObject* pyobj_high = NULL;
    UMat high;

    const char* keywords[] = { "dst", "low", "high", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:randu", (char**)keywords, &pyobj_dst, &pyobj_low, &pyobj_high) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_low, low, ArgInfo("low", 0)) &&
        pyopencv_to_safe(pyobj_high, high, ArgInfo("high", 0)) )
    {
        ERRWRAP2(cv::randu(dst, low, high));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("randu");

    return NULL;
}

static PyObject* pyopencv_cv_readOpticalFlow(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_path = NULL;
    String path;
    Mat retval;

    const char* keywords[] = { "path", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:readOpticalFlow", (char**)keywords, &pyobj_path) &&
        pyopencv_to_safe(pyobj_path, path, ArgInfo("path", 0)) )
    {
        ERRWRAP2(retval = cv::readOpticalFlow(path));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_recoverPose(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(6);

    {
    PyObject* pyobj_E = NULL;
    Mat E;
    PyObject* pyobj_points1 = NULL;
    Mat points1;
    PyObject* pyobj_points2 = NULL;
    Mat points2;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_R = NULL;
    Mat R;
    PyObject* pyobj_t = NULL;
    Mat t;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    int retval;

    const char* keywords[] = { "E", "points1", "points2", "cameraMatrix", "R", "t", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:recoverPose", (char**)keywords, &pyobj_E, &pyobj_points1, &pyobj_points2, &pyobj_cameraMatrix, &pyobj_R, &pyobj_t, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_E, E, ArgInfo("E", 0)) &&
        pyopencv_to_safe(pyobj_points1, points1, ArgInfo("points1", 0)) &&
        pyopencv_to_safe(pyobj_points2, points2, ArgInfo("points2", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 1)) &&
        pyopencv_to_safe(pyobj_t, t, ArgInfo("t", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 1)) )
    {
        ERRWRAP2(retval = cv::recoverPose(E, points1, points2, cameraMatrix, R, t, mask));
        return Py_BuildValue("(NNNN)", pyopencv_from(retval), pyopencv_from(R), pyopencv_from(t), pyopencv_from(mask));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_E = NULL;
    UMat E;
    PyObject* pyobj_points1 = NULL;
    UMat points1;
    PyObject* pyobj_points2 = NULL;
    UMat points2;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_R = NULL;
    UMat R;
    PyObject* pyobj_t = NULL;
    UMat t;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    int retval;

    const char* keywords[] = { "E", "points1", "points2", "cameraMatrix", "R", "t", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:recoverPose", (char**)keywords, &pyobj_E, &pyobj_points1, &pyobj_points2, &pyobj_cameraMatrix, &pyobj_R, &pyobj_t, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_E, E, ArgInfo("E", 0)) &&
        pyopencv_to_safe(pyobj_points1, points1, ArgInfo("points1", 0)) &&
        pyopencv_to_safe(pyobj_points2, points2, ArgInfo("points2", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 1)) &&
        pyopencv_to_safe(pyobj_t, t, ArgInfo("t", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 1)) )
    {
        ERRWRAP2(retval = cv::recoverPose(E, points1, points2, cameraMatrix, R, t, mask));
        return Py_BuildValue("(NNNN)", pyopencv_from(retval), pyopencv_from(R), pyopencv_from(t), pyopencv_from(mask));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_E = NULL;
    Mat E;
    PyObject* pyobj_points1 = NULL;
    Mat points1;
    PyObject* pyobj_points2 = NULL;
    Mat points2;
    PyObject* pyobj_R = NULL;
    Mat R;
    PyObject* pyobj_t = NULL;
    Mat t;
    PyObject* pyobj_focal = NULL;
    double focal=1.0;
    PyObject* pyobj_pp = NULL;
    Point2d pp=Point2d(0, 0);
    PyObject* pyobj_mask = NULL;
    Mat mask;
    int retval;

    const char* keywords[] = { "E", "points1", "points2", "R", "t", "focal", "pp", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOOO:recoverPose", (char**)keywords, &pyobj_E, &pyobj_points1, &pyobj_points2, &pyobj_R, &pyobj_t, &pyobj_focal, &pyobj_pp, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_E, E, ArgInfo("E", 0)) &&
        pyopencv_to_safe(pyobj_points1, points1, ArgInfo("points1", 0)) &&
        pyopencv_to_safe(pyobj_points2, points2, ArgInfo("points2", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 1)) &&
        pyopencv_to_safe(pyobj_t, t, ArgInfo("t", 1)) &&
        pyopencv_to_safe(pyobj_focal, focal, ArgInfo("focal", 0)) &&
        pyopencv_to_safe(pyobj_pp, pp, ArgInfo("pp", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 1)) )
    {
        ERRWRAP2(retval = cv::recoverPose(E, points1, points2, R, t, focal, pp, mask));
        return Py_BuildValue("(NNNN)", pyopencv_from(retval), pyopencv_from(R), pyopencv_from(t), pyopencv_from(mask));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_E = NULL;
    UMat E;
    PyObject* pyobj_points1 = NULL;
    UMat points1;
    PyObject* pyobj_points2 = NULL;
    UMat points2;
    PyObject* pyobj_R = NULL;
    UMat R;
    PyObject* pyobj_t = NULL;
    UMat t;
    PyObject* pyobj_focal = NULL;
    double focal=1.0;
    PyObject* pyobj_pp = NULL;
    Point2d pp=Point2d(0, 0);
    PyObject* pyobj_mask = NULL;
    UMat mask;
    int retval;

    const char* keywords[] = { "E", "points1", "points2", "R", "t", "focal", "pp", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOOO:recoverPose", (char**)keywords, &pyobj_E, &pyobj_points1, &pyobj_points2, &pyobj_R, &pyobj_t, &pyobj_focal, &pyobj_pp, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_E, E, ArgInfo("E", 0)) &&
        pyopencv_to_safe(pyobj_points1, points1, ArgInfo("points1", 0)) &&
        pyopencv_to_safe(pyobj_points2, points2, ArgInfo("points2", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 1)) &&
        pyopencv_to_safe(pyobj_t, t, ArgInfo("t", 1)) &&
        pyopencv_to_safe(pyobj_focal, focal, ArgInfo("focal", 0)) &&
        pyopencv_to_safe(pyobj_pp, pp, ArgInfo("pp", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 1)) )
    {
        ERRWRAP2(retval = cv::recoverPose(E, points1, points2, R, t, focal, pp, mask));
        return Py_BuildValue("(NNNN)", pyopencv_from(retval), pyopencv_from(R), pyopencv_from(t), pyopencv_from(mask));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_E = NULL;
    Mat E;
    PyObject* pyobj_points1 = NULL;
    Mat points1;
    PyObject* pyobj_points2 = NULL;
    Mat points2;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_R = NULL;
    Mat R;
    PyObject* pyobj_t = NULL;
    Mat t;
    PyObject* pyobj_distanceThresh = NULL;
    double distanceThresh=0;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_triangulatedPoints = NULL;
    Mat triangulatedPoints;
    int retval;

    const char* keywords[] = { "E", "points1", "points2", "cameraMatrix", "distanceThresh", "R", "t", "mask", "triangulatedPoints", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OOOO:recoverPose", (char**)keywords, &pyobj_E, &pyobj_points1, &pyobj_points2, &pyobj_cameraMatrix, &pyobj_distanceThresh, &pyobj_R, &pyobj_t, &pyobj_mask, &pyobj_triangulatedPoints) &&
        pyopencv_to_safe(pyobj_E, E, ArgInfo("E", 0)) &&
        pyopencv_to_safe(pyobj_points1, points1, ArgInfo("points1", 0)) &&
        pyopencv_to_safe(pyobj_points2, points2, ArgInfo("points2", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 1)) &&
        pyopencv_to_safe(pyobj_t, t, ArgInfo("t", 1)) &&
        pyopencv_to_safe(pyobj_distanceThresh, distanceThresh, ArgInfo("distanceThresh", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 1)) &&
        pyopencv_to_safe(pyobj_triangulatedPoints, triangulatedPoints, ArgInfo("triangulatedPoints", 1)) )
    {
        ERRWRAP2(retval = cv::recoverPose(E, points1, points2, cameraMatrix, R, t, distanceThresh, mask, triangulatedPoints));
        return Py_BuildValue("(NNNNN)", pyopencv_from(retval), pyopencv_from(R), pyopencv_from(t), pyopencv_from(mask), pyopencv_from(triangulatedPoints));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_E = NULL;
    UMat E;
    PyObject* pyobj_points1 = NULL;
    UMat points1;
    PyObject* pyobj_points2 = NULL;
    UMat points2;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_R = NULL;
    UMat R;
    PyObject* pyobj_t = NULL;
    UMat t;
    PyObject* pyobj_distanceThresh = NULL;
    double distanceThresh=0;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    PyObject* pyobj_triangulatedPoints = NULL;
    UMat triangulatedPoints;
    int retval;

    const char* keywords[] = { "E", "points1", "points2", "cameraMatrix", "distanceThresh", "R", "t", "mask", "triangulatedPoints", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OOOO:recoverPose", (char**)keywords, &pyobj_E, &pyobj_points1, &pyobj_points2, &pyobj_cameraMatrix, &pyobj_distanceThresh, &pyobj_R, &pyobj_t, &pyobj_mask, &pyobj_triangulatedPoints) &&
        pyopencv_to_safe(pyobj_E, E, ArgInfo("E", 0)) &&
        pyopencv_to_safe(pyobj_points1, points1, ArgInfo("points1", 0)) &&
        pyopencv_to_safe(pyobj_points2, points2, ArgInfo("points2", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 1)) &&
        pyopencv_to_safe(pyobj_t, t, ArgInfo("t", 1)) &&
        pyopencv_to_safe(pyobj_distanceThresh, distanceThresh, ArgInfo("distanceThresh", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 1)) &&
        pyopencv_to_safe(pyobj_triangulatedPoints, triangulatedPoints, ArgInfo("triangulatedPoints", 1)) )
    {
        ERRWRAP2(retval = cv::recoverPose(E, points1, points2, cameraMatrix, R, t, distanceThresh, mask, triangulatedPoints));
        return Py_BuildValue("(NNNNN)", pyopencv_from(retval), pyopencv_from(R), pyopencv_from(t), pyopencv_from(mask), pyopencv_from(triangulatedPoints));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("recoverPose");

    return NULL;
}

static PyObject* pyopencv_cv_rectangle(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(4);

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_pt1 = NULL;
    Point pt1;
    PyObject* pyobj_pt2 = NULL;
    Point pt2;
    PyObject* pyobj_color = NULL;
    Scalar color;
    PyObject* pyobj_thickness = NULL;
    int thickness=1;
    PyObject* pyobj_lineType = NULL;
    int lineType=LINE_8;
    PyObject* pyobj_shift = NULL;
    int shift=0;

    const char* keywords[] = { "img", "pt1", "pt2", "color", "thickness", "lineType", "shift", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:rectangle", (char**)keywords, &pyobj_img, &pyobj_pt1, &pyobj_pt2, &pyobj_color, &pyobj_thickness, &pyobj_lineType, &pyobj_shift) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_pt1, pt1, ArgInfo("pt1", 0)) &&
        pyopencv_to_safe(pyobj_pt2, pt2, ArgInfo("pt2", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_thickness, thickness, ArgInfo("thickness", 0)) &&
        pyopencv_to_safe(pyobj_lineType, lineType, ArgInfo("lineType", 0)) &&
        pyopencv_to_safe(pyobj_shift, shift, ArgInfo("shift", 0)) )
    {
        ERRWRAP2(cv::rectangle(img, pt1, pt2, color, thickness, lineType, shift));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_pt1 = NULL;
    Point pt1;
    PyObject* pyobj_pt2 = NULL;
    Point pt2;
    PyObject* pyobj_color = NULL;
    Scalar color;
    PyObject* pyobj_thickness = NULL;
    int thickness=1;
    PyObject* pyobj_lineType = NULL;
    int lineType=LINE_8;
    PyObject* pyobj_shift = NULL;
    int shift=0;

    const char* keywords[] = { "img", "pt1", "pt2", "color", "thickness", "lineType", "shift", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:rectangle", (char**)keywords, &pyobj_img, &pyobj_pt1, &pyobj_pt2, &pyobj_color, &pyobj_thickness, &pyobj_lineType, &pyobj_shift) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_pt1, pt1, ArgInfo("pt1", 0)) &&
        pyopencv_to_safe(pyobj_pt2, pt2, ArgInfo("pt2", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_thickness, thickness, ArgInfo("thickness", 0)) &&
        pyopencv_to_safe(pyobj_lineType, lineType, ArgInfo("lineType", 0)) &&
        pyopencv_to_safe(pyobj_shift, shift, ArgInfo("shift", 0)) )
    {
        ERRWRAP2(cv::rectangle(img, pt1, pt2, color, thickness, lineType, shift));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_rec = NULL;
    Rect rec;
    PyObject* pyobj_color = NULL;
    Scalar color;
    PyObject* pyobj_thickness = NULL;
    int thickness=1;
    PyObject* pyobj_lineType = NULL;
    int lineType=LINE_8;
    PyObject* pyobj_shift = NULL;
    int shift=0;

    const char* keywords[] = { "img", "rec", "color", "thickness", "lineType", "shift", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:rectangle", (char**)keywords, &pyobj_img, &pyobj_rec, &pyobj_color, &pyobj_thickness, &pyobj_lineType, &pyobj_shift) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_rec, rec, ArgInfo("rec", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_thickness, thickness, ArgInfo("thickness", 0)) &&
        pyopencv_to_safe(pyobj_lineType, lineType, ArgInfo("lineType", 0)) &&
        pyopencv_to_safe(pyobj_shift, shift, ArgInfo("shift", 0)) )
    {
        ERRWRAP2(cv::rectangle(img, rec, color, thickness, lineType, shift));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_rec = NULL;
    Rect rec;
    PyObject* pyobj_color = NULL;
    Scalar color;
    PyObject* pyobj_thickness = NULL;
    int thickness=1;
    PyObject* pyobj_lineType = NULL;
    int lineType=LINE_8;
    PyObject* pyobj_shift = NULL;
    int shift=0;

    const char* keywords[] = { "img", "rec", "color", "thickness", "lineType", "shift", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:rectangle", (char**)keywords, &pyobj_img, &pyobj_rec, &pyobj_color, &pyobj_thickness, &pyobj_lineType, &pyobj_shift) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_rec, rec, ArgInfo("rec", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_thickness, thickness, ArgInfo("thickness", 0)) &&
        pyopencv_to_safe(pyobj_lineType, lineType, ArgInfo("lineType", 0)) &&
        pyopencv_to_safe(pyobj_shift, shift, ArgInfo("shift", 0)) )
    {
        ERRWRAP2(cv::rectangle(img, rec, color, thickness, lineType, shift));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("rectangle");

    return NULL;
}

static PyObject* pyopencv_cv_rectify3Collinear(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_cameraMatrix1 = NULL;
    Mat cameraMatrix1;
    PyObject* pyobj_distCoeffs1 = NULL;
    Mat distCoeffs1;
    PyObject* pyobj_cameraMatrix2 = NULL;
    Mat cameraMatrix2;
    PyObject* pyobj_distCoeffs2 = NULL;
    Mat distCoeffs2;
    PyObject* pyobj_cameraMatrix3 = NULL;
    Mat cameraMatrix3;
    PyObject* pyobj_distCoeffs3 = NULL;
    Mat distCoeffs3;
    PyObject* pyobj_imgpt1 = NULL;
    vector_Mat imgpt1;
    PyObject* pyobj_imgpt3 = NULL;
    vector_Mat imgpt3;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_R12 = NULL;
    Mat R12;
    PyObject* pyobj_T12 = NULL;
    Mat T12;
    PyObject* pyobj_R13 = NULL;
    Mat R13;
    PyObject* pyobj_T13 = NULL;
    Mat T13;
    PyObject* pyobj_R1 = NULL;
    Mat R1;
    PyObject* pyobj_R2 = NULL;
    Mat R2;
    PyObject* pyobj_R3 = NULL;
    Mat R3;
    PyObject* pyobj_P1 = NULL;
    Mat P1;
    PyObject* pyobj_P2 = NULL;
    Mat P2;
    PyObject* pyobj_P3 = NULL;
    Mat P3;
    PyObject* pyobj_Q = NULL;
    Mat Q;
    PyObject* pyobj_alpha = NULL;
    double alpha=0;
    PyObject* pyobj_newImgSize = NULL;
    Size newImgSize;
    Rect roi1;
    Rect roi2;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    float retval;

    const char* keywords[] = { "cameraMatrix1", "distCoeffs1", "cameraMatrix2", "distCoeffs2", "cameraMatrix3", "distCoeffs3", "imgpt1", "imgpt3", "imageSize", "R12", "T12", "R13", "T13", "alpha", "newImgSize", "flags", "R1", "R2", "R3", "P1", "P2", "P3", "Q", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOOOOOOOOOOO|OOOOOOO:rectify3Collinear", (char**)keywords, &pyobj_cameraMatrix1, &pyobj_distCoeffs1, &pyobj_cameraMatrix2, &pyobj_distCoeffs2, &pyobj_cameraMatrix3, &pyobj_distCoeffs3, &pyobj_imgpt1, &pyobj_imgpt3, &pyobj_imageSize, &pyobj_R12, &pyobj_T12, &pyobj_R13, &pyobj_T13, &pyobj_alpha, &pyobj_newImgSize, &pyobj_flags, &pyobj_R1, &pyobj_R2, &pyobj_R3, &pyobj_P1, &pyobj_P2, &pyobj_P3, &pyobj_Q) &&
        pyopencv_to_safe(pyobj_cameraMatrix1, cameraMatrix1, ArgInfo("cameraMatrix1", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs1, distCoeffs1, ArgInfo("distCoeffs1", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix2, cameraMatrix2, ArgInfo("cameraMatrix2", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs2, distCoeffs2, ArgInfo("distCoeffs2", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix3, cameraMatrix3, ArgInfo("cameraMatrix3", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs3, distCoeffs3, ArgInfo("distCoeffs3", 0)) &&
        pyopencv_to_safe(pyobj_imgpt1, imgpt1, ArgInfo("imgpt1", 0)) &&
        pyopencv_to_safe(pyobj_imgpt3, imgpt3, ArgInfo("imgpt3", 0)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_R12, R12, ArgInfo("R12", 0)) &&
        pyopencv_to_safe(pyobj_T12, T12, ArgInfo("T12", 0)) &&
        pyopencv_to_safe(pyobj_R13, R13, ArgInfo("R13", 0)) &&
        pyopencv_to_safe(pyobj_T13, T13, ArgInfo("T13", 0)) &&
        pyopencv_to_safe(pyobj_R1, R1, ArgInfo("R1", 1)) &&
        pyopencv_to_safe(pyobj_R2, R2, ArgInfo("R2", 1)) &&
        pyopencv_to_safe(pyobj_R3, R3, ArgInfo("R3", 1)) &&
        pyopencv_to_safe(pyobj_P1, P1, ArgInfo("P1", 1)) &&
        pyopencv_to_safe(pyobj_P2, P2, ArgInfo("P2", 1)) &&
        pyopencv_to_safe(pyobj_P3, P3, ArgInfo("P3", 1)) &&
        pyopencv_to_safe(pyobj_Q, Q, ArgInfo("Q", 1)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_newImgSize, newImgSize, ArgInfo("newImgSize", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(retval = cv::rectify3Collinear(cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, cameraMatrix3, distCoeffs3, imgpt1, imgpt3, imageSize, R12, T12, R13, T13, R1, R2, R3, P1, P2, P3, Q, alpha, newImgSize, &roi1, &roi2, flags));
        return Py_BuildValue("(NNNNNNNNNN)", pyopencv_from(retval), pyopencv_from(R1), pyopencv_from(R2), pyopencv_from(R3), pyopencv_from(P1), pyopencv_from(P2), pyopencv_from(P3), pyopencv_from(Q), pyopencv_from(roi1), pyopencv_from(roi2));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_cameraMatrix1 = NULL;
    UMat cameraMatrix1;
    PyObject* pyobj_distCoeffs1 = NULL;
    UMat distCoeffs1;
    PyObject* pyobj_cameraMatrix2 = NULL;
    UMat cameraMatrix2;
    PyObject* pyobj_distCoeffs2 = NULL;
    UMat distCoeffs2;
    PyObject* pyobj_cameraMatrix3 = NULL;
    UMat cameraMatrix3;
    PyObject* pyobj_distCoeffs3 = NULL;
    UMat distCoeffs3;
    PyObject* pyobj_imgpt1 = NULL;
    vector_UMat imgpt1;
    PyObject* pyobj_imgpt3 = NULL;
    vector_UMat imgpt3;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_R12 = NULL;
    UMat R12;
    PyObject* pyobj_T12 = NULL;
    UMat T12;
    PyObject* pyobj_R13 = NULL;
    UMat R13;
    PyObject* pyobj_T13 = NULL;
    UMat T13;
    PyObject* pyobj_R1 = NULL;
    UMat R1;
    PyObject* pyobj_R2 = NULL;
    UMat R2;
    PyObject* pyobj_R3 = NULL;
    UMat R3;
    PyObject* pyobj_P1 = NULL;
    UMat P1;
    PyObject* pyobj_P2 = NULL;
    UMat P2;
    PyObject* pyobj_P3 = NULL;
    UMat P3;
    PyObject* pyobj_Q = NULL;
    UMat Q;
    PyObject* pyobj_alpha = NULL;
    double alpha=0;
    PyObject* pyobj_newImgSize = NULL;
    Size newImgSize;
    Rect roi1;
    Rect roi2;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    float retval;

    const char* keywords[] = { "cameraMatrix1", "distCoeffs1", "cameraMatrix2", "distCoeffs2", "cameraMatrix3", "distCoeffs3", "imgpt1", "imgpt3", "imageSize", "R12", "T12", "R13", "T13", "alpha", "newImgSize", "flags", "R1", "R2", "R3", "P1", "P2", "P3", "Q", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOOOOOOOOOOO|OOOOOOO:rectify3Collinear", (char**)keywords, &pyobj_cameraMatrix1, &pyobj_distCoeffs1, &pyobj_cameraMatrix2, &pyobj_distCoeffs2, &pyobj_cameraMatrix3, &pyobj_distCoeffs3, &pyobj_imgpt1, &pyobj_imgpt3, &pyobj_imageSize, &pyobj_R12, &pyobj_T12, &pyobj_R13, &pyobj_T13, &pyobj_alpha, &pyobj_newImgSize, &pyobj_flags, &pyobj_R1, &pyobj_R2, &pyobj_R3, &pyobj_P1, &pyobj_P2, &pyobj_P3, &pyobj_Q) &&
        pyopencv_to_safe(pyobj_cameraMatrix1, cameraMatrix1, ArgInfo("cameraMatrix1", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs1, distCoeffs1, ArgInfo("distCoeffs1", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix2, cameraMatrix2, ArgInfo("cameraMatrix2", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs2, distCoeffs2, ArgInfo("distCoeffs2", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix3, cameraMatrix3, ArgInfo("cameraMatrix3", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs3, distCoeffs3, ArgInfo("distCoeffs3", 0)) &&
        pyopencv_to_safe(pyobj_imgpt1, imgpt1, ArgInfo("imgpt1", 0)) &&
        pyopencv_to_safe(pyobj_imgpt3, imgpt3, ArgInfo("imgpt3", 0)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_R12, R12, ArgInfo("R12", 0)) &&
        pyopencv_to_safe(pyobj_T12, T12, ArgInfo("T12", 0)) &&
        pyopencv_to_safe(pyobj_R13, R13, ArgInfo("R13", 0)) &&
        pyopencv_to_safe(pyobj_T13, T13, ArgInfo("T13", 0)) &&
        pyopencv_to_safe(pyobj_R1, R1, ArgInfo("R1", 1)) &&
        pyopencv_to_safe(pyobj_R2, R2, ArgInfo("R2", 1)) &&
        pyopencv_to_safe(pyobj_R3, R3, ArgInfo("R3", 1)) &&
        pyopencv_to_safe(pyobj_P1, P1, ArgInfo("P1", 1)) &&
        pyopencv_to_safe(pyobj_P2, P2, ArgInfo("P2", 1)) &&
        pyopencv_to_safe(pyobj_P3, P3, ArgInfo("P3", 1)) &&
        pyopencv_to_safe(pyobj_Q, Q, ArgInfo("Q", 1)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_newImgSize, newImgSize, ArgInfo("newImgSize", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(retval = cv::rectify3Collinear(cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, cameraMatrix3, distCoeffs3, imgpt1, imgpt3, imageSize, R12, T12, R13, T13, R1, R2, R3, P1, P2, P3, Q, alpha, newImgSize, &roi1, &roi2, flags));
        return Py_BuildValue("(NNNNNNNNNN)", pyopencv_from(retval), pyopencv_from(R1), pyopencv_from(R2), pyopencv_from(R3), pyopencv_from(P1), pyopencv_from(P2), pyopencv_from(P3), pyopencv_from(Q), pyopencv_from(roi1), pyopencv_from(roi2));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("rectify3Collinear");

    return NULL;
}

static PyObject* pyopencv_cv_reduce(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_dim = NULL;
    int dim=0;
    PyObject* pyobj_rtype = NULL;
    int rtype=0;
    PyObject* pyobj_dtype = NULL;
    int dtype=-1;

    const char* keywords[] = { "src", "dim", "rtype", "dst", "dtype", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:reduce", (char**)keywords, &pyobj_src, &pyobj_dim, &pyobj_rtype, &pyobj_dst, &pyobj_dtype) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_dim, dim, ArgInfo("dim", 0)) &&
        pyopencv_to_safe(pyobj_rtype, rtype, ArgInfo("rtype", 0)) &&
        pyopencv_to_safe(pyobj_dtype, dtype, ArgInfo("dtype", 0)) )
    {
        ERRWRAP2(cv::reduce(src, dst, dim, rtype, dtype));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_dim = NULL;
    int dim=0;
    PyObject* pyobj_rtype = NULL;
    int rtype=0;
    PyObject* pyobj_dtype = NULL;
    int dtype=-1;

    const char* keywords[] = { "src", "dim", "rtype", "dst", "dtype", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:reduce", (char**)keywords, &pyobj_src, &pyobj_dim, &pyobj_rtype, &pyobj_dst, &pyobj_dtype) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_dim, dim, ArgInfo("dim", 0)) &&
        pyopencv_to_safe(pyobj_rtype, rtype, ArgInfo("rtype", 0)) &&
        pyopencv_to_safe(pyobj_dtype, dtype, ArgInfo("dtype", 0)) )
    {
        ERRWRAP2(cv::reduce(src, dst, dim, rtype, dtype));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("reduce");

    return NULL;
}

static PyObject* pyopencv_cv_remap(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_map1 = NULL;
    Mat map1;
    PyObject* pyobj_map2 = NULL;
    Mat map2;
    PyObject* pyobj_interpolation = NULL;
    int interpolation=0;
    PyObject* pyobj_borderMode = NULL;
    int borderMode=BORDER_CONSTANT;
    PyObject* pyobj_borderValue = NULL;
    Scalar borderValue;

    const char* keywords[] = { "src", "map1", "map2", "interpolation", "dst", "borderMode", "borderValue", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:remap", (char**)keywords, &pyobj_src, &pyobj_map1, &pyobj_map2, &pyobj_interpolation, &pyobj_dst, &pyobj_borderMode, &pyobj_borderValue) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_map1, map1, ArgInfo("map1", 0)) &&
        pyopencv_to_safe(pyobj_map2, map2, ArgInfo("map2", 0)) &&
        pyopencv_to_safe(pyobj_interpolation, interpolation, ArgInfo("interpolation", 0)) &&
        pyopencv_to_safe(pyobj_borderMode, borderMode, ArgInfo("borderMode", 0)) &&
        pyopencv_to_safe(pyobj_borderValue, borderValue, ArgInfo("borderValue", 0)) )
    {
        ERRWRAP2(cv::remap(src, dst, map1, map2, interpolation, borderMode, borderValue));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_map1 = NULL;
    UMat map1;
    PyObject* pyobj_map2 = NULL;
    UMat map2;
    PyObject* pyobj_interpolation = NULL;
    int interpolation=0;
    PyObject* pyobj_borderMode = NULL;
    int borderMode=BORDER_CONSTANT;
    PyObject* pyobj_borderValue = NULL;
    Scalar borderValue;

    const char* keywords[] = { "src", "map1", "map2", "interpolation", "dst", "borderMode", "borderValue", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:remap", (char**)keywords, &pyobj_src, &pyobj_map1, &pyobj_map2, &pyobj_interpolation, &pyobj_dst, &pyobj_borderMode, &pyobj_borderValue) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_map1, map1, ArgInfo("map1", 0)) &&
        pyopencv_to_safe(pyobj_map2, map2, ArgInfo("map2", 0)) &&
        pyopencv_to_safe(pyobj_interpolation, interpolation, ArgInfo("interpolation", 0)) &&
        pyopencv_to_safe(pyobj_borderMode, borderMode, ArgInfo("borderMode", 0)) &&
        pyopencv_to_safe(pyobj_borderValue, borderValue, ArgInfo("borderValue", 0)) )
    {
        ERRWRAP2(cv::remap(src, dst, map1, map2, interpolation, borderMode, borderValue));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("remap");

    return NULL;
}

static PyObject* pyopencv_cv_repeat(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_ny = NULL;
    int ny=0;
    PyObject* pyobj_nx = NULL;
    int nx=0;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src", "ny", "nx", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:repeat", (char**)keywords, &pyobj_src, &pyobj_ny, &pyobj_nx, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_ny, ny, ArgInfo("ny", 0)) &&
        pyopencv_to_safe(pyobj_nx, nx, ArgInfo("nx", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::repeat(src, ny, nx, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_ny = NULL;
    int ny=0;
    PyObject* pyobj_nx = NULL;
    int nx=0;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "src", "ny", "nx", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:repeat", (char**)keywords, &pyobj_src, &pyobj_ny, &pyobj_nx, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_ny, ny, ArgInfo("ny", 0)) &&
        pyopencv_to_safe(pyobj_nx, nx, ArgInfo("nx", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::repeat(src, ny, nx, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("repeat");

    return NULL;
}

static PyObject* pyopencv_cv_reprojectImageTo3D(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_disparity = NULL;
    Mat disparity;
    PyObject* pyobj__3dImage = NULL;
    Mat _3dImage;
    PyObject* pyobj_Q = NULL;
    Mat Q;
    PyObject* pyobj_handleMissingValues = NULL;
    bool handleMissingValues=false;
    PyObject* pyobj_ddepth = NULL;
    int ddepth=-1;

    const char* keywords[] = { "disparity", "Q", "_3dImage", "handleMissingValues", "ddepth", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:reprojectImageTo3D", (char**)keywords, &pyobj_disparity, &pyobj_Q, &pyobj__3dImage, &pyobj_handleMissingValues, &pyobj_ddepth) &&
        pyopencv_to_safe(pyobj_disparity, disparity, ArgInfo("disparity", 0)) &&
        pyopencv_to_safe(pyobj__3dImage, _3dImage, ArgInfo("_3dImage", 1)) &&
        pyopencv_to_safe(pyobj_Q, Q, ArgInfo("Q", 0)) &&
        pyopencv_to_safe(pyobj_handleMissingValues, handleMissingValues, ArgInfo("handleMissingValues", 0)) &&
        pyopencv_to_safe(pyobj_ddepth, ddepth, ArgInfo("ddepth", 0)) )
    {
        ERRWRAP2(cv::reprojectImageTo3D(disparity, _3dImage, Q, handleMissingValues, ddepth));
        return pyopencv_from(_3dImage);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_disparity = NULL;
    UMat disparity;
    PyObject* pyobj__3dImage = NULL;
    UMat _3dImage;
    PyObject* pyobj_Q = NULL;
    UMat Q;
    PyObject* pyobj_handleMissingValues = NULL;
    bool handleMissingValues=false;
    PyObject* pyobj_ddepth = NULL;
    int ddepth=-1;

    const char* keywords[] = { "disparity", "Q", "_3dImage", "handleMissingValues", "ddepth", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:reprojectImageTo3D", (char**)keywords, &pyobj_disparity, &pyobj_Q, &pyobj__3dImage, &pyobj_handleMissingValues, &pyobj_ddepth) &&
        pyopencv_to_safe(pyobj_disparity, disparity, ArgInfo("disparity", 0)) &&
        pyopencv_to_safe(pyobj__3dImage, _3dImage, ArgInfo("_3dImage", 1)) &&
        pyopencv_to_safe(pyobj_Q, Q, ArgInfo("Q", 0)) &&
        pyopencv_to_safe(pyobj_handleMissingValues, handleMissingValues, ArgInfo("handleMissingValues", 0)) &&
        pyopencv_to_safe(pyobj_ddepth, ddepth, ArgInfo("ddepth", 0)) )
    {
        ERRWRAP2(cv::reprojectImageTo3D(disparity, _3dImage, Q, handleMissingValues, ddepth));
        return pyopencv_from(_3dImage);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("reprojectImageTo3D");

    return NULL;
}

static PyObject* pyopencv_cv_resize(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_dsize = NULL;
    Size dsize;
    PyObject* pyobj_fx = NULL;
    double fx=0;
    PyObject* pyobj_fy = NULL;
    double fy=0;
    PyObject* pyobj_interpolation = NULL;
    int interpolation=INTER_LINEAR;

    const char* keywords[] = { "src", "dsize", "dst", "fx", "fy", "interpolation", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOO:resize", (char**)keywords, &pyobj_src, &pyobj_dsize, &pyobj_dst, &pyobj_fx, &pyobj_fy, &pyobj_interpolation) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_dsize, dsize, ArgInfo("dsize", 0)) &&
        pyopencv_to_safe(pyobj_fx, fx, ArgInfo("fx", 0)) &&
        pyopencv_to_safe(pyobj_fy, fy, ArgInfo("fy", 0)) &&
        pyopencv_to_safe(pyobj_interpolation, interpolation, ArgInfo("interpolation", 0)) )
    {
        ERRWRAP2(cv::resize(src, dst, dsize, fx, fy, interpolation));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_dsize = NULL;
    Size dsize;
    PyObject* pyobj_fx = NULL;
    double fx=0;
    PyObject* pyobj_fy = NULL;
    double fy=0;
    PyObject* pyobj_interpolation = NULL;
    int interpolation=INTER_LINEAR;

    const char* keywords[] = { "src", "dsize", "dst", "fx", "fy", "interpolation", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOO:resize", (char**)keywords, &pyobj_src, &pyobj_dsize, &pyobj_dst, &pyobj_fx, &pyobj_fy, &pyobj_interpolation) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_dsize, dsize, ArgInfo("dsize", 0)) &&
        pyopencv_to_safe(pyobj_fx, fx, ArgInfo("fx", 0)) &&
        pyopencv_to_safe(pyobj_fy, fy, ArgInfo("fy", 0)) &&
        pyopencv_to_safe(pyobj_interpolation, interpolation, ArgInfo("interpolation", 0)) )
    {
        ERRWRAP2(cv::resize(src, dst, dsize, fx, fy, interpolation));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("resize");

    return NULL;
}

static PyObject* pyopencv_cv_resizeWindow(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_winname = NULL;
    String winname;
    PyObject* pyobj_width = NULL;
    int width=0;
    PyObject* pyobj_height = NULL;
    int height=0;

    const char* keywords[] = { "winname", "width", "height", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:resizeWindow", (char**)keywords, &pyobj_winname, &pyobj_width, &pyobj_height) &&
        pyopencv_to_safe(pyobj_winname, winname, ArgInfo("winname", 0)) &&
        pyopencv_to_safe(pyobj_width, width, ArgInfo("width", 0)) &&
        pyopencv_to_safe(pyobj_height, height, ArgInfo("height", 0)) )
    {
        ERRWRAP2(cv::resizeWindow(winname, width, height));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_winname = NULL;
    String winname;
    PyObject* pyobj_size = NULL;
    Size size;

    const char* keywords[] = { "winname", "size", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:resizeWindow", (char**)keywords, &pyobj_winname, &pyobj_size) &&
        pyopencv_to_safe(pyobj_winname, winname, ArgInfo("winname", 0)) &&
        pyopencv_to_safe(pyobj_size, size, ArgInfo("size", 0)) )
    {
        ERRWRAP2(cv::resizeWindow(winname, size));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("resizeWindow");

    return NULL;
}

static PyObject* pyopencv_cv_rotate(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_rotateCode = NULL;
    int rotateCode=0;

    const char* keywords[] = { "src", "rotateCode", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:rotate", (char**)keywords, &pyobj_src, &pyobj_rotateCode, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_rotateCode, rotateCode, ArgInfo("rotateCode", 0)) )
    {
        ERRWRAP2(cv::rotate(src, dst, rotateCode));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_rotateCode = NULL;
    int rotateCode=0;

    const char* keywords[] = { "src", "rotateCode", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:rotate", (char**)keywords, &pyobj_src, &pyobj_rotateCode, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_rotateCode, rotateCode, ArgInfo("rotateCode", 0)) )
    {
        ERRWRAP2(cv::rotate(src, dst, rotateCode));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("rotate");

    return NULL;
}

static PyObject* pyopencv_cv_rotatedRectangleIntersection(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_rect1 = NULL;
    RotatedRect rect1;
    PyObject* pyobj_rect2 = NULL;
    RotatedRect rect2;
    PyObject* pyobj_intersectingRegion = NULL;
    Mat intersectingRegion;
    int retval;

    const char* keywords[] = { "rect1", "rect2", "intersectingRegion", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:rotatedRectangleIntersection", (char**)keywords, &pyobj_rect1, &pyobj_rect2, &pyobj_intersectingRegion) &&
        pyopencv_to_safe(pyobj_rect1, rect1, ArgInfo("rect1", 0)) &&
        pyopencv_to_safe(pyobj_rect2, rect2, ArgInfo("rect2", 0)) &&
        pyopencv_to_safe(pyobj_intersectingRegion, intersectingRegion, ArgInfo("intersectingRegion", 1)) )
    {
        ERRWRAP2(retval = cv::rotatedRectangleIntersection(rect1, rect2, intersectingRegion));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(intersectingRegion));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_rect1 = NULL;
    RotatedRect rect1;
    PyObject* pyobj_rect2 = NULL;
    RotatedRect rect2;
    PyObject* pyobj_intersectingRegion = NULL;
    UMat intersectingRegion;
    int retval;

    const char* keywords[] = { "rect1", "rect2", "intersectingRegion", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:rotatedRectangleIntersection", (char**)keywords, &pyobj_rect1, &pyobj_rect2, &pyobj_intersectingRegion) &&
        pyopencv_to_safe(pyobj_rect1, rect1, ArgInfo("rect1", 0)) &&
        pyopencv_to_safe(pyobj_rect2, rect2, ArgInfo("rect2", 0)) &&
        pyopencv_to_safe(pyobj_intersectingRegion, intersectingRegion, ArgInfo("intersectingRegion", 1)) )
    {
        ERRWRAP2(retval = cv::rotatedRectangleIntersection(rect1, rect2, intersectingRegion));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(intersectingRegion));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("rotatedRectangleIntersection");

    return NULL;
}

static PyObject* pyopencv_cv_sampsonDistance(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_pt1 = NULL;
    Mat pt1;
    PyObject* pyobj_pt2 = NULL;
    Mat pt2;
    PyObject* pyobj_F = NULL;
    Mat F;
    double retval;

    const char* keywords[] = { "pt1", "pt2", "F", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:sampsonDistance", (char**)keywords, &pyobj_pt1, &pyobj_pt2, &pyobj_F) &&
        pyopencv_to_safe(pyobj_pt1, pt1, ArgInfo("pt1", 0)) &&
        pyopencv_to_safe(pyobj_pt2, pt2, ArgInfo("pt2", 0)) &&
        pyopencv_to_safe(pyobj_F, F, ArgInfo("F", 0)) )
    {
        ERRWRAP2(retval = cv::sampsonDistance(pt1, pt2, F));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_pt1 = NULL;
    UMat pt1;
    PyObject* pyobj_pt2 = NULL;
    UMat pt2;
    PyObject* pyobj_F = NULL;
    UMat F;
    double retval;

    const char* keywords[] = { "pt1", "pt2", "F", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:sampsonDistance", (char**)keywords, &pyobj_pt1, &pyobj_pt2, &pyobj_F) &&
        pyopencv_to_safe(pyobj_pt1, pt1, ArgInfo("pt1", 0)) &&
        pyopencv_to_safe(pyobj_pt2, pt2, ArgInfo("pt2", 0)) &&
        pyopencv_to_safe(pyobj_F, F, ArgInfo("F", 0)) )
    {
        ERRWRAP2(retval = cv::sampsonDistance(pt1, pt2, F));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("sampsonDistance");

    return NULL;
}

static PyObject* pyopencv_cv_scaleAdd(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src1 = NULL;
    Mat src1;
    PyObject* pyobj_alpha = NULL;
    double alpha=0;
    PyObject* pyobj_src2 = NULL;
    Mat src2;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src1", "alpha", "src2", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:scaleAdd", (char**)keywords, &pyobj_src1, &pyobj_alpha, &pyobj_src2, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::scaleAdd(src1, alpha, src2, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src1 = NULL;
    UMat src1;
    PyObject* pyobj_alpha = NULL;
    double alpha=0;
    PyObject* pyobj_src2 = NULL;
    UMat src2;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "src1", "alpha", "src2", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:scaleAdd", (char**)keywords, &pyobj_src1, &pyobj_alpha, &pyobj_src2, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::scaleAdd(src1, alpha, src2, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("scaleAdd");

    return NULL;
}

static PyObject* pyopencv_cv_seamlessClone(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_p = NULL;
    Point p;
    PyObject* pyobj_blend = NULL;
    Mat blend;
    PyObject* pyobj_flags = NULL;
    int flags=0;

    const char* keywords[] = { "src", "dst", "mask", "p", "flags", "blend", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|O:seamlessClone", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_mask, &pyobj_p, &pyobj_flags, &pyobj_blend) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_p, p, ArgInfo("p", 0)) &&
        pyopencv_to_safe(pyobj_blend, blend, ArgInfo("blend", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::seamlessClone(src, dst, mask, p, blend, flags));
        return pyopencv_from(blend);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    PyObject* pyobj_p = NULL;
    Point p;
    PyObject* pyobj_blend = NULL;
    UMat blend;
    PyObject* pyobj_flags = NULL;
    int flags=0;

    const char* keywords[] = { "src", "dst", "mask", "p", "flags", "blend", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|O:seamlessClone", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_mask, &pyobj_p, &pyobj_flags, &pyobj_blend) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_p, p, ArgInfo("p", 0)) &&
        pyopencv_to_safe(pyobj_blend, blend, ArgInfo("blend", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::seamlessClone(src, dst, mask, p, blend, flags));
        return pyopencv_from(blend);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("seamlessClone");

    return NULL;
}

static PyObject* pyopencv_cv_selectROI(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(4);

    {
    PyObject* pyobj_windowName = NULL;
    String windowName;
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_showCrosshair = NULL;
    bool showCrosshair=true;
    PyObject* pyobj_fromCenter = NULL;
    bool fromCenter=false;
    Rect retval;

    const char* keywords[] = { "windowName", "img", "showCrosshair", "fromCenter", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:selectROI", (char**)keywords, &pyobj_windowName, &pyobj_img, &pyobj_showCrosshair, &pyobj_fromCenter) &&
        pyopencv_to_safe(pyobj_windowName, windowName, ArgInfo("windowName", 0)) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_showCrosshair, showCrosshair, ArgInfo("showCrosshair", 0)) &&
        pyopencv_to_safe(pyobj_fromCenter, fromCenter, ArgInfo("fromCenter", 0)) )
    {
        ERRWRAP2(retval = cv::selectROI(windowName, img, showCrosshair, fromCenter));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_windowName = NULL;
    String windowName;
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_showCrosshair = NULL;
    bool showCrosshair=true;
    PyObject* pyobj_fromCenter = NULL;
    bool fromCenter=false;
    Rect retval;

    const char* keywords[] = { "windowName", "img", "showCrosshair", "fromCenter", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:selectROI", (char**)keywords, &pyobj_windowName, &pyobj_img, &pyobj_showCrosshair, &pyobj_fromCenter) &&
        pyopencv_to_safe(pyobj_windowName, windowName, ArgInfo("windowName", 0)) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_showCrosshair, showCrosshair, ArgInfo("showCrosshair", 0)) &&
        pyopencv_to_safe(pyobj_fromCenter, fromCenter, ArgInfo("fromCenter", 0)) )
    {
        ERRWRAP2(retval = cv::selectROI(windowName, img, showCrosshair, fromCenter));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_showCrosshair = NULL;
    bool showCrosshair=true;
    PyObject* pyobj_fromCenter = NULL;
    bool fromCenter=false;
    Rect retval;

    const char* keywords[] = { "img", "showCrosshair", "fromCenter", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:selectROI", (char**)keywords, &pyobj_img, &pyobj_showCrosshair, &pyobj_fromCenter) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_showCrosshair, showCrosshair, ArgInfo("showCrosshair", 0)) &&
        pyopencv_to_safe(pyobj_fromCenter, fromCenter, ArgInfo("fromCenter", 0)) )
    {
        ERRWRAP2(retval = cv::selectROI(img, showCrosshair, fromCenter));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_showCrosshair = NULL;
    bool showCrosshair=true;
    PyObject* pyobj_fromCenter = NULL;
    bool fromCenter=false;
    Rect retval;

    const char* keywords[] = { "img", "showCrosshair", "fromCenter", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:selectROI", (char**)keywords, &pyobj_img, &pyobj_showCrosshair, &pyobj_fromCenter) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_showCrosshair, showCrosshair, ArgInfo("showCrosshair", 0)) &&
        pyopencv_to_safe(pyobj_fromCenter, fromCenter, ArgInfo("fromCenter", 0)) )
    {
        ERRWRAP2(retval = cv::selectROI(img, showCrosshair, fromCenter));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("selectROI");

    return NULL;
}

static PyObject* pyopencv_cv_selectROIs(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_windowName = NULL;
    String windowName;
    PyObject* pyobj_img = NULL;
    Mat img;
    vector_Rect boundingBoxes;
    PyObject* pyobj_showCrosshair = NULL;
    bool showCrosshair=true;
    PyObject* pyobj_fromCenter = NULL;
    bool fromCenter=false;

    const char* keywords[] = { "windowName", "img", "showCrosshair", "fromCenter", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:selectROIs", (char**)keywords, &pyobj_windowName, &pyobj_img, &pyobj_showCrosshair, &pyobj_fromCenter) &&
        pyopencv_to_safe(pyobj_windowName, windowName, ArgInfo("windowName", 0)) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_showCrosshair, showCrosshair, ArgInfo("showCrosshair", 0)) &&
        pyopencv_to_safe(pyobj_fromCenter, fromCenter, ArgInfo("fromCenter", 0)) )
    {
        ERRWRAP2(cv::selectROIs(windowName, img, boundingBoxes, showCrosshair, fromCenter));
        return pyopencv_from(boundingBoxes);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_windowName = NULL;
    String windowName;
    PyObject* pyobj_img = NULL;
    UMat img;
    vector_Rect boundingBoxes;
    PyObject* pyobj_showCrosshair = NULL;
    bool showCrosshair=true;
    PyObject* pyobj_fromCenter = NULL;
    bool fromCenter=false;

    const char* keywords[] = { "windowName", "img", "showCrosshair", "fromCenter", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:selectROIs", (char**)keywords, &pyobj_windowName, &pyobj_img, &pyobj_showCrosshair, &pyobj_fromCenter) &&
        pyopencv_to_safe(pyobj_windowName, windowName, ArgInfo("windowName", 0)) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_showCrosshair, showCrosshair, ArgInfo("showCrosshair", 0)) &&
        pyopencv_to_safe(pyobj_fromCenter, fromCenter, ArgInfo("fromCenter", 0)) )
    {
        ERRWRAP2(cv::selectROIs(windowName, img, boundingBoxes, showCrosshair, fromCenter));
        return pyopencv_from(boundingBoxes);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("selectROIs");

    return NULL;
}

static PyObject* pyopencv_cv_sepFilter2D(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_ddepth = NULL;
    int ddepth=0;
    PyObject* pyobj_kernelX = NULL;
    Mat kernelX;
    PyObject* pyobj_kernelY = NULL;
    Mat kernelY;
    PyObject* pyobj_anchor = NULL;
    Point anchor=Point(-1,-1);
    PyObject* pyobj_delta = NULL;
    double delta=0;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "ddepth", "kernelX", "kernelY", "dst", "anchor", "delta", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOO:sepFilter2D", (char**)keywords, &pyobj_src, &pyobj_ddepth, &pyobj_kernelX, &pyobj_kernelY, &pyobj_dst, &pyobj_anchor, &pyobj_delta, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_ddepth, ddepth, ArgInfo("ddepth", 0)) &&
        pyopencv_to_safe(pyobj_kernelX, kernelX, ArgInfo("kernelX", 0)) &&
        pyopencv_to_safe(pyobj_kernelY, kernelY, ArgInfo("kernelY", 0)) &&
        pyopencv_to_safe(pyobj_anchor, anchor, ArgInfo("anchor", 0)) &&
        pyopencv_to_safe(pyobj_delta, delta, ArgInfo("delta", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::sepFilter2D(src, dst, ddepth, kernelX, kernelY, anchor, delta, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_ddepth = NULL;
    int ddepth=0;
    PyObject* pyobj_kernelX = NULL;
    UMat kernelX;
    PyObject* pyobj_kernelY = NULL;
    UMat kernelY;
    PyObject* pyobj_anchor = NULL;
    Point anchor=Point(-1,-1);
    PyObject* pyobj_delta = NULL;
    double delta=0;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "ddepth", "kernelX", "kernelY", "dst", "anchor", "delta", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOO:sepFilter2D", (char**)keywords, &pyobj_src, &pyobj_ddepth, &pyobj_kernelX, &pyobj_kernelY, &pyobj_dst, &pyobj_anchor, &pyobj_delta, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_ddepth, ddepth, ArgInfo("ddepth", 0)) &&
        pyopencv_to_safe(pyobj_kernelX, kernelX, ArgInfo("kernelX", 0)) &&
        pyopencv_to_safe(pyobj_kernelY, kernelY, ArgInfo("kernelY", 0)) &&
        pyopencv_to_safe(pyobj_anchor, anchor, ArgInfo("anchor", 0)) &&
        pyopencv_to_safe(pyobj_delta, delta, ArgInfo("delta", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::sepFilter2D(src, dst, ddepth, kernelX, kernelY, anchor, delta, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("sepFilter2D");

    return NULL;
}

static PyObject* pyopencv_cv_setIdentity(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_mtx = NULL;
    Mat mtx;
    PyObject* pyobj_s = NULL;
    Scalar s=Scalar(1);

    const char* keywords[] = { "mtx", "s", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:setIdentity", (char**)keywords, &pyobj_mtx, &pyobj_s) &&
        pyopencv_to_safe(pyobj_mtx, mtx, ArgInfo("mtx", 1)) &&
        pyopencv_to_safe(pyobj_s, s, ArgInfo("s", 0)) )
    {
        ERRWRAP2(cv::setIdentity(mtx, s));
        return pyopencv_from(mtx);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_mtx = NULL;
    UMat mtx;
    PyObject* pyobj_s = NULL;
    Scalar s=Scalar(1);

    const char* keywords[] = { "mtx", "s", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:setIdentity", (char**)keywords, &pyobj_mtx, &pyobj_s) &&
        pyopencv_to_safe(pyobj_mtx, mtx, ArgInfo("mtx", 1)) &&
        pyopencv_to_safe(pyobj_s, s, ArgInfo("s", 0)) )
    {
        ERRWRAP2(cv::setIdentity(mtx, s));
        return pyopencv_from(mtx);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("setIdentity");

    return NULL;
}

static PyObject* pyopencv_cv_setLogLevel(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_level = NULL;
    int level=0;
    int retval;

    const char* keywords[] = { "level", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:setLogLevel", (char**)keywords, &pyobj_level) &&
        pyopencv_to_safe(pyobj_level, level, ArgInfo("level", 0)) )
    {
        ERRWRAP2(retval = cv::setLogLevel(level));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_setNumThreads(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_nthreads = NULL;
    int nthreads=0;

    const char* keywords[] = { "nthreads", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:setNumThreads", (char**)keywords, &pyobj_nthreads) &&
        pyopencv_to_safe(pyobj_nthreads, nthreads, ArgInfo("nthreads", 0)) )
    {
        ERRWRAP2(cv::setNumThreads(nthreads));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_setRNGSeed(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_seed = NULL;
    int seed=0;

    const char* keywords[] = { "seed", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:setRNGSeed", (char**)keywords, &pyobj_seed) &&
        pyopencv_to_safe(pyobj_seed, seed, ArgInfo("seed", 0)) )
    {
        ERRWRAP2(cv::setRNGSeed(seed));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_setTrackbarMax(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_trackbarname = NULL;
    String trackbarname;
    PyObject* pyobj_winname = NULL;
    String winname;
    PyObject* pyobj_maxval = NULL;
    int maxval=0;

    const char* keywords[] = { "trackbarname", "winname", "maxval", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:setTrackbarMax", (char**)keywords, &pyobj_trackbarname, &pyobj_winname, &pyobj_maxval) &&
        pyopencv_to_safe(pyobj_trackbarname, trackbarname, ArgInfo("trackbarname", 0)) &&
        pyopencv_to_safe(pyobj_winname, winname, ArgInfo("winname", 0)) &&
        pyopencv_to_safe(pyobj_maxval, maxval, ArgInfo("maxval", 0)) )
    {
        ERRWRAP2(cv::setTrackbarMax(trackbarname, winname, maxval));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_setTrackbarMin(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_trackbarname = NULL;
    String trackbarname;
    PyObject* pyobj_winname = NULL;
    String winname;
    PyObject* pyobj_minval = NULL;
    int minval=0;

    const char* keywords[] = { "trackbarname", "winname", "minval", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:setTrackbarMin", (char**)keywords, &pyobj_trackbarname, &pyobj_winname, &pyobj_minval) &&
        pyopencv_to_safe(pyobj_trackbarname, trackbarname, ArgInfo("trackbarname", 0)) &&
        pyopencv_to_safe(pyobj_winname, winname, ArgInfo("winname", 0)) &&
        pyopencv_to_safe(pyobj_minval, minval, ArgInfo("minval", 0)) )
    {
        ERRWRAP2(cv::setTrackbarMin(trackbarname, winname, minval));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_setTrackbarPos(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_trackbarname = NULL;
    String trackbarname;
    PyObject* pyobj_winname = NULL;
    String winname;
    PyObject* pyobj_pos = NULL;
    int pos=0;

    const char* keywords[] = { "trackbarname", "winname", "pos", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:setTrackbarPos", (char**)keywords, &pyobj_trackbarname, &pyobj_winname, &pyobj_pos) &&
        pyopencv_to_safe(pyobj_trackbarname, trackbarname, ArgInfo("trackbarname", 0)) &&
        pyopencv_to_safe(pyobj_winname, winname, ArgInfo("winname", 0)) &&
        pyopencv_to_safe(pyobj_pos, pos, ArgInfo("pos", 0)) )
    {
        ERRWRAP2(cv::setTrackbarPos(trackbarname, winname, pos));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_setUseOpenVX(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_flag = NULL;
    bool flag=0;

    const char* keywords[] = { "flag", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:setUseOpenVX", (char**)keywords, &pyobj_flag) &&
        pyopencv_to_safe(pyobj_flag, flag, ArgInfo("flag", 0)) )
    {
        ERRWRAP2(cv::setUseOpenVX(flag));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_setUseOptimized(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_onoff = NULL;
    bool onoff=0;

    const char* keywords[] = { "onoff", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:setUseOptimized", (char**)keywords, &pyobj_onoff) &&
        pyopencv_to_safe(pyobj_onoff, onoff, ArgInfo("onoff", 0)) )
    {
        ERRWRAP2(cv::setUseOptimized(onoff));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_setWindowProperty(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_winname = NULL;
    String winname;
    PyObject* pyobj_prop_id = NULL;
    int prop_id=0;
    PyObject* pyobj_prop_value = NULL;
    double prop_value=0;

    const char* keywords[] = { "winname", "prop_id", "prop_value", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:setWindowProperty", (char**)keywords, &pyobj_winname, &pyobj_prop_id, &pyobj_prop_value) &&
        pyopencv_to_safe(pyobj_winname, winname, ArgInfo("winname", 0)) &&
        pyopencv_to_safe(pyobj_prop_id, prop_id, ArgInfo("prop_id", 0)) &&
        pyopencv_to_safe(pyobj_prop_value, prop_value, ArgInfo("prop_value", 0)) )
    {
        ERRWRAP2(cv::setWindowProperty(winname, prop_id, prop_value));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_setWindowTitle(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_winname = NULL;
    String winname;
    PyObject* pyobj_title = NULL;
    String title;

    const char* keywords[] = { "winname", "title", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:setWindowTitle", (char**)keywords, &pyobj_winname, &pyobj_title) &&
        pyopencv_to_safe(pyobj_winname, winname, ArgInfo("winname", 0)) &&
        pyopencv_to_safe(pyobj_title, title, ArgInfo("title", 0)) )
    {
        ERRWRAP2(cv::setWindowTitle(winname, title));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_solve(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src1 = NULL;
    Mat src1;
    PyObject* pyobj_src2 = NULL;
    Mat src2;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_flags = NULL;
    int flags=DECOMP_LU;
    bool retval;

    const char* keywords[] = { "src1", "src2", "dst", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:solve", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_dst, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(retval = cv::solve(src1, src2, dst, flags));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(dst));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src1 = NULL;
    UMat src1;
    PyObject* pyobj_src2 = NULL;
    UMat src2;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_flags = NULL;
    int flags=DECOMP_LU;
    bool retval;

    const char* keywords[] = { "src1", "src2", "dst", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:solve", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_dst, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(retval = cv::solve(src1, src2, dst, flags));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(dst));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("solve");

    return NULL;
}

static PyObject* pyopencv_cv_solveCubic(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_coeffs = NULL;
    Mat coeffs;
    PyObject* pyobj_roots = NULL;
    Mat roots;
    int retval;

    const char* keywords[] = { "coeffs", "roots", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:solveCubic", (char**)keywords, &pyobj_coeffs, &pyobj_roots) &&
        pyopencv_to_safe(pyobj_coeffs, coeffs, ArgInfo("coeffs", 0)) &&
        pyopencv_to_safe(pyobj_roots, roots, ArgInfo("roots", 1)) )
    {
        ERRWRAP2(retval = cv::solveCubic(coeffs, roots));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(roots));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_coeffs = NULL;
    UMat coeffs;
    PyObject* pyobj_roots = NULL;
    UMat roots;
    int retval;

    const char* keywords[] = { "coeffs", "roots", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:solveCubic", (char**)keywords, &pyobj_coeffs, &pyobj_roots) &&
        pyopencv_to_safe(pyobj_coeffs, coeffs, ArgInfo("coeffs", 0)) &&
        pyopencv_to_safe(pyobj_roots, roots, ArgInfo("roots", 1)) )
    {
        ERRWRAP2(retval = cv::solveCubic(coeffs, roots));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(roots));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("solveCubic");

    return NULL;
}

static PyObject* pyopencv_cv_solveLP(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_Func = NULL;
    Mat Func;
    PyObject* pyobj_Constr = NULL;
    Mat Constr;
    PyObject* pyobj_z = NULL;
    Mat z;
    int retval;

    const char* keywords[] = { "Func", "Constr", "z", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:solveLP", (char**)keywords, &pyobj_Func, &pyobj_Constr, &pyobj_z) &&
        pyopencv_to_safe(pyobj_Func, Func, ArgInfo("Func", 0)) &&
        pyopencv_to_safe(pyobj_Constr, Constr, ArgInfo("Constr", 0)) &&
        pyopencv_to_safe(pyobj_z, z, ArgInfo("z", 1)) )
    {
        ERRWRAP2(retval = cv::solveLP(Func, Constr, z));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(z));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_Func = NULL;
    UMat Func;
    PyObject* pyobj_Constr = NULL;
    UMat Constr;
    PyObject* pyobj_z = NULL;
    UMat z;
    int retval;

    const char* keywords[] = { "Func", "Constr", "z", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:solveLP", (char**)keywords, &pyobj_Func, &pyobj_Constr, &pyobj_z) &&
        pyopencv_to_safe(pyobj_Func, Func, ArgInfo("Func", 0)) &&
        pyopencv_to_safe(pyobj_Constr, Constr, ArgInfo("Constr", 0)) &&
        pyopencv_to_safe(pyobj_z, z, ArgInfo("z", 1)) )
    {
        ERRWRAP2(retval = cv::solveLP(Func, Constr, z));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(z));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("solveLP");

    return NULL;
}

static PyObject* pyopencv_cv_solveP3P(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_objectPoints = NULL;
    Mat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    Mat imagePoints;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    Mat distCoeffs;
    PyObject* pyobj_rvecs = NULL;
    vector_Mat rvecs;
    PyObject* pyobj_tvecs = NULL;
    vector_Mat tvecs;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    int retval;

    const char* keywords[] = { "objectPoints", "imagePoints", "cameraMatrix", "distCoeffs", "flags", "rvecs", "tvecs", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OO:solveP3P", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_flags, &pyobj_rvecs, &pyobj_tvecs) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_rvecs, rvecs, ArgInfo("rvecs", 1)) &&
        pyopencv_to_safe(pyobj_tvecs, tvecs, ArgInfo("tvecs", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(retval = cv::solveP3P(objectPoints, imagePoints, cameraMatrix, distCoeffs, rvecs, tvecs, flags));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(rvecs), pyopencv_from(tvecs));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_objectPoints = NULL;
    UMat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    UMat imagePoints;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    UMat distCoeffs;
    PyObject* pyobj_rvecs = NULL;
    vector_UMat rvecs;
    PyObject* pyobj_tvecs = NULL;
    vector_UMat tvecs;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    int retval;

    const char* keywords[] = { "objectPoints", "imagePoints", "cameraMatrix", "distCoeffs", "flags", "rvecs", "tvecs", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OO:solveP3P", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_flags, &pyobj_rvecs, &pyobj_tvecs) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_rvecs, rvecs, ArgInfo("rvecs", 1)) &&
        pyopencv_to_safe(pyobj_tvecs, tvecs, ArgInfo("tvecs", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(retval = cv::solveP3P(objectPoints, imagePoints, cameraMatrix, distCoeffs, rvecs, tvecs, flags));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(rvecs), pyopencv_from(tvecs));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("solveP3P");

    return NULL;
}

static PyObject* pyopencv_cv_solvePnP(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_objectPoints = NULL;
    Mat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    Mat imagePoints;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    Mat distCoeffs;
    PyObject* pyobj_rvec = NULL;
    Mat rvec;
    PyObject* pyobj_tvec = NULL;
    Mat tvec;
    PyObject* pyobj_useExtrinsicGuess = NULL;
    bool useExtrinsicGuess=false;
    PyObject* pyobj_flags = NULL;
    int flags=SOLVEPNP_ITERATIVE;
    bool retval;

    const char* keywords[] = { "objectPoints", "imagePoints", "cameraMatrix", "distCoeffs", "rvec", "tvec", "useExtrinsicGuess", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOO:solvePnP", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvec, &pyobj_tvec, &pyobj_useExtrinsicGuess, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 1)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 1)) &&
        pyopencv_to_safe(pyobj_useExtrinsicGuess, useExtrinsicGuess, ArgInfo("useExtrinsicGuess", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(retval = cv::solvePnP(objectPoints, imagePoints, cameraMatrix, distCoeffs, rvec, tvec, useExtrinsicGuess, flags));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(rvec), pyopencv_from(tvec));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_objectPoints = NULL;
    UMat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    UMat imagePoints;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    UMat distCoeffs;
    PyObject* pyobj_rvec = NULL;
    UMat rvec;
    PyObject* pyobj_tvec = NULL;
    UMat tvec;
    PyObject* pyobj_useExtrinsicGuess = NULL;
    bool useExtrinsicGuess=false;
    PyObject* pyobj_flags = NULL;
    int flags=SOLVEPNP_ITERATIVE;
    bool retval;

    const char* keywords[] = { "objectPoints", "imagePoints", "cameraMatrix", "distCoeffs", "rvec", "tvec", "useExtrinsicGuess", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOO:solvePnP", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvec, &pyobj_tvec, &pyobj_useExtrinsicGuess, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 1)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 1)) &&
        pyopencv_to_safe(pyobj_useExtrinsicGuess, useExtrinsicGuess, ArgInfo("useExtrinsicGuess", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(retval = cv::solvePnP(objectPoints, imagePoints, cameraMatrix, distCoeffs, rvec, tvec, useExtrinsicGuess, flags));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(rvec), pyopencv_from(tvec));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("solvePnP");

    return NULL;
}

static PyObject* pyopencv_cv_solvePnPGeneric(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_objectPoints = NULL;
    Mat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    Mat imagePoints;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    Mat distCoeffs;
    PyObject* pyobj_rvecs = NULL;
    vector_Mat rvecs;
    PyObject* pyobj_tvecs = NULL;
    vector_Mat tvecs;
    PyObject* pyobj_useExtrinsicGuess = NULL;
    bool useExtrinsicGuess=false;
    PyObject* pyobj_flags = NULL;
    SolvePnPMethod flags=SOLVEPNP_ITERATIVE;
    PyObject* pyobj_rvec = NULL;
    Mat rvec;
    PyObject* pyobj_tvec = NULL;
    Mat tvec;
    PyObject* pyobj_reprojectionError = NULL;
    Mat reprojectionError;
    int retval;

    const char* keywords[] = { "objectPoints", "imagePoints", "cameraMatrix", "distCoeffs", "rvecs", "tvecs", "useExtrinsicGuess", "flags", "rvec", "tvec", "reprojectionError", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOOOOO:solvePnPGeneric", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvecs, &pyobj_tvecs, &pyobj_useExtrinsicGuess, &pyobj_flags, &pyobj_rvec, &pyobj_tvec, &pyobj_reprojectionError) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_rvecs, rvecs, ArgInfo("rvecs", 1)) &&
        pyopencv_to_safe(pyobj_tvecs, tvecs, ArgInfo("tvecs", 1)) &&
        pyopencv_to_safe(pyobj_useExtrinsicGuess, useExtrinsicGuess, ArgInfo("useExtrinsicGuess", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 0)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 0)) &&
        pyopencv_to_safe(pyobj_reprojectionError, reprojectionError, ArgInfo("reprojectionError", 1)) )
    {
        ERRWRAP2(retval = cv::solvePnPGeneric(objectPoints, imagePoints, cameraMatrix, distCoeffs, rvecs, tvecs, useExtrinsicGuess, flags, rvec, tvec, reprojectionError));
        return Py_BuildValue("(NNNN)", pyopencv_from(retval), pyopencv_from(rvecs), pyopencv_from(tvecs), pyopencv_from(reprojectionError));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_objectPoints = NULL;
    UMat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    UMat imagePoints;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    UMat distCoeffs;
    PyObject* pyobj_rvecs = NULL;
    vector_UMat rvecs;
    PyObject* pyobj_tvecs = NULL;
    vector_UMat tvecs;
    PyObject* pyobj_useExtrinsicGuess = NULL;
    bool useExtrinsicGuess=false;
    PyObject* pyobj_flags = NULL;
    SolvePnPMethod flags=SOLVEPNP_ITERATIVE;
    PyObject* pyobj_rvec = NULL;
    UMat rvec;
    PyObject* pyobj_tvec = NULL;
    UMat tvec;
    PyObject* pyobj_reprojectionError = NULL;
    UMat reprojectionError;
    int retval;

    const char* keywords[] = { "objectPoints", "imagePoints", "cameraMatrix", "distCoeffs", "rvecs", "tvecs", "useExtrinsicGuess", "flags", "rvec", "tvec", "reprojectionError", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOOOOO:solvePnPGeneric", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvecs, &pyobj_tvecs, &pyobj_useExtrinsicGuess, &pyobj_flags, &pyobj_rvec, &pyobj_tvec, &pyobj_reprojectionError) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_rvecs, rvecs, ArgInfo("rvecs", 1)) &&
        pyopencv_to_safe(pyobj_tvecs, tvecs, ArgInfo("tvecs", 1)) &&
        pyopencv_to_safe(pyobj_useExtrinsicGuess, useExtrinsicGuess, ArgInfo("useExtrinsicGuess", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 0)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 0)) &&
        pyopencv_to_safe(pyobj_reprojectionError, reprojectionError, ArgInfo("reprojectionError", 1)) )
    {
        ERRWRAP2(retval = cv::solvePnPGeneric(objectPoints, imagePoints, cameraMatrix, distCoeffs, rvecs, tvecs, useExtrinsicGuess, flags, rvec, tvec, reprojectionError));
        return Py_BuildValue("(NNNN)", pyopencv_from(retval), pyopencv_from(rvecs), pyopencv_from(tvecs), pyopencv_from(reprojectionError));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("solvePnPGeneric");

    return NULL;
}

static PyObject* pyopencv_cv_solvePnPRansac(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(4);

    {
    PyObject* pyobj_objectPoints = NULL;
    Mat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    Mat imagePoints;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    Mat distCoeffs;
    PyObject* pyobj_rvec = NULL;
    Mat rvec;
    PyObject* pyobj_tvec = NULL;
    Mat tvec;
    PyObject* pyobj_useExtrinsicGuess = NULL;
    bool useExtrinsicGuess=false;
    PyObject* pyobj_iterationsCount = NULL;
    int iterationsCount=100;
    PyObject* pyobj_reprojectionError = NULL;
    float reprojectionError=8.0;
    PyObject* pyobj_confidence = NULL;
    double confidence=0.99;
    PyObject* pyobj_inliers = NULL;
    Mat inliers;
    PyObject* pyobj_flags = NULL;
    int flags=SOLVEPNP_ITERATIVE;
    bool retval;

    const char* keywords[] = { "objectPoints", "imagePoints", "cameraMatrix", "distCoeffs", "rvec", "tvec", "useExtrinsicGuess", "iterationsCount", "reprojectionError", "confidence", "inliers", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOOOOOO:solvePnPRansac", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvec, &pyobj_tvec, &pyobj_useExtrinsicGuess, &pyobj_iterationsCount, &pyobj_reprojectionError, &pyobj_confidence, &pyobj_inliers, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 1)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 1)) &&
        pyopencv_to_safe(pyobj_useExtrinsicGuess, useExtrinsicGuess, ArgInfo("useExtrinsicGuess", 0)) &&
        pyopencv_to_safe(pyobj_iterationsCount, iterationsCount, ArgInfo("iterationsCount", 0)) &&
        pyopencv_to_safe(pyobj_reprojectionError, reprojectionError, ArgInfo("reprojectionError", 0)) &&
        pyopencv_to_safe(pyobj_confidence, confidence, ArgInfo("confidence", 0)) &&
        pyopencv_to_safe(pyobj_inliers, inliers, ArgInfo("inliers", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(retval = cv::solvePnPRansac(objectPoints, imagePoints, cameraMatrix, distCoeffs, rvec, tvec, useExtrinsicGuess, iterationsCount, reprojectionError, confidence, inliers, flags));
        return Py_BuildValue("(NNNN)", pyopencv_from(retval), pyopencv_from(rvec), pyopencv_from(tvec), pyopencv_from(inliers));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_objectPoints = NULL;
    UMat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    UMat imagePoints;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    UMat distCoeffs;
    PyObject* pyobj_rvec = NULL;
    UMat rvec;
    PyObject* pyobj_tvec = NULL;
    UMat tvec;
    PyObject* pyobj_useExtrinsicGuess = NULL;
    bool useExtrinsicGuess=false;
    PyObject* pyobj_iterationsCount = NULL;
    int iterationsCount=100;
    PyObject* pyobj_reprojectionError = NULL;
    float reprojectionError=8.0;
    PyObject* pyobj_confidence = NULL;
    double confidence=0.99;
    PyObject* pyobj_inliers = NULL;
    UMat inliers;
    PyObject* pyobj_flags = NULL;
    int flags=SOLVEPNP_ITERATIVE;
    bool retval;

    const char* keywords[] = { "objectPoints", "imagePoints", "cameraMatrix", "distCoeffs", "rvec", "tvec", "useExtrinsicGuess", "iterationsCount", "reprojectionError", "confidence", "inliers", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOOOOOO:solvePnPRansac", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvec, &pyobj_tvec, &pyobj_useExtrinsicGuess, &pyobj_iterationsCount, &pyobj_reprojectionError, &pyobj_confidence, &pyobj_inliers, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 1)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 1)) &&
        pyopencv_to_safe(pyobj_useExtrinsicGuess, useExtrinsicGuess, ArgInfo("useExtrinsicGuess", 0)) &&
        pyopencv_to_safe(pyobj_iterationsCount, iterationsCount, ArgInfo("iterationsCount", 0)) &&
        pyopencv_to_safe(pyobj_reprojectionError, reprojectionError, ArgInfo("reprojectionError", 0)) &&
        pyopencv_to_safe(pyobj_confidence, confidence, ArgInfo("confidence", 0)) &&
        pyopencv_to_safe(pyobj_inliers, inliers, ArgInfo("inliers", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(retval = cv::solvePnPRansac(objectPoints, imagePoints, cameraMatrix, distCoeffs, rvec, tvec, useExtrinsicGuess, iterationsCount, reprojectionError, confidence, inliers, flags));
        return Py_BuildValue("(NNNN)", pyopencv_from(retval), pyopencv_from(rvec), pyopencv_from(tvec), pyopencv_from(inliers));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_objectPoints = NULL;
    Mat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    Mat imagePoints;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    Mat distCoeffs;
    PyObject* pyobj_rvec = NULL;
    Mat rvec;
    PyObject* pyobj_tvec = NULL;
    Mat tvec;
    PyObject* pyobj_inliers = NULL;
    Mat inliers;
    PyObject* pyobj_params = NULL;
    UsacParams params;
    bool retval;

    const char* keywords[] = { "objectPoints", "imagePoints", "cameraMatrix", "distCoeffs", "rvec", "tvec", "inliers", "params", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOO:solvePnPRansac", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvec, &pyobj_tvec, &pyobj_inliers, &pyobj_params) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 1)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 1)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 1)) &&
        pyopencv_to_safe(pyobj_inliers, inliers, ArgInfo("inliers", 1)) &&
        pyopencv_to_safe(pyobj_params, params, ArgInfo("params", 0)) )
    {
        ERRWRAP2(retval = cv::solvePnPRansac(objectPoints, imagePoints, cameraMatrix, distCoeffs, rvec, tvec, inliers, params));
        return Py_BuildValue("(NNNNN)", pyopencv_from(retval), pyopencv_from(cameraMatrix), pyopencv_from(rvec), pyopencv_from(tvec), pyopencv_from(inliers));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_objectPoints = NULL;
    UMat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    UMat imagePoints;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    UMat distCoeffs;
    PyObject* pyobj_rvec = NULL;
    UMat rvec;
    PyObject* pyobj_tvec = NULL;
    UMat tvec;
    PyObject* pyobj_inliers = NULL;
    UMat inliers;
    PyObject* pyobj_params = NULL;
    UsacParams params;
    bool retval;

    const char* keywords[] = { "objectPoints", "imagePoints", "cameraMatrix", "distCoeffs", "rvec", "tvec", "inliers", "params", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOO:solvePnPRansac", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvec, &pyobj_tvec, &pyobj_inliers, &pyobj_params) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 1)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 1)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 1)) &&
        pyopencv_to_safe(pyobj_inliers, inliers, ArgInfo("inliers", 1)) &&
        pyopencv_to_safe(pyobj_params, params, ArgInfo("params", 0)) )
    {
        ERRWRAP2(retval = cv::solvePnPRansac(objectPoints, imagePoints, cameraMatrix, distCoeffs, rvec, tvec, inliers, params));
        return Py_BuildValue("(NNNNN)", pyopencv_from(retval), pyopencv_from(cameraMatrix), pyopencv_from(rvec), pyopencv_from(tvec), pyopencv_from(inliers));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("solvePnPRansac");

    return NULL;
}

static PyObject* pyopencv_cv_solvePnPRefineLM(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_objectPoints = NULL;
    Mat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    Mat imagePoints;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    Mat distCoeffs;
    PyObject* pyobj_rvec = NULL;
    Mat rvec;
    PyObject* pyobj_tvec = NULL;
    Mat tvec;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria(TermCriteria::EPS + TermCriteria::COUNT, 20, FLT_EPSILON);

    const char* keywords[] = { "objectPoints", "imagePoints", "cameraMatrix", "distCoeffs", "rvec", "tvec", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|O:solvePnPRefineLM", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvec, &pyobj_tvec, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 1)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 1)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(cv::solvePnPRefineLM(objectPoints, imagePoints, cameraMatrix, distCoeffs, rvec, tvec, criteria));
        return Py_BuildValue("(NN)", pyopencv_from(rvec), pyopencv_from(tvec));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_objectPoints = NULL;
    UMat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    UMat imagePoints;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    UMat distCoeffs;
    PyObject* pyobj_rvec = NULL;
    UMat rvec;
    PyObject* pyobj_tvec = NULL;
    UMat tvec;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria(TermCriteria::EPS + TermCriteria::COUNT, 20, FLT_EPSILON);

    const char* keywords[] = { "objectPoints", "imagePoints", "cameraMatrix", "distCoeffs", "rvec", "tvec", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|O:solvePnPRefineLM", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvec, &pyobj_tvec, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 1)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 1)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(cv::solvePnPRefineLM(objectPoints, imagePoints, cameraMatrix, distCoeffs, rvec, tvec, criteria));
        return Py_BuildValue("(NN)", pyopencv_from(rvec), pyopencv_from(tvec));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("solvePnPRefineLM");

    return NULL;
}

static PyObject* pyopencv_cv_solvePnPRefineVVS(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_objectPoints = NULL;
    Mat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    Mat imagePoints;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    Mat distCoeffs;
    PyObject* pyobj_rvec = NULL;
    Mat rvec;
    PyObject* pyobj_tvec = NULL;
    Mat tvec;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria(TermCriteria::EPS + TermCriteria::COUNT, 20, FLT_EPSILON);
    PyObject* pyobj_VVSlambda = NULL;
    double VVSlambda=1;

    const char* keywords[] = { "objectPoints", "imagePoints", "cameraMatrix", "distCoeffs", "rvec", "tvec", "criteria", "VVSlambda", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|OO:solvePnPRefineVVS", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvec, &pyobj_tvec, &pyobj_criteria, &pyobj_VVSlambda) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 1)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 1)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) &&
        pyopencv_to_safe(pyobj_VVSlambda, VVSlambda, ArgInfo("VVSlambda", 0)) )
    {
        ERRWRAP2(cv::solvePnPRefineVVS(objectPoints, imagePoints, cameraMatrix, distCoeffs, rvec, tvec, criteria, VVSlambda));
        return Py_BuildValue("(NN)", pyopencv_from(rvec), pyopencv_from(tvec));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_objectPoints = NULL;
    UMat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    UMat imagePoints;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    UMat distCoeffs;
    PyObject* pyobj_rvec = NULL;
    UMat rvec;
    PyObject* pyobj_tvec = NULL;
    UMat tvec;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria(TermCriteria::EPS + TermCriteria::COUNT, 20, FLT_EPSILON);
    PyObject* pyobj_VVSlambda = NULL;
    double VVSlambda=1;

    const char* keywords[] = { "objectPoints", "imagePoints", "cameraMatrix", "distCoeffs", "rvec", "tvec", "criteria", "VVSlambda", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|OO:solvePnPRefineVVS", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvec, &pyobj_tvec, &pyobj_criteria, &pyobj_VVSlambda) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 1)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 1)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) &&
        pyopencv_to_safe(pyobj_VVSlambda, VVSlambda, ArgInfo("VVSlambda", 0)) )
    {
        ERRWRAP2(cv::solvePnPRefineVVS(objectPoints, imagePoints, cameraMatrix, distCoeffs, rvec, tvec, criteria, VVSlambda));
        return Py_BuildValue("(NN)", pyopencv_from(rvec), pyopencv_from(tvec));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("solvePnPRefineVVS");

    return NULL;
}

static PyObject* pyopencv_cv_solvePoly(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_coeffs = NULL;
    Mat coeffs;
    PyObject* pyobj_roots = NULL;
    Mat roots;
    PyObject* pyobj_maxIters = NULL;
    int maxIters=300;
    double retval;

    const char* keywords[] = { "coeffs", "roots", "maxIters", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:solvePoly", (char**)keywords, &pyobj_coeffs, &pyobj_roots, &pyobj_maxIters) &&
        pyopencv_to_safe(pyobj_coeffs, coeffs, ArgInfo("coeffs", 0)) &&
        pyopencv_to_safe(pyobj_roots, roots, ArgInfo("roots", 1)) &&
        pyopencv_to_safe(pyobj_maxIters, maxIters, ArgInfo("maxIters", 0)) )
    {
        ERRWRAP2(retval = cv::solvePoly(coeffs, roots, maxIters));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(roots));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_coeffs = NULL;
    UMat coeffs;
    PyObject* pyobj_roots = NULL;
    UMat roots;
    PyObject* pyobj_maxIters = NULL;
    int maxIters=300;
    double retval;

    const char* keywords[] = { "coeffs", "roots", "maxIters", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:solvePoly", (char**)keywords, &pyobj_coeffs, &pyobj_roots, &pyobj_maxIters) &&
        pyopencv_to_safe(pyobj_coeffs, coeffs, ArgInfo("coeffs", 0)) &&
        pyopencv_to_safe(pyobj_roots, roots, ArgInfo("roots", 1)) &&
        pyopencv_to_safe(pyobj_maxIters, maxIters, ArgInfo("maxIters", 0)) )
    {
        ERRWRAP2(retval = cv::solvePoly(coeffs, roots, maxIters));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(roots));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("solvePoly");

    return NULL;
}

static PyObject* pyopencv_cv_sort(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_flags = NULL;
    int flags=0;

    const char* keywords[] = { "src", "flags", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:sort", (char**)keywords, &pyobj_src, &pyobj_flags, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::sort(src, dst, flags));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_flags = NULL;
    int flags=0;

    const char* keywords[] = { "src", "flags", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:sort", (char**)keywords, &pyobj_src, &pyobj_flags, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::sort(src, dst, flags));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("sort");

    return NULL;
}

static PyObject* pyopencv_cv_sortIdx(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_flags = NULL;
    int flags=0;

    const char* keywords[] = { "src", "flags", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:sortIdx", (char**)keywords, &pyobj_src, &pyobj_flags, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::sortIdx(src, dst, flags));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_flags = NULL;
    int flags=0;

    const char* keywords[] = { "src", "flags", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:sortIdx", (char**)keywords, &pyobj_src, &pyobj_flags, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::sortIdx(src, dst, flags));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("sortIdx");

    return NULL;
}

static PyObject* pyopencv_cv_spatialGradient(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dx = NULL;
    Mat dx;
    PyObject* pyobj_dy = NULL;
    Mat dy;
    PyObject* pyobj_ksize = NULL;
    int ksize=3;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "dx", "dy", "ksize", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOO:spatialGradient", (char**)keywords, &pyobj_src, &pyobj_dx, &pyobj_dy, &pyobj_ksize, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dx, dx, ArgInfo("dx", 1)) &&
        pyopencv_to_safe(pyobj_dy, dy, ArgInfo("dy", 1)) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::spatialGradient(src, dx, dy, ksize, borderType));
        return Py_BuildValue("(NN)", pyopencv_from(dx), pyopencv_from(dy));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dx = NULL;
    UMat dx;
    PyObject* pyobj_dy = NULL;
    UMat dy;
    PyObject* pyobj_ksize = NULL;
    int ksize=3;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "dx", "dy", "ksize", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOO:spatialGradient", (char**)keywords, &pyobj_src, &pyobj_dx, &pyobj_dy, &pyobj_ksize, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dx, dx, ArgInfo("dx", 1)) &&
        pyopencv_to_safe(pyobj_dy, dy, ArgInfo("dy", 1)) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::spatialGradient(src, dx, dy, ksize, borderType));
        return Py_BuildValue("(NN)", pyopencv_from(dx), pyopencv_from(dy));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("spatialGradient");

    return NULL;
}

static PyObject* pyopencv_cv_split(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_m = NULL;
    Mat m;
    PyObject* pyobj_mv = NULL;
    vector_Mat mv;

    const char* keywords[] = { "m", "mv", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:split", (char**)keywords, &pyobj_m, &pyobj_mv) &&
        pyopencv_to_safe(pyobj_m, m, ArgInfo("m", 0)) &&
        pyopencv_to_safe(pyobj_mv, mv, ArgInfo("mv", 1)) )
    {
        ERRWRAP2(cv::split(m, mv));
        return pyopencv_from(mv);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_m = NULL;
    UMat m;
    PyObject* pyobj_mv = NULL;
    vector_UMat mv;

    const char* keywords[] = { "m", "mv", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:split", (char**)keywords, &pyobj_m, &pyobj_mv) &&
        pyopencv_to_safe(pyobj_m, m, ArgInfo("m", 0)) &&
        pyopencv_to_safe(pyobj_mv, mv, ArgInfo("mv", 1)) )
    {
        ERRWRAP2(cv::split(m, mv));
        return pyopencv_from(mv);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("split");

    return NULL;
}

static PyObject* pyopencv_cv_sqrBoxFilter(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_ddepth = NULL;
    int ddepth=0;
    PyObject* pyobj_ksize = NULL;
    Size ksize;
    PyObject* pyobj_anchor = NULL;
    Point anchor=Point(-1, -1);
    PyObject* pyobj_normalize = NULL;
    bool normalize=true;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "ddepth", "ksize", "dst", "anchor", "normalize", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOO:sqrBoxFilter", (char**)keywords, &pyobj_src, &pyobj_ddepth, &pyobj_ksize, &pyobj_dst, &pyobj_anchor, &pyobj_normalize, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_ddepth, ddepth, ArgInfo("ddepth", 0)) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) &&
        pyopencv_to_safe(pyobj_anchor, anchor, ArgInfo("anchor", 0)) &&
        pyopencv_to_safe(pyobj_normalize, normalize, ArgInfo("normalize", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::sqrBoxFilter(src, dst, ddepth, ksize, anchor, normalize, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_ddepth = NULL;
    int ddepth=0;
    PyObject* pyobj_ksize = NULL;
    Size ksize;
    PyObject* pyobj_anchor = NULL;
    Point anchor=Point(-1, -1);
    PyObject* pyobj_normalize = NULL;
    bool normalize=true;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "ddepth", "ksize", "dst", "anchor", "normalize", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOO:sqrBoxFilter", (char**)keywords, &pyobj_src, &pyobj_ddepth, &pyobj_ksize, &pyobj_dst, &pyobj_anchor, &pyobj_normalize, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_ddepth, ddepth, ArgInfo("ddepth", 0)) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) &&
        pyopencv_to_safe(pyobj_anchor, anchor, ArgInfo("anchor", 0)) &&
        pyopencv_to_safe(pyobj_normalize, normalize, ArgInfo("normalize", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::sqrBoxFilter(src, dst, ddepth, ksize, anchor, normalize, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("sqrBoxFilter");

    return NULL;
}

static PyObject* pyopencv_cv_sqrt(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:sqrt", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::sqrt(src, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:sqrt", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::sqrt(src, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("sqrt");

    return NULL;
}

static PyObject* pyopencv_cv_startWindowThread(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    int retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::startWindowThread());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_stereoCalibrate(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_objectPoints = NULL;
    vector_Mat objectPoints;
    PyObject* pyobj_imagePoints1 = NULL;
    vector_Mat imagePoints1;
    PyObject* pyobj_imagePoints2 = NULL;
    vector_Mat imagePoints2;
    PyObject* pyobj_cameraMatrix1 = NULL;
    Mat cameraMatrix1;
    PyObject* pyobj_distCoeffs1 = NULL;
    Mat distCoeffs1;
    PyObject* pyobj_cameraMatrix2 = NULL;
    Mat cameraMatrix2;
    PyObject* pyobj_distCoeffs2 = NULL;
    Mat distCoeffs2;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_R = NULL;
    Mat R;
    PyObject* pyobj_T = NULL;
    Mat T;
    PyObject* pyobj_E = NULL;
    Mat E;
    PyObject* pyobj_F = NULL;
    Mat F;
    PyObject* pyobj_flags = NULL;
    int flags=CALIB_FIX_INTRINSIC;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, 1e-6);
    double retval;

    const char* keywords[] = { "objectPoints", "imagePoints1", "imagePoints2", "cameraMatrix1", "distCoeffs1", "cameraMatrix2", "distCoeffs2", "imageSize", "R", "T", "E", "F", "flags", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOOO|OOOOOO:stereoCalibrate", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints1, &pyobj_imagePoints2, &pyobj_cameraMatrix1, &pyobj_distCoeffs1, &pyobj_cameraMatrix2, &pyobj_distCoeffs2, &pyobj_imageSize, &pyobj_R, &pyobj_T, &pyobj_E, &pyobj_F, &pyobj_flags, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints1, imagePoints1, ArgInfo("imagePoints1", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints2, imagePoints2, ArgInfo("imagePoints2", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix1, cameraMatrix1, ArgInfo("cameraMatrix1", 1)) &&
        pyopencv_to_safe(pyobj_distCoeffs1, distCoeffs1, ArgInfo("distCoeffs1", 1)) &&
        pyopencv_to_safe(pyobj_cameraMatrix2, cameraMatrix2, ArgInfo("cameraMatrix2", 1)) &&
        pyopencv_to_safe(pyobj_distCoeffs2, distCoeffs2, ArgInfo("distCoeffs2", 1)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 1)) &&
        pyopencv_to_safe(pyobj_T, T, ArgInfo("T", 1)) &&
        pyopencv_to_safe(pyobj_E, E, ArgInfo("E", 1)) &&
        pyopencv_to_safe(pyobj_F, F, ArgInfo("F", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(retval = cv::stereoCalibrate(objectPoints, imagePoints1, imagePoints2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, imageSize, R, T, E, F, flags, criteria));
        return Py_BuildValue("(NNNNNNNNN)", pyopencv_from(retval), pyopencv_from(cameraMatrix1), pyopencv_from(distCoeffs1), pyopencv_from(cameraMatrix2), pyopencv_from(distCoeffs2), pyopencv_from(R), pyopencv_from(T), pyopencv_from(E), pyopencv_from(F));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_objectPoints = NULL;
    vector_UMat objectPoints;
    PyObject* pyobj_imagePoints1 = NULL;
    vector_UMat imagePoints1;
    PyObject* pyobj_imagePoints2 = NULL;
    vector_UMat imagePoints2;
    PyObject* pyobj_cameraMatrix1 = NULL;
    UMat cameraMatrix1;
    PyObject* pyobj_distCoeffs1 = NULL;
    UMat distCoeffs1;
    PyObject* pyobj_cameraMatrix2 = NULL;
    UMat cameraMatrix2;
    PyObject* pyobj_distCoeffs2 = NULL;
    UMat distCoeffs2;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_R = NULL;
    UMat R;
    PyObject* pyobj_T = NULL;
    UMat T;
    PyObject* pyobj_E = NULL;
    UMat E;
    PyObject* pyobj_F = NULL;
    UMat F;
    PyObject* pyobj_flags = NULL;
    int flags=CALIB_FIX_INTRINSIC;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, 1e-6);
    double retval;

    const char* keywords[] = { "objectPoints", "imagePoints1", "imagePoints2", "cameraMatrix1", "distCoeffs1", "cameraMatrix2", "distCoeffs2", "imageSize", "R", "T", "E", "F", "flags", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOOO|OOOOOO:stereoCalibrate", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints1, &pyobj_imagePoints2, &pyobj_cameraMatrix1, &pyobj_distCoeffs1, &pyobj_cameraMatrix2, &pyobj_distCoeffs2, &pyobj_imageSize, &pyobj_R, &pyobj_T, &pyobj_E, &pyobj_F, &pyobj_flags, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints1, imagePoints1, ArgInfo("imagePoints1", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints2, imagePoints2, ArgInfo("imagePoints2", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix1, cameraMatrix1, ArgInfo("cameraMatrix1", 1)) &&
        pyopencv_to_safe(pyobj_distCoeffs1, distCoeffs1, ArgInfo("distCoeffs1", 1)) &&
        pyopencv_to_safe(pyobj_cameraMatrix2, cameraMatrix2, ArgInfo("cameraMatrix2", 1)) &&
        pyopencv_to_safe(pyobj_distCoeffs2, distCoeffs2, ArgInfo("distCoeffs2", 1)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 1)) &&
        pyopencv_to_safe(pyobj_T, T, ArgInfo("T", 1)) &&
        pyopencv_to_safe(pyobj_E, E, ArgInfo("E", 1)) &&
        pyopencv_to_safe(pyobj_F, F, ArgInfo("F", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(retval = cv::stereoCalibrate(objectPoints, imagePoints1, imagePoints2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, imageSize, R, T, E, F, flags, criteria));
        return Py_BuildValue("(NNNNNNNNN)", pyopencv_from(retval), pyopencv_from(cameraMatrix1), pyopencv_from(distCoeffs1), pyopencv_from(cameraMatrix2), pyopencv_from(distCoeffs2), pyopencv_from(R), pyopencv_from(T), pyopencv_from(E), pyopencv_from(F));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("stereoCalibrate");

    return NULL;
}

static PyObject* pyopencv_cv_stereoCalibrateExtended(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_objectPoints = NULL;
    vector_Mat objectPoints;
    PyObject* pyobj_imagePoints1 = NULL;
    vector_Mat imagePoints1;
    PyObject* pyobj_imagePoints2 = NULL;
    vector_Mat imagePoints2;
    PyObject* pyobj_cameraMatrix1 = NULL;
    Mat cameraMatrix1;
    PyObject* pyobj_distCoeffs1 = NULL;
    Mat distCoeffs1;
    PyObject* pyobj_cameraMatrix2 = NULL;
    Mat cameraMatrix2;
    PyObject* pyobj_distCoeffs2 = NULL;
    Mat distCoeffs2;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_R = NULL;
    Mat R;
    PyObject* pyobj_T = NULL;
    Mat T;
    PyObject* pyobj_E = NULL;
    Mat E;
    PyObject* pyobj_F = NULL;
    Mat F;
    PyObject* pyobj_perViewErrors = NULL;
    Mat perViewErrors;
    PyObject* pyobj_flags = NULL;
    int flags=CALIB_FIX_INTRINSIC;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, 1e-6);
    double retval;

    const char* keywords[] = { "objectPoints", "imagePoints1", "imagePoints2", "cameraMatrix1", "distCoeffs1", "cameraMatrix2", "distCoeffs2", "imageSize", "R", "T", "E", "F", "perViewErrors", "flags", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOOOOO|OOOOO:stereoCalibrateExtended", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints1, &pyobj_imagePoints2, &pyobj_cameraMatrix1, &pyobj_distCoeffs1, &pyobj_cameraMatrix2, &pyobj_distCoeffs2, &pyobj_imageSize, &pyobj_R, &pyobj_T, &pyobj_E, &pyobj_F, &pyobj_perViewErrors, &pyobj_flags, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints1, imagePoints1, ArgInfo("imagePoints1", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints2, imagePoints2, ArgInfo("imagePoints2", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix1, cameraMatrix1, ArgInfo("cameraMatrix1", 1)) &&
        pyopencv_to_safe(pyobj_distCoeffs1, distCoeffs1, ArgInfo("distCoeffs1", 1)) &&
        pyopencv_to_safe(pyobj_cameraMatrix2, cameraMatrix2, ArgInfo("cameraMatrix2", 1)) &&
        pyopencv_to_safe(pyobj_distCoeffs2, distCoeffs2, ArgInfo("distCoeffs2", 1)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 1)) &&
        pyopencv_to_safe(pyobj_T, T, ArgInfo("T", 1)) &&
        pyopencv_to_safe(pyobj_E, E, ArgInfo("E", 1)) &&
        pyopencv_to_safe(pyobj_F, F, ArgInfo("F", 1)) &&
        pyopencv_to_safe(pyobj_perViewErrors, perViewErrors, ArgInfo("perViewErrors", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(retval = cv::stereoCalibrate(objectPoints, imagePoints1, imagePoints2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, imageSize, R, T, E, F, perViewErrors, flags, criteria));
        return Py_BuildValue("(NNNNNNNNNN)", pyopencv_from(retval), pyopencv_from(cameraMatrix1), pyopencv_from(distCoeffs1), pyopencv_from(cameraMatrix2), pyopencv_from(distCoeffs2), pyopencv_from(R), pyopencv_from(T), pyopencv_from(E), pyopencv_from(F), pyopencv_from(perViewErrors));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_objectPoints = NULL;
    vector_UMat objectPoints;
    PyObject* pyobj_imagePoints1 = NULL;
    vector_UMat imagePoints1;
    PyObject* pyobj_imagePoints2 = NULL;
    vector_UMat imagePoints2;
    PyObject* pyobj_cameraMatrix1 = NULL;
    UMat cameraMatrix1;
    PyObject* pyobj_distCoeffs1 = NULL;
    UMat distCoeffs1;
    PyObject* pyobj_cameraMatrix2 = NULL;
    UMat cameraMatrix2;
    PyObject* pyobj_distCoeffs2 = NULL;
    UMat distCoeffs2;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_R = NULL;
    UMat R;
    PyObject* pyobj_T = NULL;
    UMat T;
    PyObject* pyobj_E = NULL;
    UMat E;
    PyObject* pyobj_F = NULL;
    UMat F;
    PyObject* pyobj_perViewErrors = NULL;
    UMat perViewErrors;
    PyObject* pyobj_flags = NULL;
    int flags=CALIB_FIX_INTRINSIC;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, 1e-6);
    double retval;

    const char* keywords[] = { "objectPoints", "imagePoints1", "imagePoints2", "cameraMatrix1", "distCoeffs1", "cameraMatrix2", "distCoeffs2", "imageSize", "R", "T", "E", "F", "perViewErrors", "flags", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOOOOO|OOOOO:stereoCalibrateExtended", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints1, &pyobj_imagePoints2, &pyobj_cameraMatrix1, &pyobj_distCoeffs1, &pyobj_cameraMatrix2, &pyobj_distCoeffs2, &pyobj_imageSize, &pyobj_R, &pyobj_T, &pyobj_E, &pyobj_F, &pyobj_perViewErrors, &pyobj_flags, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints1, imagePoints1, ArgInfo("imagePoints1", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints2, imagePoints2, ArgInfo("imagePoints2", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix1, cameraMatrix1, ArgInfo("cameraMatrix1", 1)) &&
        pyopencv_to_safe(pyobj_distCoeffs1, distCoeffs1, ArgInfo("distCoeffs1", 1)) &&
        pyopencv_to_safe(pyobj_cameraMatrix2, cameraMatrix2, ArgInfo("cameraMatrix2", 1)) &&
        pyopencv_to_safe(pyobj_distCoeffs2, distCoeffs2, ArgInfo("distCoeffs2", 1)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 1)) &&
        pyopencv_to_safe(pyobj_T, T, ArgInfo("T", 1)) &&
        pyopencv_to_safe(pyobj_E, E, ArgInfo("E", 1)) &&
        pyopencv_to_safe(pyobj_F, F, ArgInfo("F", 1)) &&
        pyopencv_to_safe(pyobj_perViewErrors, perViewErrors, ArgInfo("perViewErrors", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(retval = cv::stereoCalibrate(objectPoints, imagePoints1, imagePoints2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, imageSize, R, T, E, F, perViewErrors, flags, criteria));
        return Py_BuildValue("(NNNNNNNNNN)", pyopencv_from(retval), pyopencv_from(cameraMatrix1), pyopencv_from(distCoeffs1), pyopencv_from(cameraMatrix2), pyopencv_from(distCoeffs2), pyopencv_from(R), pyopencv_from(T), pyopencv_from(E), pyopencv_from(F), pyopencv_from(perViewErrors));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("stereoCalibrateExtended");

    return NULL;
}

static PyObject* pyopencv_cv_stereoRectify(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_cameraMatrix1 = NULL;
    Mat cameraMatrix1;
    PyObject* pyobj_distCoeffs1 = NULL;
    Mat distCoeffs1;
    PyObject* pyobj_cameraMatrix2 = NULL;
    Mat cameraMatrix2;
    PyObject* pyobj_distCoeffs2 = NULL;
    Mat distCoeffs2;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_R = NULL;
    Mat R;
    PyObject* pyobj_T = NULL;
    Mat T;
    PyObject* pyobj_R1 = NULL;
    Mat R1;
    PyObject* pyobj_R2 = NULL;
    Mat R2;
    PyObject* pyobj_P1 = NULL;
    Mat P1;
    PyObject* pyobj_P2 = NULL;
    Mat P2;
    PyObject* pyobj_Q = NULL;
    Mat Q;
    PyObject* pyobj_flags = NULL;
    int flags=CALIB_ZERO_DISPARITY;
    PyObject* pyobj_alpha = NULL;
    double alpha=-1;
    PyObject* pyobj_newImageSize = NULL;
    Size newImageSize;
    Rect validPixROI1;
    Rect validPixROI2;

    const char* keywords[] = { "cameraMatrix1", "distCoeffs1", "cameraMatrix2", "distCoeffs2", "imageSize", "R", "T", "R1", "R2", "P1", "P2", "Q", "flags", "alpha", "newImageSize", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOO|OOOOOOOO:stereoRectify", (char**)keywords, &pyobj_cameraMatrix1, &pyobj_distCoeffs1, &pyobj_cameraMatrix2, &pyobj_distCoeffs2, &pyobj_imageSize, &pyobj_R, &pyobj_T, &pyobj_R1, &pyobj_R2, &pyobj_P1, &pyobj_P2, &pyobj_Q, &pyobj_flags, &pyobj_alpha, &pyobj_newImageSize) &&
        pyopencv_to_safe(pyobj_cameraMatrix1, cameraMatrix1, ArgInfo("cameraMatrix1", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs1, distCoeffs1, ArgInfo("distCoeffs1", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix2, cameraMatrix2, ArgInfo("cameraMatrix2", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs2, distCoeffs2, ArgInfo("distCoeffs2", 0)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) &&
        pyopencv_to_safe(pyobj_T, T, ArgInfo("T", 0)) &&
        pyopencv_to_safe(pyobj_R1, R1, ArgInfo("R1", 1)) &&
        pyopencv_to_safe(pyobj_R2, R2, ArgInfo("R2", 1)) &&
        pyopencv_to_safe(pyobj_P1, P1, ArgInfo("P1", 1)) &&
        pyopencv_to_safe(pyobj_P2, P2, ArgInfo("P2", 1)) &&
        pyopencv_to_safe(pyobj_Q, Q, ArgInfo("Q", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_newImageSize, newImageSize, ArgInfo("newImageSize", 0)) )
    {
        ERRWRAP2(cv::stereoRectify(cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, imageSize, R, T, R1, R2, P1, P2, Q, flags, alpha, newImageSize, &validPixROI1, &validPixROI2));
        return Py_BuildValue("(NNNNNNN)", pyopencv_from(R1), pyopencv_from(R2), pyopencv_from(P1), pyopencv_from(P2), pyopencv_from(Q), pyopencv_from(validPixROI1), pyopencv_from(validPixROI2));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_cameraMatrix1 = NULL;
    UMat cameraMatrix1;
    PyObject* pyobj_distCoeffs1 = NULL;
    UMat distCoeffs1;
    PyObject* pyobj_cameraMatrix2 = NULL;
    UMat cameraMatrix2;
    PyObject* pyobj_distCoeffs2 = NULL;
    UMat distCoeffs2;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_R = NULL;
    UMat R;
    PyObject* pyobj_T = NULL;
    UMat T;
    PyObject* pyobj_R1 = NULL;
    UMat R1;
    PyObject* pyobj_R2 = NULL;
    UMat R2;
    PyObject* pyobj_P1 = NULL;
    UMat P1;
    PyObject* pyobj_P2 = NULL;
    UMat P2;
    PyObject* pyobj_Q = NULL;
    UMat Q;
    PyObject* pyobj_flags = NULL;
    int flags=CALIB_ZERO_DISPARITY;
    PyObject* pyobj_alpha = NULL;
    double alpha=-1;
    PyObject* pyobj_newImageSize = NULL;
    Size newImageSize;
    Rect validPixROI1;
    Rect validPixROI2;

    const char* keywords[] = { "cameraMatrix1", "distCoeffs1", "cameraMatrix2", "distCoeffs2", "imageSize", "R", "T", "R1", "R2", "P1", "P2", "Q", "flags", "alpha", "newImageSize", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOO|OOOOOOOO:stereoRectify", (char**)keywords, &pyobj_cameraMatrix1, &pyobj_distCoeffs1, &pyobj_cameraMatrix2, &pyobj_distCoeffs2, &pyobj_imageSize, &pyobj_R, &pyobj_T, &pyobj_R1, &pyobj_R2, &pyobj_P1, &pyobj_P2, &pyobj_Q, &pyobj_flags, &pyobj_alpha, &pyobj_newImageSize) &&
        pyopencv_to_safe(pyobj_cameraMatrix1, cameraMatrix1, ArgInfo("cameraMatrix1", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs1, distCoeffs1, ArgInfo("distCoeffs1", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix2, cameraMatrix2, ArgInfo("cameraMatrix2", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs2, distCoeffs2, ArgInfo("distCoeffs2", 0)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) &&
        pyopencv_to_safe(pyobj_T, T, ArgInfo("T", 0)) &&
        pyopencv_to_safe(pyobj_R1, R1, ArgInfo("R1", 1)) &&
        pyopencv_to_safe(pyobj_R2, R2, ArgInfo("R2", 1)) &&
        pyopencv_to_safe(pyobj_P1, P1, ArgInfo("P1", 1)) &&
        pyopencv_to_safe(pyobj_P2, P2, ArgInfo("P2", 1)) &&
        pyopencv_to_safe(pyobj_Q, Q, ArgInfo("Q", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_newImageSize, newImageSize, ArgInfo("newImageSize", 0)) )
    {
        ERRWRAP2(cv::stereoRectify(cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, imageSize, R, T, R1, R2, P1, P2, Q, flags, alpha, newImageSize, &validPixROI1, &validPixROI2));
        return Py_BuildValue("(NNNNNNN)", pyopencv_from(R1), pyopencv_from(R2), pyopencv_from(P1), pyopencv_from(P2), pyopencv_from(Q), pyopencv_from(validPixROI1), pyopencv_from(validPixROI2));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("stereoRectify");

    return NULL;
}

static PyObject* pyopencv_cv_stereoRectifyUncalibrated(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_points1 = NULL;
    Mat points1;
    PyObject* pyobj_points2 = NULL;
    Mat points2;
    PyObject* pyobj_F = NULL;
    Mat F;
    PyObject* pyobj_imgSize = NULL;
    Size imgSize;
    PyObject* pyobj_H1 = NULL;
    Mat H1;
    PyObject* pyobj_H2 = NULL;
    Mat H2;
    PyObject* pyobj_threshold = NULL;
    double threshold=5;
    bool retval;

    const char* keywords[] = { "points1", "points2", "F", "imgSize", "H1", "H2", "threshold", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:stereoRectifyUncalibrated", (char**)keywords, &pyobj_points1, &pyobj_points2, &pyobj_F, &pyobj_imgSize, &pyobj_H1, &pyobj_H2, &pyobj_threshold) &&
        pyopencv_to_safe(pyobj_points1, points1, ArgInfo("points1", 0)) &&
        pyopencv_to_safe(pyobj_points2, points2, ArgInfo("points2", 0)) &&
        pyopencv_to_safe(pyobj_F, F, ArgInfo("F", 0)) &&
        pyopencv_to_safe(pyobj_imgSize, imgSize, ArgInfo("imgSize", 0)) &&
        pyopencv_to_safe(pyobj_H1, H1, ArgInfo("H1", 1)) &&
        pyopencv_to_safe(pyobj_H2, H2, ArgInfo("H2", 1)) &&
        pyopencv_to_safe(pyobj_threshold, threshold, ArgInfo("threshold", 0)) )
    {
        ERRWRAP2(retval = cv::stereoRectifyUncalibrated(points1, points2, F, imgSize, H1, H2, threshold));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(H1), pyopencv_from(H2));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_points1 = NULL;
    UMat points1;
    PyObject* pyobj_points2 = NULL;
    UMat points2;
    PyObject* pyobj_F = NULL;
    UMat F;
    PyObject* pyobj_imgSize = NULL;
    Size imgSize;
    PyObject* pyobj_H1 = NULL;
    UMat H1;
    PyObject* pyobj_H2 = NULL;
    UMat H2;
    PyObject* pyobj_threshold = NULL;
    double threshold=5;
    bool retval;

    const char* keywords[] = { "points1", "points2", "F", "imgSize", "H1", "H2", "threshold", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:stereoRectifyUncalibrated", (char**)keywords, &pyobj_points1, &pyobj_points2, &pyobj_F, &pyobj_imgSize, &pyobj_H1, &pyobj_H2, &pyobj_threshold) &&
        pyopencv_to_safe(pyobj_points1, points1, ArgInfo("points1", 0)) &&
        pyopencv_to_safe(pyobj_points2, points2, ArgInfo("points2", 0)) &&
        pyopencv_to_safe(pyobj_F, F, ArgInfo("F", 0)) &&
        pyopencv_to_safe(pyobj_imgSize, imgSize, ArgInfo("imgSize", 0)) &&
        pyopencv_to_safe(pyobj_H1, H1, ArgInfo("H1", 1)) &&
        pyopencv_to_safe(pyobj_H2, H2, ArgInfo("H2", 1)) &&
        pyopencv_to_safe(pyobj_threshold, threshold, ArgInfo("threshold", 0)) )
    {
        ERRWRAP2(retval = cv::stereoRectifyUncalibrated(points1, points2, F, imgSize, H1, H2, threshold));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(H1), pyopencv_from(H2));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("stereoRectifyUncalibrated");

    return NULL;
}

static PyObject* pyopencv_cv_stylization(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_sigma_s = NULL;
    float sigma_s=60;
    PyObject* pyobj_sigma_r = NULL;
    float sigma_r=0.45f;

    const char* keywords[] = { "src", "dst", "sigma_s", "sigma_r", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:stylization", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_sigma_s, &pyobj_sigma_r) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_sigma_s, sigma_s, ArgInfo("sigma_s", 0)) &&
        pyopencv_to_safe(pyobj_sigma_r, sigma_r, ArgInfo("sigma_r", 0)) )
    {
        ERRWRAP2(cv::stylization(src, dst, sigma_s, sigma_r));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_sigma_s = NULL;
    float sigma_s=60;
    PyObject* pyobj_sigma_r = NULL;
    float sigma_r=0.45f;

    const char* keywords[] = { "src", "dst", "sigma_s", "sigma_r", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:stylization", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_sigma_s, &pyobj_sigma_r) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_sigma_s, sigma_s, ArgInfo("sigma_s", 0)) &&
        pyopencv_to_safe(pyobj_sigma_r, sigma_r, ArgInfo("sigma_r", 0)) )
    {
        ERRWRAP2(cv::stylization(src, dst, sigma_s, sigma_r));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("stylization");

    return NULL;
}

static PyObject* pyopencv_cv_subtract(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src1 = NULL;
    Mat src1;
    PyObject* pyobj_src2 = NULL;
    Mat src2;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_dtype = NULL;
    int dtype=-1;

    const char* keywords[] = { "src1", "src2", "dst", "mask", "dtype", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:subtract", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_dst, &pyobj_mask, &pyobj_dtype) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_dtype, dtype, ArgInfo("dtype", 0)) )
    {
        ERRWRAP2(cv::subtract(src1, src2, dst, mask, dtype));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src1 = NULL;
    UMat src1;
    PyObject* pyobj_src2 = NULL;
    UMat src2;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    PyObject* pyobj_dtype = NULL;
    int dtype=-1;

    const char* keywords[] = { "src1", "src2", "dst", "mask", "dtype", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:subtract", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_dst, &pyobj_mask, &pyobj_dtype) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_dtype, dtype, ArgInfo("dtype", 0)) )
    {
        ERRWRAP2(cv::subtract(src1, src2, dst, mask, dtype));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("subtract");

    return NULL;
}

static PyObject* pyopencv_cv_sumElems(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    Scalar retval;

    const char* keywords[] = { "src", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:sumElems", (char**)keywords, &pyobj_src) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) )
    {
        ERRWRAP2(retval = cv::sum(src));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    Scalar retval;

    const char* keywords[] = { "src", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:sumElems", (char**)keywords, &pyobj_src) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) )
    {
        ERRWRAP2(retval = cv::sum(src));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("sumElems");

    return NULL;
}

static PyObject* pyopencv_cv_textureFlattening(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_low_threshold = NULL;
    float low_threshold=30;
    PyObject* pyobj_high_threshold = NULL;
    float high_threshold=45;
    PyObject* pyobj_kernel_size = NULL;
    int kernel_size=3;

    const char* keywords[] = { "src", "mask", "dst", "low_threshold", "high_threshold", "kernel_size", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOO:textureFlattening", (char**)keywords, &pyobj_src, &pyobj_mask, &pyobj_dst, &pyobj_low_threshold, &pyobj_high_threshold, &pyobj_kernel_size) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_low_threshold, low_threshold, ArgInfo("low_threshold", 0)) &&
        pyopencv_to_safe(pyobj_high_threshold, high_threshold, ArgInfo("high_threshold", 0)) &&
        pyopencv_to_safe(pyobj_kernel_size, kernel_size, ArgInfo("kernel_size", 0)) )
    {
        ERRWRAP2(cv::textureFlattening(src, mask, dst, low_threshold, high_threshold, kernel_size));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_low_threshold = NULL;
    float low_threshold=30;
    PyObject* pyobj_high_threshold = NULL;
    float high_threshold=45;
    PyObject* pyobj_kernel_size = NULL;
    int kernel_size=3;

    const char* keywords[] = { "src", "mask", "dst", "low_threshold", "high_threshold", "kernel_size", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOO:textureFlattening", (char**)keywords, &pyobj_src, &pyobj_mask, &pyobj_dst, &pyobj_low_threshold, &pyobj_high_threshold, &pyobj_kernel_size) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_low_threshold, low_threshold, ArgInfo("low_threshold", 0)) &&
        pyopencv_to_safe(pyobj_high_threshold, high_threshold, ArgInfo("high_threshold", 0)) &&
        pyopencv_to_safe(pyobj_kernel_size, kernel_size, ArgInfo("kernel_size", 0)) )
    {
        ERRWRAP2(cv::textureFlattening(src, mask, dst, low_threshold, high_threshold, kernel_size));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("textureFlattening");

    return NULL;
}

static PyObject* pyopencv_cv_threshold(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_thresh = NULL;
    double thresh=0;
    PyObject* pyobj_maxval = NULL;
    double maxval=0;
    PyObject* pyobj_type = NULL;
    int type=0;
    double retval;

    const char* keywords[] = { "src", "thresh", "maxval", "type", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:threshold", (char**)keywords, &pyobj_src, &pyobj_thresh, &pyobj_maxval, &pyobj_type, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_thresh, thresh, ArgInfo("thresh", 0)) &&
        pyopencv_to_safe(pyobj_maxval, maxval, ArgInfo("maxval", 0)) &&
        pyopencv_to_safe(pyobj_type, type, ArgInfo("type", 0)) )
    {
        ERRWRAP2(retval = cv::threshold(src, dst, thresh, maxval, type));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(dst));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_thresh = NULL;
    double thresh=0;
    PyObject* pyobj_maxval = NULL;
    double maxval=0;
    PyObject* pyobj_type = NULL;
    int type=0;
    double retval;

    const char* keywords[] = { "src", "thresh", "maxval", "type", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:threshold", (char**)keywords, &pyobj_src, &pyobj_thresh, &pyobj_maxval, &pyobj_type, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_thresh, thresh, ArgInfo("thresh", 0)) &&
        pyopencv_to_safe(pyobj_maxval, maxval, ArgInfo("maxval", 0)) &&
        pyopencv_to_safe(pyobj_type, type, ArgInfo("type", 0)) )
    {
        ERRWRAP2(retval = cv::threshold(src, dst, thresh, maxval, type));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(dst));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("threshold");

    return NULL;
}

static PyObject* pyopencv_cv_trace(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_mtx = NULL;
    Mat mtx;
    Scalar retval;

    const char* keywords[] = { "mtx", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:trace", (char**)keywords, &pyobj_mtx) &&
        pyopencv_to_safe(pyobj_mtx, mtx, ArgInfo("mtx", 0)) )
    {
        ERRWRAP2(retval = cv::trace(mtx));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_mtx = NULL;
    UMat mtx;
    Scalar retval;

    const char* keywords[] = { "mtx", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:trace", (char**)keywords, &pyobj_mtx) &&
        pyopencv_to_safe(pyobj_mtx, mtx, ArgInfo("mtx", 0)) )
    {
        ERRWRAP2(retval = cv::trace(mtx));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("trace");

    return NULL;
}

static PyObject* pyopencv_cv_transform(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_m = NULL;
    Mat m;

    const char* keywords[] = { "src", "m", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:transform", (char**)keywords, &pyobj_src, &pyobj_m, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_m, m, ArgInfo("m", 0)) )
    {
        ERRWRAP2(cv::transform(src, dst, m));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_m = NULL;
    UMat m;

    const char* keywords[] = { "src", "m", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:transform", (char**)keywords, &pyobj_src, &pyobj_m, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_m, m, ArgInfo("m", 0)) )
    {
        ERRWRAP2(cv::transform(src, dst, m));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("transform");

    return NULL;
}

static PyObject* pyopencv_cv_transpose(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:transpose", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::transpose(src, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:transpose", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::transpose(src, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("transpose");

    return NULL;
}

static PyObject* pyopencv_cv_triangulatePoints(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_projMatr1 = NULL;
    Mat projMatr1;
    PyObject* pyobj_projMatr2 = NULL;
    Mat projMatr2;
    PyObject* pyobj_projPoints1 = NULL;
    Mat projPoints1;
    PyObject* pyobj_projPoints2 = NULL;
    Mat projPoints2;
    PyObject* pyobj_points4D = NULL;
    Mat points4D;

    const char* keywords[] = { "projMatr1", "projMatr2", "projPoints1", "projPoints2", "points4D", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:triangulatePoints", (char**)keywords, &pyobj_projMatr1, &pyobj_projMatr2, &pyobj_projPoints1, &pyobj_projPoints2, &pyobj_points4D) &&
        pyopencv_to_safe(pyobj_projMatr1, projMatr1, ArgInfo("projMatr1", 0)) &&
        pyopencv_to_safe(pyobj_projMatr2, projMatr2, ArgInfo("projMatr2", 0)) &&
        pyopencv_to_safe(pyobj_projPoints1, projPoints1, ArgInfo("projPoints1", 0)) &&
        pyopencv_to_safe(pyobj_projPoints2, projPoints2, ArgInfo("projPoints2", 0)) &&
        pyopencv_to_safe(pyobj_points4D, points4D, ArgInfo("points4D", 1)) )
    {
        ERRWRAP2(cv::triangulatePoints(projMatr1, projMatr2, projPoints1, projPoints2, points4D));
        return pyopencv_from(points4D);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_projMatr1 = NULL;
    UMat projMatr1;
    PyObject* pyobj_projMatr2 = NULL;
    UMat projMatr2;
    PyObject* pyobj_projPoints1 = NULL;
    UMat projPoints1;
    PyObject* pyobj_projPoints2 = NULL;
    UMat projPoints2;
    PyObject* pyobj_points4D = NULL;
    UMat points4D;

    const char* keywords[] = { "projMatr1", "projMatr2", "projPoints1", "projPoints2", "points4D", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:triangulatePoints", (char**)keywords, &pyobj_projMatr1, &pyobj_projMatr2, &pyobj_projPoints1, &pyobj_projPoints2, &pyobj_points4D) &&
        pyopencv_to_safe(pyobj_projMatr1, projMatr1, ArgInfo("projMatr1", 0)) &&
        pyopencv_to_safe(pyobj_projMatr2, projMatr2, ArgInfo("projMatr2", 0)) &&
        pyopencv_to_safe(pyobj_projPoints1, projPoints1, ArgInfo("projPoints1", 0)) &&
        pyopencv_to_safe(pyobj_projPoints2, projPoints2, ArgInfo("projPoints2", 0)) &&
        pyopencv_to_safe(pyobj_points4D, points4D, ArgInfo("points4D", 1)) )
    {
        ERRWRAP2(cv::triangulatePoints(projMatr1, projMatr2, projPoints1, projPoints2, points4D));
        return pyopencv_from(points4D);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("triangulatePoints");

    return NULL;
}

static PyObject* pyopencv_cv_undistort(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    Mat distCoeffs;
    PyObject* pyobj_newCameraMatrix = NULL;
    Mat newCameraMatrix;

    const char* keywords[] = { "src", "cameraMatrix", "distCoeffs", "dst", "newCameraMatrix", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:undistort", (char**)keywords, &pyobj_src, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_dst, &pyobj_newCameraMatrix) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_newCameraMatrix, newCameraMatrix, ArgInfo("newCameraMatrix", 0)) )
    {
        ERRWRAP2(cv::undistort(src, dst, cameraMatrix, distCoeffs, newCameraMatrix));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    UMat distCoeffs;
    PyObject* pyobj_newCameraMatrix = NULL;
    UMat newCameraMatrix;

    const char* keywords[] = { "src", "cameraMatrix", "distCoeffs", "dst", "newCameraMatrix", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:undistort", (char**)keywords, &pyobj_src, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_dst, &pyobj_newCameraMatrix) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_newCameraMatrix, newCameraMatrix, ArgInfo("newCameraMatrix", 0)) )
    {
        ERRWRAP2(cv::undistort(src, dst, cameraMatrix, distCoeffs, newCameraMatrix));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("undistort");

    return NULL;
}

static PyObject* pyopencv_cv_undistortPoints(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    Mat distCoeffs;
    PyObject* pyobj_R = NULL;
    Mat R;
    PyObject* pyobj_P = NULL;
    Mat P;

    const char* keywords[] = { "src", "cameraMatrix", "distCoeffs", "dst", "R", "P", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:undistortPoints", (char**)keywords, &pyobj_src, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_dst, &pyobj_R, &pyobj_P) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) &&
        pyopencv_to_safe(pyobj_P, P, ArgInfo("P", 0)) )
    {
        ERRWRAP2(cv::undistortPoints(src, dst, cameraMatrix, distCoeffs, R, P));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    UMat distCoeffs;
    PyObject* pyobj_R = NULL;
    UMat R;
    PyObject* pyobj_P = NULL;
    UMat P;

    const char* keywords[] = { "src", "cameraMatrix", "distCoeffs", "dst", "R", "P", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:undistortPoints", (char**)keywords, &pyobj_src, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_dst, &pyobj_R, &pyobj_P) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) &&
        pyopencv_to_safe(pyobj_P, P, ArgInfo("P", 0)) )
    {
        ERRWRAP2(cv::undistortPoints(src, dst, cameraMatrix, distCoeffs, R, P));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("undistortPoints");

    return NULL;
}

static PyObject* pyopencv_cv_undistortPointsIter(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    Mat distCoeffs;
    PyObject* pyobj_R = NULL;
    Mat R;
    PyObject* pyobj_P = NULL;
    Mat P;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria;

    const char* keywords[] = { "src", "cameraMatrix", "distCoeffs", "R", "P", "criteria", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|O:undistortPointsIter", (char**)keywords, &pyobj_src, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_R, &pyobj_P, &pyobj_criteria, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) &&
        pyopencv_to_safe(pyobj_P, P, ArgInfo("P", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(cv::undistortPoints(src, dst, cameraMatrix, distCoeffs, R, P, criteria));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    UMat distCoeffs;
    PyObject* pyobj_R = NULL;
    UMat R;
    PyObject* pyobj_P = NULL;
    UMat P;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria;

    const char* keywords[] = { "src", "cameraMatrix", "distCoeffs", "R", "P", "criteria", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|O:undistortPointsIter", (char**)keywords, &pyobj_src, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_R, &pyobj_P, &pyobj_criteria, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) &&
        pyopencv_to_safe(pyobj_P, P, ArgInfo("P", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(cv::undistortPoints(src, dst, cameraMatrix, distCoeffs, R, P, criteria));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("undistortPointsIter");

    return NULL;
}

static PyObject* pyopencv_cv_useOpenVX(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    bool retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::useOpenVX());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_useOptimized(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    bool retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::useOptimized());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_validateDisparity(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_disparity = NULL;
    Mat disparity;
    PyObject* pyobj_cost = NULL;
    Mat cost;
    PyObject* pyobj_minDisparity = NULL;
    int minDisparity=0;
    PyObject* pyobj_numberOfDisparities = NULL;
    int numberOfDisparities=0;
    PyObject* pyobj_disp12MaxDisp = NULL;
    int disp12MaxDisp=1;

    const char* keywords[] = { "disparity", "cost", "minDisparity", "numberOfDisparities", "disp12MaxDisp", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:validateDisparity", (char**)keywords, &pyobj_disparity, &pyobj_cost, &pyobj_minDisparity, &pyobj_numberOfDisparities, &pyobj_disp12MaxDisp) &&
        pyopencv_to_safe(pyobj_disparity, disparity, ArgInfo("disparity", 1)) &&
        pyopencv_to_safe(pyobj_cost, cost, ArgInfo("cost", 0)) &&
        pyopencv_to_safe(pyobj_minDisparity, minDisparity, ArgInfo("minDisparity", 0)) &&
        pyopencv_to_safe(pyobj_numberOfDisparities, numberOfDisparities, ArgInfo("numberOfDisparities", 0)) &&
        pyopencv_to_safe(pyobj_disp12MaxDisp, disp12MaxDisp, ArgInfo("disp12MaxDisp", 0)) )
    {
        ERRWRAP2(cv::validateDisparity(disparity, cost, minDisparity, numberOfDisparities, disp12MaxDisp));
        return pyopencv_from(disparity);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_disparity = NULL;
    UMat disparity;
    PyObject* pyobj_cost = NULL;
    UMat cost;
    PyObject* pyobj_minDisparity = NULL;
    int minDisparity=0;
    PyObject* pyobj_numberOfDisparities = NULL;
    int numberOfDisparities=0;
    PyObject* pyobj_disp12MaxDisp = NULL;
    int disp12MaxDisp=1;

    const char* keywords[] = { "disparity", "cost", "minDisparity", "numberOfDisparities", "disp12MaxDisp", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:validateDisparity", (char**)keywords, &pyobj_disparity, &pyobj_cost, &pyobj_minDisparity, &pyobj_numberOfDisparities, &pyobj_disp12MaxDisp) &&
        pyopencv_to_safe(pyobj_disparity, disparity, ArgInfo("disparity", 1)) &&
        pyopencv_to_safe(pyobj_cost, cost, ArgInfo("cost", 0)) &&
        pyopencv_to_safe(pyobj_minDisparity, minDisparity, ArgInfo("minDisparity", 0)) &&
        pyopencv_to_safe(pyobj_numberOfDisparities, numberOfDisparities, ArgInfo("numberOfDisparities", 0)) &&
        pyopencv_to_safe(pyobj_disp12MaxDisp, disp12MaxDisp, ArgInfo("disp12MaxDisp", 0)) )
    {
        ERRWRAP2(cv::validateDisparity(disparity, cost, minDisparity, numberOfDisparities, disp12MaxDisp));
        return pyopencv_from(disparity);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("validateDisparity");

    return NULL;
}

static PyObject* pyopencv_cv_vconcat(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    vector_Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:vconcat", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::vconcat(src, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    vector_UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:vconcat", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::vconcat(src, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("vconcat");

    return NULL;
}

static PyObject* pyopencv_cv_waitKey(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_delay = NULL;
    int delay=0;
    int retval;

    const char* keywords[] = { "delay", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|O:waitKey", (char**)keywords, &pyobj_delay) &&
        pyopencv_to_safe(pyobj_delay, delay, ArgInfo("delay", 0)) )
    {
        ERRWRAP2(retval = cv::waitKey(delay));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_waitKeyEx(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    PyObject* pyobj_delay = NULL;
    int delay=0;
    int retval;

    const char* keywords[] = { "delay", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|O:waitKeyEx", (char**)keywords, &pyobj_delay) &&
        pyopencv_to_safe(pyobj_delay, delay, ArgInfo("delay", 0)) )
    {
        ERRWRAP2(retval = cv::waitKeyEx(delay));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_warpAffine(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_M = NULL;
    Mat M;
    PyObject* pyobj_dsize = NULL;
    Size dsize;
    PyObject* pyobj_flags = NULL;
    int flags=INTER_LINEAR;
    PyObject* pyobj_borderMode = NULL;
    int borderMode=BORDER_CONSTANT;
    PyObject* pyobj_borderValue = NULL;
    Scalar borderValue;

    const char* keywords[] = { "src", "M", "dsize", "dst", "flags", "borderMode", "borderValue", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOO:warpAffine", (char**)keywords, &pyobj_src, &pyobj_M, &pyobj_dsize, &pyobj_dst, &pyobj_flags, &pyobj_borderMode, &pyobj_borderValue) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_M, M, ArgInfo("M", 0)) &&
        pyopencv_to_safe(pyobj_dsize, dsize, ArgInfo("dsize", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_borderMode, borderMode, ArgInfo("borderMode", 0)) &&
        pyopencv_to_safe(pyobj_borderValue, borderValue, ArgInfo("borderValue", 0)) )
    {
        ERRWRAP2(cv::warpAffine(src, dst, M, dsize, flags, borderMode, borderValue));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_M = NULL;
    UMat M;
    PyObject* pyobj_dsize = NULL;
    Size dsize;
    PyObject* pyobj_flags = NULL;
    int flags=INTER_LINEAR;
    PyObject* pyobj_borderMode = NULL;
    int borderMode=BORDER_CONSTANT;
    PyObject* pyobj_borderValue = NULL;
    Scalar borderValue;

    const char* keywords[] = { "src", "M", "dsize", "dst", "flags", "borderMode", "borderValue", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOO:warpAffine", (char**)keywords, &pyobj_src, &pyobj_M, &pyobj_dsize, &pyobj_dst, &pyobj_flags, &pyobj_borderMode, &pyobj_borderValue) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_M, M, ArgInfo("M", 0)) &&
        pyopencv_to_safe(pyobj_dsize, dsize, ArgInfo("dsize", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_borderMode, borderMode, ArgInfo("borderMode", 0)) &&
        pyopencv_to_safe(pyobj_borderValue, borderValue, ArgInfo("borderValue", 0)) )
    {
        ERRWRAP2(cv::warpAffine(src, dst, M, dsize, flags, borderMode, borderValue));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("warpAffine");

    return NULL;
}

static PyObject* pyopencv_cv_warpPerspective(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_M = NULL;
    Mat M;
    PyObject* pyobj_dsize = NULL;
    Size dsize;
    PyObject* pyobj_flags = NULL;
    int flags=INTER_LINEAR;
    PyObject* pyobj_borderMode = NULL;
    int borderMode=BORDER_CONSTANT;
    PyObject* pyobj_borderValue = NULL;
    Scalar borderValue;

    const char* keywords[] = { "src", "M", "dsize", "dst", "flags", "borderMode", "borderValue", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOO:warpPerspective", (char**)keywords, &pyobj_src, &pyobj_M, &pyobj_dsize, &pyobj_dst, &pyobj_flags, &pyobj_borderMode, &pyobj_borderValue) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_M, M, ArgInfo("M", 0)) &&
        pyopencv_to_safe(pyobj_dsize, dsize, ArgInfo("dsize", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_borderMode, borderMode, ArgInfo("borderMode", 0)) &&
        pyopencv_to_safe(pyobj_borderValue, borderValue, ArgInfo("borderValue", 0)) )
    {
        ERRWRAP2(cv::warpPerspective(src, dst, M, dsize, flags, borderMode, borderValue));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_M = NULL;
    UMat M;
    PyObject* pyobj_dsize = NULL;
    Size dsize;
    PyObject* pyobj_flags = NULL;
    int flags=INTER_LINEAR;
    PyObject* pyobj_borderMode = NULL;
    int borderMode=BORDER_CONSTANT;
    PyObject* pyobj_borderValue = NULL;
    Scalar borderValue;

    const char* keywords[] = { "src", "M", "dsize", "dst", "flags", "borderMode", "borderValue", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOO:warpPerspective", (char**)keywords, &pyobj_src, &pyobj_M, &pyobj_dsize, &pyobj_dst, &pyobj_flags, &pyobj_borderMode, &pyobj_borderValue) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_M, M, ArgInfo("M", 0)) &&
        pyopencv_to_safe(pyobj_dsize, dsize, ArgInfo("dsize", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_borderMode, borderMode, ArgInfo("borderMode", 0)) &&
        pyopencv_to_safe(pyobj_borderValue, borderValue, ArgInfo("borderValue", 0)) )
    {
        ERRWRAP2(cv::warpPerspective(src, dst, M, dsize, flags, borderMode, borderValue));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("warpPerspective");

    return NULL;
}

static PyObject* pyopencv_cv_warpPolar(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_dsize = NULL;
    Size dsize;
    PyObject* pyobj_center = NULL;
    Point2f center;
    PyObject* pyobj_maxRadius = NULL;
    double maxRadius=0;
    PyObject* pyobj_flags = NULL;
    int flags=0;

    const char* keywords[] = { "src", "dsize", "center", "maxRadius", "flags", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|O:warpPolar", (char**)keywords, &pyobj_src, &pyobj_dsize, &pyobj_center, &pyobj_maxRadius, &pyobj_flags, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_dsize, dsize, ArgInfo("dsize", 0)) &&
        pyopencv_to_safe(pyobj_center, center, ArgInfo("center", 0)) &&
        pyopencv_to_safe(pyobj_maxRadius, maxRadius, ArgInfo("maxRadius", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::warpPolar(src, dst, dsize, center, maxRadius, flags));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_dsize = NULL;
    Size dsize;
    PyObject* pyobj_center = NULL;
    Point2f center;
    PyObject* pyobj_maxRadius = NULL;
    double maxRadius=0;
    PyObject* pyobj_flags = NULL;
    int flags=0;

    const char* keywords[] = { "src", "dsize", "center", "maxRadius", "flags", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|O:warpPolar", (char**)keywords, &pyobj_src, &pyobj_dsize, &pyobj_center, &pyobj_maxRadius, &pyobj_flags, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_dsize, dsize, ArgInfo("dsize", 0)) &&
        pyopencv_to_safe(pyobj_center, center, ArgInfo("center", 0)) &&
        pyopencv_to_safe(pyobj_maxRadius, maxRadius, ArgInfo("maxRadius", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::warpPolar(src, dst, dsize, center, maxRadius, flags));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("warpPolar");

    return NULL;
}

static PyObject* pyopencv_cv_watershed(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_markers = NULL;
    Mat markers;

    const char* keywords[] = { "image", "markers", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:watershed", (char**)keywords, &pyobj_image, &pyobj_markers) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_markers, markers, ArgInfo("markers", 1)) )
    {
        ERRWRAP2(cv::watershed(image, markers));
        return pyopencv_from(markers);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_markers = NULL;
    UMat markers;

    const char* keywords[] = { "image", "markers", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:watershed", (char**)keywords, &pyobj_image, &pyobj_markers) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_markers, markers, ArgInfo("markers", 1)) )
    {
        ERRWRAP2(cv::watershed(image, markers));
        return pyopencv_from(markers);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("watershed");

    return NULL;
}

static PyObject* pyopencv_cv_writeOpticalFlow(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_path = NULL;
    String path;
    PyObject* pyobj_flow = NULL;
    Mat flow;
    bool retval;

    const char* keywords[] = { "path", "flow", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:writeOpticalFlow", (char**)keywords, &pyobj_path, &pyobj_flow) &&
        pyopencv_to_safe(pyobj_path, path, ArgInfo("path", 0)) &&
        pyopencv_to_safe(pyobj_flow, flow, ArgInfo("flow", 0)) )
    {
        ERRWRAP2(retval = cv::writeOpticalFlow(path, flow));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_path = NULL;
    String path;
    PyObject* pyobj_flow = NULL;
    UMat flow;
    bool retval;

    const char* keywords[] = { "path", "flow", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:writeOpticalFlow", (char**)keywords, &pyobj_path, &pyobj_flow) &&
        pyopencv_to_safe(pyobj_path, path, ArgInfo("path", 0)) &&
        pyopencv_to_safe(pyobj_flow, flow, ArgInfo("flow", 0)) )
    {
        ERRWRAP2(retval = cv::writeOpticalFlow(path, flow));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("writeOpticalFlow");

    return NULL;
}

static PyObject* pyopencv_cv_alphamat_infoFlow(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::alphamat;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_tmap = NULL;
    Mat tmap;
    PyObject* pyobj_result = NULL;
    Mat result;

    const char* keywords[] = { "image", "tmap", "result", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:infoFlow", (char**)keywords, &pyobj_image, &pyobj_tmap, &pyobj_result) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_tmap, tmap, ArgInfo("tmap", 0)) &&
        pyopencv_to_safe(pyobj_result, result, ArgInfo("result", 1)) )
    {
        ERRWRAP2(cv::alphamat::infoFlow(image, tmap, result));
        return pyopencv_from(result);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_tmap = NULL;
    UMat tmap;
    PyObject* pyobj_result = NULL;
    UMat result;

    const char* keywords[] = { "image", "tmap", "result", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:infoFlow", (char**)keywords, &pyobj_image, &pyobj_tmap, &pyobj_result) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_tmap, tmap, ArgInfo("tmap", 0)) &&
        pyopencv_to_safe(pyobj_result, result, ArgInfo("result", 1)) )
    {
        ERRWRAP2(cv::alphamat::infoFlow(image, tmap, result));
        return pyopencv_from(result);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("infoFlow");

    return NULL;
}

static PyObject* pyopencv_cv_aruco_Board_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_objPoints = NULL;
    vector_Mat objPoints;
    PyObject* pyobj_dictionary = NULL;
    Ptr<Dictionary> dictionary;
    PyObject* pyobj_ids = NULL;
    Mat ids;
    Ptr<Board> retval;

    const char* keywords[] = { "objPoints", "dictionary", "ids", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:Board_create", (char**)keywords, &pyobj_objPoints, &pyobj_dictionary, &pyobj_ids) &&
        pyopencv_to_safe(pyobj_objPoints, objPoints, ArgInfo("objPoints", 0)) &&
        pyopencv_to_safe(pyobj_dictionary, dictionary, ArgInfo("dictionary", 0)) &&
        pyopencv_to_safe(pyobj_ids, ids, ArgInfo("ids", 0)) )
    {
        ERRWRAP2(retval = cv::aruco::Board::create(objPoints, dictionary, ids));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_objPoints = NULL;
    vector_UMat objPoints;
    PyObject* pyobj_dictionary = NULL;
    Ptr<Dictionary> dictionary;
    PyObject* pyobj_ids = NULL;
    UMat ids;
    Ptr<Board> retval;

    const char* keywords[] = { "objPoints", "dictionary", "ids", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:Board_create", (char**)keywords, &pyobj_objPoints, &pyobj_dictionary, &pyobj_ids) &&
        pyopencv_to_safe(pyobj_objPoints, objPoints, ArgInfo("objPoints", 0)) &&
        pyopencv_to_safe(pyobj_dictionary, dictionary, ArgInfo("dictionary", 0)) &&
        pyopencv_to_safe(pyobj_ids, ids, ArgInfo("ids", 0)) )
    {
        ERRWRAP2(retval = cv::aruco::Board::create(objPoints, dictionary, ids));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("Board_create");

    return NULL;
}

static PyObject* pyopencv_cv_aruco_CharucoBoard_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    PyObject* pyobj_squaresX = NULL;
    int squaresX=0;
    PyObject* pyobj_squaresY = NULL;
    int squaresY=0;
    PyObject* pyobj_squareLength = NULL;
    float squareLength=0.f;
    PyObject* pyobj_markerLength = NULL;
    float markerLength=0.f;
    PyObject* pyobj_dictionary = NULL;
    Ptr<Dictionary> dictionary;
    Ptr<CharucoBoard> retval;

    const char* keywords[] = { "squaresX", "squaresY", "squareLength", "markerLength", "dictionary", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO:CharucoBoard_create", (char**)keywords, &pyobj_squaresX, &pyobj_squaresY, &pyobj_squareLength, &pyobj_markerLength, &pyobj_dictionary) &&
        pyopencv_to_safe(pyobj_squaresX, squaresX, ArgInfo("squaresX", 0)) &&
        pyopencv_to_safe(pyobj_squaresY, squaresY, ArgInfo("squaresY", 0)) &&
        pyopencv_to_safe(pyobj_squareLength, squareLength, ArgInfo("squareLength", 0)) &&
        pyopencv_to_safe(pyobj_markerLength, markerLength, ArgInfo("markerLength", 0)) &&
        pyopencv_to_safe(pyobj_dictionary, dictionary, ArgInfo("dictionary", 0)) )
    {
        ERRWRAP2(retval = cv::aruco::CharucoBoard::create(squaresX, squaresY, squareLength, markerLength, dictionary));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_aruco_DetectorParameters_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    Ptr<DetectorParameters> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::aruco::DetectorParameters::create());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_aruco_Dictionary_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    PyObject* pyobj_nMarkers = NULL;
    int nMarkers=0;
    PyObject* pyobj_markerSize = NULL;
    int markerSize=0;
    PyObject* pyobj_randomSeed = NULL;
    int randomSeed=0;
    Ptr<Dictionary> retval;

    const char* keywords[] = { "nMarkers", "markerSize", "randomSeed", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:Dictionary_create", (char**)keywords, &pyobj_nMarkers, &pyobj_markerSize, &pyobj_randomSeed) &&
        pyopencv_to_safe(pyobj_nMarkers, nMarkers, ArgInfo("nMarkers", 0)) &&
        pyopencv_to_safe(pyobj_markerSize, markerSize, ArgInfo("markerSize", 0)) &&
        pyopencv_to_safe(pyobj_randomSeed, randomSeed, ArgInfo("randomSeed", 0)) )
    {
        ERRWRAP2(retval = cv::aruco::Dictionary::create(nMarkers, markerSize, randomSeed));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_aruco_Dictionary_create_from(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    PyObject* pyobj_nMarkers = NULL;
    int nMarkers=0;
    PyObject* pyobj_markerSize = NULL;
    int markerSize=0;
    PyObject* pyobj_baseDictionary = NULL;
    Ptr<Dictionary> baseDictionary;
    PyObject* pyobj_randomSeed = NULL;
    int randomSeed=0;
    Ptr<Dictionary> retval;

    const char* keywords[] = { "nMarkers", "markerSize", "baseDictionary", "randomSeed", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:Dictionary_create_from", (char**)keywords, &pyobj_nMarkers, &pyobj_markerSize, &pyobj_baseDictionary, &pyobj_randomSeed) &&
        pyopencv_to_safe(pyobj_nMarkers, nMarkers, ArgInfo("nMarkers", 0)) &&
        pyopencv_to_safe(pyobj_markerSize, markerSize, ArgInfo("markerSize", 0)) &&
        pyopencv_to_safe(pyobj_baseDictionary, baseDictionary, ArgInfo("baseDictionary", 0)) &&
        pyopencv_to_safe(pyobj_randomSeed, randomSeed, ArgInfo("randomSeed", 0)) )
    {
        ERRWRAP2(retval = cv::aruco::Dictionary::create(nMarkers, markerSize, baseDictionary, randomSeed));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_aruco_Dictionary_get(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    PyObject* pyobj_dict = NULL;
    int dict=0;
    Ptr<Dictionary> retval;

    const char* keywords[] = { "dict", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:Dictionary_get", (char**)keywords, &pyobj_dict) &&
        pyopencv_to_safe(pyobj_dict, dict, ArgInfo("dict", 0)) )
    {
        ERRWRAP2(retval = cv::aruco::Dictionary::get(dict));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_aruco_Dictionary_getBitsFromByteList(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_byteList = NULL;
    Mat byteList;
    PyObject* pyobj_markerSize = NULL;
    int markerSize=0;
    Mat retval;

    const char* keywords[] = { "byteList", "markerSize", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:Dictionary_getBitsFromByteList", (char**)keywords, &pyobj_byteList, &pyobj_markerSize) &&
        pyopencv_to_safe(pyobj_byteList, byteList, ArgInfo("byteList", 0)) &&
        pyopencv_to_safe(pyobj_markerSize, markerSize, ArgInfo("markerSize", 0)) )
    {
        ERRWRAP2(retval = cv::aruco::Dictionary::getBitsFromByteList(byteList, markerSize));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_byteList = NULL;
    Mat byteList;
    PyObject* pyobj_markerSize = NULL;
    int markerSize=0;
    Mat retval;

    const char* keywords[] = { "byteList", "markerSize", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:Dictionary_getBitsFromByteList", (char**)keywords, &pyobj_byteList, &pyobj_markerSize) &&
        pyopencv_to_safe(pyobj_byteList, byteList, ArgInfo("byteList", 0)) &&
        pyopencv_to_safe(pyobj_markerSize, markerSize, ArgInfo("markerSize", 0)) )
    {
        ERRWRAP2(retval = cv::aruco::Dictionary::getBitsFromByteList(byteList, markerSize));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("Dictionary_getBitsFromByteList");

    return NULL;
}

static PyObject* pyopencv_cv_aruco_Dictionary_getByteListFromBits(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_bits = NULL;
    Mat bits;
    Mat retval;

    const char* keywords[] = { "bits", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:Dictionary_getByteListFromBits", (char**)keywords, &pyobj_bits) &&
        pyopencv_to_safe(pyobj_bits, bits, ArgInfo("bits", 0)) )
    {
        ERRWRAP2(retval = cv::aruco::Dictionary::getByteListFromBits(bits));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_bits = NULL;
    Mat bits;
    Mat retval;

    const char* keywords[] = { "bits", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:Dictionary_getByteListFromBits", (char**)keywords, &pyobj_bits) &&
        pyopencv_to_safe(pyobj_bits, bits, ArgInfo("bits", 0)) )
    {
        ERRWRAP2(retval = cv::aruco::Dictionary::getByteListFromBits(bits));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("Dictionary_getByteListFromBits");

    return NULL;
}

static PyObject* pyopencv_cv_aruco_GridBoard_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    PyObject* pyobj_markersX = NULL;
    int markersX=0;
    PyObject* pyobj_markersY = NULL;
    int markersY=0;
    PyObject* pyobj_markerLength = NULL;
    float markerLength=0.f;
    PyObject* pyobj_markerSeparation = NULL;
    float markerSeparation=0.f;
    PyObject* pyobj_dictionary = NULL;
    Ptr<Dictionary> dictionary;
    PyObject* pyobj_firstMarker = NULL;
    int firstMarker=0;
    Ptr<GridBoard> retval;

    const char* keywords[] = { "markersX", "markersY", "markerLength", "markerSeparation", "dictionary", "firstMarker", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|O:GridBoard_create", (char**)keywords, &pyobj_markersX, &pyobj_markersY, &pyobj_markerLength, &pyobj_markerSeparation, &pyobj_dictionary, &pyobj_firstMarker) &&
        pyopencv_to_safe(pyobj_markersX, markersX, ArgInfo("markersX", 0)) &&
        pyopencv_to_safe(pyobj_markersY, markersY, ArgInfo("markersY", 0)) &&
        pyopencv_to_safe(pyobj_markerLength, markerLength, ArgInfo("markerLength", 0)) &&
        pyopencv_to_safe(pyobj_markerSeparation, markerSeparation, ArgInfo("markerSeparation", 0)) &&
        pyopencv_to_safe(pyobj_dictionary, dictionary, ArgInfo("dictionary", 0)) &&
        pyopencv_to_safe(pyobj_firstMarker, firstMarker, ArgInfo("firstMarker", 0)) )
    {
        ERRWRAP2(retval = cv::aruco::GridBoard::create(markersX, markersY, markerLength, markerSeparation, dictionary, firstMarker));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_aruco_calibrateCameraAruco(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_corners = NULL;
    vector_Mat corners;
    PyObject* pyobj_ids = NULL;
    Mat ids;
    PyObject* pyobj_counter = NULL;
    Mat counter;
    PyObject* pyobj_board = NULL;
    Ptr<Board> board;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    Mat distCoeffs;
    PyObject* pyobj_rvecs = NULL;
    vector_Mat rvecs;
    PyObject* pyobj_tvecs = NULL;
    vector_Mat tvecs;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria(TermCriteria::COUNT + TermCriteria::EPS, 30, DBL_EPSILON);
    double retval;

    const char* keywords[] = { "corners", "ids", "counter", "board", "imageSize", "cameraMatrix", "distCoeffs", "rvecs", "tvecs", "flags", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOO|OOOO:calibrateCameraAruco", (char**)keywords, &pyobj_corners, &pyobj_ids, &pyobj_counter, &pyobj_board, &pyobj_imageSize, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvecs, &pyobj_tvecs, &pyobj_flags, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 0)) &&
        pyopencv_to_safe(pyobj_ids, ids, ArgInfo("ids", 0)) &&
        pyopencv_to_safe(pyobj_counter, counter, ArgInfo("counter", 0)) &&
        pyopencv_to_safe(pyobj_board, board, ArgInfo("board", 0)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 1)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 1)) &&
        pyopencv_to_safe(pyobj_rvecs, rvecs, ArgInfo("rvecs", 1)) &&
        pyopencv_to_safe(pyobj_tvecs, tvecs, ArgInfo("tvecs", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(retval = cv::aruco::calibrateCameraAruco(corners, ids, counter, board, imageSize, cameraMatrix, distCoeffs, rvecs, tvecs, flags, criteria));
        return Py_BuildValue("(NNNNN)", pyopencv_from(retval), pyopencv_from(cameraMatrix), pyopencv_from(distCoeffs), pyopencv_from(rvecs), pyopencv_from(tvecs));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_corners = NULL;
    vector_UMat corners;
    PyObject* pyobj_ids = NULL;
    UMat ids;
    PyObject* pyobj_counter = NULL;
    UMat counter;
    PyObject* pyobj_board = NULL;
    Ptr<Board> board;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    UMat distCoeffs;
    PyObject* pyobj_rvecs = NULL;
    vector_UMat rvecs;
    PyObject* pyobj_tvecs = NULL;
    vector_UMat tvecs;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria(TermCriteria::COUNT + TermCriteria::EPS, 30, DBL_EPSILON);
    double retval;

    const char* keywords[] = { "corners", "ids", "counter", "board", "imageSize", "cameraMatrix", "distCoeffs", "rvecs", "tvecs", "flags", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOO|OOOO:calibrateCameraAruco", (char**)keywords, &pyobj_corners, &pyobj_ids, &pyobj_counter, &pyobj_board, &pyobj_imageSize, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvecs, &pyobj_tvecs, &pyobj_flags, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 0)) &&
        pyopencv_to_safe(pyobj_ids, ids, ArgInfo("ids", 0)) &&
        pyopencv_to_safe(pyobj_counter, counter, ArgInfo("counter", 0)) &&
        pyopencv_to_safe(pyobj_board, board, ArgInfo("board", 0)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 1)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 1)) &&
        pyopencv_to_safe(pyobj_rvecs, rvecs, ArgInfo("rvecs", 1)) &&
        pyopencv_to_safe(pyobj_tvecs, tvecs, ArgInfo("tvecs", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(retval = cv::aruco::calibrateCameraAruco(corners, ids, counter, board, imageSize, cameraMatrix, distCoeffs, rvecs, tvecs, flags, criteria));
        return Py_BuildValue("(NNNNN)", pyopencv_from(retval), pyopencv_from(cameraMatrix), pyopencv_from(distCoeffs), pyopencv_from(rvecs), pyopencv_from(tvecs));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("calibrateCameraAruco");

    return NULL;
}

static PyObject* pyopencv_cv_aruco_calibrateCameraArucoExtended(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_corners = NULL;
    vector_Mat corners;
    PyObject* pyobj_ids = NULL;
    Mat ids;
    PyObject* pyobj_counter = NULL;
    Mat counter;
    PyObject* pyobj_board = NULL;
    Ptr<Board> board;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    Mat distCoeffs;
    PyObject* pyobj_rvecs = NULL;
    vector_Mat rvecs;
    PyObject* pyobj_tvecs = NULL;
    vector_Mat tvecs;
    PyObject* pyobj_stdDeviationsIntrinsics = NULL;
    Mat stdDeviationsIntrinsics;
    PyObject* pyobj_stdDeviationsExtrinsics = NULL;
    Mat stdDeviationsExtrinsics;
    PyObject* pyobj_perViewErrors = NULL;
    Mat perViewErrors;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria(TermCriteria::COUNT + TermCriteria::EPS, 30, DBL_EPSILON);
    double retval;

    const char* keywords[] = { "corners", "ids", "counter", "board", "imageSize", "cameraMatrix", "distCoeffs", "rvecs", "tvecs", "stdDeviationsIntrinsics", "stdDeviationsExtrinsics", "perViewErrors", "flags", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOO|OOOOOOO:calibrateCameraArucoExtended", (char**)keywords, &pyobj_corners, &pyobj_ids, &pyobj_counter, &pyobj_board, &pyobj_imageSize, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvecs, &pyobj_tvecs, &pyobj_stdDeviationsIntrinsics, &pyobj_stdDeviationsExtrinsics, &pyobj_perViewErrors, &pyobj_flags, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 0)) &&
        pyopencv_to_safe(pyobj_ids, ids, ArgInfo("ids", 0)) &&
        pyopencv_to_safe(pyobj_counter, counter, ArgInfo("counter", 0)) &&
        pyopencv_to_safe(pyobj_board, board, ArgInfo("board", 0)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 1)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 1)) &&
        pyopencv_to_safe(pyobj_rvecs, rvecs, ArgInfo("rvecs", 1)) &&
        pyopencv_to_safe(pyobj_tvecs, tvecs, ArgInfo("tvecs", 1)) &&
        pyopencv_to_safe(pyobj_stdDeviationsIntrinsics, stdDeviationsIntrinsics, ArgInfo("stdDeviationsIntrinsics", 1)) &&
        pyopencv_to_safe(pyobj_stdDeviationsExtrinsics, stdDeviationsExtrinsics, ArgInfo("stdDeviationsExtrinsics", 1)) &&
        pyopencv_to_safe(pyobj_perViewErrors, perViewErrors, ArgInfo("perViewErrors", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(retval = cv::aruco::calibrateCameraAruco(corners, ids, counter, board, imageSize, cameraMatrix, distCoeffs, rvecs, tvecs, stdDeviationsIntrinsics, stdDeviationsExtrinsics, perViewErrors, flags, criteria));
        return Py_BuildValue("(NNNNNNNN)", pyopencv_from(retval), pyopencv_from(cameraMatrix), pyopencv_from(distCoeffs), pyopencv_from(rvecs), pyopencv_from(tvecs), pyopencv_from(stdDeviationsIntrinsics), pyopencv_from(stdDeviationsExtrinsics), pyopencv_from(perViewErrors));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_corners = NULL;
    vector_UMat corners;
    PyObject* pyobj_ids = NULL;
    UMat ids;
    PyObject* pyobj_counter = NULL;
    UMat counter;
    PyObject* pyobj_board = NULL;
    Ptr<Board> board;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    UMat distCoeffs;
    PyObject* pyobj_rvecs = NULL;
    vector_UMat rvecs;
    PyObject* pyobj_tvecs = NULL;
    vector_UMat tvecs;
    PyObject* pyobj_stdDeviationsIntrinsics = NULL;
    UMat stdDeviationsIntrinsics;
    PyObject* pyobj_stdDeviationsExtrinsics = NULL;
    UMat stdDeviationsExtrinsics;
    PyObject* pyobj_perViewErrors = NULL;
    UMat perViewErrors;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria(TermCriteria::COUNT + TermCriteria::EPS, 30, DBL_EPSILON);
    double retval;

    const char* keywords[] = { "corners", "ids", "counter", "board", "imageSize", "cameraMatrix", "distCoeffs", "rvecs", "tvecs", "stdDeviationsIntrinsics", "stdDeviationsExtrinsics", "perViewErrors", "flags", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOO|OOOOOOO:calibrateCameraArucoExtended", (char**)keywords, &pyobj_corners, &pyobj_ids, &pyobj_counter, &pyobj_board, &pyobj_imageSize, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvecs, &pyobj_tvecs, &pyobj_stdDeviationsIntrinsics, &pyobj_stdDeviationsExtrinsics, &pyobj_perViewErrors, &pyobj_flags, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 0)) &&
        pyopencv_to_safe(pyobj_ids, ids, ArgInfo("ids", 0)) &&
        pyopencv_to_safe(pyobj_counter, counter, ArgInfo("counter", 0)) &&
        pyopencv_to_safe(pyobj_board, board, ArgInfo("board", 0)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 1)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 1)) &&
        pyopencv_to_safe(pyobj_rvecs, rvecs, ArgInfo("rvecs", 1)) &&
        pyopencv_to_safe(pyobj_tvecs, tvecs, ArgInfo("tvecs", 1)) &&
        pyopencv_to_safe(pyobj_stdDeviationsIntrinsics, stdDeviationsIntrinsics, ArgInfo("stdDeviationsIntrinsics", 1)) &&
        pyopencv_to_safe(pyobj_stdDeviationsExtrinsics, stdDeviationsExtrinsics, ArgInfo("stdDeviationsExtrinsics", 1)) &&
        pyopencv_to_safe(pyobj_perViewErrors, perViewErrors, ArgInfo("perViewErrors", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(retval = cv::aruco::calibrateCameraAruco(corners, ids, counter, board, imageSize, cameraMatrix, distCoeffs, rvecs, tvecs, stdDeviationsIntrinsics, stdDeviationsExtrinsics, perViewErrors, flags, criteria));
        return Py_BuildValue("(NNNNNNNN)", pyopencv_from(retval), pyopencv_from(cameraMatrix), pyopencv_from(distCoeffs), pyopencv_from(rvecs), pyopencv_from(tvecs), pyopencv_from(stdDeviationsIntrinsics), pyopencv_from(stdDeviationsExtrinsics), pyopencv_from(perViewErrors));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("calibrateCameraArucoExtended");

    return NULL;
}

static PyObject* pyopencv_cv_aruco_calibrateCameraCharuco(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_charucoCorners = NULL;
    vector_Mat charucoCorners;
    PyObject* pyobj_charucoIds = NULL;
    vector_Mat charucoIds;
    PyObject* pyobj_board = NULL;
    Ptr<CharucoBoard> board;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    Mat distCoeffs;
    PyObject* pyobj_rvecs = NULL;
    vector_Mat rvecs;
    PyObject* pyobj_tvecs = NULL;
    vector_Mat tvecs;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria(TermCriteria::COUNT + TermCriteria::EPS, 30, DBL_EPSILON);
    double retval;

    const char* keywords[] = { "charucoCorners", "charucoIds", "board", "imageSize", "cameraMatrix", "distCoeffs", "rvecs", "tvecs", "flags", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|OOOO:calibrateCameraCharuco", (char**)keywords, &pyobj_charucoCorners, &pyobj_charucoIds, &pyobj_board, &pyobj_imageSize, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvecs, &pyobj_tvecs, &pyobj_flags, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_charucoCorners, charucoCorners, ArgInfo("charucoCorners", 0)) &&
        pyopencv_to_safe(pyobj_charucoIds, charucoIds, ArgInfo("charucoIds", 0)) &&
        pyopencv_to_safe(pyobj_board, board, ArgInfo("board", 0)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 1)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 1)) &&
        pyopencv_to_safe(pyobj_rvecs, rvecs, ArgInfo("rvecs", 1)) &&
        pyopencv_to_safe(pyobj_tvecs, tvecs, ArgInfo("tvecs", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(retval = cv::aruco::calibrateCameraCharuco(charucoCorners, charucoIds, board, imageSize, cameraMatrix, distCoeffs, rvecs, tvecs, flags, criteria));
        return Py_BuildValue("(NNNNN)", pyopencv_from(retval), pyopencv_from(cameraMatrix), pyopencv_from(distCoeffs), pyopencv_from(rvecs), pyopencv_from(tvecs));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_charucoCorners = NULL;
    vector_UMat charucoCorners;
    PyObject* pyobj_charucoIds = NULL;
    vector_UMat charucoIds;
    PyObject* pyobj_board = NULL;
    Ptr<CharucoBoard> board;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    UMat distCoeffs;
    PyObject* pyobj_rvecs = NULL;
    vector_UMat rvecs;
    PyObject* pyobj_tvecs = NULL;
    vector_UMat tvecs;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria(TermCriteria::COUNT + TermCriteria::EPS, 30, DBL_EPSILON);
    double retval;

    const char* keywords[] = { "charucoCorners", "charucoIds", "board", "imageSize", "cameraMatrix", "distCoeffs", "rvecs", "tvecs", "flags", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|OOOO:calibrateCameraCharuco", (char**)keywords, &pyobj_charucoCorners, &pyobj_charucoIds, &pyobj_board, &pyobj_imageSize, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvecs, &pyobj_tvecs, &pyobj_flags, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_charucoCorners, charucoCorners, ArgInfo("charucoCorners", 0)) &&
        pyopencv_to_safe(pyobj_charucoIds, charucoIds, ArgInfo("charucoIds", 0)) &&
        pyopencv_to_safe(pyobj_board, board, ArgInfo("board", 0)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 1)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 1)) &&
        pyopencv_to_safe(pyobj_rvecs, rvecs, ArgInfo("rvecs", 1)) &&
        pyopencv_to_safe(pyobj_tvecs, tvecs, ArgInfo("tvecs", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(retval = cv::aruco::calibrateCameraCharuco(charucoCorners, charucoIds, board, imageSize, cameraMatrix, distCoeffs, rvecs, tvecs, flags, criteria));
        return Py_BuildValue("(NNNNN)", pyopencv_from(retval), pyopencv_from(cameraMatrix), pyopencv_from(distCoeffs), pyopencv_from(rvecs), pyopencv_from(tvecs));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("calibrateCameraCharuco");

    return NULL;
}

static PyObject* pyopencv_cv_aruco_calibrateCameraCharucoExtended(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_charucoCorners = NULL;
    vector_Mat charucoCorners;
    PyObject* pyobj_charucoIds = NULL;
    vector_Mat charucoIds;
    PyObject* pyobj_board = NULL;
    Ptr<CharucoBoard> board;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    Mat distCoeffs;
    PyObject* pyobj_rvecs = NULL;
    vector_Mat rvecs;
    PyObject* pyobj_tvecs = NULL;
    vector_Mat tvecs;
    PyObject* pyobj_stdDeviationsIntrinsics = NULL;
    Mat stdDeviationsIntrinsics;
    PyObject* pyobj_stdDeviationsExtrinsics = NULL;
    Mat stdDeviationsExtrinsics;
    PyObject* pyobj_perViewErrors = NULL;
    Mat perViewErrors;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria(TermCriteria::COUNT + TermCriteria::EPS, 30, DBL_EPSILON);
    double retval;

    const char* keywords[] = { "charucoCorners", "charucoIds", "board", "imageSize", "cameraMatrix", "distCoeffs", "rvecs", "tvecs", "stdDeviationsIntrinsics", "stdDeviationsExtrinsics", "perViewErrors", "flags", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|OOOOOOO:calibrateCameraCharucoExtended", (char**)keywords, &pyobj_charucoCorners, &pyobj_charucoIds, &pyobj_board, &pyobj_imageSize, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvecs, &pyobj_tvecs, &pyobj_stdDeviationsIntrinsics, &pyobj_stdDeviationsExtrinsics, &pyobj_perViewErrors, &pyobj_flags, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_charucoCorners, charucoCorners, ArgInfo("charucoCorners", 0)) &&
        pyopencv_to_safe(pyobj_charucoIds, charucoIds, ArgInfo("charucoIds", 0)) &&
        pyopencv_to_safe(pyobj_board, board, ArgInfo("board", 0)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 1)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 1)) &&
        pyopencv_to_safe(pyobj_rvecs, rvecs, ArgInfo("rvecs", 1)) &&
        pyopencv_to_safe(pyobj_tvecs, tvecs, ArgInfo("tvecs", 1)) &&
        pyopencv_to_safe(pyobj_stdDeviationsIntrinsics, stdDeviationsIntrinsics, ArgInfo("stdDeviationsIntrinsics", 1)) &&
        pyopencv_to_safe(pyobj_stdDeviationsExtrinsics, stdDeviationsExtrinsics, ArgInfo("stdDeviationsExtrinsics", 1)) &&
        pyopencv_to_safe(pyobj_perViewErrors, perViewErrors, ArgInfo("perViewErrors", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(retval = cv::aruco::calibrateCameraCharuco(charucoCorners, charucoIds, board, imageSize, cameraMatrix, distCoeffs, rvecs, tvecs, stdDeviationsIntrinsics, stdDeviationsExtrinsics, perViewErrors, flags, criteria));
        return Py_BuildValue("(NNNNNNNN)", pyopencv_from(retval), pyopencv_from(cameraMatrix), pyopencv_from(distCoeffs), pyopencv_from(rvecs), pyopencv_from(tvecs), pyopencv_from(stdDeviationsIntrinsics), pyopencv_from(stdDeviationsExtrinsics), pyopencv_from(perViewErrors));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_charucoCorners = NULL;
    vector_UMat charucoCorners;
    PyObject* pyobj_charucoIds = NULL;
    vector_UMat charucoIds;
    PyObject* pyobj_board = NULL;
    Ptr<CharucoBoard> board;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    UMat distCoeffs;
    PyObject* pyobj_rvecs = NULL;
    vector_UMat rvecs;
    PyObject* pyobj_tvecs = NULL;
    vector_UMat tvecs;
    PyObject* pyobj_stdDeviationsIntrinsics = NULL;
    UMat stdDeviationsIntrinsics;
    PyObject* pyobj_stdDeviationsExtrinsics = NULL;
    UMat stdDeviationsExtrinsics;
    PyObject* pyobj_perViewErrors = NULL;
    UMat perViewErrors;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria(TermCriteria::COUNT + TermCriteria::EPS, 30, DBL_EPSILON);
    double retval;

    const char* keywords[] = { "charucoCorners", "charucoIds", "board", "imageSize", "cameraMatrix", "distCoeffs", "rvecs", "tvecs", "stdDeviationsIntrinsics", "stdDeviationsExtrinsics", "perViewErrors", "flags", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|OOOOOOO:calibrateCameraCharucoExtended", (char**)keywords, &pyobj_charucoCorners, &pyobj_charucoIds, &pyobj_board, &pyobj_imageSize, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvecs, &pyobj_tvecs, &pyobj_stdDeviationsIntrinsics, &pyobj_stdDeviationsExtrinsics, &pyobj_perViewErrors, &pyobj_flags, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_charucoCorners, charucoCorners, ArgInfo("charucoCorners", 0)) &&
        pyopencv_to_safe(pyobj_charucoIds, charucoIds, ArgInfo("charucoIds", 0)) &&
        pyopencv_to_safe(pyobj_board, board, ArgInfo("board", 0)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 1)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 1)) &&
        pyopencv_to_safe(pyobj_rvecs, rvecs, ArgInfo("rvecs", 1)) &&
        pyopencv_to_safe(pyobj_tvecs, tvecs, ArgInfo("tvecs", 1)) &&
        pyopencv_to_safe(pyobj_stdDeviationsIntrinsics, stdDeviationsIntrinsics, ArgInfo("stdDeviationsIntrinsics", 1)) &&
        pyopencv_to_safe(pyobj_stdDeviationsExtrinsics, stdDeviationsExtrinsics, ArgInfo("stdDeviationsExtrinsics", 1)) &&
        pyopencv_to_safe(pyobj_perViewErrors, perViewErrors, ArgInfo("perViewErrors", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(retval = cv::aruco::calibrateCameraCharuco(charucoCorners, charucoIds, board, imageSize, cameraMatrix, distCoeffs, rvecs, tvecs, stdDeviationsIntrinsics, stdDeviationsExtrinsics, perViewErrors, flags, criteria));
        return Py_BuildValue("(NNNNNNNN)", pyopencv_from(retval), pyopencv_from(cameraMatrix), pyopencv_from(distCoeffs), pyopencv_from(rvecs), pyopencv_from(tvecs), pyopencv_from(stdDeviationsIntrinsics), pyopencv_from(stdDeviationsExtrinsics), pyopencv_from(perViewErrors));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("calibrateCameraCharucoExtended");

    return NULL;
}

static PyObject* pyopencv_cv_aruco_custom_dictionary(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    PyObject* pyobj_nMarkers = NULL;
    int nMarkers=0;
    PyObject* pyobj_markerSize = NULL;
    int markerSize=0;
    PyObject* pyobj_randomSeed = NULL;
    int randomSeed=0;
    Ptr<Dictionary> retval;

    const char* keywords[] = { "nMarkers", "markerSize", "randomSeed", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:custom_dictionary", (char**)keywords, &pyobj_nMarkers, &pyobj_markerSize, &pyobj_randomSeed) &&
        pyopencv_to_safe(pyobj_nMarkers, nMarkers, ArgInfo("nMarkers", 0)) &&
        pyopencv_to_safe(pyobj_markerSize, markerSize, ArgInfo("markerSize", 0)) &&
        pyopencv_to_safe(pyobj_randomSeed, randomSeed, ArgInfo("randomSeed", 0)) )
    {
        ERRWRAP2(retval = cv::aruco::generateCustomDictionary(nMarkers, markerSize, randomSeed));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_aruco_custom_dictionary_from(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    PyObject* pyobj_nMarkers = NULL;
    int nMarkers=0;
    PyObject* pyobj_markerSize = NULL;
    int markerSize=0;
    PyObject* pyobj_baseDictionary = NULL;
    Ptr<Dictionary> baseDictionary;
    PyObject* pyobj_randomSeed = NULL;
    int randomSeed=0;
    Ptr<Dictionary> retval;

    const char* keywords[] = { "nMarkers", "markerSize", "baseDictionary", "randomSeed", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:custom_dictionary_from", (char**)keywords, &pyobj_nMarkers, &pyobj_markerSize, &pyobj_baseDictionary, &pyobj_randomSeed) &&
        pyopencv_to_safe(pyobj_nMarkers, nMarkers, ArgInfo("nMarkers", 0)) &&
        pyopencv_to_safe(pyobj_markerSize, markerSize, ArgInfo("markerSize", 0)) &&
        pyopencv_to_safe(pyobj_baseDictionary, baseDictionary, ArgInfo("baseDictionary", 0)) &&
        pyopencv_to_safe(pyobj_randomSeed, randomSeed, ArgInfo("randomSeed", 0)) )
    {
        ERRWRAP2(retval = cv::aruco::generateCustomDictionary(nMarkers, markerSize, baseDictionary, randomSeed));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_aruco_detectCharucoDiamond(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_markerCorners = NULL;
    vector_Mat markerCorners;
    PyObject* pyobj_markerIds = NULL;
    Mat markerIds;
    PyObject* pyobj_squareMarkerLengthRate = NULL;
    float squareMarkerLengthRate=0.f;
    PyObject* pyobj_diamondCorners = NULL;
    vector_Mat diamondCorners;
    PyObject* pyobj_diamondIds = NULL;
    Mat diamondIds;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    Mat distCoeffs;

    const char* keywords[] = { "image", "markerCorners", "markerIds", "squareMarkerLengthRate", "diamondCorners", "diamondIds", "cameraMatrix", "distCoeffs", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOO:detectCharucoDiamond", (char**)keywords, &pyobj_image, &pyobj_markerCorners, &pyobj_markerIds, &pyobj_squareMarkerLengthRate, &pyobj_diamondCorners, &pyobj_diamondIds, &pyobj_cameraMatrix, &pyobj_distCoeffs) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_markerCorners, markerCorners, ArgInfo("markerCorners", 0)) &&
        pyopencv_to_safe(pyobj_markerIds, markerIds, ArgInfo("markerIds", 0)) &&
        pyopencv_to_safe(pyobj_squareMarkerLengthRate, squareMarkerLengthRate, ArgInfo("squareMarkerLengthRate", 0)) &&
        pyopencv_to_safe(pyobj_diamondCorners, diamondCorners, ArgInfo("diamondCorners", 1)) &&
        pyopencv_to_safe(pyobj_diamondIds, diamondIds, ArgInfo("diamondIds", 1)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) )
    {
        ERRWRAP2(cv::aruco::detectCharucoDiamond(image, markerCorners, markerIds, squareMarkerLengthRate, diamondCorners, diamondIds, cameraMatrix, distCoeffs));
        return Py_BuildValue("(NN)", pyopencv_from(diamondCorners), pyopencv_from(diamondIds));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_markerCorners = NULL;
    vector_UMat markerCorners;
    PyObject* pyobj_markerIds = NULL;
    UMat markerIds;
    PyObject* pyobj_squareMarkerLengthRate = NULL;
    float squareMarkerLengthRate=0.f;
    PyObject* pyobj_diamondCorners = NULL;
    vector_UMat diamondCorners;
    PyObject* pyobj_diamondIds = NULL;
    UMat diamondIds;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    UMat distCoeffs;

    const char* keywords[] = { "image", "markerCorners", "markerIds", "squareMarkerLengthRate", "diamondCorners", "diamondIds", "cameraMatrix", "distCoeffs", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOO:detectCharucoDiamond", (char**)keywords, &pyobj_image, &pyobj_markerCorners, &pyobj_markerIds, &pyobj_squareMarkerLengthRate, &pyobj_diamondCorners, &pyobj_diamondIds, &pyobj_cameraMatrix, &pyobj_distCoeffs) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_markerCorners, markerCorners, ArgInfo("markerCorners", 0)) &&
        pyopencv_to_safe(pyobj_markerIds, markerIds, ArgInfo("markerIds", 0)) &&
        pyopencv_to_safe(pyobj_squareMarkerLengthRate, squareMarkerLengthRate, ArgInfo("squareMarkerLengthRate", 0)) &&
        pyopencv_to_safe(pyobj_diamondCorners, diamondCorners, ArgInfo("diamondCorners", 1)) &&
        pyopencv_to_safe(pyobj_diamondIds, diamondIds, ArgInfo("diamondIds", 1)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) )
    {
        ERRWRAP2(cv::aruco::detectCharucoDiamond(image, markerCorners, markerIds, squareMarkerLengthRate, diamondCorners, diamondIds, cameraMatrix, distCoeffs));
        return Py_BuildValue("(NN)", pyopencv_from(diamondCorners), pyopencv_from(diamondIds));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("detectCharucoDiamond");

    return NULL;
}

static PyObject* pyopencv_cv_aruco_detectMarkers(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_dictionary = NULL;
    Ptr<Dictionary> dictionary;
    PyObject* pyobj_corners = NULL;
    vector_Mat corners;
    PyObject* pyobj_ids = NULL;
    Mat ids;
    PyObject* pyobj_parameters = NULL;
    Ptr<DetectorParameters> parameters=DetectorParameters::create();
    PyObject* pyobj_rejectedImgPoints = NULL;
    vector_Mat rejectedImgPoints;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeff = NULL;
    Mat distCoeff;

    const char* keywords[] = { "image", "dictionary", "corners", "ids", "parameters", "rejectedImgPoints", "cameraMatrix", "distCoeff", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOOOO:detectMarkers", (char**)keywords, &pyobj_image, &pyobj_dictionary, &pyobj_corners, &pyobj_ids, &pyobj_parameters, &pyobj_rejectedImgPoints, &pyobj_cameraMatrix, &pyobj_distCoeff) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_dictionary, dictionary, ArgInfo("dictionary", 0)) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 1)) &&
        pyopencv_to_safe(pyobj_ids, ids, ArgInfo("ids", 1)) &&
        pyopencv_to_safe(pyobj_parameters, parameters, ArgInfo("parameters", 0)) &&
        pyopencv_to_safe(pyobj_rejectedImgPoints, rejectedImgPoints, ArgInfo("rejectedImgPoints", 1)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeff, distCoeff, ArgInfo("distCoeff", 0)) )
    {
        ERRWRAP2(cv::aruco::detectMarkers(image, dictionary, corners, ids, parameters, rejectedImgPoints, cameraMatrix, distCoeff));
        return Py_BuildValue("(NNN)", pyopencv_from(corners), pyopencv_from(ids), pyopencv_from(rejectedImgPoints));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_dictionary = NULL;
    Ptr<Dictionary> dictionary;
    PyObject* pyobj_corners = NULL;
    vector_UMat corners;
    PyObject* pyobj_ids = NULL;
    UMat ids;
    PyObject* pyobj_parameters = NULL;
    Ptr<DetectorParameters> parameters=DetectorParameters::create();
    PyObject* pyobj_rejectedImgPoints = NULL;
    vector_UMat rejectedImgPoints;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_distCoeff = NULL;
    UMat distCoeff;

    const char* keywords[] = { "image", "dictionary", "corners", "ids", "parameters", "rejectedImgPoints", "cameraMatrix", "distCoeff", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOOOO:detectMarkers", (char**)keywords, &pyobj_image, &pyobj_dictionary, &pyobj_corners, &pyobj_ids, &pyobj_parameters, &pyobj_rejectedImgPoints, &pyobj_cameraMatrix, &pyobj_distCoeff) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_dictionary, dictionary, ArgInfo("dictionary", 0)) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 1)) &&
        pyopencv_to_safe(pyobj_ids, ids, ArgInfo("ids", 1)) &&
        pyopencv_to_safe(pyobj_parameters, parameters, ArgInfo("parameters", 0)) &&
        pyopencv_to_safe(pyobj_rejectedImgPoints, rejectedImgPoints, ArgInfo("rejectedImgPoints", 1)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeff, distCoeff, ArgInfo("distCoeff", 0)) )
    {
        ERRWRAP2(cv::aruco::detectMarkers(image, dictionary, corners, ids, parameters, rejectedImgPoints, cameraMatrix, distCoeff));
        return Py_BuildValue("(NNN)", pyopencv_from(corners), pyopencv_from(ids), pyopencv_from(rejectedImgPoints));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("detectMarkers");

    return NULL;
}

static PyObject* pyopencv_cv_aruco_drawAxis(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    Mat distCoeffs;
    PyObject* pyobj_rvec = NULL;
    Mat rvec;
    PyObject* pyobj_tvec = NULL;
    Mat tvec;
    PyObject* pyobj_length = NULL;
    float length=0.f;

    const char* keywords[] = { "image", "cameraMatrix", "distCoeffs", "rvec", "tvec", "length", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO:drawAxis", (char**)keywords, &pyobj_image, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvec, &pyobj_tvec, &pyobj_length) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 1)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 0)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 0)) &&
        pyopencv_to_safe(pyobj_length, length, ArgInfo("length", 0)) )
    {
        ERRWRAP2(cv::aruco::drawAxis(image, cameraMatrix, distCoeffs, rvec, tvec, length));
        return pyopencv_from(image);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    UMat distCoeffs;
    PyObject* pyobj_rvec = NULL;
    UMat rvec;
    PyObject* pyobj_tvec = NULL;
    UMat tvec;
    PyObject* pyobj_length = NULL;
    float length=0.f;

    const char* keywords[] = { "image", "cameraMatrix", "distCoeffs", "rvec", "tvec", "length", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO:drawAxis", (char**)keywords, &pyobj_image, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvec, &pyobj_tvec, &pyobj_length) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 1)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 0)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 0)) &&
        pyopencv_to_safe(pyobj_length, length, ArgInfo("length", 0)) )
    {
        ERRWRAP2(cv::aruco::drawAxis(image, cameraMatrix, distCoeffs, rvec, tvec, length));
        return pyopencv_from(image);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("drawAxis");

    return NULL;
}

static PyObject* pyopencv_cv_aruco_drawDetectedCornersCharuco(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_charucoCorners = NULL;
    Mat charucoCorners;
    PyObject* pyobj_charucoIds = NULL;
    Mat charucoIds;
    PyObject* pyobj_cornerColor = NULL;
    Scalar cornerColor=Scalar(255, 0, 0);

    const char* keywords[] = { "image", "charucoCorners", "charucoIds", "cornerColor", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:drawDetectedCornersCharuco", (char**)keywords, &pyobj_image, &pyobj_charucoCorners, &pyobj_charucoIds, &pyobj_cornerColor) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 1)) &&
        pyopencv_to_safe(pyobj_charucoCorners, charucoCorners, ArgInfo("charucoCorners", 0)) &&
        pyopencv_to_safe(pyobj_charucoIds, charucoIds, ArgInfo("charucoIds", 0)) &&
        pyopencv_to_safe(pyobj_cornerColor, cornerColor, ArgInfo("cornerColor", 0)) )
    {
        ERRWRAP2(cv::aruco::drawDetectedCornersCharuco(image, charucoCorners, charucoIds, cornerColor));
        return pyopencv_from(image);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_charucoCorners = NULL;
    UMat charucoCorners;
    PyObject* pyobj_charucoIds = NULL;
    UMat charucoIds;
    PyObject* pyobj_cornerColor = NULL;
    Scalar cornerColor=Scalar(255, 0, 0);

    const char* keywords[] = { "image", "charucoCorners", "charucoIds", "cornerColor", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:drawDetectedCornersCharuco", (char**)keywords, &pyobj_image, &pyobj_charucoCorners, &pyobj_charucoIds, &pyobj_cornerColor) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 1)) &&
        pyopencv_to_safe(pyobj_charucoCorners, charucoCorners, ArgInfo("charucoCorners", 0)) &&
        pyopencv_to_safe(pyobj_charucoIds, charucoIds, ArgInfo("charucoIds", 0)) &&
        pyopencv_to_safe(pyobj_cornerColor, cornerColor, ArgInfo("cornerColor", 0)) )
    {
        ERRWRAP2(cv::aruco::drawDetectedCornersCharuco(image, charucoCorners, charucoIds, cornerColor));
        return pyopencv_from(image);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("drawDetectedCornersCharuco");

    return NULL;
}

static PyObject* pyopencv_cv_aruco_drawDetectedDiamonds(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_diamondCorners = NULL;
    vector_Mat diamondCorners;
    PyObject* pyobj_diamondIds = NULL;
    Mat diamondIds;
    PyObject* pyobj_borderColor = NULL;
    Scalar borderColor=Scalar(0, 0, 255);

    const char* keywords[] = { "image", "diamondCorners", "diamondIds", "borderColor", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:drawDetectedDiamonds", (char**)keywords, &pyobj_image, &pyobj_diamondCorners, &pyobj_diamondIds, &pyobj_borderColor) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 1)) &&
        pyopencv_to_safe(pyobj_diamondCorners, diamondCorners, ArgInfo("diamondCorners", 0)) &&
        pyopencv_to_safe(pyobj_diamondIds, diamondIds, ArgInfo("diamondIds", 0)) &&
        pyopencv_to_safe(pyobj_borderColor, borderColor, ArgInfo("borderColor", 0)) )
    {
        ERRWRAP2(cv::aruco::drawDetectedDiamonds(image, diamondCorners, diamondIds, borderColor));
        return pyopencv_from(image);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_diamondCorners = NULL;
    vector_UMat diamondCorners;
    PyObject* pyobj_diamondIds = NULL;
    UMat diamondIds;
    PyObject* pyobj_borderColor = NULL;
    Scalar borderColor=Scalar(0, 0, 255);

    const char* keywords[] = { "image", "diamondCorners", "diamondIds", "borderColor", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:drawDetectedDiamonds", (char**)keywords, &pyobj_image, &pyobj_diamondCorners, &pyobj_diamondIds, &pyobj_borderColor) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 1)) &&
        pyopencv_to_safe(pyobj_diamondCorners, diamondCorners, ArgInfo("diamondCorners", 0)) &&
        pyopencv_to_safe(pyobj_diamondIds, diamondIds, ArgInfo("diamondIds", 0)) &&
        pyopencv_to_safe(pyobj_borderColor, borderColor, ArgInfo("borderColor", 0)) )
    {
        ERRWRAP2(cv::aruco::drawDetectedDiamonds(image, diamondCorners, diamondIds, borderColor));
        return pyopencv_from(image);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("drawDetectedDiamonds");

    return NULL;
}

static PyObject* pyopencv_cv_aruco_drawDetectedMarkers(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_corners = NULL;
    vector_Mat corners;
    PyObject* pyobj_ids = NULL;
    Mat ids;
    PyObject* pyobj_borderColor = NULL;
    Scalar borderColor=Scalar(0, 255, 0);

    const char* keywords[] = { "image", "corners", "ids", "borderColor", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:drawDetectedMarkers", (char**)keywords, &pyobj_image, &pyobj_corners, &pyobj_ids, &pyobj_borderColor) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 1)) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 0)) &&
        pyopencv_to_safe(pyobj_ids, ids, ArgInfo("ids", 0)) &&
        pyopencv_to_safe(pyobj_borderColor, borderColor, ArgInfo("borderColor", 0)) )
    {
        ERRWRAP2(cv::aruco::drawDetectedMarkers(image, corners, ids, borderColor));
        return pyopencv_from(image);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_corners = NULL;
    vector_UMat corners;
    PyObject* pyobj_ids = NULL;
    UMat ids;
    PyObject* pyobj_borderColor = NULL;
    Scalar borderColor=Scalar(0, 255, 0);

    const char* keywords[] = { "image", "corners", "ids", "borderColor", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:drawDetectedMarkers", (char**)keywords, &pyobj_image, &pyobj_corners, &pyobj_ids, &pyobj_borderColor) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 1)) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 0)) &&
        pyopencv_to_safe(pyobj_ids, ids, ArgInfo("ids", 0)) &&
        pyopencv_to_safe(pyobj_borderColor, borderColor, ArgInfo("borderColor", 0)) )
    {
        ERRWRAP2(cv::aruco::drawDetectedMarkers(image, corners, ids, borderColor));
        return pyopencv_from(image);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("drawDetectedMarkers");

    return NULL;
}

static PyObject* pyopencv_cv_aruco_drawMarker(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_dictionary = NULL;
    Ptr<Dictionary> dictionary;
    PyObject* pyobj_id = NULL;
    int id=0;
    PyObject* pyobj_sidePixels = NULL;
    int sidePixels=0;
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_borderBits = NULL;
    int borderBits=1;

    const char* keywords[] = { "dictionary", "id", "sidePixels", "img", "borderBits", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:drawMarker", (char**)keywords, &pyobj_dictionary, &pyobj_id, &pyobj_sidePixels, &pyobj_img, &pyobj_borderBits) &&
        pyopencv_to_safe(pyobj_dictionary, dictionary, ArgInfo("dictionary", 0)) &&
        pyopencv_to_safe(pyobj_id, id, ArgInfo("id", 0)) &&
        pyopencv_to_safe(pyobj_sidePixels, sidePixels, ArgInfo("sidePixels", 0)) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_borderBits, borderBits, ArgInfo("borderBits", 0)) )
    {
        ERRWRAP2(cv::aruco::drawMarker(dictionary, id, sidePixels, img, borderBits));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_dictionary = NULL;
    Ptr<Dictionary> dictionary;
    PyObject* pyobj_id = NULL;
    int id=0;
    PyObject* pyobj_sidePixels = NULL;
    int sidePixels=0;
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_borderBits = NULL;
    int borderBits=1;

    const char* keywords[] = { "dictionary", "id", "sidePixels", "img", "borderBits", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:drawMarker", (char**)keywords, &pyobj_dictionary, &pyobj_id, &pyobj_sidePixels, &pyobj_img, &pyobj_borderBits) &&
        pyopencv_to_safe(pyobj_dictionary, dictionary, ArgInfo("dictionary", 0)) &&
        pyopencv_to_safe(pyobj_id, id, ArgInfo("id", 0)) &&
        pyopencv_to_safe(pyobj_sidePixels, sidePixels, ArgInfo("sidePixels", 0)) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_borderBits, borderBits, ArgInfo("borderBits", 0)) )
    {
        ERRWRAP2(cv::aruco::drawMarker(dictionary, id, sidePixels, img, borderBits));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("drawMarker");

    return NULL;
}

static PyObject* pyopencv_cv_aruco_drawPlanarBoard(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_board = NULL;
    Ptr<Board> board;
    PyObject* pyobj_outSize = NULL;
    Size outSize;
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_marginSize = NULL;
    int marginSize=0;
    PyObject* pyobj_borderBits = NULL;
    int borderBits=1;

    const char* keywords[] = { "board", "outSize", "img", "marginSize", "borderBits", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:drawPlanarBoard", (char**)keywords, &pyobj_board, &pyobj_outSize, &pyobj_img, &pyobj_marginSize, &pyobj_borderBits) &&
        pyopencv_to_safe(pyobj_board, board, ArgInfo("board", 0)) &&
        pyopencv_to_safe(pyobj_outSize, outSize, ArgInfo("outSize", 0)) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_marginSize, marginSize, ArgInfo("marginSize", 0)) &&
        pyopencv_to_safe(pyobj_borderBits, borderBits, ArgInfo("borderBits", 0)) )
    {
        ERRWRAP2(cv::aruco::drawPlanarBoard(board, outSize, img, marginSize, borderBits));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_board = NULL;
    Ptr<Board> board;
    PyObject* pyobj_outSize = NULL;
    Size outSize;
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_marginSize = NULL;
    int marginSize=0;
    PyObject* pyobj_borderBits = NULL;
    int borderBits=1;

    const char* keywords[] = { "board", "outSize", "img", "marginSize", "borderBits", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:drawPlanarBoard", (char**)keywords, &pyobj_board, &pyobj_outSize, &pyobj_img, &pyobj_marginSize, &pyobj_borderBits) &&
        pyopencv_to_safe(pyobj_board, board, ArgInfo("board", 0)) &&
        pyopencv_to_safe(pyobj_outSize, outSize, ArgInfo("outSize", 0)) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_marginSize, marginSize, ArgInfo("marginSize", 0)) &&
        pyopencv_to_safe(pyobj_borderBits, borderBits, ArgInfo("borderBits", 0)) )
    {
        ERRWRAP2(cv::aruco::drawPlanarBoard(board, outSize, img, marginSize, borderBits));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("drawPlanarBoard");

    return NULL;
}

static PyObject* pyopencv_cv_aruco_estimatePoseBoard(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_corners = NULL;
    vector_Mat corners;
    PyObject* pyobj_ids = NULL;
    Mat ids;
    PyObject* pyobj_board = NULL;
    Ptr<Board> board;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    Mat distCoeffs;
    PyObject* pyobj_rvec = NULL;
    Mat rvec;
    PyObject* pyobj_tvec = NULL;
    Mat tvec;
    PyObject* pyobj_useExtrinsicGuess = NULL;
    bool useExtrinsicGuess=false;
    int retval;

    const char* keywords[] = { "corners", "ids", "board", "cameraMatrix", "distCoeffs", "rvec", "tvec", "useExtrinsicGuess", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOO|O:estimatePoseBoard", (char**)keywords, &pyobj_corners, &pyobj_ids, &pyobj_board, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvec, &pyobj_tvec, &pyobj_useExtrinsicGuess) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 0)) &&
        pyopencv_to_safe(pyobj_ids, ids, ArgInfo("ids", 0)) &&
        pyopencv_to_safe(pyobj_board, board, ArgInfo("board", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 1)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 1)) &&
        pyopencv_to_safe(pyobj_useExtrinsicGuess, useExtrinsicGuess, ArgInfo("useExtrinsicGuess", 0)) )
    {
        ERRWRAP2(retval = cv::aruco::estimatePoseBoard(corners, ids, board, cameraMatrix, distCoeffs, rvec, tvec, useExtrinsicGuess));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(rvec), pyopencv_from(tvec));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_corners = NULL;
    vector_UMat corners;
    PyObject* pyobj_ids = NULL;
    UMat ids;
    PyObject* pyobj_board = NULL;
    Ptr<Board> board;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    UMat distCoeffs;
    PyObject* pyobj_rvec = NULL;
    UMat rvec;
    PyObject* pyobj_tvec = NULL;
    UMat tvec;
    PyObject* pyobj_useExtrinsicGuess = NULL;
    bool useExtrinsicGuess=false;
    int retval;

    const char* keywords[] = { "corners", "ids", "board", "cameraMatrix", "distCoeffs", "rvec", "tvec", "useExtrinsicGuess", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOO|O:estimatePoseBoard", (char**)keywords, &pyobj_corners, &pyobj_ids, &pyobj_board, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvec, &pyobj_tvec, &pyobj_useExtrinsicGuess) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 0)) &&
        pyopencv_to_safe(pyobj_ids, ids, ArgInfo("ids", 0)) &&
        pyopencv_to_safe(pyobj_board, board, ArgInfo("board", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 1)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 1)) &&
        pyopencv_to_safe(pyobj_useExtrinsicGuess, useExtrinsicGuess, ArgInfo("useExtrinsicGuess", 0)) )
    {
        ERRWRAP2(retval = cv::aruco::estimatePoseBoard(corners, ids, board, cameraMatrix, distCoeffs, rvec, tvec, useExtrinsicGuess));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(rvec), pyopencv_from(tvec));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("estimatePoseBoard");

    return NULL;
}

static PyObject* pyopencv_cv_aruco_estimatePoseCharucoBoard(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_charucoCorners = NULL;
    Mat charucoCorners;
    PyObject* pyobj_charucoIds = NULL;
    Mat charucoIds;
    PyObject* pyobj_board = NULL;
    Ptr<CharucoBoard> board;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    Mat distCoeffs;
    PyObject* pyobj_rvec = NULL;
    Mat rvec;
    PyObject* pyobj_tvec = NULL;
    Mat tvec;
    PyObject* pyobj_useExtrinsicGuess = NULL;
    bool useExtrinsicGuess=false;
    bool retval;

    const char* keywords[] = { "charucoCorners", "charucoIds", "board", "cameraMatrix", "distCoeffs", "rvec", "tvec", "useExtrinsicGuess", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOO|O:estimatePoseCharucoBoard", (char**)keywords, &pyobj_charucoCorners, &pyobj_charucoIds, &pyobj_board, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvec, &pyobj_tvec, &pyobj_useExtrinsicGuess) &&
        pyopencv_to_safe(pyobj_charucoCorners, charucoCorners, ArgInfo("charucoCorners", 0)) &&
        pyopencv_to_safe(pyobj_charucoIds, charucoIds, ArgInfo("charucoIds", 0)) &&
        pyopencv_to_safe(pyobj_board, board, ArgInfo("board", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 1)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 1)) &&
        pyopencv_to_safe(pyobj_useExtrinsicGuess, useExtrinsicGuess, ArgInfo("useExtrinsicGuess", 0)) )
    {
        ERRWRAP2(retval = cv::aruco::estimatePoseCharucoBoard(charucoCorners, charucoIds, board, cameraMatrix, distCoeffs, rvec, tvec, useExtrinsicGuess));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(rvec), pyopencv_from(tvec));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_charucoCorners = NULL;
    UMat charucoCorners;
    PyObject* pyobj_charucoIds = NULL;
    UMat charucoIds;
    PyObject* pyobj_board = NULL;
    Ptr<CharucoBoard> board;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    UMat distCoeffs;
    PyObject* pyobj_rvec = NULL;
    UMat rvec;
    PyObject* pyobj_tvec = NULL;
    UMat tvec;
    PyObject* pyobj_useExtrinsicGuess = NULL;
    bool useExtrinsicGuess=false;
    bool retval;

    const char* keywords[] = { "charucoCorners", "charucoIds", "board", "cameraMatrix", "distCoeffs", "rvec", "tvec", "useExtrinsicGuess", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOO|O:estimatePoseCharucoBoard", (char**)keywords, &pyobj_charucoCorners, &pyobj_charucoIds, &pyobj_board, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvec, &pyobj_tvec, &pyobj_useExtrinsicGuess) &&
        pyopencv_to_safe(pyobj_charucoCorners, charucoCorners, ArgInfo("charucoCorners", 0)) &&
        pyopencv_to_safe(pyobj_charucoIds, charucoIds, ArgInfo("charucoIds", 0)) &&
        pyopencv_to_safe(pyobj_board, board, ArgInfo("board", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 1)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 1)) &&
        pyopencv_to_safe(pyobj_useExtrinsicGuess, useExtrinsicGuess, ArgInfo("useExtrinsicGuess", 0)) )
    {
        ERRWRAP2(retval = cv::aruco::estimatePoseCharucoBoard(charucoCorners, charucoIds, board, cameraMatrix, distCoeffs, rvec, tvec, useExtrinsicGuess));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(rvec), pyopencv_from(tvec));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("estimatePoseCharucoBoard");

    return NULL;
}

static PyObject* pyopencv_cv_aruco_estimatePoseSingleMarkers(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_corners = NULL;
    vector_Mat corners;
    PyObject* pyobj_markerLength = NULL;
    float markerLength=0.f;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    Mat distCoeffs;
    PyObject* pyobj_rvecs = NULL;
    Mat rvecs;
    PyObject* pyobj_tvecs = NULL;
    Mat tvecs;
    PyObject* pyobj__objPoints = NULL;
    Mat _objPoints;

    const char* keywords[] = { "corners", "markerLength", "cameraMatrix", "distCoeffs", "rvecs", "tvecs", "_objPoints", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:estimatePoseSingleMarkers", (char**)keywords, &pyobj_corners, &pyobj_markerLength, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvecs, &pyobj_tvecs, &pyobj__objPoints) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 0)) &&
        pyopencv_to_safe(pyobj_markerLength, markerLength, ArgInfo("markerLength", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_rvecs, rvecs, ArgInfo("rvecs", 1)) &&
        pyopencv_to_safe(pyobj_tvecs, tvecs, ArgInfo("tvecs", 1)) &&
        pyopencv_to_safe(pyobj__objPoints, _objPoints, ArgInfo("_objPoints", 1)) )
    {
        ERRWRAP2(cv::aruco::estimatePoseSingleMarkers(corners, markerLength, cameraMatrix, distCoeffs, rvecs, tvecs, _objPoints));
        return Py_BuildValue("(NNN)", pyopencv_from(rvecs), pyopencv_from(tvecs), pyopencv_from(_objPoints));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_corners = NULL;
    vector_UMat corners;
    PyObject* pyobj_markerLength = NULL;
    float markerLength=0.f;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    UMat distCoeffs;
    PyObject* pyobj_rvecs = NULL;
    UMat rvecs;
    PyObject* pyobj_tvecs = NULL;
    UMat tvecs;
    PyObject* pyobj__objPoints = NULL;
    UMat _objPoints;

    const char* keywords[] = { "corners", "markerLength", "cameraMatrix", "distCoeffs", "rvecs", "tvecs", "_objPoints", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:estimatePoseSingleMarkers", (char**)keywords, &pyobj_corners, &pyobj_markerLength, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_rvecs, &pyobj_tvecs, &pyobj__objPoints) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 0)) &&
        pyopencv_to_safe(pyobj_markerLength, markerLength, ArgInfo("markerLength", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_rvecs, rvecs, ArgInfo("rvecs", 1)) &&
        pyopencv_to_safe(pyobj_tvecs, tvecs, ArgInfo("tvecs", 1)) &&
        pyopencv_to_safe(pyobj__objPoints, _objPoints, ArgInfo("_objPoints", 1)) )
    {
        ERRWRAP2(cv::aruco::estimatePoseSingleMarkers(corners, markerLength, cameraMatrix, distCoeffs, rvecs, tvecs, _objPoints));
        return Py_BuildValue("(NNN)", pyopencv_from(rvecs), pyopencv_from(tvecs), pyopencv_from(_objPoints));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("estimatePoseSingleMarkers");

    return NULL;
}

static PyObject* pyopencv_cv_aruco_getBoardObjectAndImagePoints(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_board = NULL;
    Ptr<Board> board;
    PyObject* pyobj_detectedCorners = NULL;
    vector_Mat detectedCorners;
    PyObject* pyobj_detectedIds = NULL;
    Mat detectedIds;
    PyObject* pyobj_objPoints = NULL;
    Mat objPoints;
    PyObject* pyobj_imgPoints = NULL;
    Mat imgPoints;

    const char* keywords[] = { "board", "detectedCorners", "detectedIds", "objPoints", "imgPoints", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:getBoardObjectAndImagePoints", (char**)keywords, &pyobj_board, &pyobj_detectedCorners, &pyobj_detectedIds, &pyobj_objPoints, &pyobj_imgPoints) &&
        pyopencv_to_safe(pyobj_board, board, ArgInfo("board", 0)) &&
        pyopencv_to_safe(pyobj_detectedCorners, detectedCorners, ArgInfo("detectedCorners", 0)) &&
        pyopencv_to_safe(pyobj_detectedIds, detectedIds, ArgInfo("detectedIds", 0)) &&
        pyopencv_to_safe(pyobj_objPoints, objPoints, ArgInfo("objPoints", 1)) &&
        pyopencv_to_safe(pyobj_imgPoints, imgPoints, ArgInfo("imgPoints", 1)) )
    {
        ERRWRAP2(cv::aruco::getBoardObjectAndImagePoints(board, detectedCorners, detectedIds, objPoints, imgPoints));
        return Py_BuildValue("(NN)", pyopencv_from(objPoints), pyopencv_from(imgPoints));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_board = NULL;
    Ptr<Board> board;
    PyObject* pyobj_detectedCorners = NULL;
    vector_UMat detectedCorners;
    PyObject* pyobj_detectedIds = NULL;
    UMat detectedIds;
    PyObject* pyobj_objPoints = NULL;
    UMat objPoints;
    PyObject* pyobj_imgPoints = NULL;
    UMat imgPoints;

    const char* keywords[] = { "board", "detectedCorners", "detectedIds", "objPoints", "imgPoints", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:getBoardObjectAndImagePoints", (char**)keywords, &pyobj_board, &pyobj_detectedCorners, &pyobj_detectedIds, &pyobj_objPoints, &pyobj_imgPoints) &&
        pyopencv_to_safe(pyobj_board, board, ArgInfo("board", 0)) &&
        pyopencv_to_safe(pyobj_detectedCorners, detectedCorners, ArgInfo("detectedCorners", 0)) &&
        pyopencv_to_safe(pyobj_detectedIds, detectedIds, ArgInfo("detectedIds", 0)) &&
        pyopencv_to_safe(pyobj_objPoints, objPoints, ArgInfo("objPoints", 1)) &&
        pyopencv_to_safe(pyobj_imgPoints, imgPoints, ArgInfo("imgPoints", 1)) )
    {
        ERRWRAP2(cv::aruco::getBoardObjectAndImagePoints(board, detectedCorners, detectedIds, objPoints, imgPoints));
        return Py_BuildValue("(NN)", pyopencv_from(objPoints), pyopencv_from(imgPoints));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("getBoardObjectAndImagePoints");

    return NULL;
}

static PyObject* pyopencv_cv_aruco_getPredefinedDictionary(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    PyObject* pyobj_dict = NULL;
    int dict=0;
    Ptr<Dictionary> retval;

    const char* keywords[] = { "dict", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:getPredefinedDictionary", (char**)keywords, &pyobj_dict) &&
        pyopencv_to_safe(pyobj_dict, dict, ArgInfo("dict", 0)) )
    {
        ERRWRAP2(retval = cv::aruco::getPredefinedDictionary(dict));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_aruco_interpolateCornersCharuco(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_markerCorners = NULL;
    vector_Mat markerCorners;
    PyObject* pyobj_markerIds = NULL;
    Mat markerIds;
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_board = NULL;
    Ptr<CharucoBoard> board;
    PyObject* pyobj_charucoCorners = NULL;
    Mat charucoCorners;
    PyObject* pyobj_charucoIds = NULL;
    Mat charucoIds;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    Mat distCoeffs;
    PyObject* pyobj_minMarkers = NULL;
    int minMarkers=2;
    int retval;

    const char* keywords[] = { "markerCorners", "markerIds", "image", "board", "charucoCorners", "charucoIds", "cameraMatrix", "distCoeffs", "minMarkers", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOOO:interpolateCornersCharuco", (char**)keywords, &pyobj_markerCorners, &pyobj_markerIds, &pyobj_image, &pyobj_board, &pyobj_charucoCorners, &pyobj_charucoIds, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_minMarkers) &&
        pyopencv_to_safe(pyobj_markerCorners, markerCorners, ArgInfo("markerCorners", 0)) &&
        pyopencv_to_safe(pyobj_markerIds, markerIds, ArgInfo("markerIds", 0)) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_board, board, ArgInfo("board", 0)) &&
        pyopencv_to_safe(pyobj_charucoCorners, charucoCorners, ArgInfo("charucoCorners", 1)) &&
        pyopencv_to_safe(pyobj_charucoIds, charucoIds, ArgInfo("charucoIds", 1)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_minMarkers, minMarkers, ArgInfo("minMarkers", 0)) )
    {
        ERRWRAP2(retval = cv::aruco::interpolateCornersCharuco(markerCorners, markerIds, image, board, charucoCorners, charucoIds, cameraMatrix, distCoeffs, minMarkers));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(charucoCorners), pyopencv_from(charucoIds));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_markerCorners = NULL;
    vector_UMat markerCorners;
    PyObject* pyobj_markerIds = NULL;
    UMat markerIds;
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_board = NULL;
    Ptr<CharucoBoard> board;
    PyObject* pyobj_charucoCorners = NULL;
    UMat charucoCorners;
    PyObject* pyobj_charucoIds = NULL;
    UMat charucoIds;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    UMat distCoeffs;
    PyObject* pyobj_minMarkers = NULL;
    int minMarkers=2;
    int retval;

    const char* keywords[] = { "markerCorners", "markerIds", "image", "board", "charucoCorners", "charucoIds", "cameraMatrix", "distCoeffs", "minMarkers", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOOO:interpolateCornersCharuco", (char**)keywords, &pyobj_markerCorners, &pyobj_markerIds, &pyobj_image, &pyobj_board, &pyobj_charucoCorners, &pyobj_charucoIds, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_minMarkers) &&
        pyopencv_to_safe(pyobj_markerCorners, markerCorners, ArgInfo("markerCorners", 0)) &&
        pyopencv_to_safe(pyobj_markerIds, markerIds, ArgInfo("markerIds", 0)) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_board, board, ArgInfo("board", 0)) &&
        pyopencv_to_safe(pyobj_charucoCorners, charucoCorners, ArgInfo("charucoCorners", 1)) &&
        pyopencv_to_safe(pyobj_charucoIds, charucoIds, ArgInfo("charucoIds", 1)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_minMarkers, minMarkers, ArgInfo("minMarkers", 0)) )
    {
        ERRWRAP2(retval = cv::aruco::interpolateCornersCharuco(markerCorners, markerIds, image, board, charucoCorners, charucoIds, cameraMatrix, distCoeffs, minMarkers));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(charucoCorners), pyopencv_from(charucoIds));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("interpolateCornersCharuco");

    return NULL;
}

static PyObject* pyopencv_cv_aruco_refineDetectedMarkers(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_board = NULL;
    Ptr<Board> board;
    PyObject* pyobj_detectedCorners = NULL;
    vector_Mat detectedCorners;
    PyObject* pyobj_detectedIds = NULL;
    Mat detectedIds;
    PyObject* pyobj_rejectedCorners = NULL;
    vector_Mat rejectedCorners;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    Mat distCoeffs;
    PyObject* pyobj_minRepDistance = NULL;
    float minRepDistance=10.f;
    PyObject* pyobj_errorCorrectionRate = NULL;
    float errorCorrectionRate=3.f;
    PyObject* pyobj_checkAllOrders = NULL;
    bool checkAllOrders=true;
    PyObject* pyobj_recoveredIdxs = NULL;
    Mat recoveredIdxs;
    PyObject* pyobj_parameters = NULL;
    Ptr<DetectorParameters> parameters=DetectorParameters::create();

    const char* keywords[] = { "image", "board", "detectedCorners", "detectedIds", "rejectedCorners", "cameraMatrix", "distCoeffs", "minRepDistance", "errorCorrectionRate", "checkAllOrders", "recoveredIdxs", "parameters", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OOOOOOO:refineDetectedMarkers", (char**)keywords, &pyobj_image, &pyobj_board, &pyobj_detectedCorners, &pyobj_detectedIds, &pyobj_rejectedCorners, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_minRepDistance, &pyobj_errorCorrectionRate, &pyobj_checkAllOrders, &pyobj_recoveredIdxs, &pyobj_parameters) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_board, board, ArgInfo("board", 0)) &&
        pyopencv_to_safe(pyobj_detectedCorners, detectedCorners, ArgInfo("detectedCorners", 1)) &&
        pyopencv_to_safe(pyobj_detectedIds, detectedIds, ArgInfo("detectedIds", 1)) &&
        pyopencv_to_safe(pyobj_rejectedCorners, rejectedCorners, ArgInfo("rejectedCorners", 1)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_minRepDistance, minRepDistance, ArgInfo("minRepDistance", 0)) &&
        pyopencv_to_safe(pyobj_errorCorrectionRate, errorCorrectionRate, ArgInfo("errorCorrectionRate", 0)) &&
        pyopencv_to_safe(pyobj_checkAllOrders, checkAllOrders, ArgInfo("checkAllOrders", 0)) &&
        pyopencv_to_safe(pyobj_recoveredIdxs, recoveredIdxs, ArgInfo("recoveredIdxs", 1)) &&
        pyopencv_to_safe(pyobj_parameters, parameters, ArgInfo("parameters", 0)) )
    {
        ERRWRAP2(cv::aruco::refineDetectedMarkers(image, board, detectedCorners, detectedIds, rejectedCorners, cameraMatrix, distCoeffs, minRepDistance, errorCorrectionRate, checkAllOrders, recoveredIdxs, parameters));
        return Py_BuildValue("(NNNN)", pyopencv_from(detectedCorners), pyopencv_from(detectedIds), pyopencv_from(rejectedCorners), pyopencv_from(recoveredIdxs));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_board = NULL;
    Ptr<Board> board;
    PyObject* pyobj_detectedCorners = NULL;
    vector_UMat detectedCorners;
    PyObject* pyobj_detectedIds = NULL;
    UMat detectedIds;
    PyObject* pyobj_rejectedCorners = NULL;
    vector_UMat rejectedCorners;
    PyObject* pyobj_cameraMatrix = NULL;
    UMat cameraMatrix;
    PyObject* pyobj_distCoeffs = NULL;
    UMat distCoeffs;
    PyObject* pyobj_minRepDistance = NULL;
    float minRepDistance=10.f;
    PyObject* pyobj_errorCorrectionRate = NULL;
    float errorCorrectionRate=3.f;
    PyObject* pyobj_checkAllOrders = NULL;
    bool checkAllOrders=true;
    PyObject* pyobj_recoveredIdxs = NULL;
    UMat recoveredIdxs;
    PyObject* pyobj_parameters = NULL;
    Ptr<DetectorParameters> parameters=DetectorParameters::create();

    const char* keywords[] = { "image", "board", "detectedCorners", "detectedIds", "rejectedCorners", "cameraMatrix", "distCoeffs", "minRepDistance", "errorCorrectionRate", "checkAllOrders", "recoveredIdxs", "parameters", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OOOOOOO:refineDetectedMarkers", (char**)keywords, &pyobj_image, &pyobj_board, &pyobj_detectedCorners, &pyobj_detectedIds, &pyobj_rejectedCorners, &pyobj_cameraMatrix, &pyobj_distCoeffs, &pyobj_minRepDistance, &pyobj_errorCorrectionRate, &pyobj_checkAllOrders, &pyobj_recoveredIdxs, &pyobj_parameters) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_board, board, ArgInfo("board", 0)) &&
        pyopencv_to_safe(pyobj_detectedCorners, detectedCorners, ArgInfo("detectedCorners", 1)) &&
        pyopencv_to_safe(pyobj_detectedIds, detectedIds, ArgInfo("detectedIds", 1)) &&
        pyopencv_to_safe(pyobj_rejectedCorners, rejectedCorners, ArgInfo("rejectedCorners", 1)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeffs, distCoeffs, ArgInfo("distCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_minRepDistance, minRepDistance, ArgInfo("minRepDistance", 0)) &&
        pyopencv_to_safe(pyobj_errorCorrectionRate, errorCorrectionRate, ArgInfo("errorCorrectionRate", 0)) &&
        pyopencv_to_safe(pyobj_checkAllOrders, checkAllOrders, ArgInfo("checkAllOrders", 0)) &&
        pyopencv_to_safe(pyobj_recoveredIdxs, recoveredIdxs, ArgInfo("recoveredIdxs", 1)) &&
        pyopencv_to_safe(pyobj_parameters, parameters, ArgInfo("parameters", 0)) )
    {
        ERRWRAP2(cv::aruco::refineDetectedMarkers(image, board, detectedCorners, detectedIds, rejectedCorners, cameraMatrix, distCoeffs, minRepDistance, errorCorrectionRate, checkAllOrders, recoveredIdxs, parameters));
        return Py_BuildValue("(NNNN)", pyopencv_from(detectedCorners), pyopencv_from(detectedIds), pyopencv_from(rejectedCorners), pyopencv_from(recoveredIdxs));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("refineDetectedMarkers");

    return NULL;
}

static PyObject* pyopencv_cv_aruco_testCharucoCornersCollinear(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::aruco;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj__board = NULL;
    Ptr<CharucoBoard> _board;
    PyObject* pyobj__charucoIds = NULL;
    Mat _charucoIds;
    bool retval;

    const char* keywords[] = { "_board", "_charucoIds", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:testCharucoCornersCollinear", (char**)keywords, &pyobj__board, &pyobj__charucoIds) &&
        pyopencv_to_safe(pyobj__board, _board, ArgInfo("_board", 0)) &&
        pyopencv_to_safe(pyobj__charucoIds, _charucoIds, ArgInfo("_charucoIds", 0)) )
    {
        ERRWRAP2(retval = cv::aruco::testCharucoCornersCollinear(_board, _charucoIds));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj__board = NULL;
    Ptr<CharucoBoard> _board;
    PyObject* pyobj__charucoIds = NULL;
    UMat _charucoIds;
    bool retval;

    const char* keywords[] = { "_board", "_charucoIds", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:testCharucoCornersCollinear", (char**)keywords, &pyobj__board, &pyobj__charucoIds) &&
        pyopencv_to_safe(pyobj__board, _board, ArgInfo("_board", 0)) &&
        pyopencv_to_safe(pyobj__charucoIds, _charucoIds, ArgInfo("_charucoIds", 0)) )
    {
        ERRWRAP2(retval = cv::aruco::testCharucoCornersCollinear(_board, _charucoIds));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("testCharucoCornersCollinear");

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_createBackgroundSubtractorCNT(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::bgsegm;

    PyObject* pyobj_minPixelStability = NULL;
    int minPixelStability=15;
    PyObject* pyobj_useHistory = NULL;
    bool useHistory=true;
    PyObject* pyobj_maxPixelStability = NULL;
    int maxPixelStability=15*60;
    PyObject* pyobj_isParallel = NULL;
    bool isParallel=true;
    Ptr<BackgroundSubtractorCNT> retval;

    const char* keywords[] = { "minPixelStability", "useHistory", "maxPixelStability", "isParallel", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOO:createBackgroundSubtractorCNT", (char**)keywords, &pyobj_minPixelStability, &pyobj_useHistory, &pyobj_maxPixelStability, &pyobj_isParallel) &&
        pyopencv_to_safe(pyobj_minPixelStability, minPixelStability, ArgInfo("minPixelStability", 0)) &&
        pyopencv_to_safe(pyobj_useHistory, useHistory, ArgInfo("useHistory", 0)) &&
        pyopencv_to_safe(pyobj_maxPixelStability, maxPixelStability, ArgInfo("maxPixelStability", 0)) &&
        pyopencv_to_safe(pyobj_isParallel, isParallel, ArgInfo("isParallel", 0)) )
    {
        ERRWRAP2(retval = cv::bgsegm::createBackgroundSubtractorCNT(minPixelStability, useHistory, maxPixelStability, isParallel));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_createBackgroundSubtractorGMG(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::bgsegm;

    PyObject* pyobj_initializationFrames = NULL;
    int initializationFrames=120;
    PyObject* pyobj_decisionThreshold = NULL;
    double decisionThreshold=0.8;
    Ptr<BackgroundSubtractorGMG> retval;

    const char* keywords[] = { "initializationFrames", "decisionThreshold", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OO:createBackgroundSubtractorGMG", (char**)keywords, &pyobj_initializationFrames, &pyobj_decisionThreshold) &&
        pyopencv_to_safe(pyobj_initializationFrames, initializationFrames, ArgInfo("initializationFrames", 0)) &&
        pyopencv_to_safe(pyobj_decisionThreshold, decisionThreshold, ArgInfo("decisionThreshold", 0)) )
    {
        ERRWRAP2(retval = cv::bgsegm::createBackgroundSubtractorGMG(initializationFrames, decisionThreshold));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_createBackgroundSubtractorGSOC(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::bgsegm;

    PyObject* pyobj_mc = NULL;
    int mc=LSBP_CAMERA_MOTION_COMPENSATION_NONE;
    PyObject* pyobj_nSamples = NULL;
    int nSamples=20;
    PyObject* pyobj_replaceRate = NULL;
    float replaceRate=0.003f;
    PyObject* pyobj_propagationRate = NULL;
    float propagationRate=0.01f;
    PyObject* pyobj_hitsThreshold = NULL;
    int hitsThreshold=32;
    PyObject* pyobj_alpha = NULL;
    float alpha=0.01f;
    PyObject* pyobj_beta = NULL;
    float beta=0.0022f;
    PyObject* pyobj_blinkingSupressionDecay = NULL;
    float blinkingSupressionDecay=0.1f;
    PyObject* pyobj_blinkingSupressionMultiplier = NULL;
    float blinkingSupressionMultiplier=0.1f;
    PyObject* pyobj_noiseRemovalThresholdFacBG = NULL;
    float noiseRemovalThresholdFacBG=0.0004f;
    PyObject* pyobj_noiseRemovalThresholdFacFG = NULL;
    float noiseRemovalThresholdFacFG=0.0008f;
    Ptr<BackgroundSubtractorGSOC> retval;

    const char* keywords[] = { "mc", "nSamples", "replaceRate", "propagationRate", "hitsThreshold", "alpha", "beta", "blinkingSupressionDecay", "blinkingSupressionMultiplier", "noiseRemovalThresholdFacBG", "noiseRemovalThresholdFacFG", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOOOOOOOO:createBackgroundSubtractorGSOC", (char**)keywords, &pyobj_mc, &pyobj_nSamples, &pyobj_replaceRate, &pyobj_propagationRate, &pyobj_hitsThreshold, &pyobj_alpha, &pyobj_beta, &pyobj_blinkingSupressionDecay, &pyobj_blinkingSupressionMultiplier, &pyobj_noiseRemovalThresholdFacBG, &pyobj_noiseRemovalThresholdFacFG) &&
        pyopencv_to_safe(pyobj_mc, mc, ArgInfo("mc", 0)) &&
        pyopencv_to_safe(pyobj_nSamples, nSamples, ArgInfo("nSamples", 0)) &&
        pyopencv_to_safe(pyobj_replaceRate, replaceRate, ArgInfo("replaceRate", 0)) &&
        pyopencv_to_safe(pyobj_propagationRate, propagationRate, ArgInfo("propagationRate", 0)) &&
        pyopencv_to_safe(pyobj_hitsThreshold, hitsThreshold, ArgInfo("hitsThreshold", 0)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_beta, beta, ArgInfo("beta", 0)) &&
        pyopencv_to_safe(pyobj_blinkingSupressionDecay, blinkingSupressionDecay, ArgInfo("blinkingSupressionDecay", 0)) &&
        pyopencv_to_safe(pyobj_blinkingSupressionMultiplier, blinkingSupressionMultiplier, ArgInfo("blinkingSupressionMultiplier", 0)) &&
        pyopencv_to_safe(pyobj_noiseRemovalThresholdFacBG, noiseRemovalThresholdFacBG, ArgInfo("noiseRemovalThresholdFacBG", 0)) &&
        pyopencv_to_safe(pyobj_noiseRemovalThresholdFacFG, noiseRemovalThresholdFacFG, ArgInfo("noiseRemovalThresholdFacFG", 0)) )
    {
        ERRWRAP2(retval = cv::bgsegm::createBackgroundSubtractorGSOC(mc, nSamples, replaceRate, propagationRate, hitsThreshold, alpha, beta, blinkingSupressionDecay, blinkingSupressionMultiplier, noiseRemovalThresholdFacBG, noiseRemovalThresholdFacFG));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_createBackgroundSubtractorLSBP(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::bgsegm;

    PyObject* pyobj_mc = NULL;
    int mc=LSBP_CAMERA_MOTION_COMPENSATION_NONE;
    PyObject* pyobj_nSamples = NULL;
    int nSamples=20;
    PyObject* pyobj_LSBPRadius = NULL;
    int LSBPRadius=16;
    PyObject* pyobj_Tlower = NULL;
    float Tlower=2.0f;
    PyObject* pyobj_Tupper = NULL;
    float Tupper=32.0f;
    PyObject* pyobj_Tinc = NULL;
    float Tinc=1.0f;
    PyObject* pyobj_Tdec = NULL;
    float Tdec=0.05f;
    PyObject* pyobj_Rscale = NULL;
    float Rscale=10.0f;
    PyObject* pyobj_Rincdec = NULL;
    float Rincdec=0.005f;
    PyObject* pyobj_noiseRemovalThresholdFacBG = NULL;
    float noiseRemovalThresholdFacBG=0.0004f;
    PyObject* pyobj_noiseRemovalThresholdFacFG = NULL;
    float noiseRemovalThresholdFacFG=0.0008f;
    PyObject* pyobj_LSBPthreshold = NULL;
    int LSBPthreshold=8;
    PyObject* pyobj_minCount = NULL;
    int minCount=2;
    Ptr<BackgroundSubtractorLSBP> retval;

    const char* keywords[] = { "mc", "nSamples", "LSBPRadius", "Tlower", "Tupper", "Tinc", "Tdec", "Rscale", "Rincdec", "noiseRemovalThresholdFacBG", "noiseRemovalThresholdFacFG", "LSBPthreshold", "minCount", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOOOOOOOOOO:createBackgroundSubtractorLSBP", (char**)keywords, &pyobj_mc, &pyobj_nSamples, &pyobj_LSBPRadius, &pyobj_Tlower, &pyobj_Tupper, &pyobj_Tinc, &pyobj_Tdec, &pyobj_Rscale, &pyobj_Rincdec, &pyobj_noiseRemovalThresholdFacBG, &pyobj_noiseRemovalThresholdFacFG, &pyobj_LSBPthreshold, &pyobj_minCount) &&
        pyopencv_to_safe(pyobj_mc, mc, ArgInfo("mc", 0)) &&
        pyopencv_to_safe(pyobj_nSamples, nSamples, ArgInfo("nSamples", 0)) &&
        pyopencv_to_safe(pyobj_LSBPRadius, LSBPRadius, ArgInfo("LSBPRadius", 0)) &&
        pyopencv_to_safe(pyobj_Tlower, Tlower, ArgInfo("Tlower", 0)) &&
        pyopencv_to_safe(pyobj_Tupper, Tupper, ArgInfo("Tupper", 0)) &&
        pyopencv_to_safe(pyobj_Tinc, Tinc, ArgInfo("Tinc", 0)) &&
        pyopencv_to_safe(pyobj_Tdec, Tdec, ArgInfo("Tdec", 0)) &&
        pyopencv_to_safe(pyobj_Rscale, Rscale, ArgInfo("Rscale", 0)) &&
        pyopencv_to_safe(pyobj_Rincdec, Rincdec, ArgInfo("Rincdec", 0)) &&
        pyopencv_to_safe(pyobj_noiseRemovalThresholdFacBG, noiseRemovalThresholdFacBG, ArgInfo("noiseRemovalThresholdFacBG", 0)) &&
        pyopencv_to_safe(pyobj_noiseRemovalThresholdFacFG, noiseRemovalThresholdFacFG, ArgInfo("noiseRemovalThresholdFacFG", 0)) &&
        pyopencv_to_safe(pyobj_LSBPthreshold, LSBPthreshold, ArgInfo("LSBPthreshold", 0)) &&
        pyopencv_to_safe(pyobj_minCount, minCount, ArgInfo("minCount", 0)) )
    {
        ERRWRAP2(retval = cv::bgsegm::createBackgroundSubtractorLSBP(mc, nSamples, LSBPRadius, Tlower, Tupper, Tinc, Tdec, Rscale, Rincdec, noiseRemovalThresholdFacBG, noiseRemovalThresholdFacFG, LSBPthreshold, minCount));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_createBackgroundSubtractorMOG(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::bgsegm;

    PyObject* pyobj_history = NULL;
    int history=200;
    PyObject* pyobj_nmixtures = NULL;
    int nmixtures=5;
    PyObject* pyobj_backgroundRatio = NULL;
    double backgroundRatio=0.7;
    PyObject* pyobj_noiseSigma = NULL;
    double noiseSigma=0;
    Ptr<BackgroundSubtractorMOG> retval;

    const char* keywords[] = { "history", "nmixtures", "backgroundRatio", "noiseSigma", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOO:createBackgroundSubtractorMOG", (char**)keywords, &pyobj_history, &pyobj_nmixtures, &pyobj_backgroundRatio, &pyobj_noiseSigma) &&
        pyopencv_to_safe(pyobj_history, history, ArgInfo("history", 0)) &&
        pyopencv_to_safe(pyobj_nmixtures, nmixtures, ArgInfo("nmixtures", 0)) &&
        pyopencv_to_safe(pyobj_backgroundRatio, backgroundRatio, ArgInfo("backgroundRatio", 0)) &&
        pyopencv_to_safe(pyobj_noiseSigma, noiseSigma, ArgInfo("noiseSigma", 0)) )
    {
        ERRWRAP2(retval = cv::bgsegm::createBackgroundSubtractorMOG(history, nmixtures, backgroundRatio, noiseSigma));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_bgsegm_createSyntheticSequenceGenerator(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::bgsegm;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_background = NULL;
    Mat background;
    PyObject* pyobj_object = NULL;
    Mat object;
    PyObject* pyobj_amplitude = NULL;
    double amplitude=2.0;
    PyObject* pyobj_wavelength = NULL;
    double wavelength=20.0;
    PyObject* pyobj_wavespeed = NULL;
    double wavespeed=0.2;
    PyObject* pyobj_objspeed = NULL;
    double objspeed=6.0;
    Ptr<SyntheticSequenceGenerator> retval;

    const char* keywords[] = { "background", "object", "amplitude", "wavelength", "wavespeed", "objspeed", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOO:createSyntheticSequenceGenerator", (char**)keywords, &pyobj_background, &pyobj_object, &pyobj_amplitude, &pyobj_wavelength, &pyobj_wavespeed, &pyobj_objspeed) &&
        pyopencv_to_safe(pyobj_background, background, ArgInfo("background", 0)) &&
        pyopencv_to_safe(pyobj_object, object, ArgInfo("object", 0)) &&
        pyopencv_to_safe(pyobj_amplitude, amplitude, ArgInfo("amplitude", 0)) &&
        pyopencv_to_safe(pyobj_wavelength, wavelength, ArgInfo("wavelength", 0)) &&
        pyopencv_to_safe(pyobj_wavespeed, wavespeed, ArgInfo("wavespeed", 0)) &&
        pyopencv_to_safe(pyobj_objspeed, objspeed, ArgInfo("objspeed", 0)) )
    {
        ERRWRAP2(retval = cv::bgsegm::createSyntheticSequenceGenerator(background, object, amplitude, wavelength, wavespeed, objspeed));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_background = NULL;
    UMat background;
    PyObject* pyobj_object = NULL;
    UMat object;
    PyObject* pyobj_amplitude = NULL;
    double amplitude=2.0;
    PyObject* pyobj_wavelength = NULL;
    double wavelength=20.0;
    PyObject* pyobj_wavespeed = NULL;
    double wavespeed=0.2;
    PyObject* pyobj_objspeed = NULL;
    double objspeed=6.0;
    Ptr<SyntheticSequenceGenerator> retval;

    const char* keywords[] = { "background", "object", "amplitude", "wavelength", "wavespeed", "objspeed", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOO:createSyntheticSequenceGenerator", (char**)keywords, &pyobj_background, &pyobj_object, &pyobj_amplitude, &pyobj_wavelength, &pyobj_wavespeed, &pyobj_objspeed) &&
        pyopencv_to_safe(pyobj_background, background, ArgInfo("background", 0)) &&
        pyopencv_to_safe(pyobj_object, object, ArgInfo("object", 0)) &&
        pyopencv_to_safe(pyobj_amplitude, amplitude, ArgInfo("amplitude", 0)) &&
        pyopencv_to_safe(pyobj_wavelength, wavelength, ArgInfo("wavelength", 0)) &&
        pyopencv_to_safe(pyobj_wavespeed, wavespeed, ArgInfo("wavespeed", 0)) &&
        pyopencv_to_safe(pyobj_objspeed, objspeed, ArgInfo("objspeed", 0)) )
    {
        ERRWRAP2(retval = cv::bgsegm::createSyntheticSequenceGenerator(background, object, amplitude, wavelength, wavespeed, objspeed));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("createSyntheticSequenceGenerator");

    return NULL;
}

static PyObject* pyopencv_cv_bioinspired_RetinaFastToneMapping_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::bioinspired;

    PyObject* pyobj_inputSize = NULL;
    Size inputSize;
    Ptr<RetinaFastToneMapping> retval;

    const char* keywords[] = { "inputSize", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:RetinaFastToneMapping_create", (char**)keywords, &pyobj_inputSize) &&
        pyopencv_to_safe(pyobj_inputSize, inputSize, ArgInfo("inputSize", 0)) )
    {
        ERRWRAP2(retval = cv::bioinspired::RetinaFastToneMapping::create(inputSize));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_bioinspired_Retina_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::bioinspired;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_inputSize = NULL;
    Size inputSize;
    Ptr<Retina> retval;

    const char* keywords[] = { "inputSize", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:Retina_create", (char**)keywords, &pyobj_inputSize) &&
        pyopencv_to_safe(pyobj_inputSize, inputSize, ArgInfo("inputSize", 0)) )
    {
        ERRWRAP2(retval = cv::bioinspired::Retina::create(inputSize));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_inputSize = NULL;
    Size inputSize;
    PyObject* pyobj_colorMode = NULL;
    bool colorMode=0;
    PyObject* pyobj_colorSamplingMethod = NULL;
    int colorSamplingMethod=RETINA_COLOR_BAYER;
    PyObject* pyobj_useRetinaLogSampling = NULL;
    bool useRetinaLogSampling=false;
    PyObject* pyobj_reductionFactor = NULL;
    float reductionFactor=1.0f;
    PyObject* pyobj_samplingStrength = NULL;
    float samplingStrength=10.0f;
    Ptr<Retina> retval;

    const char* keywords[] = { "inputSize", "colorMode", "colorSamplingMethod", "useRetinaLogSampling", "reductionFactor", "samplingStrength", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOO:Retina_create", (char**)keywords, &pyobj_inputSize, &pyobj_colorMode, &pyobj_colorSamplingMethod, &pyobj_useRetinaLogSampling, &pyobj_reductionFactor, &pyobj_samplingStrength) &&
        pyopencv_to_safe(pyobj_inputSize, inputSize, ArgInfo("inputSize", 0)) &&
        pyopencv_to_safe(pyobj_colorMode, colorMode, ArgInfo("colorMode", 0)) &&
        pyopencv_to_safe(pyobj_colorSamplingMethod, colorSamplingMethod, ArgInfo("colorSamplingMethod", 0)) &&
        pyopencv_to_safe(pyobj_useRetinaLogSampling, useRetinaLogSampling, ArgInfo("useRetinaLogSampling", 0)) &&
        pyopencv_to_safe(pyobj_reductionFactor, reductionFactor, ArgInfo("reductionFactor", 0)) &&
        pyopencv_to_safe(pyobj_samplingStrength, samplingStrength, ArgInfo("samplingStrength", 0)) )
    {
        ERRWRAP2(retval = cv::bioinspired::Retina::create(inputSize, colorMode, colorSamplingMethod, useRetinaLogSampling, reductionFactor, samplingStrength));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("Retina_create");

    return NULL;
}

static PyObject* pyopencv_cv_bioinspired_TransientAreasSegmentationModule_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::bioinspired;

    PyObject* pyobj_inputSize = NULL;
    Size inputSize;
    Ptr<TransientAreasSegmentationModule> retval;

    const char* keywords[] = { "inputSize", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:TransientAreasSegmentationModule_create", (char**)keywords, &pyobj_inputSize) &&
        pyopencv_to_safe(pyobj_inputSize, inputSize, ArgInfo("inputSize", 0)) )
    {
        ERRWRAP2(retval = cv::bioinspired::TransientAreasSegmentationModule::create(inputSize));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_cuda_Event_elapsedTime(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::cuda;

    PyObject* pyobj_start = NULL;
    Event start;
    PyObject* pyobj_end = NULL;
    Event end;
    float retval;

    const char* keywords[] = { "start", "end", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:Event_elapsedTime", (char**)keywords, &pyobj_start, &pyobj_end) &&
        pyopencv_to_safe(pyobj_start, start, ArgInfo("start", 0)) &&
        pyopencv_to_safe(pyobj_end, end, ArgInfo("end", 0)) )
    {
        ERRWRAP2(retval = cv::cuda::Event::elapsedTime(start, end));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_cuda_GpuMat_defaultAllocator(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::cuda;

    GpuMat::Allocator* retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::cuda::GpuMat::defaultAllocator());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_cuda_GpuMat_setDefaultAllocator(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::cuda;

    PyObject* pyobj_allocator = NULL;
    GpuMat_Allocator* allocator;

    const char* keywords[] = { "allocator", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:GpuMat_setDefaultAllocator", (char**)keywords, &pyobj_allocator) &&
        pyopencv_to_safe(pyobj_allocator, allocator, ArgInfo("allocator", 0)) )
    {
        ERRWRAP2(cv::cuda::GpuMat::setDefaultAllocator(allocator));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_cuda_SURF_CUDA_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::cuda;

    PyObject* pyobj__hessianThreshold = NULL;
    double _hessianThreshold=0;
    PyObject* pyobj__nOctaves = NULL;
    int _nOctaves=4;
    PyObject* pyobj__nOctaveLayers = NULL;
    int _nOctaveLayers=2;
    PyObject* pyobj__extended = NULL;
    bool _extended=false;
    PyObject* pyobj__keypointsRatio = NULL;
    float _keypointsRatio=0.01f;
    PyObject* pyobj__upright = NULL;
    bool _upright=false;
    Ptr<SURF_CUDA> retval;

    const char* keywords[] = { "_hessianThreshold", "_nOctaves", "_nOctaveLayers", "_extended", "_keypointsRatio", "_upright", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOOO:SURF_CUDA_create", (char**)keywords, &pyobj__hessianThreshold, &pyobj__nOctaves, &pyobj__nOctaveLayers, &pyobj__extended, &pyobj__keypointsRatio, &pyobj__upright) &&
        pyopencv_to_safe(pyobj__hessianThreshold, _hessianThreshold, ArgInfo("_hessianThreshold", 0)) &&
        pyopencv_to_safe(pyobj__nOctaves, _nOctaves, ArgInfo("_nOctaves", 0)) &&
        pyopencv_to_safe(pyobj__nOctaveLayers, _nOctaveLayers, ArgInfo("_nOctaveLayers", 0)) &&
        pyopencv_to_safe(pyobj__extended, _extended, ArgInfo("_extended", 0)) &&
        pyopencv_to_safe(pyobj__keypointsRatio, _keypointsRatio, ArgInfo("_keypointsRatio", 0)) &&
        pyopencv_to_safe(pyobj__upright, _upright, ArgInfo("_upright", 0)) )
    {
        ERRWRAP2(retval = cv::cuda::SURF_CUDA::create(_hessianThreshold, _nOctaves, _nOctaveLayers, _extended, _keypointsRatio, _upright));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_cuda_Stream_Null(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::cuda;

    Stream retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::cuda::Stream::Null());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_cuda_TargetArchs_has(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::cuda;

    PyObject* pyobj_major = NULL;
    int major=0;
    PyObject* pyobj_minor = NULL;
    int minor=0;
    bool retval;

    const char* keywords[] = { "major", "minor", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:TargetArchs_has", (char**)keywords, &pyobj_major, &pyobj_minor) &&
        pyopencv_to_safe(pyobj_major, major, ArgInfo("major", 0)) &&
        pyopencv_to_safe(pyobj_minor, minor, ArgInfo("minor", 0)) )
    {
        ERRWRAP2(retval = cv::cuda::TargetArchs::has(major, minor));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_cuda_TargetArchs_hasBin(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::cuda;

    PyObject* pyobj_major = NULL;
    int major=0;
    PyObject* pyobj_minor = NULL;
    int minor=0;
    bool retval;

    const char* keywords[] = { "major", "minor", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:TargetArchs_hasBin", (char**)keywords, &pyobj_major, &pyobj_minor) &&
        pyopencv_to_safe(pyobj_major, major, ArgInfo("major", 0)) &&
        pyopencv_to_safe(pyobj_minor, minor, ArgInfo("minor", 0)) )
    {
        ERRWRAP2(retval = cv::cuda::TargetArchs::hasBin(major, minor));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_cuda_TargetArchs_hasEqualOrGreater(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::cuda;

    PyObject* pyobj_major = NULL;
    int major=0;
    PyObject* pyobj_minor = NULL;
    int minor=0;
    bool retval;

    const char* keywords[] = { "major", "minor", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:TargetArchs_hasEqualOrGreater", (char**)keywords, &pyobj_major, &pyobj_minor) &&
        pyopencv_to_safe(pyobj_major, major, ArgInfo("major", 0)) &&
        pyopencv_to_safe(pyobj_minor, minor, ArgInfo("minor", 0)) )
    {
        ERRWRAP2(retval = cv::cuda::TargetArchs::hasEqualOrGreater(major, minor));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_cuda_TargetArchs_hasEqualOrGreaterBin(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::cuda;

    PyObject* pyobj_major = NULL;
    int major=0;
    PyObject* pyobj_minor = NULL;
    int minor=0;
    bool retval;

    const char* keywords[] = { "major", "minor", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:TargetArchs_hasEqualOrGreaterBin", (char**)keywords, &pyobj_major, &pyobj_minor) &&
        pyopencv_to_safe(pyobj_major, major, ArgInfo("major", 0)) &&
        pyopencv_to_safe(pyobj_minor, minor, ArgInfo("minor", 0)) )
    {
        ERRWRAP2(retval = cv::cuda::TargetArchs::hasEqualOrGreaterBin(major, minor));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_cuda_TargetArchs_hasEqualOrGreaterPtx(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::cuda;

    PyObject* pyobj_major = NULL;
    int major=0;
    PyObject* pyobj_minor = NULL;
    int minor=0;
    bool retval;

    const char* keywords[] = { "major", "minor", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:TargetArchs_hasEqualOrGreaterPtx", (char**)keywords, &pyobj_major, &pyobj_minor) &&
        pyopencv_to_safe(pyobj_major, major, ArgInfo("major", 0)) &&
        pyopencv_to_safe(pyobj_minor, minor, ArgInfo("minor", 0)) )
    {
        ERRWRAP2(retval = cv::cuda::TargetArchs::hasEqualOrGreaterPtx(major, minor));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_cuda_TargetArchs_hasEqualOrLessPtx(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::cuda;

    PyObject* pyobj_major = NULL;
    int major=0;
    PyObject* pyobj_minor = NULL;
    int minor=0;
    bool retval;

    const char* keywords[] = { "major", "minor", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:TargetArchs_hasEqualOrLessPtx", (char**)keywords, &pyobj_major, &pyobj_minor) &&
        pyopencv_to_safe(pyobj_major, major, ArgInfo("major", 0)) &&
        pyopencv_to_safe(pyobj_minor, minor, ArgInfo("minor", 0)) )
    {
        ERRWRAP2(retval = cv::cuda::TargetArchs::hasEqualOrLessPtx(major, minor));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_cuda_TargetArchs_hasPtx(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::cuda;

    PyObject* pyobj_major = NULL;
    int major=0;
    PyObject* pyobj_minor = NULL;
    int minor=0;
    bool retval;

    const char* keywords[] = { "major", "minor", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:TargetArchs_hasPtx", (char**)keywords, &pyobj_major, &pyobj_minor) &&
        pyopencv_to_safe(pyobj_major, major, ArgInfo("major", 0)) &&
        pyopencv_to_safe(pyobj_minor, minor, ArgInfo("minor", 0)) )
    {
        ERRWRAP2(retval = cv::cuda::TargetArchs::hasPtx(major, minor));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_cuda_createContinuous(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::cuda;

    pyPrepareArgumentConversionErrorsStorage(3);

    {
    PyObject* pyobj_rows = NULL;
    int rows=0;
    PyObject* pyobj_cols = NULL;
    int cols=0;
    PyObject* pyobj_type = NULL;
    int type=0;
    PyObject* pyobj_arr = NULL;
    Mat arr;

    const char* keywords[] = { "rows", "cols", "type", "arr", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:createContinuous", (char**)keywords, &pyobj_rows, &pyobj_cols, &pyobj_type, &pyobj_arr) &&
        pyopencv_to_safe(pyobj_rows, rows, ArgInfo("rows", 0)) &&
        pyopencv_to_safe(pyobj_cols, cols, ArgInfo("cols", 0)) &&
        pyopencv_to_safe(pyobj_type, type, ArgInfo("type", 0)) &&
        pyopencv_to_safe(pyobj_arr, arr, ArgInfo("arr", 1)) )
    {
        ERRWRAP2(cv::cuda::createContinuous(rows, cols, type, arr));
        return pyopencv_from(arr);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_rows = NULL;
    int rows=0;
    PyObject* pyobj_cols = NULL;
    int cols=0;
    PyObject* pyobj_type = NULL;
    int type=0;
    PyObject* pyobj_arr = NULL;
    cuda::GpuMat arr;

    const char* keywords[] = { "rows", "cols", "type", "arr", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:createContinuous", (char**)keywords, &pyobj_rows, &pyobj_cols, &pyobj_type, &pyobj_arr) &&
        pyopencv_to_safe(pyobj_rows, rows, ArgInfo("rows", 0)) &&
        pyopencv_to_safe(pyobj_cols, cols, ArgInfo("cols", 0)) &&
        pyopencv_to_safe(pyobj_type, type, ArgInfo("type", 0)) &&
        pyopencv_to_safe(pyobj_arr, arr, ArgInfo("arr", 1)) )
    {
        ERRWRAP2(cv::cuda::createContinuous(rows, cols, type, arr));
        return pyopencv_from(arr);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_rows = NULL;
    int rows=0;
    PyObject* pyobj_cols = NULL;
    int cols=0;
    PyObject* pyobj_type = NULL;
    int type=0;
    PyObject* pyobj_arr = NULL;
    UMat arr;

    const char* keywords[] = { "rows", "cols", "type", "arr", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:createContinuous", (char**)keywords, &pyobj_rows, &pyobj_cols, &pyobj_type, &pyobj_arr) &&
        pyopencv_to_safe(pyobj_rows, rows, ArgInfo("rows", 0)) &&
        pyopencv_to_safe(pyobj_cols, cols, ArgInfo("cols", 0)) &&
        pyopencv_to_safe(pyobj_type, type, ArgInfo("type", 0)) &&
        pyopencv_to_safe(pyobj_arr, arr, ArgInfo("arr", 1)) )
    {
        ERRWRAP2(cv::cuda::createContinuous(rows, cols, type, arr));
        return pyopencv_from(arr);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("createContinuous");

    return NULL;
}

static PyObject* pyopencv_cv_cuda_ensureSizeIsEnough(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::cuda;

    pyPrepareArgumentConversionErrorsStorage(3);

    {
    PyObject* pyobj_rows = NULL;
    int rows=0;
    PyObject* pyobj_cols = NULL;
    int cols=0;
    PyObject* pyobj_type = NULL;
    int type=0;
    PyObject* pyobj_arr = NULL;
    Mat arr;

    const char* keywords[] = { "rows", "cols", "type", "arr", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:ensureSizeIsEnough", (char**)keywords, &pyobj_rows, &pyobj_cols, &pyobj_type, &pyobj_arr) &&
        pyopencv_to_safe(pyobj_rows, rows, ArgInfo("rows", 0)) &&
        pyopencv_to_safe(pyobj_cols, cols, ArgInfo("cols", 0)) &&
        pyopencv_to_safe(pyobj_type, type, ArgInfo("type", 0)) &&
        pyopencv_to_safe(pyobj_arr, arr, ArgInfo("arr", 1)) )
    {
        ERRWRAP2(cv::cuda::ensureSizeIsEnough(rows, cols, type, arr));
        return pyopencv_from(arr);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_rows = NULL;
    int rows=0;
    PyObject* pyobj_cols = NULL;
    int cols=0;
    PyObject* pyobj_type = NULL;
    int type=0;
    PyObject* pyobj_arr = NULL;
    cuda::GpuMat arr;

    const char* keywords[] = { "rows", "cols", "type", "arr", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:ensureSizeIsEnough", (char**)keywords, &pyobj_rows, &pyobj_cols, &pyobj_type, &pyobj_arr) &&
        pyopencv_to_safe(pyobj_rows, rows, ArgInfo("rows", 0)) &&
        pyopencv_to_safe(pyobj_cols, cols, ArgInfo("cols", 0)) &&
        pyopencv_to_safe(pyobj_type, type, ArgInfo("type", 0)) &&
        pyopencv_to_safe(pyobj_arr, arr, ArgInfo("arr", 1)) )
    {
        ERRWRAP2(cv::cuda::ensureSizeIsEnough(rows, cols, type, arr));
        return pyopencv_from(arr);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_rows = NULL;
    int rows=0;
    PyObject* pyobj_cols = NULL;
    int cols=0;
    PyObject* pyobj_type = NULL;
    int type=0;
    PyObject* pyobj_arr = NULL;
    UMat arr;

    const char* keywords[] = { "rows", "cols", "type", "arr", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:ensureSizeIsEnough", (char**)keywords, &pyobj_rows, &pyobj_cols, &pyobj_type, &pyobj_arr) &&
        pyopencv_to_safe(pyobj_rows, rows, ArgInfo("rows", 0)) &&
        pyopencv_to_safe(pyobj_cols, cols, ArgInfo("cols", 0)) &&
        pyopencv_to_safe(pyobj_type, type, ArgInfo("type", 0)) &&
        pyopencv_to_safe(pyobj_arr, arr, ArgInfo("arr", 1)) )
    {
        ERRWRAP2(cv::cuda::ensureSizeIsEnough(rows, cols, type, arr));
        return pyopencv_from(arr);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("ensureSizeIsEnough");

    return NULL;
}

static PyObject* pyopencv_cv_cuda_getCudaEnabledDeviceCount(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::cuda;

    int retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::cuda::getCudaEnabledDeviceCount());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_cuda_getDevice(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::cuda;

    int retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::cuda::getDevice());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_cuda_printCudaDeviceInfo(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::cuda;

    PyObject* pyobj_device = NULL;
    int device=0;

    const char* keywords[] = { "device", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:printCudaDeviceInfo", (char**)keywords, &pyobj_device) &&
        pyopencv_to_safe(pyobj_device, device, ArgInfo("device", 0)) )
    {
        ERRWRAP2(cv::cuda::printCudaDeviceInfo(device));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_cuda_printShortCudaDeviceInfo(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::cuda;

    PyObject* pyobj_device = NULL;
    int device=0;

    const char* keywords[] = { "device", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:printShortCudaDeviceInfo", (char**)keywords, &pyobj_device) &&
        pyopencv_to_safe(pyobj_device, device, ArgInfo("device", 0)) )
    {
        ERRWRAP2(cv::cuda::printShortCudaDeviceInfo(device));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_cuda_registerPageLocked(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::cuda;

    pyPrepareArgumentConversionErrorsStorage(3);

    {
    PyObject* pyobj_m = NULL;
    Mat m;

    const char* keywords[] = { "m", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:registerPageLocked", (char**)keywords, &pyobj_m) &&
        pyopencv_to_safe(pyobj_m, m, ArgInfo("m", 0)) )
    {
        ERRWRAP2(cv::cuda::registerPageLocked(m));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_m = NULL;
    Mat m;

    const char* keywords[] = { "m", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:registerPageLocked", (char**)keywords, &pyobj_m) &&
        pyopencv_to_safe(pyobj_m, m, ArgInfo("m", 0)) )
    {
        ERRWRAP2(cv::cuda::registerPageLocked(m));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_m = NULL;
    Mat m;

    const char* keywords[] = { "m", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:registerPageLocked", (char**)keywords, &pyobj_m) &&
        pyopencv_to_safe(pyobj_m, m, ArgInfo("m", 0)) )
    {
        ERRWRAP2(cv::cuda::registerPageLocked(m));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("registerPageLocked");

    return NULL;
}

static PyObject* pyopencv_cv_cuda_resetDevice(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::cuda;


    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(cv::cuda::resetDevice());
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_cuda_setBufferPoolConfig(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::cuda;

    PyObject* pyobj_deviceId = NULL;
    int deviceId=0;
    PyObject* pyobj_stackSize = NULL;
    size_t stackSize=0;
    PyObject* pyobj_stackCount = NULL;
    int stackCount=0;

    const char* keywords[] = { "deviceId", "stackSize", "stackCount", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:setBufferPoolConfig", (char**)keywords, &pyobj_deviceId, &pyobj_stackSize, &pyobj_stackCount) &&
        pyopencv_to_safe(pyobj_deviceId, deviceId, ArgInfo("deviceId", 0)) &&
        pyopencv_to_safe(pyobj_stackSize, stackSize, ArgInfo("stackSize", 0)) &&
        pyopencv_to_safe(pyobj_stackCount, stackCount, ArgInfo("stackCount", 0)) )
    {
        ERRWRAP2(cv::cuda::setBufferPoolConfig(deviceId, stackSize, stackCount));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_cuda_setBufferPoolUsage(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::cuda;

    PyObject* pyobj_on = NULL;
    bool on=0;

    const char* keywords[] = { "on", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:setBufferPoolUsage", (char**)keywords, &pyobj_on) &&
        pyopencv_to_safe(pyobj_on, on, ArgInfo("on", 0)) )
    {
        ERRWRAP2(cv::cuda::setBufferPoolUsage(on));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_cuda_setDevice(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::cuda;

    PyObject* pyobj_device = NULL;
    int device=0;

    const char* keywords[] = { "device", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:setDevice", (char**)keywords, &pyobj_device) &&
        pyopencv_to_safe(pyobj_device, device, ArgInfo("device", 0)) )
    {
        ERRWRAP2(cv::cuda::setDevice(device));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_cuda_unregisterPageLocked(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::cuda;

    pyPrepareArgumentConversionErrorsStorage(3);

    {
    PyObject* pyobj_m = NULL;
    Mat m;

    const char* keywords[] = { "m", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:unregisterPageLocked", (char**)keywords, &pyobj_m) &&
        pyopencv_to_safe(pyobj_m, m, ArgInfo("m", 0)) )
    {
        ERRWRAP2(cv::cuda::unregisterPageLocked(m));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_m = NULL;
    Mat m;

    const char* keywords[] = { "m", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:unregisterPageLocked", (char**)keywords, &pyobj_m) &&
        pyopencv_to_safe(pyobj_m, m, ArgInfo("m", 0)) )
    {
        ERRWRAP2(cv::cuda::unregisterPageLocked(m));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_m = NULL;
    Mat m;

    const char* keywords[] = { "m", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:unregisterPageLocked", (char**)keywords, &pyobj_m) &&
        pyopencv_to_safe(pyobj_m, m, ArgInfo("m", 0)) )
    {
        ERRWRAP2(cv::cuda::unregisterPageLocked(m));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("unregisterPageLocked");

    return NULL;
}

static PyObject* pyopencv_cv_detail_BestOf2NearestMatcher_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::detail;

    PyObject* pyobj_try_use_gpu = NULL;
    bool try_use_gpu=false;
    PyObject* pyobj_match_conf = NULL;
    float match_conf=0.3f;
    PyObject* pyobj_num_matches_thresh1 = NULL;
    int num_matches_thresh1=6;
    PyObject* pyobj_num_matches_thresh2 = NULL;
    int num_matches_thresh2=6;
    Ptr<BestOf2NearestMatcher> retval;

    const char* keywords[] = { "try_use_gpu", "match_conf", "num_matches_thresh1", "num_matches_thresh2", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOO:BestOf2NearestMatcher_create", (char**)keywords, &pyobj_try_use_gpu, &pyobj_match_conf, &pyobj_num_matches_thresh1, &pyobj_num_matches_thresh2) &&
        pyopencv_to_safe(pyobj_try_use_gpu, try_use_gpu, ArgInfo("try_use_gpu", 0)) &&
        pyopencv_to_safe(pyobj_match_conf, match_conf, ArgInfo("match_conf", 0)) &&
        pyopencv_to_safe(pyobj_num_matches_thresh1, num_matches_thresh1, ArgInfo("num_matches_thresh1", 0)) &&
        pyopencv_to_safe(pyobj_num_matches_thresh2, num_matches_thresh2, ArgInfo("num_matches_thresh2", 0)) )
    {
        ERRWRAP2(retval = cv::detail::BestOf2NearestMatcher::create(try_use_gpu, match_conf, num_matches_thresh1, num_matches_thresh2));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_detail_Blender_createDefault(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::detail;

    PyObject* pyobj_type = NULL;
    int type=0;
    PyObject* pyobj_try_gpu = NULL;
    bool try_gpu=false;
    Ptr<Blender> retval;

    const char* keywords[] = { "type", "try_gpu", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:Blender_createDefault", (char**)keywords, &pyobj_type, &pyobj_try_gpu) &&
        pyopencv_to_safe(pyobj_type, type, ArgInfo("type", 0)) &&
        pyopencv_to_safe(pyobj_try_gpu, try_gpu, ArgInfo("try_gpu", 0)) )
    {
        ERRWRAP2(retval = cv::detail::Blender::createDefault(type, try_gpu));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_detail_ExposureCompensator_createDefault(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::detail;

    PyObject* pyobj_type = NULL;
    int type=0;
    Ptr<ExposureCompensator> retval;

    const char* keywords[] = { "type", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:ExposureCompensator_createDefault", (char**)keywords, &pyobj_type) &&
        pyopencv_to_safe(pyobj_type, type, ArgInfo("type", 0)) )
    {
        ERRWRAP2(retval = cv::detail::ExposureCompensator::createDefault(type));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_detail_SeamFinder_createDefault(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::detail;

    PyObject* pyobj_type = NULL;
    int type=0;
    Ptr<SeamFinder> retval;

    const char* keywords[] = { "type", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:SeamFinder_createDefault", (char**)keywords, &pyobj_type) &&
        pyopencv_to_safe(pyobj_type, type, ArgInfo("type", 0)) )
    {
        ERRWRAP2(retval = cv::detail::SeamFinder::createDefault(type));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_detail_Timelapser_createDefault(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::detail;

    PyObject* pyobj_type = NULL;
    int type=0;
    Ptr<Timelapser> retval;

    const char* keywords[] = { "type", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:Timelapser_createDefault", (char**)keywords, &pyobj_type) &&
        pyopencv_to_safe(pyobj_type, type, ArgInfo("type", 0)) )
    {
        ERRWRAP2(retval = cv::detail::Timelapser::createDefault(type));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_detail_calibrateRotatingCamera(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::detail;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_Hs = NULL;
    vector_Mat Hs;
    PyObject* pyobj_K = NULL;
    Mat K;
    bool retval;

    const char* keywords[] = { "Hs", "K", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:calibrateRotatingCamera", (char**)keywords, &pyobj_Hs, &pyobj_K) &&
        pyopencv_to_safe(pyobj_Hs, Hs, ArgInfo("Hs", 0)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 1)) )
    {
        ERRWRAP2(retval = cv::detail::calibrateRotatingCamera(Hs, K));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(K));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_Hs = NULL;
    vector_Mat Hs;
    PyObject* pyobj_K = NULL;
    Mat K;
    bool retval;

    const char* keywords[] = { "Hs", "K", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:calibrateRotatingCamera", (char**)keywords, &pyobj_Hs, &pyobj_K) &&
        pyopencv_to_safe(pyobj_Hs, Hs, ArgInfo("Hs", 0)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 1)) )
    {
        ERRWRAP2(retval = cv::detail::calibrateRotatingCamera(Hs, K));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(K));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("calibrateRotatingCamera");

    return NULL;
}

static PyObject* pyopencv_cv_detail_computeImageFeatures(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::detail;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_featuresFinder = NULL;
    Ptr<Feature2D> featuresFinder;
    PyObject* pyobj_images = NULL;
    vector_Mat images;
    vector_ImageFeatures features;
    PyObject* pyobj_masks = NULL;
    vector_Mat masks;

    const char* keywords[] = { "featuresFinder", "images", "masks", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:computeImageFeatures", (char**)keywords, &pyobj_featuresFinder, &pyobj_images, &pyobj_masks) &&
        pyopencv_to_safe(pyobj_featuresFinder, featuresFinder, ArgInfo("featuresFinder", 0)) &&
        pyopencv_to_safe(pyobj_images, images, ArgInfo("images", 0)) &&
        pyopencv_to_safe(pyobj_masks, masks, ArgInfo("masks", 0)) )
    {
        ERRWRAP2(cv::detail::computeImageFeatures(featuresFinder, images, features, masks));
        return pyopencv_from(features);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_featuresFinder = NULL;
    Ptr<Feature2D> featuresFinder;
    PyObject* pyobj_images = NULL;
    vector_UMat images;
    vector_ImageFeatures features;
    PyObject* pyobj_masks = NULL;
    vector_UMat masks;

    const char* keywords[] = { "featuresFinder", "images", "masks", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:computeImageFeatures", (char**)keywords, &pyobj_featuresFinder, &pyobj_images, &pyobj_masks) &&
        pyopencv_to_safe(pyobj_featuresFinder, featuresFinder, ArgInfo("featuresFinder", 0)) &&
        pyopencv_to_safe(pyobj_images, images, ArgInfo("images", 0)) &&
        pyopencv_to_safe(pyobj_masks, masks, ArgInfo("masks", 0)) )
    {
        ERRWRAP2(cv::detail::computeImageFeatures(featuresFinder, images, features, masks));
        return pyopencv_from(features);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("computeImageFeatures");

    return NULL;
}

static PyObject* pyopencv_cv_detail_computeImageFeatures2(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::detail;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_featuresFinder = NULL;
    Ptr<Feature2D> featuresFinder;
    PyObject* pyobj_image = NULL;
    Mat image;
    ImageFeatures features;
    PyObject* pyobj_mask = NULL;
    Mat mask;

    const char* keywords[] = { "featuresFinder", "image", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:computeImageFeatures2", (char**)keywords, &pyobj_featuresFinder, &pyobj_image, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_featuresFinder, featuresFinder, ArgInfo("featuresFinder", 0)) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::detail::computeImageFeatures(featuresFinder, image, features, mask));
        return pyopencv_from(features);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_featuresFinder = NULL;
    Ptr<Feature2D> featuresFinder;
    PyObject* pyobj_image = NULL;
    UMat image;
    ImageFeatures features;
    PyObject* pyobj_mask = NULL;
    UMat mask;

    const char* keywords[] = { "featuresFinder", "image", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:computeImageFeatures2", (char**)keywords, &pyobj_featuresFinder, &pyobj_image, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_featuresFinder, featuresFinder, ArgInfo("featuresFinder", 0)) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::detail::computeImageFeatures(featuresFinder, image, features, mask));
        return pyopencv_from(features);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("computeImageFeatures2");

    return NULL;
}

static PyObject* pyopencv_cv_detail_createLaplacePyr(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::detail;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_num_levels = NULL;
    int num_levels=0;
    PyObject* pyobj_pyr = NULL;
    vector_UMat pyr;

    const char* keywords[] = { "img", "num_levels", "pyr", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:createLaplacePyr", (char**)keywords, &pyobj_img, &pyobj_num_levels, &pyobj_pyr) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_num_levels, num_levels, ArgInfo("num_levels", 0)) &&
        pyopencv_to_safe(pyobj_pyr, pyr, ArgInfo("pyr", 1)) )
    {
        ERRWRAP2(cv::detail::createLaplacePyr(img, num_levels, pyr));
        return pyopencv_from(pyr);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_num_levels = NULL;
    int num_levels=0;
    PyObject* pyobj_pyr = NULL;
    vector_UMat pyr;

    const char* keywords[] = { "img", "num_levels", "pyr", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:createLaplacePyr", (char**)keywords, &pyobj_img, &pyobj_num_levels, &pyobj_pyr) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_num_levels, num_levels, ArgInfo("num_levels", 0)) &&
        pyopencv_to_safe(pyobj_pyr, pyr, ArgInfo("pyr", 1)) )
    {
        ERRWRAP2(cv::detail::createLaplacePyr(img, num_levels, pyr));
        return pyopencv_from(pyr);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("createLaplacePyr");

    return NULL;
}

static PyObject* pyopencv_cv_detail_createLaplacePyrGpu(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::detail;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_num_levels = NULL;
    int num_levels=0;
    PyObject* pyobj_pyr = NULL;
    vector_UMat pyr;

    const char* keywords[] = { "img", "num_levels", "pyr", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:createLaplacePyrGpu", (char**)keywords, &pyobj_img, &pyobj_num_levels, &pyobj_pyr) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_num_levels, num_levels, ArgInfo("num_levels", 0)) &&
        pyopencv_to_safe(pyobj_pyr, pyr, ArgInfo("pyr", 1)) )
    {
        ERRWRAP2(cv::detail::createLaplacePyrGpu(img, num_levels, pyr));
        return pyopencv_from(pyr);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_num_levels = NULL;
    int num_levels=0;
    PyObject* pyobj_pyr = NULL;
    vector_UMat pyr;

    const char* keywords[] = { "img", "num_levels", "pyr", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:createLaplacePyrGpu", (char**)keywords, &pyobj_img, &pyobj_num_levels, &pyobj_pyr) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_num_levels, num_levels, ArgInfo("num_levels", 0)) &&
        pyopencv_to_safe(pyobj_pyr, pyr, ArgInfo("pyr", 1)) )
    {
        ERRWRAP2(cv::detail::createLaplacePyrGpu(img, num_levels, pyr));
        return pyopencv_from(pyr);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("createLaplacePyrGpu");

    return NULL;
}

static PyObject* pyopencv_cv_detail_createWeightMap(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::detail;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_sharpness = NULL;
    float sharpness=0.f;
    PyObject* pyobj_weight = NULL;
    Mat weight;

    const char* keywords[] = { "mask", "sharpness", "weight", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:createWeightMap", (char**)keywords, &pyobj_mask, &pyobj_sharpness, &pyobj_weight) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_sharpness, sharpness, ArgInfo("sharpness", 0)) &&
        pyopencv_to_safe(pyobj_weight, weight, ArgInfo("weight", 1)) )
    {
        ERRWRAP2(cv::detail::createWeightMap(mask, sharpness, weight));
        return pyopencv_from(weight);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_mask = NULL;
    UMat mask;
    PyObject* pyobj_sharpness = NULL;
    float sharpness=0.f;
    PyObject* pyobj_weight = NULL;
    UMat weight;

    const char* keywords[] = { "mask", "sharpness", "weight", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:createWeightMap", (char**)keywords, &pyobj_mask, &pyobj_sharpness, &pyobj_weight) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_sharpness, sharpness, ArgInfo("sharpness", 0)) &&
        pyopencv_to_safe(pyobj_weight, weight, ArgInfo("weight", 1)) )
    {
        ERRWRAP2(cv::detail::createWeightMap(mask, sharpness, weight));
        return pyopencv_from(weight);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("createWeightMap");

    return NULL;
}

static PyObject* pyopencv_cv_detail_focalsFromHomography(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::detail;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_H = NULL;
    Mat H;
    PyObject* pyobj_f0 = NULL;
    double f0=0;
    PyObject* pyobj_f1 = NULL;
    double f1=0;
    PyObject* pyobj_f0_ok = NULL;
    bool f0_ok=0;
    PyObject* pyobj_f1_ok = NULL;
    bool f1_ok=0;

    const char* keywords[] = { "H", "f0", "f1", "f0_ok", "f1_ok", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO:focalsFromHomography", (char**)keywords, &pyobj_H, &pyobj_f0, &pyobj_f1, &pyobj_f0_ok, &pyobj_f1_ok) &&
        pyopencv_to_safe(pyobj_H, H, ArgInfo("H", 0)) &&
        pyopencv_to_safe(pyobj_f0, f0, ArgInfo("f0", 0)) &&
        pyopencv_to_safe(pyobj_f1, f1, ArgInfo("f1", 0)) &&
        pyopencv_to_safe(pyobj_f0_ok, f0_ok, ArgInfo("f0_ok", 0)) &&
        pyopencv_to_safe(pyobj_f1_ok, f1_ok, ArgInfo("f1_ok", 0)) )
    {
        ERRWRAP2(cv::detail::focalsFromHomography(H, f0, f1, f0_ok, f1_ok));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_H = NULL;
    Mat H;
    PyObject* pyobj_f0 = NULL;
    double f0=0;
    PyObject* pyobj_f1 = NULL;
    double f1=0;
    PyObject* pyobj_f0_ok = NULL;
    bool f0_ok=0;
    PyObject* pyobj_f1_ok = NULL;
    bool f1_ok=0;

    const char* keywords[] = { "H", "f0", "f1", "f0_ok", "f1_ok", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO:focalsFromHomography", (char**)keywords, &pyobj_H, &pyobj_f0, &pyobj_f1, &pyobj_f0_ok, &pyobj_f1_ok) &&
        pyopencv_to_safe(pyobj_H, H, ArgInfo("H", 0)) &&
        pyopencv_to_safe(pyobj_f0, f0, ArgInfo("f0", 0)) &&
        pyopencv_to_safe(pyobj_f1, f1, ArgInfo("f1", 0)) &&
        pyopencv_to_safe(pyobj_f0_ok, f0_ok, ArgInfo("f0_ok", 0)) &&
        pyopencv_to_safe(pyobj_f1_ok, f1_ok, ArgInfo("f1_ok", 0)) )
    {
        ERRWRAP2(cv::detail::focalsFromHomography(H, f0, f1, f0_ok, f1_ok));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("focalsFromHomography");

    return NULL;
}

static PyObject* pyopencv_cv_detail_leaveBiggestComponent(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::detail;

    PyObject* pyobj_features = NULL;
    vector_ImageFeatures features;
    PyObject* pyobj_pairwise_matches = NULL;
    vector_MatchesInfo pairwise_matches;
    PyObject* pyobj_conf_threshold = NULL;
    float conf_threshold=0.f;
    std::vector<int> retval;

    const char* keywords[] = { "features", "pairwise_matches", "conf_threshold", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:leaveBiggestComponent", (char**)keywords, &pyobj_features, &pyobj_pairwise_matches, &pyobj_conf_threshold) &&
        pyopencv_to_safe(pyobj_features, features, ArgInfo("features", 0)) &&
        pyopencv_to_safe(pyobj_pairwise_matches, pairwise_matches, ArgInfo("pairwise_matches", 0)) &&
        pyopencv_to_safe(pyobj_conf_threshold, conf_threshold, ArgInfo("conf_threshold", 0)) )
    {
        ERRWRAP2(retval = cv::detail::leaveBiggestComponent(features, pairwise_matches, conf_threshold));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_detail_matchesGraphAsString(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::detail;

    PyObject* pyobj_pathes = NULL;
    vector_String pathes;
    PyObject* pyobj_pairwise_matches = NULL;
    vector_MatchesInfo pairwise_matches;
    PyObject* pyobj_conf_threshold = NULL;
    float conf_threshold=0.f;
    String retval;

    const char* keywords[] = { "pathes", "pairwise_matches", "conf_threshold", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:matchesGraphAsString", (char**)keywords, &pyobj_pathes, &pyobj_pairwise_matches, &pyobj_conf_threshold) &&
        pyopencv_to_safe(pyobj_pathes, pathes, ArgInfo("pathes", 0)) &&
        pyopencv_to_safe(pyobj_pairwise_matches, pairwise_matches, ArgInfo("pairwise_matches", 0)) &&
        pyopencv_to_safe(pyobj_conf_threshold, conf_threshold, ArgInfo("conf_threshold", 0)) )
    {
        ERRWRAP2(retval = cv::detail::matchesGraphAsString(pathes, pairwise_matches, conf_threshold));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_detail_normalizeUsingWeightMap(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::detail;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_weight = NULL;
    Mat weight;
    PyObject* pyobj_src = NULL;
    Mat src;

    const char* keywords[] = { "weight", "src", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:normalizeUsingWeightMap", (char**)keywords, &pyobj_weight, &pyobj_src) &&
        pyopencv_to_safe(pyobj_weight, weight, ArgInfo("weight", 0)) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 1)) )
    {
        ERRWRAP2(cv::detail::normalizeUsingWeightMap(weight, src));
        return pyopencv_from(src);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_weight = NULL;
    UMat weight;
    PyObject* pyobj_src = NULL;
    UMat src;

    const char* keywords[] = { "weight", "src", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:normalizeUsingWeightMap", (char**)keywords, &pyobj_weight, &pyobj_src) &&
        pyopencv_to_safe(pyobj_weight, weight, ArgInfo("weight", 0)) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 1)) )
    {
        ERRWRAP2(cv::detail::normalizeUsingWeightMap(weight, src));
        return pyopencv_from(src);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("normalizeUsingWeightMap");

    return NULL;
}

static PyObject* pyopencv_cv_detail_overlapRoi(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::detail;

    PyObject* pyobj_tl1 = NULL;
    Point tl1;
    PyObject* pyobj_tl2 = NULL;
    Point tl2;
    PyObject* pyobj_sz1 = NULL;
    Size sz1;
    PyObject* pyobj_sz2 = NULL;
    Size sz2;
    PyObject* pyobj_roi = NULL;
    Rect roi;
    bool retval;

    const char* keywords[] = { "tl1", "tl2", "sz1", "sz2", "roi", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO:overlapRoi", (char**)keywords, &pyobj_tl1, &pyobj_tl2, &pyobj_sz1, &pyobj_sz2, &pyobj_roi) &&
        pyopencv_to_safe(pyobj_tl1, tl1, ArgInfo("tl1", 0)) &&
        pyopencv_to_safe(pyobj_tl2, tl2, ArgInfo("tl2", 0)) &&
        pyopencv_to_safe(pyobj_sz1, sz1, ArgInfo("sz1", 0)) &&
        pyopencv_to_safe(pyobj_sz2, sz2, ArgInfo("sz2", 0)) &&
        pyopencv_to_safe(pyobj_roi, roi, ArgInfo("roi", 0)) )
    {
        ERRWRAP2(retval = cv::detail::overlapRoi(tl1, tl2, sz1, sz2, roi));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_detail_restoreImageFromLaplacePyr(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::detail;

    PyObject* pyobj_pyr = NULL;
    vector_UMat pyr;

    const char* keywords[] = { "pyr", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:restoreImageFromLaplacePyr", (char**)keywords, &pyobj_pyr) &&
        pyopencv_to_safe(pyobj_pyr, pyr, ArgInfo("pyr", 1)) )
    {
        ERRWRAP2(cv::detail::restoreImageFromLaplacePyr(pyr));
        return pyopencv_from(pyr);
    }

    return NULL;
}

static PyObject* pyopencv_cv_detail_restoreImageFromLaplacePyrGpu(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::detail;

    PyObject* pyobj_pyr = NULL;
    vector_UMat pyr;

    const char* keywords[] = { "pyr", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:restoreImageFromLaplacePyrGpu", (char**)keywords, &pyobj_pyr) &&
        pyopencv_to_safe(pyobj_pyr, pyr, ArgInfo("pyr", 1)) )
    {
        ERRWRAP2(cv::detail::restoreImageFromLaplacePyrGpu(pyr));
        return pyopencv_from(pyr);
    }

    return NULL;
}

static PyObject* pyopencv_cv_detail_resultRoi(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::detail;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_corners = NULL;
    vector_Point corners;
    PyObject* pyobj_images = NULL;
    vector_UMat images;
    Rect retval;

    const char* keywords[] = { "corners", "images", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:resultRoi", (char**)keywords, &pyobj_corners, &pyobj_images) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 0)) &&
        pyopencv_to_safe(pyobj_images, images, ArgInfo("images", 0)) )
    {
        ERRWRAP2(retval = cv::detail::resultRoi(corners, images));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_corners = NULL;
    vector_Point corners;
    PyObject* pyobj_sizes = NULL;
    vector_Size sizes;
    Rect retval;

    const char* keywords[] = { "corners", "sizes", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:resultRoi", (char**)keywords, &pyobj_corners, &pyobj_sizes) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 0)) &&
        pyopencv_to_safe(pyobj_sizes, sizes, ArgInfo("sizes", 0)) )
    {
        ERRWRAP2(retval = cv::detail::resultRoi(corners, sizes));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("resultRoi");

    return NULL;
}

static PyObject* pyopencv_cv_detail_resultRoiIntersection(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::detail;

    PyObject* pyobj_corners = NULL;
    vector_Point corners;
    PyObject* pyobj_sizes = NULL;
    vector_Size sizes;
    Rect retval;

    const char* keywords[] = { "corners", "sizes", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:resultRoiIntersection", (char**)keywords, &pyobj_corners, &pyobj_sizes) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 0)) &&
        pyopencv_to_safe(pyobj_sizes, sizes, ArgInfo("sizes", 0)) )
    {
        ERRWRAP2(retval = cv::detail::resultRoiIntersection(corners, sizes));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_detail_resultTl(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::detail;

    PyObject* pyobj_corners = NULL;
    vector_Point corners;
    Point retval;

    const char* keywords[] = { "corners", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:resultTl", (char**)keywords, &pyobj_corners) &&
        pyopencv_to_safe(pyobj_corners, corners, ArgInfo("corners", 0)) )
    {
        ERRWRAP2(retval = cv::detail::resultTl(corners));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_detail_selectRandomSubset(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::detail;

    PyObject* pyobj_count = NULL;
    int count=0;
    PyObject* pyobj_size = NULL;
    int size=0;
    PyObject* pyobj_subset = NULL;
    vector_int subset;

    const char* keywords[] = { "count", "size", "subset", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:selectRandomSubset", (char**)keywords, &pyobj_count, &pyobj_size, &pyobj_subset) &&
        pyopencv_to_safe(pyobj_count, count, ArgInfo("count", 0)) &&
        pyopencv_to_safe(pyobj_size, size, ArgInfo("size", 0)) &&
        pyopencv_to_safe(pyobj_subset, subset, ArgInfo("subset", 0)) )
    {
        ERRWRAP2(cv::detail::selectRandomSubset(count, size, subset));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_detail_stitchingLogLevel(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::detail;

    int retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::detail::stitchingLogLevel());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_detail_waveCorrect(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::detail;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_rmats = NULL;
    vector_Mat rmats;
    PyObject* pyobj_kind = NULL;
    WaveCorrectKind kind=static_cast<WaveCorrectKind>(0);

    const char* keywords[] = { "rmats", "kind", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:waveCorrect", (char**)keywords, &pyobj_rmats, &pyobj_kind) &&
        pyopencv_to_safe(pyobj_rmats, rmats, ArgInfo("rmats", 1)) &&
        pyopencv_to_safe(pyobj_kind, kind, ArgInfo("kind", 0)) )
    {
        ERRWRAP2(cv::detail::waveCorrect(rmats, kind));
        return pyopencv_from(rmats);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_rmats = NULL;
    vector_Mat rmats;
    PyObject* pyobj_kind = NULL;
    WaveCorrectKind kind=static_cast<WaveCorrectKind>(0);

    const char* keywords[] = { "rmats", "kind", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:waveCorrect", (char**)keywords, &pyobj_rmats, &pyobj_kind) &&
        pyopencv_to_safe(pyobj_rmats, rmats, ArgInfo("rmats", 1)) &&
        pyopencv_to_safe(pyobj_kind, kind, ArgInfo("kind", 0)) )
    {
        ERRWRAP2(cv::detail::waveCorrect(rmats, kind));
        return pyopencv_from(rmats);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("waveCorrect");

    return NULL;
}

static PyObject* pyopencv_cv_dynafu_DynaFu_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::dynafu;

    PyObject* pyobj__params = NULL;
    Ptr<kinfu::Params> _params;
    Ptr<DynaFu> retval;

    const char* keywords[] = { "_params", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:DynaFu_create", (char**)keywords, &pyobj__params) &&
        pyopencv_to_safe(pyobj__params, _params, ArgInfo("_params", 0)) )
    {
        ERRWRAP2(retval = cv::dynafu::DynaFu::create(_params));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_BIF_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::face;

    PyObject* pyobj_num_bands = NULL;
    int num_bands=8;
    PyObject* pyobj_num_rotations = NULL;
    int num_rotations=12;
    Ptr<BIF> retval;

    const char* keywords[] = { "num_bands", "num_rotations", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OO:BIF_create", (char**)keywords, &pyobj_num_bands, &pyobj_num_rotations) &&
        pyopencv_to_safe(pyobj_num_bands, num_bands, ArgInfo("num_bands", 0)) &&
        pyopencv_to_safe(pyobj_num_rotations, num_rotations, ArgInfo("num_rotations", 0)) )
    {
        ERRWRAP2(retval = cv::face::BIF::create(num_bands, num_rotations));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_EigenFaceRecognizer_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::face;

    PyObject* pyobj_num_components = NULL;
    int num_components=0;
    PyObject* pyobj_threshold = NULL;
    double threshold=DBL_MAX;
    Ptr<EigenFaceRecognizer> retval;

    const char* keywords[] = { "num_components", "threshold", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OO:EigenFaceRecognizer_create", (char**)keywords, &pyobj_num_components, &pyobj_threshold) &&
        pyopencv_to_safe(pyobj_num_components, num_components, ArgInfo("num_components", 0)) &&
        pyopencv_to_safe(pyobj_threshold, threshold, ArgInfo("threshold", 0)) )
    {
        ERRWRAP2(retval = cv::face::EigenFaceRecognizer::create(num_components, threshold));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_FisherFaceRecognizer_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::face;

    PyObject* pyobj_num_components = NULL;
    int num_components=0;
    PyObject* pyobj_threshold = NULL;
    double threshold=DBL_MAX;
    Ptr<FisherFaceRecognizer> retval;

    const char* keywords[] = { "num_components", "threshold", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OO:FisherFaceRecognizer_create", (char**)keywords, &pyobj_num_components, &pyobj_threshold) &&
        pyopencv_to_safe(pyobj_num_components, num_components, ArgInfo("num_components", 0)) &&
        pyopencv_to_safe(pyobj_threshold, threshold, ArgInfo("threshold", 0)) )
    {
        ERRWRAP2(retval = cv::face::FisherFaceRecognizer::create(num_components, threshold));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_LBPHFaceRecognizer_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::face;

    PyObject* pyobj_radius = NULL;
    int radius=1;
    PyObject* pyobj_neighbors = NULL;
    int neighbors=8;
    PyObject* pyobj_grid_x = NULL;
    int grid_x=8;
    PyObject* pyobj_grid_y = NULL;
    int grid_y=8;
    PyObject* pyobj_threshold = NULL;
    double threshold=DBL_MAX;
    Ptr<LBPHFaceRecognizer> retval;

    const char* keywords[] = { "radius", "neighbors", "grid_x", "grid_y", "threshold", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOO:LBPHFaceRecognizer_create", (char**)keywords, &pyobj_radius, &pyobj_neighbors, &pyobj_grid_x, &pyobj_grid_y, &pyobj_threshold) &&
        pyopencv_to_safe(pyobj_radius, radius, ArgInfo("radius", 0)) &&
        pyopencv_to_safe(pyobj_neighbors, neighbors, ArgInfo("neighbors", 0)) &&
        pyopencv_to_safe(pyobj_grid_x, grid_x, ArgInfo("grid_x", 0)) &&
        pyopencv_to_safe(pyobj_grid_y, grid_y, ArgInfo("grid_y", 0)) &&
        pyopencv_to_safe(pyobj_threshold, threshold, ArgInfo("threshold", 0)) )
    {
        ERRWRAP2(retval = cv::face::LBPHFaceRecognizer::create(radius, neighbors, grid_x, grid_y, threshold));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_MACE_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::face;

    PyObject* pyobj_IMGSIZE = NULL;
    int IMGSIZE=64;
    cv::Ptr<MACE> retval;

    const char* keywords[] = { "IMGSIZE", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|O:MACE_create", (char**)keywords, &pyobj_IMGSIZE) &&
        pyopencv_to_safe(pyobj_IMGSIZE, IMGSIZE, ArgInfo("IMGSIZE", 0)) )
    {
        ERRWRAP2(retval = cv::face::MACE::create(IMGSIZE));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_MACE_load(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::face;

    PyObject* pyobj_filename = NULL;
    String filename;
    PyObject* pyobj_objname = NULL;
    String objname;
    cv::Ptr<MACE> retval;

    const char* keywords[] = { "filename", "objname", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:MACE_load", (char**)keywords, &pyobj_filename, &pyobj_objname) &&
        pyopencv_to_safe(pyobj_filename, filename, ArgInfo("filename", 0)) &&
        pyopencv_to_safe(pyobj_objname, objname, ArgInfo("objname", 0)) )
    {
        ERRWRAP2(retval = cv::face::MACE::load(filename, objname));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_StandardCollector_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::face;

    PyObject* pyobj_threshold = NULL;
    double threshold=DBL_MAX;
    Ptr<StandardCollector> retval;

    const char* keywords[] = { "threshold", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|O:StandardCollector_create", (char**)keywords, &pyobj_threshold) &&
        pyopencv_to_safe(pyobj_threshold, threshold, ArgInfo("threshold", 0)) )
    {
        ERRWRAP2(retval = cv::face::StandardCollector::create(threshold));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_createFacemarkAAM(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::face;

    Ptr<Facemark> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::face::createFacemarkAAM());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_createFacemarkKazemi(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::face;

    Ptr<Facemark> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::face::createFacemarkKazemi());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_createFacemarkLBF(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::face;

    Ptr<Facemark> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::face::createFacemarkLBF());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_drawFacemarks(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::face;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_points = NULL;
    Mat points;
    PyObject* pyobj_color = NULL;
    Scalar color=Scalar(255,0,0);

    const char* keywords[] = { "image", "points", "color", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:drawFacemarks", (char**)keywords, &pyobj_image, &pyobj_points, &pyobj_color) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 1)) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) )
    {
        ERRWRAP2(cv::face::drawFacemarks(image, points, color));
        return pyopencv_from(image);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_points = NULL;
    UMat points;
    PyObject* pyobj_color = NULL;
    Scalar color=Scalar(255,0,0);

    const char* keywords[] = { "image", "points", "color", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:drawFacemarks", (char**)keywords, &pyobj_image, &pyobj_points, &pyobj_color) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 1)) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) )
    {
        ERRWRAP2(cv::face::drawFacemarks(image, points, color));
        return pyopencv_from(image);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("drawFacemarks");

    return NULL;
}

static PyObject* pyopencv_cv_face_getFacesHAAR(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::face;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_faces = NULL;
    Mat faces;
    PyObject* pyobj_face_cascade_name = NULL;
    String face_cascade_name;
    bool retval;

    const char* keywords[] = { "image", "face_cascade_name", "faces", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:getFacesHAAR", (char**)keywords, &pyobj_image, &pyobj_face_cascade_name, &pyobj_faces) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_faces, faces, ArgInfo("faces", 1)) &&
        pyopencv_to_safe(pyobj_face_cascade_name, face_cascade_name, ArgInfo("face_cascade_name", 0)) )
    {
        ERRWRAP2(retval = cv::face::getFacesHAAR(image, faces, face_cascade_name));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(faces));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_faces = NULL;
    UMat faces;
    PyObject* pyobj_face_cascade_name = NULL;
    String face_cascade_name;
    bool retval;

    const char* keywords[] = { "image", "face_cascade_name", "faces", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:getFacesHAAR", (char**)keywords, &pyobj_image, &pyobj_face_cascade_name, &pyobj_faces) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_faces, faces, ArgInfo("faces", 1)) &&
        pyopencv_to_safe(pyobj_face_cascade_name, face_cascade_name, ArgInfo("face_cascade_name", 0)) )
    {
        ERRWRAP2(retval = cv::face::getFacesHAAR(image, faces, face_cascade_name));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(faces));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("getFacesHAAR");

    return NULL;
}

static PyObject* pyopencv_cv_face_loadDatasetList(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::face;

    PyObject* pyobj_imageList = NULL;
    String imageList;
    PyObject* pyobj_annotationList = NULL;
    String annotationList;
    PyObject* pyobj_images = NULL;
    vector_String images;
    PyObject* pyobj_annotations = NULL;
    vector_String annotations;
    bool retval;

    const char* keywords[] = { "imageList", "annotationList", "images", "annotations", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO:loadDatasetList", (char**)keywords, &pyobj_imageList, &pyobj_annotationList, &pyobj_images, &pyobj_annotations) &&
        pyopencv_to_safe(pyobj_imageList, imageList, ArgInfo("imageList", 0)) &&
        pyopencv_to_safe(pyobj_annotationList, annotationList, ArgInfo("annotationList", 0)) &&
        pyopencv_to_safe(pyobj_images, images, ArgInfo("images", 0)) &&
        pyopencv_to_safe(pyobj_annotations, annotations, ArgInfo("annotations", 0)) )
    {
        ERRWRAP2(retval = cv::face::loadDatasetList(imageList, annotationList, images, annotations));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_face_loadFacePoints(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::face;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_filename = NULL;
    String filename;
    PyObject* pyobj_points = NULL;
    Mat points;
    PyObject* pyobj_offset = NULL;
    float offset=0.0f;
    bool retval;

    const char* keywords[] = { "filename", "points", "offset", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:loadFacePoints", (char**)keywords, &pyobj_filename, &pyobj_points, &pyobj_offset) &&
        pyopencv_to_safe(pyobj_filename, filename, ArgInfo("filename", 0)) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 1)) &&
        pyopencv_to_safe(pyobj_offset, offset, ArgInfo("offset", 0)) )
    {
        ERRWRAP2(retval = cv::face::loadFacePoints(filename, points, offset));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(points));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_filename = NULL;
    String filename;
    PyObject* pyobj_points = NULL;
    UMat points;
    PyObject* pyobj_offset = NULL;
    float offset=0.0f;
    bool retval;

    const char* keywords[] = { "filename", "points", "offset", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:loadFacePoints", (char**)keywords, &pyobj_filename, &pyobj_points, &pyobj_offset) &&
        pyopencv_to_safe(pyobj_filename, filename, ArgInfo("filename", 0)) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 1)) &&
        pyopencv_to_safe(pyobj_offset, offset, ArgInfo("offset", 0)) )
    {
        ERRWRAP2(retval = cv::face::loadFacePoints(filename, points, offset));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(points));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("loadFacePoints");

    return NULL;
}

static PyObject* pyopencv_cv_face_loadTrainingData(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::face;

    pyPrepareArgumentConversionErrorsStorage(5);

    {
    PyObject* pyobj_filename = NULL;
    String filename;
    PyObject* pyobj_images = NULL;
    vector_String images;
    PyObject* pyobj_facePoints = NULL;
    Mat facePoints;
    PyObject* pyobj_delim = NULL;
    char delim=' ';
    PyObject* pyobj_offset = NULL;
    float offset=0.0f;
    bool retval;

    const char* keywords[] = { "filename", "images", "facePoints", "delim", "offset", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:loadTrainingData", (char**)keywords, &pyobj_filename, &pyobj_images, &pyobj_facePoints, &pyobj_delim, &pyobj_offset) &&
        pyopencv_to_safe(pyobj_filename, filename, ArgInfo("filename", 0)) &&
        pyopencv_to_safe(pyobj_images, images, ArgInfo("images", 0)) &&
        pyopencv_to_safe(pyobj_facePoints, facePoints, ArgInfo("facePoints", 1)) &&
        convert_to_char(pyobj_delim, &delim, ArgInfo("delim", 0)) &&
        pyopencv_to_safe(pyobj_offset, offset, ArgInfo("offset", 0)) )
    {
        ERRWRAP2(retval = cv::face::loadTrainingData(filename, images, facePoints, delim, offset));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(facePoints));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_filename = NULL;
    String filename;
    PyObject* pyobj_images = NULL;
    vector_String images;
    PyObject* pyobj_facePoints = NULL;
    UMat facePoints;
    PyObject* pyobj_delim = NULL;
    char delim=' ';
    PyObject* pyobj_offset = NULL;
    float offset=0.0f;
    bool retval;

    const char* keywords[] = { "filename", "images", "facePoints", "delim", "offset", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:loadTrainingData", (char**)keywords, &pyobj_filename, &pyobj_images, &pyobj_facePoints, &pyobj_delim, &pyobj_offset) &&
        pyopencv_to_safe(pyobj_filename, filename, ArgInfo("filename", 0)) &&
        pyopencv_to_safe(pyobj_images, images, ArgInfo("images", 0)) &&
        pyopencv_to_safe(pyobj_facePoints, facePoints, ArgInfo("facePoints", 1)) &&
        convert_to_char(pyobj_delim, &delim, ArgInfo("delim", 0)) &&
        pyopencv_to_safe(pyobj_offset, offset, ArgInfo("offset", 0)) )
    {
        ERRWRAP2(retval = cv::face::loadTrainingData(filename, images, facePoints, delim, offset));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(facePoints));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_imageList = NULL;
    String imageList;
    PyObject* pyobj_groundTruth = NULL;
    String groundTruth;
    PyObject* pyobj_images = NULL;
    vector_String images;
    PyObject* pyobj_facePoints = NULL;
    Mat facePoints;
    PyObject* pyobj_offset = NULL;
    float offset=0.0f;
    bool retval;

    const char* keywords[] = { "imageList", "groundTruth", "images", "facePoints", "offset", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:loadTrainingData", (char**)keywords, &pyobj_imageList, &pyobj_groundTruth, &pyobj_images, &pyobj_facePoints, &pyobj_offset) &&
        pyopencv_to_safe(pyobj_imageList, imageList, ArgInfo("imageList", 0)) &&
        pyopencv_to_safe(pyobj_groundTruth, groundTruth, ArgInfo("groundTruth", 0)) &&
        pyopencv_to_safe(pyobj_images, images, ArgInfo("images", 0)) &&
        pyopencv_to_safe(pyobj_facePoints, facePoints, ArgInfo("facePoints", 1)) &&
        pyopencv_to_safe(pyobj_offset, offset, ArgInfo("offset", 0)) )
    {
        ERRWRAP2(retval = cv::face::loadTrainingData(imageList, groundTruth, images, facePoints, offset));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(facePoints));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_imageList = NULL;
    String imageList;
    PyObject* pyobj_groundTruth = NULL;
    String groundTruth;
    PyObject* pyobj_images = NULL;
    vector_String images;
    PyObject* pyobj_facePoints = NULL;
    UMat facePoints;
    PyObject* pyobj_offset = NULL;
    float offset=0.0f;
    bool retval;

    const char* keywords[] = { "imageList", "groundTruth", "images", "facePoints", "offset", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:loadTrainingData", (char**)keywords, &pyobj_imageList, &pyobj_groundTruth, &pyobj_images, &pyobj_facePoints, &pyobj_offset) &&
        pyopencv_to_safe(pyobj_imageList, imageList, ArgInfo("imageList", 0)) &&
        pyopencv_to_safe(pyobj_groundTruth, groundTruth, ArgInfo("groundTruth", 0)) &&
        pyopencv_to_safe(pyobj_images, images, ArgInfo("images", 0)) &&
        pyopencv_to_safe(pyobj_facePoints, facePoints, ArgInfo("facePoints", 1)) &&
        pyopencv_to_safe(pyobj_offset, offset, ArgInfo("offset", 0)) )
    {
        ERRWRAP2(retval = cv::face::loadTrainingData(imageList, groundTruth, images, facePoints, offset));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(facePoints));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_filename = NULL;
    vector_String filename;
    PyObject* pyobj_trainlandmarks = NULL;
    vector_vector_Point2f trainlandmarks;
    PyObject* pyobj_trainimages = NULL;
    vector_String trainimages;
    bool retval;

    const char* keywords[] = { "filename", "trainlandmarks", "trainimages", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:loadTrainingData", (char**)keywords, &pyobj_filename, &pyobj_trainlandmarks, &pyobj_trainimages) &&
        pyopencv_to_safe(pyobj_filename, filename, ArgInfo("filename", 0)) &&
        pyopencv_to_safe(pyobj_trainlandmarks, trainlandmarks, ArgInfo("trainlandmarks", 0)) &&
        pyopencv_to_safe(pyobj_trainimages, trainimages, ArgInfo("trainimages", 0)) )
    {
        ERRWRAP2(retval = cv::face::loadTrainingData(filename, trainlandmarks, trainimages));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("loadTrainingData");

    return NULL;
}

static PyObject* pyopencv_cv_fisheye_calibrate(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::fisheye;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_objectPoints = NULL;
    vector_Mat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    vector_Mat imagePoints;
    PyObject* pyobj_image_size = NULL;
    Size image_size;
    PyObject* pyobj_K = NULL;
    Mat K;
    PyObject* pyobj_D = NULL;
    Mat D;
    PyObject* pyobj_rvecs = NULL;
    vector_Mat rvecs;
    PyObject* pyobj_tvecs = NULL;
    vector_Mat tvecs;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria(TermCriteria::COUNT + TermCriteria::EPS, 100, DBL_EPSILON);
    double retval;

    const char* keywords[] = { "objectPoints", "imagePoints", "image_size", "K", "D", "rvecs", "tvecs", "flags", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OOOO:calibrate", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints, &pyobj_image_size, &pyobj_K, &pyobj_D, &pyobj_rvecs, &pyobj_tvecs, &pyobj_flags, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 0)) &&
        pyopencv_to_safe(pyobj_image_size, image_size, ArgInfo("image_size", 0)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 1)) &&
        pyopencv_to_safe(pyobj_D, D, ArgInfo("D", 1)) &&
        pyopencv_to_safe(pyobj_rvecs, rvecs, ArgInfo("rvecs", 1)) &&
        pyopencv_to_safe(pyobj_tvecs, tvecs, ArgInfo("tvecs", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(retval = cv::fisheye::calibrate(objectPoints, imagePoints, image_size, K, D, rvecs, tvecs, flags, criteria));
        return Py_BuildValue("(NNNNN)", pyopencv_from(retval), pyopencv_from(K), pyopencv_from(D), pyopencv_from(rvecs), pyopencv_from(tvecs));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_objectPoints = NULL;
    vector_UMat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    vector_UMat imagePoints;
    PyObject* pyobj_image_size = NULL;
    Size image_size;
    PyObject* pyobj_K = NULL;
    UMat K;
    PyObject* pyobj_D = NULL;
    UMat D;
    PyObject* pyobj_rvecs = NULL;
    vector_UMat rvecs;
    PyObject* pyobj_tvecs = NULL;
    vector_UMat tvecs;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria(TermCriteria::COUNT + TermCriteria::EPS, 100, DBL_EPSILON);
    double retval;

    const char* keywords[] = { "objectPoints", "imagePoints", "image_size", "K", "D", "rvecs", "tvecs", "flags", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OOOO:calibrate", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints, &pyobj_image_size, &pyobj_K, &pyobj_D, &pyobj_rvecs, &pyobj_tvecs, &pyobj_flags, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 0)) &&
        pyopencv_to_safe(pyobj_image_size, image_size, ArgInfo("image_size", 0)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 1)) &&
        pyopencv_to_safe(pyobj_D, D, ArgInfo("D", 1)) &&
        pyopencv_to_safe(pyobj_rvecs, rvecs, ArgInfo("rvecs", 1)) &&
        pyopencv_to_safe(pyobj_tvecs, tvecs, ArgInfo("tvecs", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(retval = cv::fisheye::calibrate(objectPoints, imagePoints, image_size, K, D, rvecs, tvecs, flags, criteria));
        return Py_BuildValue("(NNNNN)", pyopencv_from(retval), pyopencv_from(K), pyopencv_from(D), pyopencv_from(rvecs), pyopencv_from(tvecs));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("calibrate");

    return NULL;
}

static PyObject* pyopencv_cv_fisheye_distortPoints(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::fisheye;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_undistorted = NULL;
    Mat undistorted;
    PyObject* pyobj_distorted = NULL;
    Mat distorted;
    PyObject* pyobj_K = NULL;
    Mat K;
    PyObject* pyobj_D = NULL;
    Mat D;
    PyObject* pyobj_alpha = NULL;
    double alpha=0;

    const char* keywords[] = { "undistorted", "K", "D", "distorted", "alpha", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:distortPoints", (char**)keywords, &pyobj_undistorted, &pyobj_K, &pyobj_D, &pyobj_distorted, &pyobj_alpha) &&
        pyopencv_to_safe(pyobj_undistorted, undistorted, ArgInfo("undistorted", 0)) &&
        pyopencv_to_safe(pyobj_distorted, distorted, ArgInfo("distorted", 1)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_D, D, ArgInfo("D", 0)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) )
    {
        ERRWRAP2(cv::fisheye::distortPoints(undistorted, distorted, K, D, alpha));
        return pyopencv_from(distorted);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_undistorted = NULL;
    UMat undistorted;
    PyObject* pyobj_distorted = NULL;
    UMat distorted;
    PyObject* pyobj_K = NULL;
    UMat K;
    PyObject* pyobj_D = NULL;
    UMat D;
    PyObject* pyobj_alpha = NULL;
    double alpha=0;

    const char* keywords[] = { "undistorted", "K", "D", "distorted", "alpha", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:distortPoints", (char**)keywords, &pyobj_undistorted, &pyobj_K, &pyobj_D, &pyobj_distorted, &pyobj_alpha) &&
        pyopencv_to_safe(pyobj_undistorted, undistorted, ArgInfo("undistorted", 0)) &&
        pyopencv_to_safe(pyobj_distorted, distorted, ArgInfo("distorted", 1)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_D, D, ArgInfo("D", 0)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) )
    {
        ERRWRAP2(cv::fisheye::distortPoints(undistorted, distorted, K, D, alpha));
        return pyopencv_from(distorted);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("distortPoints");

    return NULL;
}

static PyObject* pyopencv_cv_fisheye_estimateNewCameraMatrixForUndistortRectify(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::fisheye;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_K = NULL;
    Mat K;
    PyObject* pyobj_D = NULL;
    Mat D;
    PyObject* pyobj_image_size = NULL;
    Size image_size;
    PyObject* pyobj_R = NULL;
    Mat R;
    PyObject* pyobj_P = NULL;
    Mat P;
    PyObject* pyobj_balance = NULL;
    double balance=0.0;
    PyObject* pyobj_new_size = NULL;
    Size new_size;
    PyObject* pyobj_fov_scale = NULL;
    double fov_scale=1.0;

    const char* keywords[] = { "K", "D", "image_size", "R", "P", "balance", "new_size", "fov_scale", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOO:estimateNewCameraMatrixForUndistortRectify", (char**)keywords, &pyobj_K, &pyobj_D, &pyobj_image_size, &pyobj_R, &pyobj_P, &pyobj_balance, &pyobj_new_size, &pyobj_fov_scale) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_D, D, ArgInfo("D", 0)) &&
        pyopencv_to_safe(pyobj_image_size, image_size, ArgInfo("image_size", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) &&
        pyopencv_to_safe(pyobj_P, P, ArgInfo("P", 1)) &&
        pyopencv_to_safe(pyobj_balance, balance, ArgInfo("balance", 0)) &&
        pyopencv_to_safe(pyobj_new_size, new_size, ArgInfo("new_size", 0)) &&
        pyopencv_to_safe(pyobj_fov_scale, fov_scale, ArgInfo("fov_scale", 0)) )
    {
        ERRWRAP2(cv::fisheye::estimateNewCameraMatrixForUndistortRectify(K, D, image_size, R, P, balance, new_size, fov_scale));
        return pyopencv_from(P);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_K = NULL;
    UMat K;
    PyObject* pyobj_D = NULL;
    UMat D;
    PyObject* pyobj_image_size = NULL;
    Size image_size;
    PyObject* pyobj_R = NULL;
    UMat R;
    PyObject* pyobj_P = NULL;
    UMat P;
    PyObject* pyobj_balance = NULL;
    double balance=0.0;
    PyObject* pyobj_new_size = NULL;
    Size new_size;
    PyObject* pyobj_fov_scale = NULL;
    double fov_scale=1.0;

    const char* keywords[] = { "K", "D", "image_size", "R", "P", "balance", "new_size", "fov_scale", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOO:estimateNewCameraMatrixForUndistortRectify", (char**)keywords, &pyobj_K, &pyobj_D, &pyobj_image_size, &pyobj_R, &pyobj_P, &pyobj_balance, &pyobj_new_size, &pyobj_fov_scale) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_D, D, ArgInfo("D", 0)) &&
        pyopencv_to_safe(pyobj_image_size, image_size, ArgInfo("image_size", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) &&
        pyopencv_to_safe(pyobj_P, P, ArgInfo("P", 1)) &&
        pyopencv_to_safe(pyobj_balance, balance, ArgInfo("balance", 0)) &&
        pyopencv_to_safe(pyobj_new_size, new_size, ArgInfo("new_size", 0)) &&
        pyopencv_to_safe(pyobj_fov_scale, fov_scale, ArgInfo("fov_scale", 0)) )
    {
        ERRWRAP2(cv::fisheye::estimateNewCameraMatrixForUndistortRectify(K, D, image_size, R, P, balance, new_size, fov_scale));
        return pyopencv_from(P);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("estimateNewCameraMatrixForUndistortRectify");

    return NULL;
}

static PyObject* pyopencv_cv_fisheye_initUndistortRectifyMap(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::fisheye;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_K = NULL;
    Mat K;
    PyObject* pyobj_D = NULL;
    Mat D;
    PyObject* pyobj_R = NULL;
    Mat R;
    PyObject* pyobj_P = NULL;
    Mat P;
    PyObject* pyobj_size = NULL;
    Size size;
    PyObject* pyobj_m1type = NULL;
    int m1type=0;
    PyObject* pyobj_map1 = NULL;
    Mat map1;
    PyObject* pyobj_map2 = NULL;
    Mat map2;

    const char* keywords[] = { "K", "D", "R", "P", "size", "m1type", "map1", "map2", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|OO:initUndistortRectifyMap", (char**)keywords, &pyobj_K, &pyobj_D, &pyobj_R, &pyobj_P, &pyobj_size, &pyobj_m1type, &pyobj_map1, &pyobj_map2) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_D, D, ArgInfo("D", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) &&
        pyopencv_to_safe(pyobj_P, P, ArgInfo("P", 0)) &&
        pyopencv_to_safe(pyobj_size, size, ArgInfo("size", 0)) &&
        pyopencv_to_safe(pyobj_m1type, m1type, ArgInfo("m1type", 0)) &&
        pyopencv_to_safe(pyobj_map1, map1, ArgInfo("map1", 1)) &&
        pyopencv_to_safe(pyobj_map2, map2, ArgInfo("map2", 1)) )
    {
        ERRWRAP2(cv::fisheye::initUndistortRectifyMap(K, D, R, P, size, m1type, map1, map2));
        return Py_BuildValue("(NN)", pyopencv_from(map1), pyopencv_from(map2));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_K = NULL;
    UMat K;
    PyObject* pyobj_D = NULL;
    UMat D;
    PyObject* pyobj_R = NULL;
    UMat R;
    PyObject* pyobj_P = NULL;
    UMat P;
    PyObject* pyobj_size = NULL;
    Size size;
    PyObject* pyobj_m1type = NULL;
    int m1type=0;
    PyObject* pyobj_map1 = NULL;
    UMat map1;
    PyObject* pyobj_map2 = NULL;
    UMat map2;

    const char* keywords[] = { "K", "D", "R", "P", "size", "m1type", "map1", "map2", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|OO:initUndistortRectifyMap", (char**)keywords, &pyobj_K, &pyobj_D, &pyobj_R, &pyobj_P, &pyobj_size, &pyobj_m1type, &pyobj_map1, &pyobj_map2) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_D, D, ArgInfo("D", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) &&
        pyopencv_to_safe(pyobj_P, P, ArgInfo("P", 0)) &&
        pyopencv_to_safe(pyobj_size, size, ArgInfo("size", 0)) &&
        pyopencv_to_safe(pyobj_m1type, m1type, ArgInfo("m1type", 0)) &&
        pyopencv_to_safe(pyobj_map1, map1, ArgInfo("map1", 1)) &&
        pyopencv_to_safe(pyobj_map2, map2, ArgInfo("map2", 1)) )
    {
        ERRWRAP2(cv::fisheye::initUndistortRectifyMap(K, D, R, P, size, m1type, map1, map2));
        return Py_BuildValue("(NN)", pyopencv_from(map1), pyopencv_from(map2));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("initUndistortRectifyMap");

    return NULL;
}

static PyObject* pyopencv_cv_fisheye_projectPoints(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::fisheye;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_objectPoints = NULL;
    Mat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    Mat imagePoints;
    PyObject* pyobj_rvec = NULL;
    Mat rvec;
    PyObject* pyobj_tvec = NULL;
    Mat tvec;
    PyObject* pyobj_K = NULL;
    Mat K;
    PyObject* pyobj_D = NULL;
    Mat D;
    PyObject* pyobj_alpha = NULL;
    double alpha=0;
    PyObject* pyobj_jacobian = NULL;
    Mat jacobian;

    const char* keywords[] = { "objectPoints", "rvec", "tvec", "K", "D", "imagePoints", "alpha", "jacobian", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OOO:projectPoints", (char**)keywords, &pyobj_objectPoints, &pyobj_rvec, &pyobj_tvec, &pyobj_K, &pyobj_D, &pyobj_imagePoints, &pyobj_alpha, &pyobj_jacobian) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 1)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 0)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 0)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_D, D, ArgInfo("D", 0)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_jacobian, jacobian, ArgInfo("jacobian", 1)) )
    {
        ERRWRAP2(cv::fisheye::projectPoints(objectPoints, imagePoints, rvec, tvec, K, D, alpha, jacobian));
        return Py_BuildValue("(NN)", pyopencv_from(imagePoints), pyopencv_from(jacobian));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_objectPoints = NULL;
    UMat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    UMat imagePoints;
    PyObject* pyobj_rvec = NULL;
    UMat rvec;
    PyObject* pyobj_tvec = NULL;
    UMat tvec;
    PyObject* pyobj_K = NULL;
    UMat K;
    PyObject* pyobj_D = NULL;
    UMat D;
    PyObject* pyobj_alpha = NULL;
    double alpha=0;
    PyObject* pyobj_jacobian = NULL;
    UMat jacobian;

    const char* keywords[] = { "objectPoints", "rvec", "tvec", "K", "D", "imagePoints", "alpha", "jacobian", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OOO:projectPoints", (char**)keywords, &pyobj_objectPoints, &pyobj_rvec, &pyobj_tvec, &pyobj_K, &pyobj_D, &pyobj_imagePoints, &pyobj_alpha, &pyobj_jacobian) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 1)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 0)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 0)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_D, D, ArgInfo("D", 0)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_jacobian, jacobian, ArgInfo("jacobian", 1)) )
    {
        ERRWRAP2(cv::fisheye::projectPoints(objectPoints, imagePoints, rvec, tvec, K, D, alpha, jacobian));
        return Py_BuildValue("(NN)", pyopencv_from(imagePoints), pyopencv_from(jacobian));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("projectPoints");

    return NULL;
}

static PyObject* pyopencv_cv_fisheye_stereoCalibrate(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::fisheye;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_objectPoints = NULL;
    vector_Mat objectPoints;
    PyObject* pyobj_imagePoints1 = NULL;
    vector_Mat imagePoints1;
    PyObject* pyobj_imagePoints2 = NULL;
    vector_Mat imagePoints2;
    PyObject* pyobj_K1 = NULL;
    Mat K1;
    PyObject* pyobj_D1 = NULL;
    Mat D1;
    PyObject* pyobj_K2 = NULL;
    Mat K2;
    PyObject* pyobj_D2 = NULL;
    Mat D2;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_R = NULL;
    Mat R;
    PyObject* pyobj_T = NULL;
    Mat T;
    PyObject* pyobj_flags = NULL;
    int flags=fisheye::CALIB_FIX_INTRINSIC;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria(TermCriteria::COUNT + TermCriteria::EPS, 100, DBL_EPSILON);
    double retval;

    const char* keywords[] = { "objectPoints", "imagePoints1", "imagePoints2", "K1", "D1", "K2", "D2", "imageSize", "R", "T", "flags", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOOO|OOOO:stereoCalibrate", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints1, &pyobj_imagePoints2, &pyobj_K1, &pyobj_D1, &pyobj_K2, &pyobj_D2, &pyobj_imageSize, &pyobj_R, &pyobj_T, &pyobj_flags, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints1, imagePoints1, ArgInfo("imagePoints1", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints2, imagePoints2, ArgInfo("imagePoints2", 0)) &&
        pyopencv_to_safe(pyobj_K1, K1, ArgInfo("K1", 1)) &&
        pyopencv_to_safe(pyobj_D1, D1, ArgInfo("D1", 1)) &&
        pyopencv_to_safe(pyobj_K2, K2, ArgInfo("K2", 1)) &&
        pyopencv_to_safe(pyobj_D2, D2, ArgInfo("D2", 1)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 1)) &&
        pyopencv_to_safe(pyobj_T, T, ArgInfo("T", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(retval = cv::fisheye::stereoCalibrate(objectPoints, imagePoints1, imagePoints2, K1, D1, K2, D2, imageSize, R, T, flags, criteria));
        return Py_BuildValue("(NNNNNNN)", pyopencv_from(retval), pyopencv_from(K1), pyopencv_from(D1), pyopencv_from(K2), pyopencv_from(D2), pyopencv_from(R), pyopencv_from(T));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_objectPoints = NULL;
    vector_UMat objectPoints;
    PyObject* pyobj_imagePoints1 = NULL;
    vector_UMat imagePoints1;
    PyObject* pyobj_imagePoints2 = NULL;
    vector_UMat imagePoints2;
    PyObject* pyobj_K1 = NULL;
    UMat K1;
    PyObject* pyobj_D1 = NULL;
    UMat D1;
    PyObject* pyobj_K2 = NULL;
    UMat K2;
    PyObject* pyobj_D2 = NULL;
    UMat D2;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_R = NULL;
    UMat R;
    PyObject* pyobj_T = NULL;
    UMat T;
    PyObject* pyobj_flags = NULL;
    int flags=fisheye::CALIB_FIX_INTRINSIC;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria=TermCriteria(TermCriteria::COUNT + TermCriteria::EPS, 100, DBL_EPSILON);
    double retval;

    const char* keywords[] = { "objectPoints", "imagePoints1", "imagePoints2", "K1", "D1", "K2", "D2", "imageSize", "R", "T", "flags", "criteria", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOOO|OOOO:stereoCalibrate", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints1, &pyobj_imagePoints2, &pyobj_K1, &pyobj_D1, &pyobj_K2, &pyobj_D2, &pyobj_imageSize, &pyobj_R, &pyobj_T, &pyobj_flags, &pyobj_criteria) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints1, imagePoints1, ArgInfo("imagePoints1", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints2, imagePoints2, ArgInfo("imagePoints2", 0)) &&
        pyopencv_to_safe(pyobj_K1, K1, ArgInfo("K1", 1)) &&
        pyopencv_to_safe(pyobj_D1, D1, ArgInfo("D1", 1)) &&
        pyopencv_to_safe(pyobj_K2, K2, ArgInfo("K2", 1)) &&
        pyopencv_to_safe(pyobj_D2, D2, ArgInfo("D2", 1)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 1)) &&
        pyopencv_to_safe(pyobj_T, T, ArgInfo("T", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) )
    {
        ERRWRAP2(retval = cv::fisheye::stereoCalibrate(objectPoints, imagePoints1, imagePoints2, K1, D1, K2, D2, imageSize, R, T, flags, criteria));
        return Py_BuildValue("(NNNNNNN)", pyopencv_from(retval), pyopencv_from(K1), pyopencv_from(D1), pyopencv_from(K2), pyopencv_from(D2), pyopencv_from(R), pyopencv_from(T));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("stereoCalibrate");

    return NULL;
}

static PyObject* pyopencv_cv_fisheye_stereoRectify(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::fisheye;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_K1 = NULL;
    Mat K1;
    PyObject* pyobj_D1 = NULL;
    Mat D1;
    PyObject* pyobj_K2 = NULL;
    Mat K2;
    PyObject* pyobj_D2 = NULL;
    Mat D2;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_R = NULL;
    Mat R;
    PyObject* pyobj_tvec = NULL;
    Mat tvec;
    PyObject* pyobj_R1 = NULL;
    Mat R1;
    PyObject* pyobj_R2 = NULL;
    Mat R2;
    PyObject* pyobj_P1 = NULL;
    Mat P1;
    PyObject* pyobj_P2 = NULL;
    Mat P2;
    PyObject* pyobj_Q = NULL;
    Mat Q;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_newImageSize = NULL;
    Size newImageSize;
    PyObject* pyobj_balance = NULL;
    double balance=0.0;
    PyObject* pyobj_fov_scale = NULL;
    double fov_scale=1.0;

    const char* keywords[] = { "K1", "D1", "K2", "D2", "imageSize", "R", "tvec", "flags", "R1", "R2", "P1", "P2", "Q", "newImageSize", "balance", "fov_scale", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOOO|OOOOOOOO:stereoRectify", (char**)keywords, &pyobj_K1, &pyobj_D1, &pyobj_K2, &pyobj_D2, &pyobj_imageSize, &pyobj_R, &pyobj_tvec, &pyobj_flags, &pyobj_R1, &pyobj_R2, &pyobj_P1, &pyobj_P2, &pyobj_Q, &pyobj_newImageSize, &pyobj_balance, &pyobj_fov_scale) &&
        pyopencv_to_safe(pyobj_K1, K1, ArgInfo("K1", 0)) &&
        pyopencv_to_safe(pyobj_D1, D1, ArgInfo("D1", 0)) &&
        pyopencv_to_safe(pyobj_K2, K2, ArgInfo("K2", 0)) &&
        pyopencv_to_safe(pyobj_D2, D2, ArgInfo("D2", 0)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 0)) &&
        pyopencv_to_safe(pyobj_R1, R1, ArgInfo("R1", 1)) &&
        pyopencv_to_safe(pyobj_R2, R2, ArgInfo("R2", 1)) &&
        pyopencv_to_safe(pyobj_P1, P1, ArgInfo("P1", 1)) &&
        pyopencv_to_safe(pyobj_P2, P2, ArgInfo("P2", 1)) &&
        pyopencv_to_safe(pyobj_Q, Q, ArgInfo("Q", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_newImageSize, newImageSize, ArgInfo("newImageSize", 0)) &&
        pyopencv_to_safe(pyobj_balance, balance, ArgInfo("balance", 0)) &&
        pyopencv_to_safe(pyobj_fov_scale, fov_scale, ArgInfo("fov_scale", 0)) )
    {
        ERRWRAP2(cv::fisheye::stereoRectify(K1, D1, K2, D2, imageSize, R, tvec, R1, R2, P1, P2, Q, flags, newImageSize, balance, fov_scale));
        return Py_BuildValue("(NNNNN)", pyopencv_from(R1), pyopencv_from(R2), pyopencv_from(P1), pyopencv_from(P2), pyopencv_from(Q));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_K1 = NULL;
    UMat K1;
    PyObject* pyobj_D1 = NULL;
    UMat D1;
    PyObject* pyobj_K2 = NULL;
    UMat K2;
    PyObject* pyobj_D2 = NULL;
    UMat D2;
    PyObject* pyobj_imageSize = NULL;
    Size imageSize;
    PyObject* pyobj_R = NULL;
    UMat R;
    PyObject* pyobj_tvec = NULL;
    UMat tvec;
    PyObject* pyobj_R1 = NULL;
    UMat R1;
    PyObject* pyobj_R2 = NULL;
    UMat R2;
    PyObject* pyobj_P1 = NULL;
    UMat P1;
    PyObject* pyobj_P2 = NULL;
    UMat P2;
    PyObject* pyobj_Q = NULL;
    UMat Q;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_newImageSize = NULL;
    Size newImageSize;
    PyObject* pyobj_balance = NULL;
    double balance=0.0;
    PyObject* pyobj_fov_scale = NULL;
    double fov_scale=1.0;

    const char* keywords[] = { "K1", "D1", "K2", "D2", "imageSize", "R", "tvec", "flags", "R1", "R2", "P1", "P2", "Q", "newImageSize", "balance", "fov_scale", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOOO|OOOOOOOO:stereoRectify", (char**)keywords, &pyobj_K1, &pyobj_D1, &pyobj_K2, &pyobj_D2, &pyobj_imageSize, &pyobj_R, &pyobj_tvec, &pyobj_flags, &pyobj_R1, &pyobj_R2, &pyobj_P1, &pyobj_P2, &pyobj_Q, &pyobj_newImageSize, &pyobj_balance, &pyobj_fov_scale) &&
        pyopencv_to_safe(pyobj_K1, K1, ArgInfo("K1", 0)) &&
        pyopencv_to_safe(pyobj_D1, D1, ArgInfo("D1", 0)) &&
        pyopencv_to_safe(pyobj_K2, K2, ArgInfo("K2", 0)) &&
        pyopencv_to_safe(pyobj_D2, D2, ArgInfo("D2", 0)) &&
        pyopencv_to_safe(pyobj_imageSize, imageSize, ArgInfo("imageSize", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 0)) &&
        pyopencv_to_safe(pyobj_R1, R1, ArgInfo("R1", 1)) &&
        pyopencv_to_safe(pyobj_R2, R2, ArgInfo("R2", 1)) &&
        pyopencv_to_safe(pyobj_P1, P1, ArgInfo("P1", 1)) &&
        pyopencv_to_safe(pyobj_P2, P2, ArgInfo("P2", 1)) &&
        pyopencv_to_safe(pyobj_Q, Q, ArgInfo("Q", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_newImageSize, newImageSize, ArgInfo("newImageSize", 0)) &&
        pyopencv_to_safe(pyobj_balance, balance, ArgInfo("balance", 0)) &&
        pyopencv_to_safe(pyobj_fov_scale, fov_scale, ArgInfo("fov_scale", 0)) )
    {
        ERRWRAP2(cv::fisheye::stereoRectify(K1, D1, K2, D2, imageSize, R, tvec, R1, R2, P1, P2, Q, flags, newImageSize, balance, fov_scale));
        return Py_BuildValue("(NNNNN)", pyopencv_from(R1), pyopencv_from(R2), pyopencv_from(P1), pyopencv_from(P2), pyopencv_from(Q));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("stereoRectify");

    return NULL;
}

static PyObject* pyopencv_cv_fisheye_undistortImage(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::fisheye;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_distorted = NULL;
    Mat distorted;
    PyObject* pyobj_undistorted = NULL;
    Mat undistorted;
    PyObject* pyobj_K = NULL;
    Mat K;
    PyObject* pyobj_D = NULL;
    Mat D;
    PyObject* pyobj_Knew = NULL;
    Mat Knew=cv::Mat();
    PyObject* pyobj_new_size = NULL;
    Size new_size;

    const char* keywords[] = { "distorted", "K", "D", "undistorted", "Knew", "new_size", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:undistortImage", (char**)keywords, &pyobj_distorted, &pyobj_K, &pyobj_D, &pyobj_undistorted, &pyobj_Knew, &pyobj_new_size) &&
        pyopencv_to_safe(pyobj_distorted, distorted, ArgInfo("distorted", 0)) &&
        pyopencv_to_safe(pyobj_undistorted, undistorted, ArgInfo("undistorted", 1)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_D, D, ArgInfo("D", 0)) &&
        pyopencv_to_safe(pyobj_Knew, Knew, ArgInfo("Knew", 0)) &&
        pyopencv_to_safe(pyobj_new_size, new_size, ArgInfo("new_size", 0)) )
    {
        ERRWRAP2(cv::fisheye::undistortImage(distorted, undistorted, K, D, Knew, new_size));
        return pyopencv_from(undistorted);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_distorted = NULL;
    UMat distorted;
    PyObject* pyobj_undistorted = NULL;
    UMat undistorted;
    PyObject* pyobj_K = NULL;
    UMat K;
    PyObject* pyobj_D = NULL;
    UMat D;
    PyObject* pyobj_Knew = NULL;
    UMat Knew=cv::UMat();
    PyObject* pyobj_new_size = NULL;
    Size new_size;

    const char* keywords[] = { "distorted", "K", "D", "undistorted", "Knew", "new_size", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:undistortImage", (char**)keywords, &pyobj_distorted, &pyobj_K, &pyobj_D, &pyobj_undistorted, &pyobj_Knew, &pyobj_new_size) &&
        pyopencv_to_safe(pyobj_distorted, distorted, ArgInfo("distorted", 0)) &&
        pyopencv_to_safe(pyobj_undistorted, undistorted, ArgInfo("undistorted", 1)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_D, D, ArgInfo("D", 0)) &&
        pyopencv_to_safe(pyobj_Knew, Knew, ArgInfo("Knew", 0)) &&
        pyopencv_to_safe(pyobj_new_size, new_size, ArgInfo("new_size", 0)) )
    {
        ERRWRAP2(cv::fisheye::undistortImage(distorted, undistorted, K, D, Knew, new_size));
        return pyopencv_from(undistorted);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("undistortImage");

    return NULL;
}

static PyObject* pyopencv_cv_fisheye_undistortPoints(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::fisheye;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_distorted = NULL;
    Mat distorted;
    PyObject* pyobj_undistorted = NULL;
    Mat undistorted;
    PyObject* pyobj_K = NULL;
    Mat K;
    PyObject* pyobj_D = NULL;
    Mat D;
    PyObject* pyobj_R = NULL;
    Mat R;
    PyObject* pyobj_P = NULL;
    Mat P;

    const char* keywords[] = { "distorted", "K", "D", "undistorted", "R", "P", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:undistortPoints", (char**)keywords, &pyobj_distorted, &pyobj_K, &pyobj_D, &pyobj_undistorted, &pyobj_R, &pyobj_P) &&
        pyopencv_to_safe(pyobj_distorted, distorted, ArgInfo("distorted", 0)) &&
        pyopencv_to_safe(pyobj_undistorted, undistorted, ArgInfo("undistorted", 1)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_D, D, ArgInfo("D", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) &&
        pyopencv_to_safe(pyobj_P, P, ArgInfo("P", 0)) )
    {
        ERRWRAP2(cv::fisheye::undistortPoints(distorted, undistorted, K, D, R, P));
        return pyopencv_from(undistorted);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_distorted = NULL;
    UMat distorted;
    PyObject* pyobj_undistorted = NULL;
    UMat undistorted;
    PyObject* pyobj_K = NULL;
    UMat K;
    PyObject* pyobj_D = NULL;
    UMat D;
    PyObject* pyobj_R = NULL;
    UMat R;
    PyObject* pyobj_P = NULL;
    UMat P;

    const char* keywords[] = { "distorted", "K", "D", "undistorted", "R", "P", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:undistortPoints", (char**)keywords, &pyobj_distorted, &pyobj_K, &pyobj_D, &pyobj_undistorted, &pyobj_R, &pyobj_P) &&
        pyopencv_to_safe(pyobj_distorted, distorted, ArgInfo("distorted", 0)) &&
        pyopencv_to_safe(pyobj_undistorted, undistorted, ArgInfo("undistorted", 1)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_D, D, ArgInfo("D", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) &&
        pyopencv_to_safe(pyobj_P, P, ArgInfo("P", 0)) )
    {
        ERRWRAP2(cv::fisheye::undistortPoints(distorted, undistorted, K, D, R, P));
        return pyopencv_from(undistorted);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("undistortPoints");

    return NULL;
}

static PyObject* pyopencv_cv_ft_FT02D_FL_process(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ft;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_matrix = NULL;
    Mat matrix;
    PyObject* pyobj_radius = NULL;
    int radius=0;
    PyObject* pyobj_output = NULL;
    Mat output;

    const char* keywords[] = { "matrix", "radius", "output", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:FT02D_FL_process", (char**)keywords, &pyobj_matrix, &pyobj_radius, &pyobj_output) &&
        pyopencv_to_safe(pyobj_matrix, matrix, ArgInfo("matrix", 0)) &&
        pyopencv_to_safe(pyobj_radius, radius, ArgInfo("radius", 0)) &&
        pyopencv_to_safe(pyobj_output, output, ArgInfo("output", 1)) )
    {
        ERRWRAP2(cv::ft::FT02D_FL_process(matrix, radius, output));
        return pyopencv_from(output);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_matrix = NULL;
    UMat matrix;
    PyObject* pyobj_radius = NULL;
    int radius=0;
    PyObject* pyobj_output = NULL;
    UMat output;

    const char* keywords[] = { "matrix", "radius", "output", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:FT02D_FL_process", (char**)keywords, &pyobj_matrix, &pyobj_radius, &pyobj_output) &&
        pyopencv_to_safe(pyobj_matrix, matrix, ArgInfo("matrix", 0)) &&
        pyopencv_to_safe(pyobj_radius, radius, ArgInfo("radius", 0)) &&
        pyopencv_to_safe(pyobj_output, output, ArgInfo("output", 1)) )
    {
        ERRWRAP2(cv::ft::FT02D_FL_process(matrix, radius, output));
        return pyopencv_from(output);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("FT02D_FL_process");

    return NULL;
}

static PyObject* pyopencv_cv_ft_FT02D_FL_process_float(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ft;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_matrix = NULL;
    Mat matrix;
    PyObject* pyobj_radius = NULL;
    int radius=0;
    PyObject* pyobj_output = NULL;
    Mat output;

    const char* keywords[] = { "matrix", "radius", "output", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:FT02D_FL_process_float", (char**)keywords, &pyobj_matrix, &pyobj_radius, &pyobj_output) &&
        pyopencv_to_safe(pyobj_matrix, matrix, ArgInfo("matrix", 0)) &&
        pyopencv_to_safe(pyobj_radius, radius, ArgInfo("radius", 0)) &&
        pyopencv_to_safe(pyobj_output, output, ArgInfo("output", 1)) )
    {
        ERRWRAP2(cv::ft::FT02D_FL_process_float(matrix, radius, output));
        return pyopencv_from(output);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_matrix = NULL;
    UMat matrix;
    PyObject* pyobj_radius = NULL;
    int radius=0;
    PyObject* pyobj_output = NULL;
    UMat output;

    const char* keywords[] = { "matrix", "radius", "output", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:FT02D_FL_process_float", (char**)keywords, &pyobj_matrix, &pyobj_radius, &pyobj_output) &&
        pyopencv_to_safe(pyobj_matrix, matrix, ArgInfo("matrix", 0)) &&
        pyopencv_to_safe(pyobj_radius, radius, ArgInfo("radius", 0)) &&
        pyopencv_to_safe(pyobj_output, output, ArgInfo("output", 1)) )
    {
        ERRWRAP2(cv::ft::FT02D_FL_process_float(matrix, radius, output));
        return pyopencv_from(output);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("FT02D_FL_process_float");

    return NULL;
}

static PyObject* pyopencv_cv_ft_FT02D_components(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ft;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_matrix = NULL;
    Mat matrix;
    PyObject* pyobj_kernel = NULL;
    Mat kernel;
    PyObject* pyobj_components = NULL;
    Mat components;
    PyObject* pyobj_mask = NULL;
    Mat mask;

    const char* keywords[] = { "matrix", "kernel", "components", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:FT02D_components", (char**)keywords, &pyobj_matrix, &pyobj_kernel, &pyobj_components, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_matrix, matrix, ArgInfo("matrix", 0)) &&
        pyopencv_to_safe(pyobj_kernel, kernel, ArgInfo("kernel", 0)) &&
        pyopencv_to_safe(pyobj_components, components, ArgInfo("components", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::ft::FT02D_components(matrix, kernel, components, mask));
        return pyopencv_from(components);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_matrix = NULL;
    UMat matrix;
    PyObject* pyobj_kernel = NULL;
    UMat kernel;
    PyObject* pyobj_components = NULL;
    UMat components;
    PyObject* pyobj_mask = NULL;
    UMat mask;

    const char* keywords[] = { "matrix", "kernel", "components", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:FT02D_components", (char**)keywords, &pyobj_matrix, &pyobj_kernel, &pyobj_components, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_matrix, matrix, ArgInfo("matrix", 0)) &&
        pyopencv_to_safe(pyobj_kernel, kernel, ArgInfo("kernel", 0)) &&
        pyopencv_to_safe(pyobj_components, components, ArgInfo("components", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::ft::FT02D_components(matrix, kernel, components, mask));
        return pyopencv_from(components);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("FT02D_components");

    return NULL;
}

static PyObject* pyopencv_cv_ft_FT02D_inverseFT(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ft;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_components = NULL;
    Mat components;
    PyObject* pyobj_kernel = NULL;
    Mat kernel;
    PyObject* pyobj_output = NULL;
    Mat output;
    PyObject* pyobj_width = NULL;
    int width=0;
    PyObject* pyobj_height = NULL;
    int height=0;

    const char* keywords[] = { "components", "kernel", "width", "height", "output", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:FT02D_inverseFT", (char**)keywords, &pyobj_components, &pyobj_kernel, &pyobj_width, &pyobj_height, &pyobj_output) &&
        pyopencv_to_safe(pyobj_components, components, ArgInfo("components", 0)) &&
        pyopencv_to_safe(pyobj_kernel, kernel, ArgInfo("kernel", 0)) &&
        pyopencv_to_safe(pyobj_output, output, ArgInfo("output", 1)) &&
        pyopencv_to_safe(pyobj_width, width, ArgInfo("width", 0)) &&
        pyopencv_to_safe(pyobj_height, height, ArgInfo("height", 0)) )
    {
        ERRWRAP2(cv::ft::FT02D_inverseFT(components, kernel, output, width, height));
        return pyopencv_from(output);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_components = NULL;
    UMat components;
    PyObject* pyobj_kernel = NULL;
    UMat kernel;
    PyObject* pyobj_output = NULL;
    UMat output;
    PyObject* pyobj_width = NULL;
    int width=0;
    PyObject* pyobj_height = NULL;
    int height=0;

    const char* keywords[] = { "components", "kernel", "width", "height", "output", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:FT02D_inverseFT", (char**)keywords, &pyobj_components, &pyobj_kernel, &pyobj_width, &pyobj_height, &pyobj_output) &&
        pyopencv_to_safe(pyobj_components, components, ArgInfo("components", 0)) &&
        pyopencv_to_safe(pyobj_kernel, kernel, ArgInfo("kernel", 0)) &&
        pyopencv_to_safe(pyobj_output, output, ArgInfo("output", 1)) &&
        pyopencv_to_safe(pyobj_width, width, ArgInfo("width", 0)) &&
        pyopencv_to_safe(pyobj_height, height, ArgInfo("height", 0)) )
    {
        ERRWRAP2(cv::ft::FT02D_inverseFT(components, kernel, output, width, height));
        return pyopencv_from(output);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("FT02D_inverseFT");

    return NULL;
}

static PyObject* pyopencv_cv_ft_FT02D_iteration(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ft;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_matrix = NULL;
    Mat matrix;
    PyObject* pyobj_kernel = NULL;
    Mat kernel;
    PyObject* pyobj_output = NULL;
    Mat output;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_maskOutput = NULL;
    Mat maskOutput;
    PyObject* pyobj_firstStop = NULL;
    bool firstStop=0;
    int retval;

    const char* keywords[] = { "matrix", "kernel", "mask", "firstStop", "output", "maskOutput", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OO:FT02D_iteration", (char**)keywords, &pyobj_matrix, &pyobj_kernel, &pyobj_mask, &pyobj_firstStop, &pyobj_output, &pyobj_maskOutput) &&
        pyopencv_to_safe(pyobj_matrix, matrix, ArgInfo("matrix", 0)) &&
        pyopencv_to_safe(pyobj_kernel, kernel, ArgInfo("kernel", 0)) &&
        pyopencv_to_safe(pyobj_output, output, ArgInfo("output", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_maskOutput, maskOutput, ArgInfo("maskOutput", 1)) &&
        pyopencv_to_safe(pyobj_firstStop, firstStop, ArgInfo("firstStop", 0)) )
    {
        ERRWRAP2(retval = cv::ft::FT02D_iteration(matrix, kernel, output, mask, maskOutput, firstStop));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(output), pyopencv_from(maskOutput));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_matrix = NULL;
    UMat matrix;
    PyObject* pyobj_kernel = NULL;
    UMat kernel;
    PyObject* pyobj_output = NULL;
    UMat output;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    PyObject* pyobj_maskOutput = NULL;
    UMat maskOutput;
    PyObject* pyobj_firstStop = NULL;
    bool firstStop=0;
    int retval;

    const char* keywords[] = { "matrix", "kernel", "mask", "firstStop", "output", "maskOutput", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OO:FT02D_iteration", (char**)keywords, &pyobj_matrix, &pyobj_kernel, &pyobj_mask, &pyobj_firstStop, &pyobj_output, &pyobj_maskOutput) &&
        pyopencv_to_safe(pyobj_matrix, matrix, ArgInfo("matrix", 0)) &&
        pyopencv_to_safe(pyobj_kernel, kernel, ArgInfo("kernel", 0)) &&
        pyopencv_to_safe(pyobj_output, output, ArgInfo("output", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_maskOutput, maskOutput, ArgInfo("maskOutput", 1)) &&
        pyopencv_to_safe(pyobj_firstStop, firstStop, ArgInfo("firstStop", 0)) )
    {
        ERRWRAP2(retval = cv::ft::FT02D_iteration(matrix, kernel, output, mask, maskOutput, firstStop));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(output), pyopencv_from(maskOutput));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("FT02D_iteration");

    return NULL;
}

static PyObject* pyopencv_cv_ft_FT02D_process(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ft;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_matrix = NULL;
    Mat matrix;
    PyObject* pyobj_kernel = NULL;
    Mat kernel;
    PyObject* pyobj_output = NULL;
    Mat output;
    PyObject* pyobj_mask = NULL;
    Mat mask;

    const char* keywords[] = { "matrix", "kernel", "output", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:FT02D_process", (char**)keywords, &pyobj_matrix, &pyobj_kernel, &pyobj_output, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_matrix, matrix, ArgInfo("matrix", 0)) &&
        pyopencv_to_safe(pyobj_kernel, kernel, ArgInfo("kernel", 0)) &&
        pyopencv_to_safe(pyobj_output, output, ArgInfo("output", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::ft::FT02D_process(matrix, kernel, output, mask));
        return pyopencv_from(output);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_matrix = NULL;
    UMat matrix;
    PyObject* pyobj_kernel = NULL;
    UMat kernel;
    PyObject* pyobj_output = NULL;
    UMat output;
    PyObject* pyobj_mask = NULL;
    UMat mask;

    const char* keywords[] = { "matrix", "kernel", "output", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:FT02D_process", (char**)keywords, &pyobj_matrix, &pyobj_kernel, &pyobj_output, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_matrix, matrix, ArgInfo("matrix", 0)) &&
        pyopencv_to_safe(pyobj_kernel, kernel, ArgInfo("kernel", 0)) &&
        pyopencv_to_safe(pyobj_output, output, ArgInfo("output", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::ft::FT02D_process(matrix, kernel, output, mask));
        return pyopencv_from(output);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("FT02D_process");

    return NULL;
}

static PyObject* pyopencv_cv_ft_FT12D_components(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ft;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_matrix = NULL;
    Mat matrix;
    PyObject* pyobj_kernel = NULL;
    Mat kernel;
    PyObject* pyobj_components = NULL;
    Mat components;

    const char* keywords[] = { "matrix", "kernel", "components", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:FT12D_components", (char**)keywords, &pyobj_matrix, &pyobj_kernel, &pyobj_components) &&
        pyopencv_to_safe(pyobj_matrix, matrix, ArgInfo("matrix", 0)) &&
        pyopencv_to_safe(pyobj_kernel, kernel, ArgInfo("kernel", 0)) &&
        pyopencv_to_safe(pyobj_components, components, ArgInfo("components", 1)) )
    {
        ERRWRAP2(cv::ft::FT12D_components(matrix, kernel, components));
        return pyopencv_from(components);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_matrix = NULL;
    UMat matrix;
    PyObject* pyobj_kernel = NULL;
    UMat kernel;
    PyObject* pyobj_components = NULL;
    UMat components;

    const char* keywords[] = { "matrix", "kernel", "components", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:FT12D_components", (char**)keywords, &pyobj_matrix, &pyobj_kernel, &pyobj_components) &&
        pyopencv_to_safe(pyobj_matrix, matrix, ArgInfo("matrix", 0)) &&
        pyopencv_to_safe(pyobj_kernel, kernel, ArgInfo("kernel", 0)) &&
        pyopencv_to_safe(pyobj_components, components, ArgInfo("components", 1)) )
    {
        ERRWRAP2(cv::ft::FT12D_components(matrix, kernel, components));
        return pyopencv_from(components);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("FT12D_components");

    return NULL;
}

static PyObject* pyopencv_cv_ft_FT12D_createPolynomMatrixHorizontal(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ft;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_radius = NULL;
    int radius=0;
    PyObject* pyobj_matrix = NULL;
    Mat matrix;
    PyObject* pyobj_chn = NULL;
    int chn=0;

    const char* keywords[] = { "radius", "chn", "matrix", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:FT12D_createPolynomMatrixHorizontal", (char**)keywords, &pyobj_radius, &pyobj_chn, &pyobj_matrix) &&
        pyopencv_to_safe(pyobj_radius, radius, ArgInfo("radius", 0)) &&
        pyopencv_to_safe(pyobj_matrix, matrix, ArgInfo("matrix", 1)) &&
        pyopencv_to_safe(pyobj_chn, chn, ArgInfo("chn", 0)) )
    {
        ERRWRAP2(cv::ft::FT12D_createPolynomMatrixHorizontal(radius, matrix, chn));
        return pyopencv_from(matrix);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_radius = NULL;
    int radius=0;
    PyObject* pyobj_matrix = NULL;
    UMat matrix;
    PyObject* pyobj_chn = NULL;
    int chn=0;

    const char* keywords[] = { "radius", "chn", "matrix", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:FT12D_createPolynomMatrixHorizontal", (char**)keywords, &pyobj_radius, &pyobj_chn, &pyobj_matrix) &&
        pyopencv_to_safe(pyobj_radius, radius, ArgInfo("radius", 0)) &&
        pyopencv_to_safe(pyobj_matrix, matrix, ArgInfo("matrix", 1)) &&
        pyopencv_to_safe(pyobj_chn, chn, ArgInfo("chn", 0)) )
    {
        ERRWRAP2(cv::ft::FT12D_createPolynomMatrixHorizontal(radius, matrix, chn));
        return pyopencv_from(matrix);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("FT12D_createPolynomMatrixHorizontal");

    return NULL;
}

static PyObject* pyopencv_cv_ft_FT12D_createPolynomMatrixVertical(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ft;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_radius = NULL;
    int radius=0;
    PyObject* pyobj_matrix = NULL;
    Mat matrix;
    PyObject* pyobj_chn = NULL;
    int chn=0;

    const char* keywords[] = { "radius", "chn", "matrix", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:FT12D_createPolynomMatrixVertical", (char**)keywords, &pyobj_radius, &pyobj_chn, &pyobj_matrix) &&
        pyopencv_to_safe(pyobj_radius, radius, ArgInfo("radius", 0)) &&
        pyopencv_to_safe(pyobj_matrix, matrix, ArgInfo("matrix", 1)) &&
        pyopencv_to_safe(pyobj_chn, chn, ArgInfo("chn", 0)) )
    {
        ERRWRAP2(cv::ft::FT12D_createPolynomMatrixVertical(radius, matrix, chn));
        return pyopencv_from(matrix);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_radius = NULL;
    int radius=0;
    PyObject* pyobj_matrix = NULL;
    UMat matrix;
    PyObject* pyobj_chn = NULL;
    int chn=0;

    const char* keywords[] = { "radius", "chn", "matrix", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:FT12D_createPolynomMatrixVertical", (char**)keywords, &pyobj_radius, &pyobj_chn, &pyobj_matrix) &&
        pyopencv_to_safe(pyobj_radius, radius, ArgInfo("radius", 0)) &&
        pyopencv_to_safe(pyobj_matrix, matrix, ArgInfo("matrix", 1)) &&
        pyopencv_to_safe(pyobj_chn, chn, ArgInfo("chn", 0)) )
    {
        ERRWRAP2(cv::ft::FT12D_createPolynomMatrixVertical(radius, matrix, chn));
        return pyopencv_from(matrix);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("FT12D_createPolynomMatrixVertical");

    return NULL;
}

static PyObject* pyopencv_cv_ft_FT12D_inverseFT(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ft;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_components = NULL;
    Mat components;
    PyObject* pyobj_kernel = NULL;
    Mat kernel;
    PyObject* pyobj_output = NULL;
    Mat output;
    PyObject* pyobj_width = NULL;
    int width=0;
    PyObject* pyobj_height = NULL;
    int height=0;

    const char* keywords[] = { "components", "kernel", "width", "height", "output", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:FT12D_inverseFT", (char**)keywords, &pyobj_components, &pyobj_kernel, &pyobj_width, &pyobj_height, &pyobj_output) &&
        pyopencv_to_safe(pyobj_components, components, ArgInfo("components", 0)) &&
        pyopencv_to_safe(pyobj_kernel, kernel, ArgInfo("kernel", 0)) &&
        pyopencv_to_safe(pyobj_output, output, ArgInfo("output", 1)) &&
        pyopencv_to_safe(pyobj_width, width, ArgInfo("width", 0)) &&
        pyopencv_to_safe(pyobj_height, height, ArgInfo("height", 0)) )
    {
        ERRWRAP2(cv::ft::FT12D_inverseFT(components, kernel, output, width, height));
        return pyopencv_from(output);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_components = NULL;
    UMat components;
    PyObject* pyobj_kernel = NULL;
    UMat kernel;
    PyObject* pyobj_output = NULL;
    UMat output;
    PyObject* pyobj_width = NULL;
    int width=0;
    PyObject* pyobj_height = NULL;
    int height=0;

    const char* keywords[] = { "components", "kernel", "width", "height", "output", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:FT12D_inverseFT", (char**)keywords, &pyobj_components, &pyobj_kernel, &pyobj_width, &pyobj_height, &pyobj_output) &&
        pyopencv_to_safe(pyobj_components, components, ArgInfo("components", 0)) &&
        pyopencv_to_safe(pyobj_kernel, kernel, ArgInfo("kernel", 0)) &&
        pyopencv_to_safe(pyobj_output, output, ArgInfo("output", 1)) &&
        pyopencv_to_safe(pyobj_width, width, ArgInfo("width", 0)) &&
        pyopencv_to_safe(pyobj_height, height, ArgInfo("height", 0)) )
    {
        ERRWRAP2(cv::ft::FT12D_inverseFT(components, kernel, output, width, height));
        return pyopencv_from(output);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("FT12D_inverseFT");

    return NULL;
}

static PyObject* pyopencv_cv_ft_FT12D_polynomial(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ft;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_matrix = NULL;
    Mat matrix;
    PyObject* pyobj_kernel = NULL;
    Mat kernel;
    PyObject* pyobj_c00 = NULL;
    Mat c00;
    PyObject* pyobj_c10 = NULL;
    Mat c10;
    PyObject* pyobj_c01 = NULL;
    Mat c01;
    PyObject* pyobj_components = NULL;
    Mat components;
    PyObject* pyobj_mask = NULL;
    Mat mask;

    const char* keywords[] = { "matrix", "kernel", "c00", "c10", "c01", "components", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOOO:FT12D_polynomial", (char**)keywords, &pyobj_matrix, &pyobj_kernel, &pyobj_c00, &pyobj_c10, &pyobj_c01, &pyobj_components, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_matrix, matrix, ArgInfo("matrix", 0)) &&
        pyopencv_to_safe(pyobj_kernel, kernel, ArgInfo("kernel", 0)) &&
        pyopencv_to_safe(pyobj_c00, c00, ArgInfo("c00", 1)) &&
        pyopencv_to_safe(pyobj_c10, c10, ArgInfo("c10", 1)) &&
        pyopencv_to_safe(pyobj_c01, c01, ArgInfo("c01", 1)) &&
        pyopencv_to_safe(pyobj_components, components, ArgInfo("components", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::ft::FT12D_polynomial(matrix, kernel, c00, c10, c01, components, mask));
        return Py_BuildValue("(NNNN)", pyopencv_from(c00), pyopencv_from(c10), pyopencv_from(c01), pyopencv_from(components));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_matrix = NULL;
    UMat matrix;
    PyObject* pyobj_kernel = NULL;
    UMat kernel;
    PyObject* pyobj_c00 = NULL;
    UMat c00;
    PyObject* pyobj_c10 = NULL;
    UMat c10;
    PyObject* pyobj_c01 = NULL;
    UMat c01;
    PyObject* pyobj_components = NULL;
    UMat components;
    PyObject* pyobj_mask = NULL;
    UMat mask;

    const char* keywords[] = { "matrix", "kernel", "c00", "c10", "c01", "components", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOOO:FT12D_polynomial", (char**)keywords, &pyobj_matrix, &pyobj_kernel, &pyobj_c00, &pyobj_c10, &pyobj_c01, &pyobj_components, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_matrix, matrix, ArgInfo("matrix", 0)) &&
        pyopencv_to_safe(pyobj_kernel, kernel, ArgInfo("kernel", 0)) &&
        pyopencv_to_safe(pyobj_c00, c00, ArgInfo("c00", 1)) &&
        pyopencv_to_safe(pyobj_c10, c10, ArgInfo("c10", 1)) &&
        pyopencv_to_safe(pyobj_c01, c01, ArgInfo("c01", 1)) &&
        pyopencv_to_safe(pyobj_components, components, ArgInfo("components", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::ft::FT12D_polynomial(matrix, kernel, c00, c10, c01, components, mask));
        return Py_BuildValue("(NNNN)", pyopencv_from(c00), pyopencv_from(c10), pyopencv_from(c01), pyopencv_from(components));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("FT12D_polynomial");

    return NULL;
}

static PyObject* pyopencv_cv_ft_FT12D_process(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ft;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_matrix = NULL;
    Mat matrix;
    PyObject* pyobj_kernel = NULL;
    Mat kernel;
    PyObject* pyobj_output = NULL;
    Mat output;
    PyObject* pyobj_mask = NULL;
    Mat mask;

    const char* keywords[] = { "matrix", "kernel", "output", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:FT12D_process", (char**)keywords, &pyobj_matrix, &pyobj_kernel, &pyobj_output, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_matrix, matrix, ArgInfo("matrix", 0)) &&
        pyopencv_to_safe(pyobj_kernel, kernel, ArgInfo("kernel", 0)) &&
        pyopencv_to_safe(pyobj_output, output, ArgInfo("output", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::ft::FT12D_process(matrix, kernel, output, mask));
        return pyopencv_from(output);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_matrix = NULL;
    UMat matrix;
    PyObject* pyobj_kernel = NULL;
    UMat kernel;
    PyObject* pyobj_output = NULL;
    UMat output;
    PyObject* pyobj_mask = NULL;
    UMat mask;

    const char* keywords[] = { "matrix", "kernel", "output", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:FT12D_process", (char**)keywords, &pyobj_matrix, &pyobj_kernel, &pyobj_output, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_matrix, matrix, ArgInfo("matrix", 0)) &&
        pyopencv_to_safe(pyobj_kernel, kernel, ArgInfo("kernel", 0)) &&
        pyopencv_to_safe(pyobj_output, output, ArgInfo("output", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::ft::FT12D_process(matrix, kernel, output, mask));
        return pyopencv_from(output);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("FT12D_process");

    return NULL;
}

static PyObject* pyopencv_cv_ft_createKernel(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ft;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_function = NULL;
    int function=0;
    PyObject* pyobj_radius = NULL;
    int radius=0;
    PyObject* pyobj_kernel = NULL;
    Mat kernel;
    PyObject* pyobj_chn = NULL;
    int chn=0;

    const char* keywords[] = { "function", "radius", "chn", "kernel", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:createKernel", (char**)keywords, &pyobj_function, &pyobj_radius, &pyobj_chn, &pyobj_kernel) &&
        pyopencv_to_safe(pyobj_function, function, ArgInfo("function", 0)) &&
        pyopencv_to_safe(pyobj_radius, radius, ArgInfo("radius", 0)) &&
        pyopencv_to_safe(pyobj_kernel, kernel, ArgInfo("kernel", 1)) &&
        pyopencv_to_safe(pyobj_chn, chn, ArgInfo("chn", 0)) )
    {
        ERRWRAP2(cv::ft::createKernel(function, radius, kernel, chn));
        return pyopencv_from(kernel);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_function = NULL;
    int function=0;
    PyObject* pyobj_radius = NULL;
    int radius=0;
    PyObject* pyobj_kernel = NULL;
    UMat kernel;
    PyObject* pyobj_chn = NULL;
    int chn=0;

    const char* keywords[] = { "function", "radius", "chn", "kernel", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:createKernel", (char**)keywords, &pyobj_function, &pyobj_radius, &pyobj_chn, &pyobj_kernel) &&
        pyopencv_to_safe(pyobj_function, function, ArgInfo("function", 0)) &&
        pyopencv_to_safe(pyobj_radius, radius, ArgInfo("radius", 0)) &&
        pyopencv_to_safe(pyobj_kernel, kernel, ArgInfo("kernel", 1)) &&
        pyopencv_to_safe(pyobj_chn, chn, ArgInfo("chn", 0)) )
    {
        ERRWRAP2(cv::ft::createKernel(function, radius, kernel, chn));
        return pyopencv_from(kernel);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("createKernel");

    return NULL;
}

static PyObject* pyopencv_cv_ft_createKernel1(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ft;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_A = NULL;
    Mat A;
    PyObject* pyobj_B = NULL;
    Mat B;
    PyObject* pyobj_kernel = NULL;
    Mat kernel;
    PyObject* pyobj_chn = NULL;
    int chn=0;

    const char* keywords[] = { "A", "B", "chn", "kernel", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:createKernel1", (char**)keywords, &pyobj_A, &pyobj_B, &pyobj_chn, &pyobj_kernel) &&
        pyopencv_to_safe(pyobj_A, A, ArgInfo("A", 0)) &&
        pyopencv_to_safe(pyobj_B, B, ArgInfo("B", 0)) &&
        pyopencv_to_safe(pyobj_kernel, kernel, ArgInfo("kernel", 1)) &&
        pyopencv_to_safe(pyobj_chn, chn, ArgInfo("chn", 0)) )
    {
        ERRWRAP2(cv::ft::createKernel(A, B, kernel, chn));
        return pyopencv_from(kernel);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_A = NULL;
    UMat A;
    PyObject* pyobj_B = NULL;
    UMat B;
    PyObject* pyobj_kernel = NULL;
    UMat kernel;
    PyObject* pyobj_chn = NULL;
    int chn=0;

    const char* keywords[] = { "A", "B", "chn", "kernel", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:createKernel1", (char**)keywords, &pyobj_A, &pyobj_B, &pyobj_chn, &pyobj_kernel) &&
        pyopencv_to_safe(pyobj_A, A, ArgInfo("A", 0)) &&
        pyopencv_to_safe(pyobj_B, B, ArgInfo("B", 0)) &&
        pyopencv_to_safe(pyobj_kernel, kernel, ArgInfo("kernel", 1)) &&
        pyopencv_to_safe(pyobj_chn, chn, ArgInfo("chn", 0)) )
    {
        ERRWRAP2(cv::ft::createKernel(A, B, kernel, chn));
        return pyopencv_from(kernel);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("createKernel1");

    return NULL;
}

static PyObject* pyopencv_cv_ft_filter(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ft;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_kernel = NULL;
    Mat kernel;
    PyObject* pyobj_output = NULL;
    Mat output;

    const char* keywords[] = { "image", "kernel", "output", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:filter", (char**)keywords, &pyobj_image, &pyobj_kernel, &pyobj_output) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_kernel, kernel, ArgInfo("kernel", 0)) &&
        pyopencv_to_safe(pyobj_output, output, ArgInfo("output", 1)) )
    {
        ERRWRAP2(cv::ft::filter(image, kernel, output));
        return pyopencv_from(output);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_kernel = NULL;
    UMat kernel;
    PyObject* pyobj_output = NULL;
    UMat output;

    const char* keywords[] = { "image", "kernel", "output", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:filter", (char**)keywords, &pyobj_image, &pyobj_kernel, &pyobj_output) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_kernel, kernel, ArgInfo("kernel", 0)) &&
        pyopencv_to_safe(pyobj_output, output, ArgInfo("output", 1)) )
    {
        ERRWRAP2(cv::ft::filter(image, kernel, output));
        return pyopencv_from(output);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("filter");

    return NULL;
}

static PyObject* pyopencv_cv_ft_inpaint(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ft;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_output = NULL;
    Mat output;
    PyObject* pyobj_radius = NULL;
    int radius=0;
    PyObject* pyobj_function = NULL;
    int function=0;
    PyObject* pyobj_algorithm = NULL;
    int algorithm=0;

    const char* keywords[] = { "image", "mask", "radius", "function", "algorithm", "output", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|O:inpaint", (char**)keywords, &pyobj_image, &pyobj_mask, &pyobj_radius, &pyobj_function, &pyobj_algorithm, &pyobj_output) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_output, output, ArgInfo("output", 1)) &&
        pyopencv_to_safe(pyobj_radius, radius, ArgInfo("radius", 0)) &&
        pyopencv_to_safe(pyobj_function, function, ArgInfo("function", 0)) &&
        pyopencv_to_safe(pyobj_algorithm, algorithm, ArgInfo("algorithm", 0)) )
    {
        ERRWRAP2(cv::ft::inpaint(image, mask, output, radius, function, algorithm));
        return pyopencv_from(output);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    PyObject* pyobj_output = NULL;
    UMat output;
    PyObject* pyobj_radius = NULL;
    int radius=0;
    PyObject* pyobj_function = NULL;
    int function=0;
    PyObject* pyobj_algorithm = NULL;
    int algorithm=0;

    const char* keywords[] = { "image", "mask", "radius", "function", "algorithm", "output", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|O:inpaint", (char**)keywords, &pyobj_image, &pyobj_mask, &pyobj_radius, &pyobj_function, &pyobj_algorithm, &pyobj_output) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_output, output, ArgInfo("output", 1)) &&
        pyopencv_to_safe(pyobj_radius, radius, ArgInfo("radius", 0)) &&
        pyopencv_to_safe(pyobj_function, function, ArgInfo("function", 0)) &&
        pyopencv_to_safe(pyobj_algorithm, algorithm, ArgInfo("algorithm", 0)) )
    {
        ERRWRAP2(cv::ft::inpaint(image, mask, output, radius, function, algorithm));
        return pyopencv_from(output);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("inpaint");

    return NULL;
}

static PyObject* pyopencv_cv_gapi_RGB2Gray(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::gapi;

    PyObject* pyobj_src = NULL;
    GMat src;
    GMat retval;

    const char* keywords[] = { "src", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:RGB2Gray", (char**)keywords, &pyobj_src) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) )
    {
        ERRWRAP2(retval = cv::gapi::RGB2Gray(src));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_gapi_add(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::gapi;

    PyObject* pyobj_src1 = NULL;
    GMat src1;
    PyObject* pyobj_src2 = NULL;
    GMat src2;
    PyObject* pyobj_ddepth = NULL;
    int ddepth=-1;
    GMat retval;

    const char* keywords[] = { "src1", "src2", "ddepth", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:add", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_ddepth) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_ddepth, ddepth, ArgInfo("ddepth", 0)) )
    {
        ERRWRAP2(retval = cv::gapi::add(src1, src2, ddepth));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_gapi_addC(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::gapi;

    PyObject* pyobj_src1 = NULL;
    GMat src1;
    PyObject* pyobj_c = NULL;
    GScalar c;
    PyObject* pyobj_ddepth = NULL;
    int ddepth=-1;
    GMat retval;

    const char* keywords[] = { "src1", "c", "ddepth", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:addC", (char**)keywords, &pyobj_src1, &pyobj_c, &pyobj_ddepth) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_c, c, ArgInfo("c", 0)) &&
        pyopencv_to_safe(pyobj_ddepth, ddepth, ArgInfo("ddepth", 0)) )
    {
        ERRWRAP2(retval = cv::gapi::addC(src1, c, ddepth));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_gapi_boundingRect(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::gapi;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    GMat src;
    GOpaque<Rect> retval;

    const char* keywords[] = { "src", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:boundingRect", (char**)keywords, &pyobj_src) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) )
    {
        ERRWRAP2(retval = cv::gapi::boundingRect(src));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    GArray_Point2i src;
    GOpaque<Rect> retval;

    const char* keywords[] = { "src", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:boundingRect", (char**)keywords, &pyobj_src) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) )
    {
        ERRWRAP2(retval = cv::gapi::boundingRect(src));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("boundingRect");

    return NULL;
}

static PyObject* pyopencv_cv_gapi_goodFeaturesToTrack(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::gapi;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    GMat image;
    PyObject* pyobj_maxCorners = NULL;
    int maxCorners=0;
    PyObject* pyobj_qualityLevel = NULL;
    double qualityLevel=0;
    PyObject* pyobj_minDistance = NULL;
    double minDistance=0;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_blockSize = NULL;
    int blockSize=3;
    PyObject* pyobj_useHarrisDetector = NULL;
    bool useHarrisDetector=false;
    PyObject* pyobj_k = NULL;
    double k=0.04;
    GArray<Point2f> retval;

    const char* keywords[] = { "image", "maxCorners", "qualityLevel", "minDistance", "mask", "blockSize", "useHarrisDetector", "k", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOO:goodFeaturesToTrack", (char**)keywords, &pyobj_image, &pyobj_maxCorners, &pyobj_qualityLevel, &pyobj_minDistance, &pyobj_mask, &pyobj_blockSize, &pyobj_useHarrisDetector, &pyobj_k) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_maxCorners, maxCorners, ArgInfo("maxCorners", 0)) &&
        pyopencv_to_safe(pyobj_qualityLevel, qualityLevel, ArgInfo("qualityLevel", 0)) &&
        pyopencv_to_safe(pyobj_minDistance, minDistance, ArgInfo("minDistance", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_blockSize, blockSize, ArgInfo("blockSize", 0)) &&
        pyopencv_to_safe(pyobj_useHarrisDetector, useHarrisDetector, ArgInfo("useHarrisDetector", 0)) &&
        pyopencv_to_safe(pyobj_k, k, ArgInfo("k", 0)) )
    {
        ERRWRAP2(retval = cv::gapi::goodFeaturesToTrack(image, maxCorners, qualityLevel, minDistance, mask, blockSize, useHarrisDetector, k));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    GMat image;
    PyObject* pyobj_maxCorners = NULL;
    int maxCorners=0;
    PyObject* pyobj_qualityLevel = NULL;
    double qualityLevel=0;
    PyObject* pyobj_minDistance = NULL;
    double minDistance=0;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_blockSize = NULL;
    int blockSize=3;
    PyObject* pyobj_useHarrisDetector = NULL;
    bool useHarrisDetector=false;
    PyObject* pyobj_k = NULL;
    double k=0.04;
    GArray<Point2f> retval;

    const char* keywords[] = { "image", "maxCorners", "qualityLevel", "minDistance", "mask", "blockSize", "useHarrisDetector", "k", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOO:goodFeaturesToTrack", (char**)keywords, &pyobj_image, &pyobj_maxCorners, &pyobj_qualityLevel, &pyobj_minDistance, &pyobj_mask, &pyobj_blockSize, &pyobj_useHarrisDetector, &pyobj_k) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_maxCorners, maxCorners, ArgInfo("maxCorners", 0)) &&
        pyopencv_to_safe(pyobj_qualityLevel, qualityLevel, ArgInfo("qualityLevel", 0)) &&
        pyopencv_to_safe(pyobj_minDistance, minDistance, ArgInfo("minDistance", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_blockSize, blockSize, ArgInfo("blockSize", 0)) &&
        pyopencv_to_safe(pyobj_useHarrisDetector, useHarrisDetector, ArgInfo("useHarrisDetector", 0)) &&
        pyopencv_to_safe(pyobj_k, k, ArgInfo("k", 0)) )
    {
        ERRWRAP2(retval = cv::gapi::goodFeaturesToTrack(image, maxCorners, qualityLevel, minDistance, mask, blockSize, useHarrisDetector, k));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("goodFeaturesToTrack");

    return NULL;
}

static PyObject* pyopencv_cv_gapi_infer(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::gapi;

    pyPrepareArgumentConversionErrorsStorage(3);

    {
    PyObject* pyobj_name = NULL;
    String name;
    PyObject* pyobj_inputs = NULL;
    GInferInputs inputs;
    cv::GInferOutputs retval;

    const char* keywords[] = { "name", "inputs", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:infer", (char**)keywords, &pyobj_name, &pyobj_inputs) &&
        pyopencv_to_safe(pyobj_name, name, ArgInfo("name", 0)) &&
        pyopencv_to_safe(pyobj_inputs, inputs, ArgInfo("inputs", 0)) )
    {
        ERRWRAP2(retval = cv::gapi::infer(name, inputs));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_name = NULL;
    std::string name;
    PyObject* pyobj_roi = NULL;
    GOpaque_Rect roi;
    PyObject* pyobj_inputs = NULL;
    GInferInputs inputs;
    GInferOutputs retval;

    const char* keywords[] = { "name", "roi", "inputs", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:infer", (char**)keywords, &pyobj_name, &pyobj_roi, &pyobj_inputs) &&
        pyopencv_to_safe(pyobj_name, name, ArgInfo("name", 0)) &&
        pyopencv_to_safe(pyobj_roi, roi, ArgInfo("roi", 0)) &&
        pyopencv_to_safe(pyobj_inputs, inputs, ArgInfo("inputs", 0)) )
    {
        ERRWRAP2(retval = cv::gapi::infer(name, roi, inputs));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_name = NULL;
    std::string name;
    PyObject* pyobj_rois = NULL;
    GArray_Rect rois;
    PyObject* pyobj_inputs = NULL;
    GInferInputs inputs;
    GInferListOutputs retval;

    const char* keywords[] = { "name", "rois", "inputs", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:infer", (char**)keywords, &pyobj_name, &pyobj_rois, &pyobj_inputs) &&
        pyopencv_to_safe(pyobj_name, name, ArgInfo("name", 0)) &&
        pyopencv_to_safe(pyobj_rois, rois, ArgInfo("rois", 0)) &&
        pyopencv_to_safe(pyobj_inputs, inputs, ArgInfo("inputs", 0)) )
    {
        ERRWRAP2(retval = cv::gapi::infer(name, rois, inputs));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("infer");

    return NULL;
}

static PyObject* pyopencv_cv_gapi_infer2(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::gapi;

    PyObject* pyobj_name = NULL;
    std::string name;
    PyObject* pyobj_in = NULL;
    GMat in;
    PyObject* pyobj_inputs = NULL;
    GInferListInputs inputs;
    GInferListOutputs retval;

    const char* keywords[] = { "name", "in", "inputs", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:infer2", (char**)keywords, &pyobj_name, &pyobj_in, &pyobj_inputs) &&
        pyopencv_to_safe(pyobj_name, name, ArgInfo("name", 0)) &&
        pyopencv_to_safe(pyobj_in, in, ArgInfo("in", 0)) &&
        pyopencv_to_safe(pyobj_inputs, inputs, ArgInfo("inputs", 0)) )
    {
        ERRWRAP2(retval = cv::gapi::infer2(name, in, inputs));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_gapi_kmeans(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::gapi;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_data = NULL;
    GMat data;
    PyObject* pyobj_K = NULL;
    int K=0;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria;
    PyObject* pyobj_attempts = NULL;
    int attempts=0;
    PyObject* pyobj_flags = NULL;
    KmeansFlags flags=static_cast<KmeansFlags>(0);
    std::tuple<GOpaque<double>,GMat,GMat> retval;

    const char* keywords[] = { "data", "K", "criteria", "attempts", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO:kmeans", (char**)keywords, &pyobj_data, &pyobj_K, &pyobj_criteria, &pyobj_attempts, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_data, data, ArgInfo("data", 0)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) &&
        pyopencv_to_safe(pyobj_attempts, attempts, ArgInfo("attempts", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(retval = cv::gapi::kmeans(data, K, criteria, attempts, flags));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_data = NULL;
    GArray_Point2f data;
    PyObject* pyobj_K = NULL;
    int K=0;
    PyObject* pyobj_bestLabels = NULL;
    GArray_int bestLabels;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria;
    PyObject* pyobj_attempts = NULL;
    int attempts=0;
    PyObject* pyobj_flags = NULL;
    KmeansFlags flags=static_cast<KmeansFlags>(0);
    std::tuple<GOpaque<double>,GArray<int>,GArray<Point2f>> retval;

    const char* keywords[] = { "data", "K", "bestLabels", "criteria", "attempts", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO:kmeans", (char**)keywords, &pyobj_data, &pyobj_K, &pyobj_bestLabels, &pyobj_criteria, &pyobj_attempts, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_data, data, ArgInfo("data", 0)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_bestLabels, bestLabels, ArgInfo("bestLabels", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) &&
        pyopencv_to_safe(pyobj_attempts, attempts, ArgInfo("attempts", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(retval = cv::gapi::kmeans(data, K, bestLabels, criteria, attempts, flags));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("kmeans");

    return NULL;
}

static PyObject* pyopencv_cv_gapi_mean(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::gapi;

    PyObject* pyobj_src = NULL;
    GMat src;
    GScalar retval;

    const char* keywords[] = { "src", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:mean", (char**)keywords, &pyobj_src) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) )
    {
        ERRWRAP2(retval = cv::gapi::mean(src));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_gapi_medianBlur(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::gapi;

    PyObject* pyobj_src = NULL;
    GMat src;
    PyObject* pyobj_ksize = NULL;
    int ksize=0;
    GMat retval;

    const char* keywords[] = { "src", "ksize", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:medianBlur", (char**)keywords, &pyobj_src, &pyobj_ksize) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) )
    {
        ERRWRAP2(retval = cv::gapi::medianBlur(src, ksize));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_gapi_networks(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::gapi;

    PyObject* pyobj_params = NULL;
    gapi_ie_PyParams params;
    gapi::GNetPackage retval;

    const char* keywords[] = { "params", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:networks", (char**)keywords, &pyobj_params) &&
        pyopencv_to_safe(pyobj_params, params, ArgInfo("params", 0)) )
    {
        ERRWRAP2(retval = cv::gapi::networks(params));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_gapi_parseSSD(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::gapi;

    PyObject* pyobj_in = NULL;
    GMat in;
    PyObject* pyobj_inSz = NULL;
    GOpaque_Size inSz;
    PyObject* pyobj_confidenceThreshold = NULL;
    float confidenceThreshold=0.5f;
    PyObject* pyobj_alignmentToSquare = NULL;
    bool alignmentToSquare=false;
    PyObject* pyobj_filterOutOfBounds = NULL;
    bool filterOutOfBounds=false;
    GArray<Rect> retval;

    const char* keywords[] = { "in", "inSz", "confidenceThreshold", "alignmentToSquare", "filterOutOfBounds", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:parseSSD", (char**)keywords, &pyobj_in, &pyobj_inSz, &pyobj_confidenceThreshold, &pyobj_alignmentToSquare, &pyobj_filterOutOfBounds) &&
        pyopencv_to_safe(pyobj_in, in, ArgInfo("in", 0)) &&
        pyopencv_to_safe(pyobj_inSz, inSz, ArgInfo("inSz", 0)) &&
        pyopencv_to_safe(pyobj_confidenceThreshold, confidenceThreshold, ArgInfo("confidenceThreshold", 0)) &&
        pyopencv_to_safe(pyobj_alignmentToSquare, alignmentToSquare, ArgInfo("alignmentToSquare", 0)) &&
        pyopencv_to_safe(pyobj_filterOutOfBounds, filterOutOfBounds, ArgInfo("filterOutOfBounds", 0)) )
    {
        ERRWRAP2(retval = cv::gapi::parseSSD(in, inSz, confidenceThreshold, alignmentToSquare, filterOutOfBounds));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_gapi_split3(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::gapi;

    PyObject* pyobj_src = NULL;
    GMat src;
    std::tuple<GMat, GMat, GMat> retval;

    const char* keywords[] = { "src", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:split3", (char**)keywords, &pyobj_src) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) )
    {
        ERRWRAP2(retval = cv::gapi::split3(src));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_gapi_threshold(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::gapi;

    PyObject* pyobj_src = NULL;
    GMat src;
    PyObject* pyobj_maxval = NULL;
    GScalar maxval;
    PyObject* pyobj_type = NULL;
    int type=0;
    std::tuple<GMat, GScalar> retval;

    const char* keywords[] = { "src", "maxval", "type", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:threshold", (char**)keywords, &pyobj_src, &pyobj_maxval, &pyobj_type) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_maxval, maxval, ArgInfo("maxval", 0)) &&
        pyopencv_to_safe(pyobj_type, type, ArgInfo("type", 0)) )
    {
        ERRWRAP2(retval = cv::gapi::threshold(src, maxval, type));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_gapi_core_cpu_kernels(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::gapi::core::cpu;

    cv::gapi::GKernelPackage retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::gapi::core::cpu::kernels());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_gapi_core_fluid_kernels(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::gapi::core::fluid;

    cv::gapi::GKernelPackage retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::gapi::core::fluid::kernels());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_gapi_core_ocl_kernels(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::gapi::core::ocl;

    cv::gapi::GKernelPackage retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::gapi::core::ocl::kernels());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_gapi_ie_params(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::gapi::ie;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_tag = NULL;
    std::string tag;
    PyObject* pyobj_model = NULL;
    std::string model;
    PyObject* pyobj_weights = NULL;
    std::string weights;
    PyObject* pyobj_device = NULL;
    std::string device;
    PyParams retval;

    const char* keywords[] = { "tag", "model", "weights", "device", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO:params", (char**)keywords, &pyobj_tag, &pyobj_model, &pyobj_weights, &pyobj_device) &&
        pyopencv_to_safe(pyobj_tag, tag, ArgInfo("tag", 0)) &&
        pyopencv_to_safe(pyobj_model, model, ArgInfo("model", 0)) &&
        pyopencv_to_safe(pyobj_weights, weights, ArgInfo("weights", 0)) &&
        pyopencv_to_safe(pyobj_device, device, ArgInfo("device", 0)) )
    {
        ERRWRAP2(retval = cv::gapi::ie::params(tag, model, weights, device));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_tag = NULL;
    std::string tag;
    PyObject* pyobj_model = NULL;
    std::string model;
    PyObject* pyobj_device = NULL;
    std::string device;
    PyParams retval;

    const char* keywords[] = { "tag", "model", "device", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:params", (char**)keywords, &pyobj_tag, &pyobj_model, &pyobj_device) &&
        pyopencv_to_safe(pyobj_tag, tag, ArgInfo("tag", 0)) &&
        pyopencv_to_safe(pyobj_model, model, ArgInfo("model", 0)) &&
        pyopencv_to_safe(pyobj_device, device, ArgInfo("device", 0)) )
    {
        ERRWRAP2(retval = cv::gapi::ie::params(tag, model, device));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("params");

    return NULL;
}

static PyObject* pyopencv_cv_gapi_streaming_size(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::gapi::streaming;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    GMat src;
    GOpaque<Size> retval;

    const char* keywords[] = { "src", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:size", (char**)keywords, &pyobj_src) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) )
    {
        ERRWRAP2(retval = cv::gapi::streaming::size(src));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_r = NULL;
    GOpaque_Rect r;
    GOpaque<Size> retval;

    const char* keywords[] = { "r", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:size", (char**)keywords, &pyobj_r) &&
        pyopencv_to_safe(pyobj_r, r, ArgInfo("r", 0)) )
    {
        ERRWRAP2(retval = cv::gapi::streaming::size(r));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("size");

    return NULL;
}

static PyObject* pyopencv_cv_gapi_wip_make_capture_src(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::gapi::wip;

    PyObject* pyobj_path = NULL;
    std::string path;
    cv::Ptr<IStreamSource> retval;

    const char* keywords[] = { "path", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:make_capture_src", (char**)keywords, &pyobj_path) &&
        pyopencv_to_safe(pyobj_path, path, ArgInfo("path", 0)) )
    {
        ERRWRAP2(retval = cv::gapi::wip::make_capture_src(path));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_hfs_HfsSegment_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::hfs;

    PyObject* pyobj_height = NULL;
    int height=0;
    PyObject* pyobj_width = NULL;
    int width=0;
    PyObject* pyobj_segEgbThresholdI = NULL;
    float segEgbThresholdI=0.08f;
    PyObject* pyobj_minRegionSizeI = NULL;
    int minRegionSizeI=100;
    PyObject* pyobj_segEgbThresholdII = NULL;
    float segEgbThresholdII=0.28f;
    PyObject* pyobj_minRegionSizeII = NULL;
    int minRegionSizeII=200;
    PyObject* pyobj_spatialWeight = NULL;
    float spatialWeight=0.6f;
    PyObject* pyobj_slicSpixelSize = NULL;
    int slicSpixelSize=8;
    PyObject* pyobj_numSlicIter = NULL;
    int numSlicIter=5;
    Ptr<HfsSegment> retval;

    const char* keywords[] = { "height", "width", "segEgbThresholdI", "minRegionSizeI", "segEgbThresholdII", "minRegionSizeII", "spatialWeight", "slicSpixelSize", "numSlicIter", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOOOOO:HfsSegment_create", (char**)keywords, &pyobj_height, &pyobj_width, &pyobj_segEgbThresholdI, &pyobj_minRegionSizeI, &pyobj_segEgbThresholdII, &pyobj_minRegionSizeII, &pyobj_spatialWeight, &pyobj_slicSpixelSize, &pyobj_numSlicIter) &&
        pyopencv_to_safe(pyobj_height, height, ArgInfo("height", 0)) &&
        pyopencv_to_safe(pyobj_width, width, ArgInfo("width", 0)) &&
        pyopencv_to_safe(pyobj_segEgbThresholdI, segEgbThresholdI, ArgInfo("segEgbThresholdI", 0)) &&
        pyopencv_to_safe(pyobj_minRegionSizeI, minRegionSizeI, ArgInfo("minRegionSizeI", 0)) &&
        pyopencv_to_safe(pyobj_segEgbThresholdII, segEgbThresholdII, ArgInfo("segEgbThresholdII", 0)) &&
        pyopencv_to_safe(pyobj_minRegionSizeII, minRegionSizeII, ArgInfo("minRegionSizeII", 0)) &&
        pyopencv_to_safe(pyobj_spatialWeight, spatialWeight, ArgInfo("spatialWeight", 0)) &&
        pyopencv_to_safe(pyobj_slicSpixelSize, slicSpixelSize, ArgInfo("slicSpixelSize", 0)) &&
        pyopencv_to_safe(pyobj_numSlicIter, numSlicIter, ArgInfo("numSlicIter", 0)) )
    {
        ERRWRAP2(retval = cv::hfs::HfsSegment::create(height, width, segEgbThresholdI, minRegionSizeI, segEgbThresholdII, minRegionSizeII, spatialWeight, slicSpixelSize, numSlicIter));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_img_hash_AverageHash_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::img_hash;

    Ptr<AverageHash> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::img_hash::AverageHash::create());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_img_hash_BlockMeanHash_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::img_hash;

    PyObject* pyobj_mode = NULL;
    int mode=BLOCK_MEAN_HASH_MODE_0;
    Ptr<BlockMeanHash> retval;

    const char* keywords[] = { "mode", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|O:BlockMeanHash_create", (char**)keywords, &pyobj_mode) &&
        pyopencv_to_safe(pyobj_mode, mode, ArgInfo("mode", 0)) )
    {
        ERRWRAP2(retval = cv::img_hash::BlockMeanHash::create(mode));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_img_hash_ColorMomentHash_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::img_hash;

    Ptr<ColorMomentHash> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::img_hash::ColorMomentHash::create());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_img_hash_MarrHildrethHash_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::img_hash;

    PyObject* pyobj_alpha = NULL;
    float alpha=2.0f;
    PyObject* pyobj_scale = NULL;
    float scale=1.0f;
    Ptr<MarrHildrethHash> retval;

    const char* keywords[] = { "alpha", "scale", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OO:MarrHildrethHash_create", (char**)keywords, &pyobj_alpha, &pyobj_scale) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_scale, scale, ArgInfo("scale", 0)) )
    {
        ERRWRAP2(retval = cv::img_hash::MarrHildrethHash::create(alpha, scale));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_img_hash_PHash_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::img_hash;

    Ptr<PHash> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::img_hash::PHash::create());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_img_hash_RadialVarianceHash_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::img_hash;

    PyObject* pyobj_sigma = NULL;
    double sigma=1;
    PyObject* pyobj_numOfAngleLine = NULL;
    int numOfAngleLine=180;
    Ptr<RadialVarianceHash> retval;

    const char* keywords[] = { "sigma", "numOfAngleLine", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OO:RadialVarianceHash_create", (char**)keywords, &pyobj_sigma, &pyobj_numOfAngleLine) &&
        pyopencv_to_safe(pyobj_sigma, sigma, ArgInfo("sigma", 0)) &&
        pyopencv_to_safe(pyobj_numOfAngleLine, numOfAngleLine, ArgInfo("numOfAngleLine", 0)) )
    {
        ERRWRAP2(retval = cv::img_hash::RadialVarianceHash::create(sigma, numOfAngleLine));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_img_hash_averageHash(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::img_hash;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_inputArr = NULL;
    Mat inputArr;
    PyObject* pyobj_outputArr = NULL;
    Mat outputArr;

    const char* keywords[] = { "inputArr", "outputArr", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:averageHash", (char**)keywords, &pyobj_inputArr, &pyobj_outputArr) &&
        pyopencv_to_safe(pyobj_inputArr, inputArr, ArgInfo("inputArr", 0)) &&
        pyopencv_to_safe(pyobj_outputArr, outputArr, ArgInfo("outputArr", 1)) )
    {
        ERRWRAP2(cv::img_hash::averageHash(inputArr, outputArr));
        return pyopencv_from(outputArr);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_inputArr = NULL;
    UMat inputArr;
    PyObject* pyobj_outputArr = NULL;
    UMat outputArr;

    const char* keywords[] = { "inputArr", "outputArr", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:averageHash", (char**)keywords, &pyobj_inputArr, &pyobj_outputArr) &&
        pyopencv_to_safe(pyobj_inputArr, inputArr, ArgInfo("inputArr", 0)) &&
        pyopencv_to_safe(pyobj_outputArr, outputArr, ArgInfo("outputArr", 1)) )
    {
        ERRWRAP2(cv::img_hash::averageHash(inputArr, outputArr));
        return pyopencv_from(outputArr);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("averageHash");

    return NULL;
}

static PyObject* pyopencv_cv_img_hash_blockMeanHash(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::img_hash;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_inputArr = NULL;
    Mat inputArr;
    PyObject* pyobj_outputArr = NULL;
    Mat outputArr;
    PyObject* pyobj_mode = NULL;
    int mode=BLOCK_MEAN_HASH_MODE_0;

    const char* keywords[] = { "inputArr", "outputArr", "mode", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:blockMeanHash", (char**)keywords, &pyobj_inputArr, &pyobj_outputArr, &pyobj_mode) &&
        pyopencv_to_safe(pyobj_inputArr, inputArr, ArgInfo("inputArr", 0)) &&
        pyopencv_to_safe(pyobj_outputArr, outputArr, ArgInfo("outputArr", 1)) &&
        pyopencv_to_safe(pyobj_mode, mode, ArgInfo("mode", 0)) )
    {
        ERRWRAP2(cv::img_hash::blockMeanHash(inputArr, outputArr, mode));
        return pyopencv_from(outputArr);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_inputArr = NULL;
    UMat inputArr;
    PyObject* pyobj_outputArr = NULL;
    UMat outputArr;
    PyObject* pyobj_mode = NULL;
    int mode=BLOCK_MEAN_HASH_MODE_0;

    const char* keywords[] = { "inputArr", "outputArr", "mode", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:blockMeanHash", (char**)keywords, &pyobj_inputArr, &pyobj_outputArr, &pyobj_mode) &&
        pyopencv_to_safe(pyobj_inputArr, inputArr, ArgInfo("inputArr", 0)) &&
        pyopencv_to_safe(pyobj_outputArr, outputArr, ArgInfo("outputArr", 1)) &&
        pyopencv_to_safe(pyobj_mode, mode, ArgInfo("mode", 0)) )
    {
        ERRWRAP2(cv::img_hash::blockMeanHash(inputArr, outputArr, mode));
        return pyopencv_from(outputArr);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("blockMeanHash");

    return NULL;
}

static PyObject* pyopencv_cv_img_hash_colorMomentHash(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::img_hash;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_inputArr = NULL;
    Mat inputArr;
    PyObject* pyobj_outputArr = NULL;
    Mat outputArr;

    const char* keywords[] = { "inputArr", "outputArr", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:colorMomentHash", (char**)keywords, &pyobj_inputArr, &pyobj_outputArr) &&
        pyopencv_to_safe(pyobj_inputArr, inputArr, ArgInfo("inputArr", 0)) &&
        pyopencv_to_safe(pyobj_outputArr, outputArr, ArgInfo("outputArr", 1)) )
    {
        ERRWRAP2(cv::img_hash::colorMomentHash(inputArr, outputArr));
        return pyopencv_from(outputArr);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_inputArr = NULL;
    UMat inputArr;
    PyObject* pyobj_outputArr = NULL;
    UMat outputArr;

    const char* keywords[] = { "inputArr", "outputArr", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:colorMomentHash", (char**)keywords, &pyobj_inputArr, &pyobj_outputArr) &&
        pyopencv_to_safe(pyobj_inputArr, inputArr, ArgInfo("inputArr", 0)) &&
        pyopencv_to_safe(pyobj_outputArr, outputArr, ArgInfo("outputArr", 1)) )
    {
        ERRWRAP2(cv::img_hash::colorMomentHash(inputArr, outputArr));
        return pyopencv_from(outputArr);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("colorMomentHash");

    return NULL;
}

static PyObject* pyopencv_cv_img_hash_marrHildrethHash(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::img_hash;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_inputArr = NULL;
    Mat inputArr;
    PyObject* pyobj_outputArr = NULL;
    Mat outputArr;
    PyObject* pyobj_alpha = NULL;
    float alpha=2.0f;
    PyObject* pyobj_scale = NULL;
    float scale=1.0f;

    const char* keywords[] = { "inputArr", "outputArr", "alpha", "scale", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:marrHildrethHash", (char**)keywords, &pyobj_inputArr, &pyobj_outputArr, &pyobj_alpha, &pyobj_scale) &&
        pyopencv_to_safe(pyobj_inputArr, inputArr, ArgInfo("inputArr", 0)) &&
        pyopencv_to_safe(pyobj_outputArr, outputArr, ArgInfo("outputArr", 1)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_scale, scale, ArgInfo("scale", 0)) )
    {
        ERRWRAP2(cv::img_hash::marrHildrethHash(inputArr, outputArr, alpha, scale));
        return pyopencv_from(outputArr);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_inputArr = NULL;
    UMat inputArr;
    PyObject* pyobj_outputArr = NULL;
    UMat outputArr;
    PyObject* pyobj_alpha = NULL;
    float alpha=2.0f;
    PyObject* pyobj_scale = NULL;
    float scale=1.0f;

    const char* keywords[] = { "inputArr", "outputArr", "alpha", "scale", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:marrHildrethHash", (char**)keywords, &pyobj_inputArr, &pyobj_outputArr, &pyobj_alpha, &pyobj_scale) &&
        pyopencv_to_safe(pyobj_inputArr, inputArr, ArgInfo("inputArr", 0)) &&
        pyopencv_to_safe(pyobj_outputArr, outputArr, ArgInfo("outputArr", 1)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_scale, scale, ArgInfo("scale", 0)) )
    {
        ERRWRAP2(cv::img_hash::marrHildrethHash(inputArr, outputArr, alpha, scale));
        return pyopencv_from(outputArr);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("marrHildrethHash");

    return NULL;
}

static PyObject* pyopencv_cv_img_hash_pHash(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::img_hash;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_inputArr = NULL;
    Mat inputArr;
    PyObject* pyobj_outputArr = NULL;
    Mat outputArr;

    const char* keywords[] = { "inputArr", "outputArr", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:pHash", (char**)keywords, &pyobj_inputArr, &pyobj_outputArr) &&
        pyopencv_to_safe(pyobj_inputArr, inputArr, ArgInfo("inputArr", 0)) &&
        pyopencv_to_safe(pyobj_outputArr, outputArr, ArgInfo("outputArr", 1)) )
    {
        ERRWRAP2(cv::img_hash::pHash(inputArr, outputArr));
        return pyopencv_from(outputArr);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_inputArr = NULL;
    UMat inputArr;
    PyObject* pyobj_outputArr = NULL;
    UMat outputArr;

    const char* keywords[] = { "inputArr", "outputArr", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:pHash", (char**)keywords, &pyobj_inputArr, &pyobj_outputArr) &&
        pyopencv_to_safe(pyobj_inputArr, inputArr, ArgInfo("inputArr", 0)) &&
        pyopencv_to_safe(pyobj_outputArr, outputArr, ArgInfo("outputArr", 1)) )
    {
        ERRWRAP2(cv::img_hash::pHash(inputArr, outputArr));
        return pyopencv_from(outputArr);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("pHash");

    return NULL;
}

static PyObject* pyopencv_cv_img_hash_radialVarianceHash(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::img_hash;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_inputArr = NULL;
    Mat inputArr;
    PyObject* pyobj_outputArr = NULL;
    Mat outputArr;
    PyObject* pyobj_sigma = NULL;
    double sigma=1;
    PyObject* pyobj_numOfAngleLine = NULL;
    int numOfAngleLine=180;

    const char* keywords[] = { "inputArr", "outputArr", "sigma", "numOfAngleLine", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:radialVarianceHash", (char**)keywords, &pyobj_inputArr, &pyobj_outputArr, &pyobj_sigma, &pyobj_numOfAngleLine) &&
        pyopencv_to_safe(pyobj_inputArr, inputArr, ArgInfo("inputArr", 0)) &&
        pyopencv_to_safe(pyobj_outputArr, outputArr, ArgInfo("outputArr", 1)) &&
        pyopencv_to_safe(pyobj_sigma, sigma, ArgInfo("sigma", 0)) &&
        pyopencv_to_safe(pyobj_numOfAngleLine, numOfAngleLine, ArgInfo("numOfAngleLine", 0)) )
    {
        ERRWRAP2(cv::img_hash::radialVarianceHash(inputArr, outputArr, sigma, numOfAngleLine));
        return pyopencv_from(outputArr);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_inputArr = NULL;
    UMat inputArr;
    PyObject* pyobj_outputArr = NULL;
    UMat outputArr;
    PyObject* pyobj_sigma = NULL;
    double sigma=1;
    PyObject* pyobj_numOfAngleLine = NULL;
    int numOfAngleLine=180;

    const char* keywords[] = { "inputArr", "outputArr", "sigma", "numOfAngleLine", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:radialVarianceHash", (char**)keywords, &pyobj_inputArr, &pyobj_outputArr, &pyobj_sigma, &pyobj_numOfAngleLine) &&
        pyopencv_to_safe(pyobj_inputArr, inputArr, ArgInfo("inputArr", 0)) &&
        pyopencv_to_safe(pyobj_outputArr, outputArr, ArgInfo("outputArr", 1)) &&
        pyopencv_to_safe(pyobj_sigma, sigma, ArgInfo("sigma", 0)) &&
        pyopencv_to_safe(pyobj_numOfAngleLine, numOfAngleLine, ArgInfo("numOfAngleLine", 0)) )
    {
        ERRWRAP2(cv::img_hash::radialVarianceHash(inputArr, outputArr, sigma, numOfAngleLine));
        return pyopencv_from(outputArr);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("radialVarianceHash");

    return NULL;
}

static PyObject* pyopencv_cv_intensity_transform_BIMEF(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::intensity_transform;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_input = NULL;
    Mat input;
    PyObject* pyobj_output = NULL;
    Mat output;
    PyObject* pyobj_mu = NULL;
    float mu=0.5f;
    PyObject* pyobj_a = NULL;
    float a=-0.3293f;
    PyObject* pyobj_b = NULL;
    float b=1.1258f;

    const char* keywords[] = { "input", "output", "mu", "a", "b", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOO:BIMEF", (char**)keywords, &pyobj_input, &pyobj_output, &pyobj_mu, &pyobj_a, &pyobj_b) &&
        pyopencv_to_safe(pyobj_input, input, ArgInfo("input", 0)) &&
        pyopencv_to_safe(pyobj_output, output, ArgInfo("output", 1)) &&
        pyopencv_to_safe(pyobj_mu, mu, ArgInfo("mu", 0)) &&
        pyopencv_to_safe(pyobj_a, a, ArgInfo("a", 0)) &&
        pyopencv_to_safe(pyobj_b, b, ArgInfo("b", 0)) )
    {
        ERRWRAP2(cv::intensity_transform::BIMEF(input, output, mu, a, b));
        return pyopencv_from(output);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_input = NULL;
    UMat input;
    PyObject* pyobj_output = NULL;
    UMat output;
    PyObject* pyobj_mu = NULL;
    float mu=0.5f;
    PyObject* pyobj_a = NULL;
    float a=-0.3293f;
    PyObject* pyobj_b = NULL;
    float b=1.1258f;

    const char* keywords[] = { "input", "output", "mu", "a", "b", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOO:BIMEF", (char**)keywords, &pyobj_input, &pyobj_output, &pyobj_mu, &pyobj_a, &pyobj_b) &&
        pyopencv_to_safe(pyobj_input, input, ArgInfo("input", 0)) &&
        pyopencv_to_safe(pyobj_output, output, ArgInfo("output", 1)) &&
        pyopencv_to_safe(pyobj_mu, mu, ArgInfo("mu", 0)) &&
        pyopencv_to_safe(pyobj_a, a, ArgInfo("a", 0)) &&
        pyopencv_to_safe(pyobj_b, b, ArgInfo("b", 0)) )
    {
        ERRWRAP2(cv::intensity_transform::BIMEF(input, output, mu, a, b));
        return pyopencv_from(output);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("BIMEF");

    return NULL;
}

static PyObject* pyopencv_cv_intensity_transform_BIMEF2(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::intensity_transform;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_input = NULL;
    Mat input;
    PyObject* pyobj_output = NULL;
    Mat output;
    PyObject* pyobj_k = NULL;
    float k=0.f;
    PyObject* pyobj_mu = NULL;
    float mu=0.f;
    PyObject* pyobj_a = NULL;
    float a=0.f;
    PyObject* pyobj_b = NULL;
    float b=0.f;

    const char* keywords[] = { "input", "k", "mu", "a", "b", "output", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|O:BIMEF2", (char**)keywords, &pyobj_input, &pyobj_k, &pyobj_mu, &pyobj_a, &pyobj_b, &pyobj_output) &&
        pyopencv_to_safe(pyobj_input, input, ArgInfo("input", 0)) &&
        pyopencv_to_safe(pyobj_output, output, ArgInfo("output", 1)) &&
        pyopencv_to_safe(pyobj_k, k, ArgInfo("k", 0)) &&
        pyopencv_to_safe(pyobj_mu, mu, ArgInfo("mu", 0)) &&
        pyopencv_to_safe(pyobj_a, a, ArgInfo("a", 0)) &&
        pyopencv_to_safe(pyobj_b, b, ArgInfo("b", 0)) )
    {
        ERRWRAP2(cv::intensity_transform::BIMEF(input, output, k, mu, a, b));
        return pyopencv_from(output);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_input = NULL;
    UMat input;
    PyObject* pyobj_output = NULL;
    UMat output;
    PyObject* pyobj_k = NULL;
    float k=0.f;
    PyObject* pyobj_mu = NULL;
    float mu=0.f;
    PyObject* pyobj_a = NULL;
    float a=0.f;
    PyObject* pyobj_b = NULL;
    float b=0.f;

    const char* keywords[] = { "input", "k", "mu", "a", "b", "output", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|O:BIMEF2", (char**)keywords, &pyobj_input, &pyobj_k, &pyobj_mu, &pyobj_a, &pyobj_b, &pyobj_output) &&
        pyopencv_to_safe(pyobj_input, input, ArgInfo("input", 0)) &&
        pyopencv_to_safe(pyobj_output, output, ArgInfo("output", 1)) &&
        pyopencv_to_safe(pyobj_k, k, ArgInfo("k", 0)) &&
        pyopencv_to_safe(pyobj_mu, mu, ArgInfo("mu", 0)) &&
        pyopencv_to_safe(pyobj_a, a, ArgInfo("a", 0)) &&
        pyopencv_to_safe(pyobj_b, b, ArgInfo("b", 0)) )
    {
        ERRWRAP2(cv::intensity_transform::BIMEF(input, output, k, mu, a, b));
        return pyopencv_from(output);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("BIMEF2");

    return NULL;
}

static PyObject* pyopencv_cv_intensity_transform_autoscaling(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::intensity_transform;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_input = NULL;
    Mat input;
    PyObject* pyobj_output = NULL;
    Mat output;

    const char* keywords[] = { "input", "output", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:autoscaling", (char**)keywords, &pyobj_input, &pyobj_output) &&
        pyopencv_to_safe(pyobj_input, input, ArgInfo("input", 0)) &&
        pyopencv_to_safe(pyobj_output, output, ArgInfo("output", 0)) )
    {
        ERRWRAP2(cv::intensity_transform::autoscaling(input, output));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_input = NULL;
    Mat input;
    PyObject* pyobj_output = NULL;
    Mat output;

    const char* keywords[] = { "input", "output", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:autoscaling", (char**)keywords, &pyobj_input, &pyobj_output) &&
        pyopencv_to_safe(pyobj_input, input, ArgInfo("input", 0)) &&
        pyopencv_to_safe(pyobj_output, output, ArgInfo("output", 0)) )
    {
        ERRWRAP2(cv::intensity_transform::autoscaling(input, output));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("autoscaling");

    return NULL;
}

static PyObject* pyopencv_cv_intensity_transform_contrastStretching(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::intensity_transform;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_input = NULL;
    Mat input;
    PyObject* pyobj_output = NULL;
    Mat output;
    PyObject* pyobj_r1 = NULL;
    int r1=0;
    PyObject* pyobj_s1 = NULL;
    int s1=0;
    PyObject* pyobj_r2 = NULL;
    int r2=0;
    PyObject* pyobj_s2 = NULL;
    int s2=0;

    const char* keywords[] = { "input", "output", "r1", "s1", "r2", "s2", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO:contrastStretching", (char**)keywords, &pyobj_input, &pyobj_output, &pyobj_r1, &pyobj_s1, &pyobj_r2, &pyobj_s2) &&
        pyopencv_to_safe(pyobj_input, input, ArgInfo("input", 0)) &&
        pyopencv_to_safe(pyobj_output, output, ArgInfo("output", 0)) &&
        pyopencv_to_safe(pyobj_r1, r1, ArgInfo("r1", 0)) &&
        pyopencv_to_safe(pyobj_s1, s1, ArgInfo("s1", 0)) &&
        pyopencv_to_safe(pyobj_r2, r2, ArgInfo("r2", 0)) &&
        pyopencv_to_safe(pyobj_s2, s2, ArgInfo("s2", 0)) )
    {
        ERRWRAP2(cv::intensity_transform::contrastStretching(input, output, r1, s1, r2, s2));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_input = NULL;
    Mat input;
    PyObject* pyobj_output = NULL;
    Mat output;
    PyObject* pyobj_r1 = NULL;
    int r1=0;
    PyObject* pyobj_s1 = NULL;
    int s1=0;
    PyObject* pyobj_r2 = NULL;
    int r2=0;
    PyObject* pyobj_s2 = NULL;
    int s2=0;

    const char* keywords[] = { "input", "output", "r1", "s1", "r2", "s2", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO:contrastStretching", (char**)keywords, &pyobj_input, &pyobj_output, &pyobj_r1, &pyobj_s1, &pyobj_r2, &pyobj_s2) &&
        pyopencv_to_safe(pyobj_input, input, ArgInfo("input", 0)) &&
        pyopencv_to_safe(pyobj_output, output, ArgInfo("output", 0)) &&
        pyopencv_to_safe(pyobj_r1, r1, ArgInfo("r1", 0)) &&
        pyopencv_to_safe(pyobj_s1, s1, ArgInfo("s1", 0)) &&
        pyopencv_to_safe(pyobj_r2, r2, ArgInfo("r2", 0)) &&
        pyopencv_to_safe(pyobj_s2, s2, ArgInfo("s2", 0)) )
    {
        ERRWRAP2(cv::intensity_transform::contrastStretching(input, output, r1, s1, r2, s2));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("contrastStretching");

    return NULL;
}

static PyObject* pyopencv_cv_intensity_transform_gammaCorrection(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::intensity_transform;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_input = NULL;
    Mat input;
    PyObject* pyobj_output = NULL;
    Mat output;
    PyObject* pyobj_gamma = NULL;
    float gamma=0.f;

    const char* keywords[] = { "input", "output", "gamma", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:gammaCorrection", (char**)keywords, &pyobj_input, &pyobj_output, &pyobj_gamma) &&
        pyopencv_to_safe(pyobj_input, input, ArgInfo("input", 0)) &&
        pyopencv_to_safe(pyobj_output, output, ArgInfo("output", 0)) &&
        pyopencv_to_safe(pyobj_gamma, gamma, ArgInfo("gamma", 0)) )
    {
        ERRWRAP2(cv::intensity_transform::gammaCorrection(input, output, gamma));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_input = NULL;
    Mat input;
    PyObject* pyobj_output = NULL;
    Mat output;
    PyObject* pyobj_gamma = NULL;
    float gamma=0.f;

    const char* keywords[] = { "input", "output", "gamma", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:gammaCorrection", (char**)keywords, &pyobj_input, &pyobj_output, &pyobj_gamma) &&
        pyopencv_to_safe(pyobj_input, input, ArgInfo("input", 0)) &&
        pyopencv_to_safe(pyobj_output, output, ArgInfo("output", 0)) &&
        pyopencv_to_safe(pyobj_gamma, gamma, ArgInfo("gamma", 0)) )
    {
        ERRWRAP2(cv::intensity_transform::gammaCorrection(input, output, gamma));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("gammaCorrection");

    return NULL;
}

static PyObject* pyopencv_cv_intensity_transform_logTransform(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::intensity_transform;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_input = NULL;
    Mat input;
    PyObject* pyobj_output = NULL;
    Mat output;

    const char* keywords[] = { "input", "output", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:logTransform", (char**)keywords, &pyobj_input, &pyobj_output) &&
        pyopencv_to_safe(pyobj_input, input, ArgInfo("input", 0)) &&
        pyopencv_to_safe(pyobj_output, output, ArgInfo("output", 0)) )
    {
        ERRWRAP2(cv::intensity_transform::logTransform(input, output));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_input = NULL;
    Mat input;
    PyObject* pyobj_output = NULL;
    Mat output;

    const char* keywords[] = { "input", "output", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:logTransform", (char**)keywords, &pyobj_input, &pyobj_output) &&
        pyopencv_to_safe(pyobj_input, input, ArgInfo("input", 0)) &&
        pyopencv_to_safe(pyobj_output, output, ArgInfo("output", 0)) )
    {
        ERRWRAP2(cv::intensity_transform::logTransform(input, output));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("logTransform");

    return NULL;
}

static PyObject* pyopencv_cv_ipp_getIppVersion(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ipp;

    String retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::ipp::getIppVersion());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ipp_setUseIPP(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ipp;

    PyObject* pyobj_flag = NULL;
    bool flag=0;

    const char* keywords[] = { "flag", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:setUseIPP", (char**)keywords, &pyobj_flag) &&
        pyopencv_to_safe(pyobj_flag, flag, ArgInfo("flag", 0)) )
    {
        ERRWRAP2(cv::ipp::setUseIPP(flag));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ipp_setUseIPP_NotExact(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ipp;

    PyObject* pyobj_flag = NULL;
    bool flag=0;

    const char* keywords[] = { "flag", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:setUseIPP_NotExact", (char**)keywords, &pyobj_flag) &&
        pyopencv_to_safe(pyobj_flag, flag, ArgInfo("flag", 0)) )
    {
        ERRWRAP2(cv::ipp::setUseIPP_NotExact(flag));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ipp_useIPP(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ipp;

    bool retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::ipp::useIPP());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ipp_useIPP_NotExact(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ipp;

    bool retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::ipp::useIPP_NotExact());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_kinfu_KinFu_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::kinfu;

    PyObject* pyobj__params = NULL;
    Ptr<Params> _params;
    Ptr<KinFu> retval;

    const char* keywords[] = { "_params", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:KinFu_create", (char**)keywords, &pyobj__params) &&
        pyopencv_to_safe(pyobj__params, _params, ArgInfo("_params", 0)) )
    {
        ERRWRAP2(retval = cv::kinfu::KinFu::create(_params));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_kinfu_Params_coarseParams(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::kinfu;

    Ptr<Params> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::kinfu::Params::coarseParams());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_kinfu_Params_defaultParams(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::kinfu;

    Ptr<Params> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::kinfu::Params::defaultParams());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_kinfu_Params_hashTSDFParams(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::kinfu;

    PyObject* pyobj_isCoarse = NULL;
    bool isCoarse=0;
    Ptr<Params> retval;

    const char* keywords[] = { "isCoarse", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:Params_hashTSDFParams", (char**)keywords, &pyobj_isCoarse) &&
        pyopencv_to_safe(pyobj_isCoarse, isCoarse, ArgInfo("isCoarse", 0)) )
    {
        ERRWRAP2(retval = cv::kinfu::Params::hashTSDFParams(isCoarse));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_kinfu_VolumeParams_coarseParams(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::kinfu;

    PyObject* pyobj__volumeType = NULL;
    VolumeType _volumeType=static_cast<VolumeType>(0);
    Ptr<VolumeParams> retval;

    const char* keywords[] = { "_volumeType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:VolumeParams_coarseParams", (char**)keywords, &pyobj__volumeType) &&
        pyopencv_to_safe(pyobj__volumeType, _volumeType, ArgInfo("_volumeType", 0)) )
    {
        ERRWRAP2(retval = cv::kinfu::VolumeParams::coarseParams(_volumeType));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_kinfu_VolumeParams_defaultParams(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::kinfu;

    PyObject* pyobj__volumeType = NULL;
    VolumeType _volumeType=static_cast<VolumeType>(0);
    Ptr<VolumeParams> retval;

    const char* keywords[] = { "_volumeType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:VolumeParams_defaultParams", (char**)keywords, &pyobj__volumeType) &&
        pyopencv_to_safe(pyobj__volumeType, _volumeType, ArgInfo("_volumeType", 0)) )
    {
        ERRWRAP2(retval = cv::kinfu::VolumeParams::defaultParams(_volumeType));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_kinfu_makeVolume(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::kinfu;

    PyObject* pyobj__volumeType = NULL;
    VolumeType _volumeType=static_cast<VolumeType>(0);
    PyObject* pyobj__voxelSize = NULL;
    float _voxelSize=0.f;
    PyObject* pyobj__pose = NULL;
    Matx44f _pose;
    PyObject* pyobj__raycastStepFactor = NULL;
    float _raycastStepFactor=0.f;
    PyObject* pyobj__truncDist = NULL;
    float _truncDist=0.f;
    PyObject* pyobj__maxWeight = NULL;
    int _maxWeight=0;
    PyObject* pyobj__truncateThreshold = NULL;
    float _truncateThreshold=0.f;
    PyObject* pyobj__resolution = NULL;
    Vec3i _resolution;
    Ptr<Volume> retval;

    const char* keywords[] = { "_volumeType", "_voxelSize", "_pose", "_raycastStepFactor", "_truncDist", "_maxWeight", "_truncateThreshold", "_resolution", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOOO:makeVolume", (char**)keywords, &pyobj__volumeType, &pyobj__voxelSize, &pyobj__pose, &pyobj__raycastStepFactor, &pyobj__truncDist, &pyobj__maxWeight, &pyobj__truncateThreshold, &pyobj__resolution) &&
        pyopencv_to_safe(pyobj__volumeType, _volumeType, ArgInfo("_volumeType", 0)) &&
        pyopencv_to_safe(pyobj__voxelSize, _voxelSize, ArgInfo("_voxelSize", 0)) &&
        pyopencv_to_safe(pyobj__pose, _pose, ArgInfo("_pose", 0)) &&
        pyopencv_to_safe(pyobj__raycastStepFactor, _raycastStepFactor, ArgInfo("_raycastStepFactor", 0)) &&
        pyopencv_to_safe(pyobj__truncDist, _truncDist, ArgInfo("_truncDist", 0)) &&
        pyopencv_to_safe(pyobj__maxWeight, _maxWeight, ArgInfo("_maxWeight", 0)) &&
        pyopencv_to_safe(pyobj__truncateThreshold, _truncateThreshold, ArgInfo("_truncateThreshold", 0)) &&
        pyopencv_to_safe(pyobj__resolution, _resolution, ArgInfo("_resolution", 0)) )
    {
        ERRWRAP2(retval = cv::kinfu::makeVolume(_volumeType, _voxelSize, _pose, _raycastStepFactor, _truncDist, _maxWeight, _truncateThreshold, _resolution));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_large_kinfu_LargeKinfu_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::large_kinfu;

    PyObject* pyobj__params = NULL;
    Ptr<Params> _params;
    Ptr<LargeKinfu> retval;

    const char* keywords[] = { "_params", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:LargeKinfu_create", (char**)keywords, &pyobj__params) &&
        pyopencv_to_safe(pyobj__params, _params, ArgInfo("_params", 0)) )
    {
        ERRWRAP2(retval = cv::large_kinfu::LargeKinfu::create(_params));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_large_kinfu_Params_coarseParams(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::large_kinfu;

    Ptr<Params> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::large_kinfu::Params::coarseParams());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_large_kinfu_Params_defaultParams(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::large_kinfu;

    Ptr<Params> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::large_kinfu::Params::defaultParams());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_large_kinfu_Params_hashTSDFParams(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::large_kinfu;

    PyObject* pyobj_isCoarse = NULL;
    bool isCoarse=0;
    Ptr<Params> retval;

    const char* keywords[] = { "isCoarse", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:Params_hashTSDFParams", (char**)keywords, &pyobj_isCoarse) &&
        pyopencv_to_safe(pyobj_isCoarse, isCoarse, ArgInfo("isCoarse", 0)) )
    {
        ERRWRAP2(retval = cv::large_kinfu::Params::hashTSDFParams(isCoarse));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_legacy_MultiTracker_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::legacy;

    Ptr<MultiTracker> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::legacy::MultiTracker::create());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_legacy_TrackerBoosting_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::legacy;

    Ptr<legacy::TrackerBoosting> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::legacy::TrackerBoosting::create());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_legacy_TrackerCSRT_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::legacy;

    Ptr<legacy::TrackerCSRT> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::legacy::TrackerCSRT::create());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_legacy_TrackerKCF_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::legacy;

    Ptr<legacy::TrackerKCF> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::legacy::TrackerKCF::create());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_legacy_TrackerMIL_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::legacy;

    Ptr<legacy::TrackerMIL> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::legacy::TrackerMIL::create());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_legacy_TrackerMOSSE_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::legacy;

    Ptr<legacy::TrackerMOSSE> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::legacy::TrackerMOSSE::create());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_legacy_TrackerMedianFlow_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::legacy;

    Ptr<legacy::TrackerMedianFlow> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::legacy::TrackerMedianFlow::create());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_legacy_TrackerTLD_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::legacy;

    Ptr<legacy::TrackerTLD> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::legacy::TrackerTLD::create());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_legacy_upgradeTrackingAPI(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::legacy;

    PyObject* pyobj_legacy_tracker = NULL;
    Ptr<legacy::Tracker> legacy_tracker;
    Ptr<cv::Tracker> retval;

    const char* keywords[] = { "legacy_tracker", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:upgradeTrackingAPI", (char**)keywords, &pyobj_legacy_tracker) &&
        pyopencv_to_safe(pyobj_legacy_tracker, legacy_tracker, ArgInfo("legacy_tracker", 0)) )
    {
        ERRWRAP2(retval = cv::legacy::upgradeTrackingAPI(legacy_tracker));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_line_descriptor_BinaryDescriptor_createBinaryDescriptor(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::line_descriptor;

    Ptr<BinaryDescriptor> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::line_descriptor::BinaryDescriptor::createBinaryDescriptor());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_line_descriptor_LSDDetector_createLSDDetector(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::line_descriptor;

    Ptr<LSDDetector> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::line_descriptor::LSDDetector::createLSDDetector());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_line_descriptor_LSDDetector_createLSDDetectorWithParams(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::line_descriptor;

    PyObject* pyobj_params = NULL;
    LSDParam params;
    Ptr<LSDDetector> retval;

    const char* keywords[] = { "params", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:LSDDetector_createLSDDetectorWithParams", (char**)keywords, &pyobj_params) &&
        pyopencv_to_safe(pyobj_params, params, ArgInfo("params", 0)) )
    {
        ERRWRAP2(retval = cv::line_descriptor::LSDDetector::createLSDDetector(params));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_line_descriptor_drawKeylines(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::line_descriptor;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_keylines = NULL;
    vector_KeyLine keylines;
    PyObject* pyobj_outImage = NULL;
    Mat outImage;
    PyObject* pyobj_color = NULL;
    Scalar color=Scalar::all( -1 );
    PyObject* pyobj_flags = NULL;
    int flags=DrawLinesMatchesFlags::DEFAULT;

    const char* keywords[] = { "image", "keylines", "outImage", "color", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:drawKeylines", (char**)keywords, &pyobj_image, &pyobj_keylines, &pyobj_outImage, &pyobj_color, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_keylines, keylines, ArgInfo("keylines", 0)) &&
        pyopencv_to_safe(pyobj_outImage, outImage, ArgInfo("outImage", 1)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::line_descriptor::drawKeylines(image, keylines, outImage, color, flags));
        return pyopencv_from(outImage);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_keylines = NULL;
    vector_KeyLine keylines;
    PyObject* pyobj_outImage = NULL;
    Mat outImage;
    PyObject* pyobj_color = NULL;
    Scalar color=Scalar::all( -1 );
    PyObject* pyobj_flags = NULL;
    int flags=DrawLinesMatchesFlags::DEFAULT;

    const char* keywords[] = { "image", "keylines", "outImage", "color", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:drawKeylines", (char**)keywords, &pyobj_image, &pyobj_keylines, &pyobj_outImage, &pyobj_color, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_keylines, keylines, ArgInfo("keylines", 0)) &&
        pyopencv_to_safe(pyobj_outImage, outImage, ArgInfo("outImage", 1)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::line_descriptor::drawKeylines(image, keylines, outImage, color, flags));
        return pyopencv_from(outImage);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("drawKeylines");

    return NULL;
}

static PyObject* pyopencv_cv_line_descriptor_drawLineMatches(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::line_descriptor;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_img1 = NULL;
    Mat img1;
    PyObject* pyobj_keylines1 = NULL;
    vector_KeyLine keylines1;
    PyObject* pyobj_img2 = NULL;
    Mat img2;
    PyObject* pyobj_keylines2 = NULL;
    vector_KeyLine keylines2;
    PyObject* pyobj_matches1to2 = NULL;
    vector_DMatch matches1to2;
    PyObject* pyobj_outImg = NULL;
    Mat outImg;
    PyObject* pyobj_matchColor = NULL;
    Scalar matchColor=Scalar::all( -1 );
    PyObject* pyobj_singleLineColor = NULL;
    Scalar singleLineColor=Scalar::all( -1 );
    PyObject* pyobj_matchesMask = NULL;
    vector_char matchesMask=std::vector<char>();
    PyObject* pyobj_flags = NULL;
    int flags=DrawLinesMatchesFlags::DEFAULT;

    const char* keywords[] = { "img1", "keylines1", "img2", "keylines2", "matches1to2", "outImg", "matchColor", "singleLineColor", "matchesMask", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OOOOO:drawLineMatches", (char**)keywords, &pyobj_img1, &pyobj_keylines1, &pyobj_img2, &pyobj_keylines2, &pyobj_matches1to2, &pyobj_outImg, &pyobj_matchColor, &pyobj_singleLineColor, &pyobj_matchesMask, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_img1, img1, ArgInfo("img1", 0)) &&
        pyopencv_to_safe(pyobj_keylines1, keylines1, ArgInfo("keylines1", 0)) &&
        pyopencv_to_safe(pyobj_img2, img2, ArgInfo("img2", 0)) &&
        pyopencv_to_safe(pyobj_keylines2, keylines2, ArgInfo("keylines2", 0)) &&
        pyopencv_to_safe(pyobj_matches1to2, matches1to2, ArgInfo("matches1to2", 0)) &&
        pyopencv_to_safe(pyobj_outImg, outImg, ArgInfo("outImg", 1)) &&
        pyopencv_to_safe(pyobj_matchColor, matchColor, ArgInfo("matchColor", 0)) &&
        pyopencv_to_safe(pyobj_singleLineColor, singleLineColor, ArgInfo("singleLineColor", 0)) &&
        pyopencv_to_safe(pyobj_matchesMask, matchesMask, ArgInfo("matchesMask", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::line_descriptor::drawLineMatches(img1, keylines1, img2, keylines2, matches1to2, outImg, matchColor, singleLineColor, matchesMask, flags));
        return pyopencv_from(outImg);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img1 = NULL;
    Mat img1;
    PyObject* pyobj_keylines1 = NULL;
    vector_KeyLine keylines1;
    PyObject* pyobj_img2 = NULL;
    Mat img2;
    PyObject* pyobj_keylines2 = NULL;
    vector_KeyLine keylines2;
    PyObject* pyobj_matches1to2 = NULL;
    vector_DMatch matches1to2;
    PyObject* pyobj_outImg = NULL;
    Mat outImg;
    PyObject* pyobj_matchColor = NULL;
    Scalar matchColor=Scalar::all( -1 );
    PyObject* pyobj_singleLineColor = NULL;
    Scalar singleLineColor=Scalar::all( -1 );
    PyObject* pyobj_matchesMask = NULL;
    vector_char matchesMask=std::vector<char>();
    PyObject* pyobj_flags = NULL;
    int flags=DrawLinesMatchesFlags::DEFAULT;

    const char* keywords[] = { "img1", "keylines1", "img2", "keylines2", "matches1to2", "outImg", "matchColor", "singleLineColor", "matchesMask", "flags", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OOOOO:drawLineMatches", (char**)keywords, &pyobj_img1, &pyobj_keylines1, &pyobj_img2, &pyobj_keylines2, &pyobj_matches1to2, &pyobj_outImg, &pyobj_matchColor, &pyobj_singleLineColor, &pyobj_matchesMask, &pyobj_flags) &&
        pyopencv_to_safe(pyobj_img1, img1, ArgInfo("img1", 0)) &&
        pyopencv_to_safe(pyobj_keylines1, keylines1, ArgInfo("keylines1", 0)) &&
        pyopencv_to_safe(pyobj_img2, img2, ArgInfo("img2", 0)) &&
        pyopencv_to_safe(pyobj_keylines2, keylines2, ArgInfo("keylines2", 0)) &&
        pyopencv_to_safe(pyobj_matches1to2, matches1to2, ArgInfo("matches1to2", 0)) &&
        pyopencv_to_safe(pyobj_outImg, outImg, ArgInfo("outImg", 1)) &&
        pyopencv_to_safe(pyobj_matchColor, matchColor, ArgInfo("matchColor", 0)) &&
        pyopencv_to_safe(pyobj_singleLineColor, singleLineColor, ArgInfo("singleLineColor", 0)) &&
        pyopencv_to_safe(pyobj_matchesMask, matchesMask, ArgInfo("matchesMask", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::line_descriptor::drawLineMatches(img1, keylines1, img2, keylines2, matches1to2, outImg, matchColor, singleLineColor, matchesMask, flags));
        return pyopencv_from(outImg);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("drawLineMatches");

    return NULL;
}

static PyObject* pyopencv_cv_linemod_ColorGradient_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::linemod;

    PyObject* pyobj_weak_threshold = NULL;
    float weak_threshold=0.f;
    PyObject* pyobj_num_features = NULL;
    size_t num_features=0;
    PyObject* pyobj_strong_threshold = NULL;
    float strong_threshold=0.f;
    Ptr<ColorGradient> retval;

    const char* keywords[] = { "weak_threshold", "num_features", "strong_threshold", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:ColorGradient_create", (char**)keywords, &pyobj_weak_threshold, &pyobj_num_features, &pyobj_strong_threshold) &&
        pyopencv_to_safe(pyobj_weak_threshold, weak_threshold, ArgInfo("weak_threshold", 0)) &&
        pyopencv_to_safe(pyobj_num_features, num_features, ArgInfo("num_features", 0)) &&
        pyopencv_to_safe(pyobj_strong_threshold, strong_threshold, ArgInfo("strong_threshold", 0)) )
    {
        ERRWRAP2(retval = cv::linemod::ColorGradient::create(weak_threshold, num_features, strong_threshold));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_linemod_DepthNormal_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::linemod;

    PyObject* pyobj_distance_threshold = NULL;
    int distance_threshold=0;
    PyObject* pyobj_difference_threshold = NULL;
    int difference_threshold=0;
    PyObject* pyobj_num_features = NULL;
    size_t num_features=0;
    PyObject* pyobj_extract_threshold = NULL;
    int extract_threshold=0;
    Ptr<DepthNormal> retval;

    const char* keywords[] = { "distance_threshold", "difference_threshold", "num_features", "extract_threshold", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO:DepthNormal_create", (char**)keywords, &pyobj_distance_threshold, &pyobj_difference_threshold, &pyobj_num_features, &pyobj_extract_threshold) &&
        pyopencv_to_safe(pyobj_distance_threshold, distance_threshold, ArgInfo("distance_threshold", 0)) &&
        pyopencv_to_safe(pyobj_difference_threshold, difference_threshold, ArgInfo("difference_threshold", 0)) &&
        pyopencv_to_safe(pyobj_num_features, num_features, ArgInfo("num_features", 0)) &&
        pyopencv_to_safe(pyobj_extract_threshold, extract_threshold, ArgInfo("extract_threshold", 0)) )
    {
        ERRWRAP2(retval = cv::linemod::DepthNormal::create(distance_threshold, difference_threshold, num_features, extract_threshold));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_linemod_Modality_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::linemod;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_modality_type = NULL;
    String modality_type;
    Ptr<Modality> retval;

    const char* keywords[] = { "modality_type", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:Modality_create", (char**)keywords, &pyobj_modality_type) &&
        pyopencv_to_safe(pyobj_modality_type, modality_type, ArgInfo("modality_type", 0)) )
    {
        ERRWRAP2(retval = cv::linemod::Modality::create(modality_type));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_fn = NULL;
    FileNode fn;
    Ptr<Modality> retval;

    const char* keywords[] = { "fn", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:Modality_create", (char**)keywords, &pyobj_fn) &&
        pyopencv_to_safe(pyobj_fn, fn, ArgInfo("fn", 0)) )
    {
        ERRWRAP2(retval = cv::linemod::Modality::create(fn));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("Modality_create");

    return NULL;
}

static PyObject* pyopencv_cv_linemod_colormap(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::linemod;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_quantized = NULL;
    Mat quantized;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "quantized", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:colormap", (char**)keywords, &pyobj_quantized, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_quantized, quantized, ArgInfo("quantized", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::linemod::colormap(quantized, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_quantized = NULL;
    Mat quantized;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "quantized", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:colormap", (char**)keywords, &pyobj_quantized, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_quantized, quantized, ArgInfo("quantized", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::linemod::colormap(quantized, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("colormap");

    return NULL;
}

static PyObject* pyopencv_cv_linemod_drawFeatures(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::linemod;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_templates = NULL;
    vector_Template templates;
    PyObject* pyobj_tl = NULL;
    Point2i tl;
    PyObject* pyobj_size = NULL;
    int size=10;

    const char* keywords[] = { "img", "templates", "tl", "size", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:drawFeatures", (char**)keywords, &pyobj_img, &pyobj_templates, &pyobj_tl, &pyobj_size) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_templates, templates, ArgInfo("templates", 0)) &&
        pyopencv_to_safe(pyobj_tl, tl, ArgInfo("tl", 0)) &&
        pyopencv_to_safe(pyobj_size, size, ArgInfo("size", 0)) )
    {
        ERRWRAP2(cv::linemod::drawFeatures(img, templates, tl, size));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_templates = NULL;
    vector_Template templates;
    PyObject* pyobj_tl = NULL;
    Point2i tl;
    PyObject* pyobj_size = NULL;
    int size=10;

    const char* keywords[] = { "img", "templates", "tl", "size", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:drawFeatures", (char**)keywords, &pyobj_img, &pyobj_templates, &pyobj_tl, &pyobj_size) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_templates, templates, ArgInfo("templates", 0)) &&
        pyopencv_to_safe(pyobj_tl, tl, ArgInfo("tl", 0)) &&
        pyopencv_to_safe(pyobj_size, size, ArgInfo("size", 0)) )
    {
        ERRWRAP2(cv::linemod::drawFeatures(img, templates, tl, size));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("drawFeatures");

    return NULL;
}

static PyObject* pyopencv_cv_linemod_getDefaultLINE(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::linemod;

    Ptr<linemod::Detector> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::linemod::getDefaultLINE());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_linemod_getDefaultLINEMOD(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::linemod;

    Ptr<linemod::Detector> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::linemod::getDefaultLINEMOD());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ANN_MLP_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ml;

    Ptr<ANN_MLP> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::ml::ANN_MLP::create());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ANN_MLP_load(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ml;

    PyObject* pyobj_filepath = NULL;
    String filepath;
    Ptr<ANN_MLP> retval;

    const char* keywords[] = { "filepath", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:ANN_MLP_load", (char**)keywords, &pyobj_filepath) &&
        pyopencv_to_safe(pyobj_filepath, filepath, ArgInfo("filepath", 0)) )
    {
        ERRWRAP2(retval = cv::ml::ANN_MLP::load(filepath));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_Boost_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ml;

    Ptr<Boost> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::ml::Boost::create());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_Boost_load(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ml;

    PyObject* pyobj_filepath = NULL;
    String filepath;
    PyObject* pyobj_nodeName = NULL;
    String nodeName;
    Ptr<Boost> retval;

    const char* keywords[] = { "filepath", "nodeName", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:Boost_load", (char**)keywords, &pyobj_filepath, &pyobj_nodeName) &&
        pyopencv_to_safe(pyobj_filepath, filepath, ArgInfo("filepath", 0)) &&
        pyopencv_to_safe(pyobj_nodeName, nodeName, ArgInfo("nodeName", 0)) )
    {
        ERRWRAP2(retval = cv::ml::Boost::load(filepath, nodeName));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_DTrees_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ml;

    Ptr<DTrees> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::ml::DTrees::create());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_DTrees_load(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ml;

    PyObject* pyobj_filepath = NULL;
    String filepath;
    PyObject* pyobj_nodeName = NULL;
    String nodeName;
    Ptr<DTrees> retval;

    const char* keywords[] = { "filepath", "nodeName", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:DTrees_load", (char**)keywords, &pyobj_filepath, &pyobj_nodeName) &&
        pyopencv_to_safe(pyobj_filepath, filepath, ArgInfo("filepath", 0)) &&
        pyopencv_to_safe(pyobj_nodeName, nodeName, ArgInfo("nodeName", 0)) )
    {
        ERRWRAP2(retval = cv::ml::DTrees::load(filepath, nodeName));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_EM_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ml;

    Ptr<EM> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::ml::EM::create());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_EM_load(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ml;

    PyObject* pyobj_filepath = NULL;
    String filepath;
    PyObject* pyobj_nodeName = NULL;
    String nodeName;
    Ptr<EM> retval;

    const char* keywords[] = { "filepath", "nodeName", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:EM_load", (char**)keywords, &pyobj_filepath, &pyobj_nodeName) &&
        pyopencv_to_safe(pyobj_filepath, filepath, ArgInfo("filepath", 0)) &&
        pyopencv_to_safe(pyobj_nodeName, nodeName, ArgInfo("nodeName", 0)) )
    {
        ERRWRAP2(retval = cv::ml::EM::load(filepath, nodeName));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_KNearest_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ml;

    Ptr<KNearest> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::ml::KNearest::create());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_KNearest_load(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ml;

    PyObject* pyobj_filepath = NULL;
    String filepath;
    Ptr<KNearest> retval;

    const char* keywords[] = { "filepath", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:KNearest_load", (char**)keywords, &pyobj_filepath) &&
        pyopencv_to_safe(pyobj_filepath, filepath, ArgInfo("filepath", 0)) )
    {
        ERRWRAP2(retval = cv::ml::KNearest::load(filepath));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_LogisticRegression_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ml;

    Ptr<LogisticRegression> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::ml::LogisticRegression::create());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_LogisticRegression_load(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ml;

    PyObject* pyobj_filepath = NULL;
    String filepath;
    PyObject* pyobj_nodeName = NULL;
    String nodeName;
    Ptr<LogisticRegression> retval;

    const char* keywords[] = { "filepath", "nodeName", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:LogisticRegression_load", (char**)keywords, &pyobj_filepath, &pyobj_nodeName) &&
        pyopencv_to_safe(pyobj_filepath, filepath, ArgInfo("filepath", 0)) &&
        pyopencv_to_safe(pyobj_nodeName, nodeName, ArgInfo("nodeName", 0)) )
    {
        ERRWRAP2(retval = cv::ml::LogisticRegression::load(filepath, nodeName));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_NormalBayesClassifier_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ml;

    Ptr<NormalBayesClassifier> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::ml::NormalBayesClassifier::create());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_NormalBayesClassifier_load(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ml;

    PyObject* pyobj_filepath = NULL;
    String filepath;
    PyObject* pyobj_nodeName = NULL;
    String nodeName;
    Ptr<NormalBayesClassifier> retval;

    const char* keywords[] = { "filepath", "nodeName", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:NormalBayesClassifier_load", (char**)keywords, &pyobj_filepath, &pyobj_nodeName) &&
        pyopencv_to_safe(pyobj_filepath, filepath, ArgInfo("filepath", 0)) &&
        pyopencv_to_safe(pyobj_nodeName, nodeName, ArgInfo("nodeName", 0)) )
    {
        ERRWRAP2(retval = cv::ml::NormalBayesClassifier::load(filepath, nodeName));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_ParamGrid_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ml;

    PyObject* pyobj_minVal = NULL;
    double minVal=0.;
    PyObject* pyobj_maxVal = NULL;
    double maxVal=0.;
    PyObject* pyobj_logstep = NULL;
    double logstep=1.;
    Ptr<ParamGrid> retval;

    const char* keywords[] = { "minVal", "maxVal", "logstep", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOO:ParamGrid_create", (char**)keywords, &pyobj_minVal, &pyobj_maxVal, &pyobj_logstep) &&
        pyopencv_to_safe(pyobj_minVal, minVal, ArgInfo("minVal", 0)) &&
        pyopencv_to_safe(pyobj_maxVal, maxVal, ArgInfo("maxVal", 0)) &&
        pyopencv_to_safe(pyobj_logstep, logstep, ArgInfo("logstep", 0)) )
    {
        ERRWRAP2(retval = cv::ml::ParamGrid::create(minVal, maxVal, logstep));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_RTrees_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ml;

    Ptr<RTrees> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::ml::RTrees::create());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_RTrees_load(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ml;

    PyObject* pyobj_filepath = NULL;
    String filepath;
    PyObject* pyobj_nodeName = NULL;
    String nodeName;
    Ptr<RTrees> retval;

    const char* keywords[] = { "filepath", "nodeName", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:RTrees_load", (char**)keywords, &pyobj_filepath, &pyobj_nodeName) &&
        pyopencv_to_safe(pyobj_filepath, filepath, ArgInfo("filepath", 0)) &&
        pyopencv_to_safe(pyobj_nodeName, nodeName, ArgInfo("nodeName", 0)) )
    {
        ERRWRAP2(retval = cv::ml::RTrees::load(filepath, nodeName));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_SVMSGD_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ml;

    Ptr<SVMSGD> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::ml::SVMSGD::create());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_SVMSGD_load(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ml;

    PyObject* pyobj_filepath = NULL;
    String filepath;
    PyObject* pyobj_nodeName = NULL;
    String nodeName;
    Ptr<SVMSGD> retval;

    const char* keywords[] = { "filepath", "nodeName", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:SVMSGD_load", (char**)keywords, &pyobj_filepath, &pyobj_nodeName) &&
        pyopencv_to_safe(pyobj_filepath, filepath, ArgInfo("filepath", 0)) &&
        pyopencv_to_safe(pyobj_nodeName, nodeName, ArgInfo("nodeName", 0)) )
    {
        ERRWRAP2(retval = cv::ml::SVMSGD::load(filepath, nodeName));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_SVM_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ml;

    Ptr<SVM> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::ml::SVM::create());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_SVM_getDefaultGridPtr(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ml;

    PyObject* pyobj_param_id = NULL;
    int param_id=0;
    Ptr<ParamGrid> retval;

    const char* keywords[] = { "param_id", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:SVM_getDefaultGridPtr", (char**)keywords, &pyobj_param_id) &&
        pyopencv_to_safe(pyobj_param_id, param_id, ArgInfo("param_id", 0)) )
    {
        ERRWRAP2(retval = cv::ml::SVM::getDefaultGridPtr(param_id));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_SVM_load(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ml;

    PyObject* pyobj_filepath = NULL;
    String filepath;
    Ptr<SVM> retval;

    const char* keywords[] = { "filepath", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:SVM_load", (char**)keywords, &pyobj_filepath) &&
        pyopencv_to_safe(pyobj_filepath, filepath, ArgInfo("filepath", 0)) )
    {
        ERRWRAP2(retval = cv::ml::SVM::load(filepath));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ml_TrainData_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ml;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_samples = NULL;
    Mat samples;
    PyObject* pyobj_layout = NULL;
    int layout=0;
    PyObject* pyobj_responses = NULL;
    Mat responses;
    PyObject* pyobj_varIdx = NULL;
    Mat varIdx;
    PyObject* pyobj_sampleIdx = NULL;
    Mat sampleIdx;
    PyObject* pyobj_sampleWeights = NULL;
    Mat sampleWeights;
    PyObject* pyobj_varType = NULL;
    Mat varType;
    Ptr<TrainData> retval;

    const char* keywords[] = { "samples", "layout", "responses", "varIdx", "sampleIdx", "sampleWeights", "varType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOO:TrainData_create", (char**)keywords, &pyobj_samples, &pyobj_layout, &pyobj_responses, &pyobj_varIdx, &pyobj_sampleIdx, &pyobj_sampleWeights, &pyobj_varType) &&
        pyopencv_to_safe(pyobj_samples, samples, ArgInfo("samples", 0)) &&
        pyopencv_to_safe(pyobj_layout, layout, ArgInfo("layout", 0)) &&
        pyopencv_to_safe(pyobj_responses, responses, ArgInfo("responses", 0)) &&
        pyopencv_to_safe(pyobj_varIdx, varIdx, ArgInfo("varIdx", 0)) &&
        pyopencv_to_safe(pyobj_sampleIdx, sampleIdx, ArgInfo("sampleIdx", 0)) &&
        pyopencv_to_safe(pyobj_sampleWeights, sampleWeights, ArgInfo("sampleWeights", 0)) &&
        pyopencv_to_safe(pyobj_varType, varType, ArgInfo("varType", 0)) )
    {
        ERRWRAP2(retval = cv::ml::TrainData::create(samples, layout, responses, varIdx, sampleIdx, sampleWeights, varType));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_samples = NULL;
    UMat samples;
    PyObject* pyobj_layout = NULL;
    int layout=0;
    PyObject* pyobj_responses = NULL;
    UMat responses;
    PyObject* pyobj_varIdx = NULL;
    UMat varIdx;
    PyObject* pyobj_sampleIdx = NULL;
    UMat sampleIdx;
    PyObject* pyobj_sampleWeights = NULL;
    UMat sampleWeights;
    PyObject* pyobj_varType = NULL;
    UMat varType;
    Ptr<TrainData> retval;

    const char* keywords[] = { "samples", "layout", "responses", "varIdx", "sampleIdx", "sampleWeights", "varType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOO:TrainData_create", (char**)keywords, &pyobj_samples, &pyobj_layout, &pyobj_responses, &pyobj_varIdx, &pyobj_sampleIdx, &pyobj_sampleWeights, &pyobj_varType) &&
        pyopencv_to_safe(pyobj_samples, samples, ArgInfo("samples", 0)) &&
        pyopencv_to_safe(pyobj_layout, layout, ArgInfo("layout", 0)) &&
        pyopencv_to_safe(pyobj_responses, responses, ArgInfo("responses", 0)) &&
        pyopencv_to_safe(pyobj_varIdx, varIdx, ArgInfo("varIdx", 0)) &&
        pyopencv_to_safe(pyobj_sampleIdx, sampleIdx, ArgInfo("sampleIdx", 0)) &&
        pyopencv_to_safe(pyobj_sampleWeights, sampleWeights, ArgInfo("sampleWeights", 0)) &&
        pyopencv_to_safe(pyobj_varType, varType, ArgInfo("varType", 0)) )
    {
        ERRWRAP2(retval = cv::ml::TrainData::create(samples, layout, responses, varIdx, sampleIdx, sampleWeights, varType));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("TrainData_create");

    return NULL;
}

static PyObject* pyopencv_cv_ml_TrainData_getSubMatrix(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ml;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_matrix = NULL;
    Mat matrix;
    PyObject* pyobj_idx = NULL;
    Mat idx;
    PyObject* pyobj_layout = NULL;
    int layout=0;
    Mat retval;

    const char* keywords[] = { "matrix", "idx", "layout", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:TrainData_getSubMatrix", (char**)keywords, &pyobj_matrix, &pyobj_idx, &pyobj_layout) &&
        pyopencv_to_safe(pyobj_matrix, matrix, ArgInfo("matrix", 0)) &&
        pyopencv_to_safe(pyobj_idx, idx, ArgInfo("idx", 0)) &&
        pyopencv_to_safe(pyobj_layout, layout, ArgInfo("layout", 0)) )
    {
        ERRWRAP2(retval = cv::ml::TrainData::getSubMatrix(matrix, idx, layout));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_matrix = NULL;
    Mat matrix;
    PyObject* pyobj_idx = NULL;
    Mat idx;
    PyObject* pyobj_layout = NULL;
    int layout=0;
    Mat retval;

    const char* keywords[] = { "matrix", "idx", "layout", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:TrainData_getSubMatrix", (char**)keywords, &pyobj_matrix, &pyobj_idx, &pyobj_layout) &&
        pyopencv_to_safe(pyobj_matrix, matrix, ArgInfo("matrix", 0)) &&
        pyopencv_to_safe(pyobj_idx, idx, ArgInfo("idx", 0)) &&
        pyopencv_to_safe(pyobj_layout, layout, ArgInfo("layout", 0)) )
    {
        ERRWRAP2(retval = cv::ml::TrainData::getSubMatrix(matrix, idx, layout));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("TrainData_getSubMatrix");

    return NULL;
}

static PyObject* pyopencv_cv_ml_TrainData_getSubVector(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ml;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_vec = NULL;
    Mat vec;
    PyObject* pyobj_idx = NULL;
    Mat idx;
    Mat retval;

    const char* keywords[] = { "vec", "idx", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:TrainData_getSubVector", (char**)keywords, &pyobj_vec, &pyobj_idx) &&
        pyopencv_to_safe(pyobj_vec, vec, ArgInfo("vec", 0)) &&
        pyopencv_to_safe(pyobj_idx, idx, ArgInfo("idx", 0)) )
    {
        ERRWRAP2(retval = cv::ml::TrainData::getSubVector(vec, idx));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_vec = NULL;
    Mat vec;
    PyObject* pyobj_idx = NULL;
    Mat idx;
    Mat retval;

    const char* keywords[] = { "vec", "idx", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:TrainData_getSubVector", (char**)keywords, &pyobj_vec, &pyobj_idx) &&
        pyopencv_to_safe(pyobj_vec, vec, ArgInfo("vec", 0)) &&
        pyopencv_to_safe(pyobj_idx, idx, ArgInfo("idx", 0)) )
    {
        ERRWRAP2(retval = cv::ml::TrainData::getSubVector(vec, idx));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("TrainData_getSubVector");

    return NULL;
}

static PyObject* pyopencv_cv_motempl_calcGlobalOrientation(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::motempl;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_orientation = NULL;
    Mat orientation;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_mhi = NULL;
    Mat mhi;
    PyObject* pyobj_timestamp = NULL;
    double timestamp=0;
    PyObject* pyobj_duration = NULL;
    double duration=0;
    double retval;

    const char* keywords[] = { "orientation", "mask", "mhi", "timestamp", "duration", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO:calcGlobalOrientation", (char**)keywords, &pyobj_orientation, &pyobj_mask, &pyobj_mhi, &pyobj_timestamp, &pyobj_duration) &&
        pyopencv_to_safe(pyobj_orientation, orientation, ArgInfo("orientation", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_mhi, mhi, ArgInfo("mhi", 0)) &&
        pyopencv_to_safe(pyobj_timestamp, timestamp, ArgInfo("timestamp", 0)) &&
        pyopencv_to_safe(pyobj_duration, duration, ArgInfo("duration", 0)) )
    {
        ERRWRAP2(retval = cv::motempl::calcGlobalOrientation(orientation, mask, mhi, timestamp, duration));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_orientation = NULL;
    UMat orientation;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    PyObject* pyobj_mhi = NULL;
    UMat mhi;
    PyObject* pyobj_timestamp = NULL;
    double timestamp=0;
    PyObject* pyobj_duration = NULL;
    double duration=0;
    double retval;

    const char* keywords[] = { "orientation", "mask", "mhi", "timestamp", "duration", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO:calcGlobalOrientation", (char**)keywords, &pyobj_orientation, &pyobj_mask, &pyobj_mhi, &pyobj_timestamp, &pyobj_duration) &&
        pyopencv_to_safe(pyobj_orientation, orientation, ArgInfo("orientation", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_mhi, mhi, ArgInfo("mhi", 0)) &&
        pyopencv_to_safe(pyobj_timestamp, timestamp, ArgInfo("timestamp", 0)) &&
        pyopencv_to_safe(pyobj_duration, duration, ArgInfo("duration", 0)) )
    {
        ERRWRAP2(retval = cv::motempl::calcGlobalOrientation(orientation, mask, mhi, timestamp, duration));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("calcGlobalOrientation");

    return NULL;
}

static PyObject* pyopencv_cv_motempl_calcMotionGradient(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::motempl;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_mhi = NULL;
    Mat mhi;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_orientation = NULL;
    Mat orientation;
    PyObject* pyobj_delta1 = NULL;
    double delta1=0;
    PyObject* pyobj_delta2 = NULL;
    double delta2=0;
    PyObject* pyobj_apertureSize = NULL;
    int apertureSize=3;

    const char* keywords[] = { "mhi", "delta1", "delta2", "mask", "orientation", "apertureSize", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:calcMotionGradient", (char**)keywords, &pyobj_mhi, &pyobj_delta1, &pyobj_delta2, &pyobj_mask, &pyobj_orientation, &pyobj_apertureSize) &&
        pyopencv_to_safe(pyobj_mhi, mhi, ArgInfo("mhi", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 1)) &&
        pyopencv_to_safe(pyobj_orientation, orientation, ArgInfo("orientation", 1)) &&
        pyopencv_to_safe(pyobj_delta1, delta1, ArgInfo("delta1", 0)) &&
        pyopencv_to_safe(pyobj_delta2, delta2, ArgInfo("delta2", 0)) &&
        pyopencv_to_safe(pyobj_apertureSize, apertureSize, ArgInfo("apertureSize", 0)) )
    {
        ERRWRAP2(cv::motempl::calcMotionGradient(mhi, mask, orientation, delta1, delta2, apertureSize));
        return Py_BuildValue("(NN)", pyopencv_from(mask), pyopencv_from(orientation));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_mhi = NULL;
    UMat mhi;
    PyObject* pyobj_mask = NULL;
    UMat mask;
    PyObject* pyobj_orientation = NULL;
    UMat orientation;
    PyObject* pyobj_delta1 = NULL;
    double delta1=0;
    PyObject* pyobj_delta2 = NULL;
    double delta2=0;
    PyObject* pyobj_apertureSize = NULL;
    int apertureSize=3;

    const char* keywords[] = { "mhi", "delta1", "delta2", "mask", "orientation", "apertureSize", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:calcMotionGradient", (char**)keywords, &pyobj_mhi, &pyobj_delta1, &pyobj_delta2, &pyobj_mask, &pyobj_orientation, &pyobj_apertureSize) &&
        pyopencv_to_safe(pyobj_mhi, mhi, ArgInfo("mhi", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 1)) &&
        pyopencv_to_safe(pyobj_orientation, orientation, ArgInfo("orientation", 1)) &&
        pyopencv_to_safe(pyobj_delta1, delta1, ArgInfo("delta1", 0)) &&
        pyopencv_to_safe(pyobj_delta2, delta2, ArgInfo("delta2", 0)) &&
        pyopencv_to_safe(pyobj_apertureSize, apertureSize, ArgInfo("apertureSize", 0)) )
    {
        ERRWRAP2(cv::motempl::calcMotionGradient(mhi, mask, orientation, delta1, delta2, apertureSize));
        return Py_BuildValue("(NN)", pyopencv_from(mask), pyopencv_from(orientation));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("calcMotionGradient");

    return NULL;
}

static PyObject* pyopencv_cv_motempl_segmentMotion(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::motempl;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_mhi = NULL;
    Mat mhi;
    PyObject* pyobj_segmask = NULL;
    Mat segmask;
    vector_Rect boundingRects;
    PyObject* pyobj_timestamp = NULL;
    double timestamp=0;
    PyObject* pyobj_segThresh = NULL;
    double segThresh=0;

    const char* keywords[] = { "mhi", "timestamp", "segThresh", "segmask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:segmentMotion", (char**)keywords, &pyobj_mhi, &pyobj_timestamp, &pyobj_segThresh, &pyobj_segmask) &&
        pyopencv_to_safe(pyobj_mhi, mhi, ArgInfo("mhi", 0)) &&
        pyopencv_to_safe(pyobj_segmask, segmask, ArgInfo("segmask", 1)) &&
        pyopencv_to_safe(pyobj_timestamp, timestamp, ArgInfo("timestamp", 0)) &&
        pyopencv_to_safe(pyobj_segThresh, segThresh, ArgInfo("segThresh", 0)) )
    {
        ERRWRAP2(cv::motempl::segmentMotion(mhi, segmask, boundingRects, timestamp, segThresh));
        return Py_BuildValue("(NN)", pyopencv_from(segmask), pyopencv_from(boundingRects));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_mhi = NULL;
    UMat mhi;
    PyObject* pyobj_segmask = NULL;
    UMat segmask;
    vector_Rect boundingRects;
    PyObject* pyobj_timestamp = NULL;
    double timestamp=0;
    PyObject* pyobj_segThresh = NULL;
    double segThresh=0;

    const char* keywords[] = { "mhi", "timestamp", "segThresh", "segmask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:segmentMotion", (char**)keywords, &pyobj_mhi, &pyobj_timestamp, &pyobj_segThresh, &pyobj_segmask) &&
        pyopencv_to_safe(pyobj_mhi, mhi, ArgInfo("mhi", 0)) &&
        pyopencv_to_safe(pyobj_segmask, segmask, ArgInfo("segmask", 1)) &&
        pyopencv_to_safe(pyobj_timestamp, timestamp, ArgInfo("timestamp", 0)) &&
        pyopencv_to_safe(pyobj_segThresh, segThresh, ArgInfo("segThresh", 0)) )
    {
        ERRWRAP2(cv::motempl::segmentMotion(mhi, segmask, boundingRects, timestamp, segThresh));
        return Py_BuildValue("(NN)", pyopencv_from(segmask), pyopencv_from(boundingRects));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("segmentMotion");

    return NULL;
}

static PyObject* pyopencv_cv_motempl_updateMotionHistory(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::motempl;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_silhouette = NULL;
    Mat silhouette;
    PyObject* pyobj_mhi = NULL;
    Mat mhi;
    PyObject* pyobj_timestamp = NULL;
    double timestamp=0;
    PyObject* pyobj_duration = NULL;
    double duration=0;

    const char* keywords[] = { "silhouette", "mhi", "timestamp", "duration", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO:updateMotionHistory", (char**)keywords, &pyobj_silhouette, &pyobj_mhi, &pyobj_timestamp, &pyobj_duration) &&
        pyopencv_to_safe(pyobj_silhouette, silhouette, ArgInfo("silhouette", 0)) &&
        pyopencv_to_safe(pyobj_mhi, mhi, ArgInfo("mhi", 1)) &&
        pyopencv_to_safe(pyobj_timestamp, timestamp, ArgInfo("timestamp", 0)) &&
        pyopencv_to_safe(pyobj_duration, duration, ArgInfo("duration", 0)) )
    {
        ERRWRAP2(cv::motempl::updateMotionHistory(silhouette, mhi, timestamp, duration));
        return pyopencv_from(mhi);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_silhouette = NULL;
    UMat silhouette;
    PyObject* pyobj_mhi = NULL;
    UMat mhi;
    PyObject* pyobj_timestamp = NULL;
    double timestamp=0;
    PyObject* pyobj_duration = NULL;
    double duration=0;

    const char* keywords[] = { "silhouette", "mhi", "timestamp", "duration", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO:updateMotionHistory", (char**)keywords, &pyobj_silhouette, &pyobj_mhi, &pyobj_timestamp, &pyobj_duration) &&
        pyopencv_to_safe(pyobj_silhouette, silhouette, ArgInfo("silhouette", 0)) &&
        pyopencv_to_safe(pyobj_mhi, mhi, ArgInfo("mhi", 1)) &&
        pyopencv_to_safe(pyobj_timestamp, timestamp, ArgInfo("timestamp", 0)) &&
        pyopencv_to_safe(pyobj_duration, duration, ArgInfo("duration", 0)) )
    {
        ERRWRAP2(cv::motempl::updateMotionHistory(silhouette, mhi, timestamp, duration));
        return pyopencv_from(mhi);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("updateMotionHistory");

    return NULL;
}

static PyObject* pyopencv_cv_ocl_Device_getDefault(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ocl;

    Device retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::ocl::Device::getDefault());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ocl_finish(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ocl;


    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(cv::ocl::finish());
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ocl_haveAmdBlas(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ocl;

    bool retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::ocl::haveAmdBlas());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ocl_haveAmdFft(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ocl;

    bool retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::ocl::haveAmdFft());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ocl_haveOpenCL(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ocl;

    bool retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::ocl::haveOpenCL());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ocl_setUseOpenCL(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ocl;

    PyObject* pyobj_flag = NULL;
    bool flag=0;

    const char* keywords[] = { "flag", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:setUseOpenCL", (char**)keywords, &pyobj_flag) &&
        pyopencv_to_safe(pyobj_flag, flag, ArgInfo("flag", 0)) )
    {
        ERRWRAP2(cv::ocl::setUseOpenCL(flag));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ocl_useOpenCL(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ocl;

    bool retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::ocl::useOpenCL());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_omnidir_calibrate(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::omnidir;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_objectPoints = NULL;
    vector_Mat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    vector_Mat imagePoints;
    PyObject* pyobj_size = NULL;
    Size size;
    PyObject* pyobj_K = NULL;
    Mat K;
    PyObject* pyobj_xi = NULL;
    Mat xi;
    PyObject* pyobj_D = NULL;
    Mat D;
    PyObject* pyobj_rvecs = NULL;
    vector_Mat rvecs;
    PyObject* pyobj_tvecs = NULL;
    vector_Mat tvecs;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria;
    PyObject* pyobj_idx = NULL;
    Mat idx;
    double retval;

    const char* keywords[] = { "objectPoints", "imagePoints", "size", "K", "xi", "D", "flags", "criteria", "rvecs", "tvecs", "idx", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOOO|OOO:calibrate", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints, &pyobj_size, &pyobj_K, &pyobj_xi, &pyobj_D, &pyobj_flags, &pyobj_criteria, &pyobj_rvecs, &pyobj_tvecs, &pyobj_idx) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 0)) &&
        pyopencv_to_safe(pyobj_size, size, ArgInfo("size", 0)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 1)) &&
        pyopencv_to_safe(pyobj_xi, xi, ArgInfo("xi", 1)) &&
        pyopencv_to_safe(pyobj_D, D, ArgInfo("D", 1)) &&
        pyopencv_to_safe(pyobj_rvecs, rvecs, ArgInfo("rvecs", 1)) &&
        pyopencv_to_safe(pyobj_tvecs, tvecs, ArgInfo("tvecs", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) &&
        pyopencv_to_safe(pyobj_idx, idx, ArgInfo("idx", 1)) )
    {
        ERRWRAP2(retval = cv::omnidir::calibrate(objectPoints, imagePoints, size, K, xi, D, rvecs, tvecs, flags, criteria, idx));
        return Py_BuildValue("(NNNNNNN)", pyopencv_from(retval), pyopencv_from(K), pyopencv_from(xi), pyopencv_from(D), pyopencv_from(rvecs), pyopencv_from(tvecs), pyopencv_from(idx));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_objectPoints = NULL;
    vector_UMat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    vector_UMat imagePoints;
    PyObject* pyobj_size = NULL;
    Size size;
    PyObject* pyobj_K = NULL;
    UMat K;
    PyObject* pyobj_xi = NULL;
    UMat xi;
    PyObject* pyobj_D = NULL;
    UMat D;
    PyObject* pyobj_rvecs = NULL;
    vector_UMat rvecs;
    PyObject* pyobj_tvecs = NULL;
    vector_UMat tvecs;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria;
    PyObject* pyobj_idx = NULL;
    UMat idx;
    double retval;

    const char* keywords[] = { "objectPoints", "imagePoints", "size", "K", "xi", "D", "flags", "criteria", "rvecs", "tvecs", "idx", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOOO|OOO:calibrate", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints, &pyobj_size, &pyobj_K, &pyobj_xi, &pyobj_D, &pyobj_flags, &pyobj_criteria, &pyobj_rvecs, &pyobj_tvecs, &pyobj_idx) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 0)) &&
        pyopencv_to_safe(pyobj_size, size, ArgInfo("size", 0)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 1)) &&
        pyopencv_to_safe(pyobj_xi, xi, ArgInfo("xi", 1)) &&
        pyopencv_to_safe(pyobj_D, D, ArgInfo("D", 1)) &&
        pyopencv_to_safe(pyobj_rvecs, rvecs, ArgInfo("rvecs", 1)) &&
        pyopencv_to_safe(pyobj_tvecs, tvecs, ArgInfo("tvecs", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) &&
        pyopencv_to_safe(pyobj_idx, idx, ArgInfo("idx", 1)) )
    {
        ERRWRAP2(retval = cv::omnidir::calibrate(objectPoints, imagePoints, size, K, xi, D, rvecs, tvecs, flags, criteria, idx));
        return Py_BuildValue("(NNNNNNN)", pyopencv_from(retval), pyopencv_from(K), pyopencv_from(xi), pyopencv_from(D), pyopencv_from(rvecs), pyopencv_from(tvecs), pyopencv_from(idx));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("calibrate");

    return NULL;
}

static PyObject* pyopencv_cv_omnidir_initUndistortRectifyMap(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::omnidir;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_K = NULL;
    Mat K;
    PyObject* pyobj_D = NULL;
    Mat D;
    PyObject* pyobj_xi = NULL;
    Mat xi;
    PyObject* pyobj_R = NULL;
    Mat R;
    PyObject* pyobj_P = NULL;
    Mat P;
    PyObject* pyobj_size = NULL;
    Size size;
    PyObject* pyobj_m1type = NULL;
    int m1type=0;
    PyObject* pyobj_map1 = NULL;
    Mat map1;
    PyObject* pyobj_map2 = NULL;
    Mat map2;
    PyObject* pyobj_flags = NULL;
    int flags=0;

    const char* keywords[] = { "K", "D", "xi", "R", "P", "size", "m1type", "flags", "map1", "map2", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOOO|OO:initUndistortRectifyMap", (char**)keywords, &pyobj_K, &pyobj_D, &pyobj_xi, &pyobj_R, &pyobj_P, &pyobj_size, &pyobj_m1type, &pyobj_flags, &pyobj_map1, &pyobj_map2) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_D, D, ArgInfo("D", 0)) &&
        pyopencv_to_safe(pyobj_xi, xi, ArgInfo("xi", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) &&
        pyopencv_to_safe(pyobj_P, P, ArgInfo("P", 0)) &&
        pyopencv_to_safe(pyobj_size, size, ArgInfo("size", 0)) &&
        pyopencv_to_safe(pyobj_m1type, m1type, ArgInfo("m1type", 0)) &&
        pyopencv_to_safe(pyobj_map1, map1, ArgInfo("map1", 1)) &&
        pyopencv_to_safe(pyobj_map2, map2, ArgInfo("map2", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::omnidir::initUndistortRectifyMap(K, D, xi, R, P, size, m1type, map1, map2, flags));
        return Py_BuildValue("(NN)", pyopencv_from(map1), pyopencv_from(map2));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_K = NULL;
    UMat K;
    PyObject* pyobj_D = NULL;
    UMat D;
    PyObject* pyobj_xi = NULL;
    UMat xi;
    PyObject* pyobj_R = NULL;
    UMat R;
    PyObject* pyobj_P = NULL;
    UMat P;
    PyObject* pyobj_size = NULL;
    Size size;
    PyObject* pyobj_m1type = NULL;
    int m1type=0;
    PyObject* pyobj_map1 = NULL;
    UMat map1;
    PyObject* pyobj_map2 = NULL;
    UMat map2;
    PyObject* pyobj_flags = NULL;
    int flags=0;

    const char* keywords[] = { "K", "D", "xi", "R", "P", "size", "m1type", "flags", "map1", "map2", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOOO|OO:initUndistortRectifyMap", (char**)keywords, &pyobj_K, &pyobj_D, &pyobj_xi, &pyobj_R, &pyobj_P, &pyobj_size, &pyobj_m1type, &pyobj_flags, &pyobj_map1, &pyobj_map2) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_D, D, ArgInfo("D", 0)) &&
        pyopencv_to_safe(pyobj_xi, xi, ArgInfo("xi", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) &&
        pyopencv_to_safe(pyobj_P, P, ArgInfo("P", 0)) &&
        pyopencv_to_safe(pyobj_size, size, ArgInfo("size", 0)) &&
        pyopencv_to_safe(pyobj_m1type, m1type, ArgInfo("m1type", 0)) &&
        pyopencv_to_safe(pyobj_map1, map1, ArgInfo("map1", 1)) &&
        pyopencv_to_safe(pyobj_map2, map2, ArgInfo("map2", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) )
    {
        ERRWRAP2(cv::omnidir::initUndistortRectifyMap(K, D, xi, R, P, size, m1type, map1, map2, flags));
        return Py_BuildValue("(NN)", pyopencv_from(map1), pyopencv_from(map2));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("initUndistortRectifyMap");

    return NULL;
}

static PyObject* pyopencv_cv_omnidir_projectPoints(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::omnidir;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_objectPoints = NULL;
    Mat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    Mat imagePoints;
    PyObject* pyobj_rvec = NULL;
    Mat rvec;
    PyObject* pyobj_tvec = NULL;
    Mat tvec;
    PyObject* pyobj_K = NULL;
    Mat K;
    PyObject* pyobj_xi = NULL;
    double xi=0;
    PyObject* pyobj_D = NULL;
    Mat D;
    PyObject* pyobj_jacobian = NULL;
    Mat jacobian;

    const char* keywords[] = { "objectPoints", "rvec", "tvec", "K", "xi", "D", "imagePoints", "jacobian", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|OO:projectPoints", (char**)keywords, &pyobj_objectPoints, &pyobj_rvec, &pyobj_tvec, &pyobj_K, &pyobj_xi, &pyobj_D, &pyobj_imagePoints, &pyobj_jacobian) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 1)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 0)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 0)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_xi, xi, ArgInfo("xi", 0)) &&
        pyopencv_to_safe(pyobj_D, D, ArgInfo("D", 0)) &&
        pyopencv_to_safe(pyobj_jacobian, jacobian, ArgInfo("jacobian", 1)) )
    {
        ERRWRAP2(cv::omnidir::projectPoints(objectPoints, imagePoints, rvec, tvec, K, xi, D, jacobian));
        return Py_BuildValue("(NN)", pyopencv_from(imagePoints), pyopencv_from(jacobian));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_objectPoints = NULL;
    UMat objectPoints;
    PyObject* pyobj_imagePoints = NULL;
    UMat imagePoints;
    PyObject* pyobj_rvec = NULL;
    UMat rvec;
    PyObject* pyobj_tvec = NULL;
    UMat tvec;
    PyObject* pyobj_K = NULL;
    UMat K;
    PyObject* pyobj_xi = NULL;
    double xi=0;
    PyObject* pyobj_D = NULL;
    UMat D;
    PyObject* pyobj_jacobian = NULL;
    UMat jacobian;

    const char* keywords[] = { "objectPoints", "rvec", "tvec", "K", "xi", "D", "imagePoints", "jacobian", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|OO:projectPoints", (char**)keywords, &pyobj_objectPoints, &pyobj_rvec, &pyobj_tvec, &pyobj_K, &pyobj_xi, &pyobj_D, &pyobj_imagePoints, &pyobj_jacobian) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 0)) &&
        pyopencv_to_safe(pyobj_imagePoints, imagePoints, ArgInfo("imagePoints", 1)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 0)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 0)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_xi, xi, ArgInfo("xi", 0)) &&
        pyopencv_to_safe(pyobj_D, D, ArgInfo("D", 0)) &&
        pyopencv_to_safe(pyobj_jacobian, jacobian, ArgInfo("jacobian", 1)) )
    {
        ERRWRAP2(cv::omnidir::projectPoints(objectPoints, imagePoints, rvec, tvec, K, xi, D, jacobian));
        return Py_BuildValue("(NN)", pyopencv_from(imagePoints), pyopencv_from(jacobian));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("projectPoints");

    return NULL;
}

static PyObject* pyopencv_cv_omnidir_stereoCalibrate(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::omnidir;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_objectPoints = NULL;
    vector_Mat objectPoints;
    PyObject* pyobj_imagePoints1 = NULL;
    vector_Mat imagePoints1;
    PyObject* pyobj_imagePoints2 = NULL;
    vector_Mat imagePoints2;
    PyObject* pyobj_imageSize1 = NULL;
    Size imageSize1;
    PyObject* pyobj_imageSize2 = NULL;
    Size imageSize2;
    PyObject* pyobj_K1 = NULL;
    Mat K1;
    PyObject* pyobj_xi1 = NULL;
    Mat xi1;
    PyObject* pyobj_D1 = NULL;
    Mat D1;
    PyObject* pyobj_K2 = NULL;
    Mat K2;
    PyObject* pyobj_xi2 = NULL;
    Mat xi2;
    PyObject* pyobj_D2 = NULL;
    Mat D2;
    PyObject* pyobj_rvec = NULL;
    Mat rvec;
    PyObject* pyobj_tvec = NULL;
    Mat tvec;
    PyObject* pyobj_rvecsL = NULL;
    vector_Mat rvecsL;
    PyObject* pyobj_tvecsL = NULL;
    vector_Mat tvecsL;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria;
    PyObject* pyobj_idx = NULL;
    Mat idx;
    double retval;

    const char* keywords[] = { "objectPoints", "imagePoints1", "imagePoints2", "imageSize1", "imageSize2", "K1", "xi1", "D1", "K2", "xi2", "D2", "flags", "criteria", "rvec", "tvec", "rvecsL", "tvecsL", "idx", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOOOOOOOO|OOOOO:stereoCalibrate", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints1, &pyobj_imagePoints2, &pyobj_imageSize1, &pyobj_imageSize2, &pyobj_K1, &pyobj_xi1, &pyobj_D1, &pyobj_K2, &pyobj_xi2, &pyobj_D2, &pyobj_flags, &pyobj_criteria, &pyobj_rvec, &pyobj_tvec, &pyobj_rvecsL, &pyobj_tvecsL, &pyobj_idx) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 1)) &&
        pyopencv_to_safe(pyobj_imagePoints1, imagePoints1, ArgInfo("imagePoints1", 1)) &&
        pyopencv_to_safe(pyobj_imagePoints2, imagePoints2, ArgInfo("imagePoints2", 1)) &&
        pyopencv_to_safe(pyobj_imageSize1, imageSize1, ArgInfo("imageSize1", 0)) &&
        pyopencv_to_safe(pyobj_imageSize2, imageSize2, ArgInfo("imageSize2", 0)) &&
        pyopencv_to_safe(pyobj_K1, K1, ArgInfo("K1", 1)) &&
        pyopencv_to_safe(pyobj_xi1, xi1, ArgInfo("xi1", 1)) &&
        pyopencv_to_safe(pyobj_D1, D1, ArgInfo("D1", 1)) &&
        pyopencv_to_safe(pyobj_K2, K2, ArgInfo("K2", 1)) &&
        pyopencv_to_safe(pyobj_xi2, xi2, ArgInfo("xi2", 1)) &&
        pyopencv_to_safe(pyobj_D2, D2, ArgInfo("D2", 1)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 1)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 1)) &&
        pyopencv_to_safe(pyobj_rvecsL, rvecsL, ArgInfo("rvecsL", 1)) &&
        pyopencv_to_safe(pyobj_tvecsL, tvecsL, ArgInfo("tvecsL", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) &&
        pyopencv_to_safe(pyobj_idx, idx, ArgInfo("idx", 1)) )
    {
        ERRWRAP2(retval = cv::omnidir::stereoCalibrate(objectPoints, imagePoints1, imagePoints2, imageSize1, imageSize2, K1, xi1, D1, K2, xi2, D2, rvec, tvec, rvecsL, tvecsL, flags, criteria, idx));
        return Py_BuildValue("(NNNNNNNNNNNNNNN)", pyopencv_from(retval), pyopencv_from(objectPoints), pyopencv_from(imagePoints1), pyopencv_from(imagePoints2), pyopencv_from(K1), pyopencv_from(xi1), pyopencv_from(D1), pyopencv_from(K2), pyopencv_from(xi2), pyopencv_from(D2), pyopencv_from(rvec), pyopencv_from(tvec), pyopencv_from(rvecsL), pyopencv_from(tvecsL), pyopencv_from(idx));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_objectPoints = NULL;
    vector_UMat objectPoints;
    PyObject* pyobj_imagePoints1 = NULL;
    vector_UMat imagePoints1;
    PyObject* pyobj_imagePoints2 = NULL;
    vector_UMat imagePoints2;
    PyObject* pyobj_imageSize1 = NULL;
    Size imageSize1;
    PyObject* pyobj_imageSize2 = NULL;
    Size imageSize2;
    PyObject* pyobj_K1 = NULL;
    UMat K1;
    PyObject* pyobj_xi1 = NULL;
    UMat xi1;
    PyObject* pyobj_D1 = NULL;
    UMat D1;
    PyObject* pyobj_K2 = NULL;
    UMat K2;
    PyObject* pyobj_xi2 = NULL;
    UMat xi2;
    PyObject* pyobj_D2 = NULL;
    UMat D2;
    PyObject* pyobj_rvec = NULL;
    UMat rvec;
    PyObject* pyobj_tvec = NULL;
    UMat tvec;
    PyObject* pyobj_rvecsL = NULL;
    vector_UMat rvecsL;
    PyObject* pyobj_tvecsL = NULL;
    vector_UMat tvecsL;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_criteria = NULL;
    TermCriteria criteria;
    PyObject* pyobj_idx = NULL;
    UMat idx;
    double retval;

    const char* keywords[] = { "objectPoints", "imagePoints1", "imagePoints2", "imageSize1", "imageSize2", "K1", "xi1", "D1", "K2", "xi2", "D2", "flags", "criteria", "rvec", "tvec", "rvecsL", "tvecsL", "idx", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOOOOOOOO|OOOOO:stereoCalibrate", (char**)keywords, &pyobj_objectPoints, &pyobj_imagePoints1, &pyobj_imagePoints2, &pyobj_imageSize1, &pyobj_imageSize2, &pyobj_K1, &pyobj_xi1, &pyobj_D1, &pyobj_K2, &pyobj_xi2, &pyobj_D2, &pyobj_flags, &pyobj_criteria, &pyobj_rvec, &pyobj_tvec, &pyobj_rvecsL, &pyobj_tvecsL, &pyobj_idx) &&
        pyopencv_to_safe(pyobj_objectPoints, objectPoints, ArgInfo("objectPoints", 1)) &&
        pyopencv_to_safe(pyobj_imagePoints1, imagePoints1, ArgInfo("imagePoints1", 1)) &&
        pyopencv_to_safe(pyobj_imagePoints2, imagePoints2, ArgInfo("imagePoints2", 1)) &&
        pyopencv_to_safe(pyobj_imageSize1, imageSize1, ArgInfo("imageSize1", 0)) &&
        pyopencv_to_safe(pyobj_imageSize2, imageSize2, ArgInfo("imageSize2", 0)) &&
        pyopencv_to_safe(pyobj_K1, K1, ArgInfo("K1", 1)) &&
        pyopencv_to_safe(pyobj_xi1, xi1, ArgInfo("xi1", 1)) &&
        pyopencv_to_safe(pyobj_D1, D1, ArgInfo("D1", 1)) &&
        pyopencv_to_safe(pyobj_K2, K2, ArgInfo("K2", 1)) &&
        pyopencv_to_safe(pyobj_xi2, xi2, ArgInfo("xi2", 1)) &&
        pyopencv_to_safe(pyobj_D2, D2, ArgInfo("D2", 1)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 1)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 1)) &&
        pyopencv_to_safe(pyobj_rvecsL, rvecsL, ArgInfo("rvecsL", 1)) &&
        pyopencv_to_safe(pyobj_tvecsL, tvecsL, ArgInfo("tvecsL", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_criteria, criteria, ArgInfo("criteria", 0)) &&
        pyopencv_to_safe(pyobj_idx, idx, ArgInfo("idx", 1)) )
    {
        ERRWRAP2(retval = cv::omnidir::stereoCalibrate(objectPoints, imagePoints1, imagePoints2, imageSize1, imageSize2, K1, xi1, D1, K2, xi2, D2, rvec, tvec, rvecsL, tvecsL, flags, criteria, idx));
        return Py_BuildValue("(NNNNNNNNNNNNNNN)", pyopencv_from(retval), pyopencv_from(objectPoints), pyopencv_from(imagePoints1), pyopencv_from(imagePoints2), pyopencv_from(K1), pyopencv_from(xi1), pyopencv_from(D1), pyopencv_from(K2), pyopencv_from(xi2), pyopencv_from(D2), pyopencv_from(rvec), pyopencv_from(tvec), pyopencv_from(rvecsL), pyopencv_from(tvecsL), pyopencv_from(idx));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("stereoCalibrate");

    return NULL;
}

static PyObject* pyopencv_cv_omnidir_stereoReconstruct(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::omnidir;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image1 = NULL;
    Mat image1;
    PyObject* pyobj_image2 = NULL;
    Mat image2;
    PyObject* pyobj_K1 = NULL;
    Mat K1;
    PyObject* pyobj_D1 = NULL;
    Mat D1;
    PyObject* pyobj_xi1 = NULL;
    Mat xi1;
    PyObject* pyobj_K2 = NULL;
    Mat K2;
    PyObject* pyobj_D2 = NULL;
    Mat D2;
    PyObject* pyobj_xi2 = NULL;
    Mat xi2;
    PyObject* pyobj_R = NULL;
    Mat R;
    PyObject* pyobj_T = NULL;
    Mat T;
    PyObject* pyobj_flag = NULL;
    int flag=0;
    PyObject* pyobj_numDisparities = NULL;
    int numDisparities=0;
    PyObject* pyobj_SADWindowSize = NULL;
    int SADWindowSize=0;
    PyObject* pyobj_disparity = NULL;
    Mat disparity;
    PyObject* pyobj_image1Rec = NULL;
    Mat image1Rec;
    PyObject* pyobj_image2Rec = NULL;
    Mat image2Rec;
    PyObject* pyobj_newSize = NULL;
    Size newSize;
    PyObject* pyobj_Knew = NULL;
    Mat Knew=cv::Mat();
    PyObject* pyobj_pointCloud = NULL;
    Mat pointCloud;
    PyObject* pyobj_pointType = NULL;
    int pointType=XYZRGB;

    const char* keywords[] = { "image1", "image2", "K1", "D1", "xi1", "K2", "D2", "xi2", "R", "T", "flag", "numDisparities", "SADWindowSize", "disparity", "image1Rec", "image2Rec", "newSize", "Knew", "pointCloud", "pointType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOOOOOOOO|OOOOOOO:stereoReconstruct", (char**)keywords, &pyobj_image1, &pyobj_image2, &pyobj_K1, &pyobj_D1, &pyobj_xi1, &pyobj_K2, &pyobj_D2, &pyobj_xi2, &pyobj_R, &pyobj_T, &pyobj_flag, &pyobj_numDisparities, &pyobj_SADWindowSize, &pyobj_disparity, &pyobj_image1Rec, &pyobj_image2Rec, &pyobj_newSize, &pyobj_Knew, &pyobj_pointCloud, &pyobj_pointType) &&
        pyopencv_to_safe(pyobj_image1, image1, ArgInfo("image1", 0)) &&
        pyopencv_to_safe(pyobj_image2, image2, ArgInfo("image2", 0)) &&
        pyopencv_to_safe(pyobj_K1, K1, ArgInfo("K1", 0)) &&
        pyopencv_to_safe(pyobj_D1, D1, ArgInfo("D1", 0)) &&
        pyopencv_to_safe(pyobj_xi1, xi1, ArgInfo("xi1", 0)) &&
        pyopencv_to_safe(pyobj_K2, K2, ArgInfo("K2", 0)) &&
        pyopencv_to_safe(pyobj_D2, D2, ArgInfo("D2", 0)) &&
        pyopencv_to_safe(pyobj_xi2, xi2, ArgInfo("xi2", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) &&
        pyopencv_to_safe(pyobj_T, T, ArgInfo("T", 0)) &&
        pyopencv_to_safe(pyobj_flag, flag, ArgInfo("flag", 0)) &&
        pyopencv_to_safe(pyobj_numDisparities, numDisparities, ArgInfo("numDisparities", 0)) &&
        pyopencv_to_safe(pyobj_SADWindowSize, SADWindowSize, ArgInfo("SADWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_disparity, disparity, ArgInfo("disparity", 1)) &&
        pyopencv_to_safe(pyobj_image1Rec, image1Rec, ArgInfo("image1Rec", 1)) &&
        pyopencv_to_safe(pyobj_image2Rec, image2Rec, ArgInfo("image2Rec", 1)) &&
        pyopencv_to_safe(pyobj_newSize, newSize, ArgInfo("newSize", 0)) &&
        pyopencv_to_safe(pyobj_Knew, Knew, ArgInfo("Knew", 0)) &&
        pyopencv_to_safe(pyobj_pointCloud, pointCloud, ArgInfo("pointCloud", 1)) &&
        pyopencv_to_safe(pyobj_pointType, pointType, ArgInfo("pointType", 0)) )
    {
        ERRWRAP2(cv::omnidir::stereoReconstruct(image1, image2, K1, D1, xi1, K2, D2, xi2, R, T, flag, numDisparities, SADWindowSize, disparity, image1Rec, image2Rec, newSize, Knew, pointCloud, pointType));
        return Py_BuildValue("(NNNN)", pyopencv_from(disparity), pyopencv_from(image1Rec), pyopencv_from(image2Rec), pyopencv_from(pointCloud));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image1 = NULL;
    UMat image1;
    PyObject* pyobj_image2 = NULL;
    UMat image2;
    PyObject* pyobj_K1 = NULL;
    UMat K1;
    PyObject* pyobj_D1 = NULL;
    UMat D1;
    PyObject* pyobj_xi1 = NULL;
    UMat xi1;
    PyObject* pyobj_K2 = NULL;
    UMat K2;
    PyObject* pyobj_D2 = NULL;
    UMat D2;
    PyObject* pyobj_xi2 = NULL;
    UMat xi2;
    PyObject* pyobj_R = NULL;
    UMat R;
    PyObject* pyobj_T = NULL;
    UMat T;
    PyObject* pyobj_flag = NULL;
    int flag=0;
    PyObject* pyobj_numDisparities = NULL;
    int numDisparities=0;
    PyObject* pyobj_SADWindowSize = NULL;
    int SADWindowSize=0;
    PyObject* pyobj_disparity = NULL;
    UMat disparity;
    PyObject* pyobj_image1Rec = NULL;
    UMat image1Rec;
    PyObject* pyobj_image2Rec = NULL;
    UMat image2Rec;
    PyObject* pyobj_newSize = NULL;
    Size newSize;
    PyObject* pyobj_Knew = NULL;
    UMat Knew=cv::UMat();
    PyObject* pyobj_pointCloud = NULL;
    UMat pointCloud;
    PyObject* pyobj_pointType = NULL;
    int pointType=XYZRGB;

    const char* keywords[] = { "image1", "image2", "K1", "D1", "xi1", "K2", "D2", "xi2", "R", "T", "flag", "numDisparities", "SADWindowSize", "disparity", "image1Rec", "image2Rec", "newSize", "Knew", "pointCloud", "pointType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOOOOOOOO|OOOOOOO:stereoReconstruct", (char**)keywords, &pyobj_image1, &pyobj_image2, &pyobj_K1, &pyobj_D1, &pyobj_xi1, &pyobj_K2, &pyobj_D2, &pyobj_xi2, &pyobj_R, &pyobj_T, &pyobj_flag, &pyobj_numDisparities, &pyobj_SADWindowSize, &pyobj_disparity, &pyobj_image1Rec, &pyobj_image2Rec, &pyobj_newSize, &pyobj_Knew, &pyobj_pointCloud, &pyobj_pointType) &&
        pyopencv_to_safe(pyobj_image1, image1, ArgInfo("image1", 0)) &&
        pyopencv_to_safe(pyobj_image2, image2, ArgInfo("image2", 0)) &&
        pyopencv_to_safe(pyobj_K1, K1, ArgInfo("K1", 0)) &&
        pyopencv_to_safe(pyobj_D1, D1, ArgInfo("D1", 0)) &&
        pyopencv_to_safe(pyobj_xi1, xi1, ArgInfo("xi1", 0)) &&
        pyopencv_to_safe(pyobj_K2, K2, ArgInfo("K2", 0)) &&
        pyopencv_to_safe(pyobj_D2, D2, ArgInfo("D2", 0)) &&
        pyopencv_to_safe(pyobj_xi2, xi2, ArgInfo("xi2", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) &&
        pyopencv_to_safe(pyobj_T, T, ArgInfo("T", 0)) &&
        pyopencv_to_safe(pyobj_flag, flag, ArgInfo("flag", 0)) &&
        pyopencv_to_safe(pyobj_numDisparities, numDisparities, ArgInfo("numDisparities", 0)) &&
        pyopencv_to_safe(pyobj_SADWindowSize, SADWindowSize, ArgInfo("SADWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_disparity, disparity, ArgInfo("disparity", 1)) &&
        pyopencv_to_safe(pyobj_image1Rec, image1Rec, ArgInfo("image1Rec", 1)) &&
        pyopencv_to_safe(pyobj_image2Rec, image2Rec, ArgInfo("image2Rec", 1)) &&
        pyopencv_to_safe(pyobj_newSize, newSize, ArgInfo("newSize", 0)) &&
        pyopencv_to_safe(pyobj_Knew, Knew, ArgInfo("Knew", 0)) &&
        pyopencv_to_safe(pyobj_pointCloud, pointCloud, ArgInfo("pointCloud", 1)) &&
        pyopencv_to_safe(pyobj_pointType, pointType, ArgInfo("pointType", 0)) )
    {
        ERRWRAP2(cv::omnidir::stereoReconstruct(image1, image2, K1, D1, xi1, K2, D2, xi2, R, T, flag, numDisparities, SADWindowSize, disparity, image1Rec, image2Rec, newSize, Knew, pointCloud, pointType));
        return Py_BuildValue("(NNNN)", pyopencv_from(disparity), pyopencv_from(image1Rec), pyopencv_from(image2Rec), pyopencv_from(pointCloud));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("stereoReconstruct");

    return NULL;
}

static PyObject* pyopencv_cv_omnidir_stereoRectify(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::omnidir;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_R = NULL;
    Mat R;
    PyObject* pyobj_T = NULL;
    Mat T;
    PyObject* pyobj_R1 = NULL;
    Mat R1;
    PyObject* pyobj_R2 = NULL;
    Mat R2;

    const char* keywords[] = { "R", "T", "R1", "R2", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:stereoRectify", (char**)keywords, &pyobj_R, &pyobj_T, &pyobj_R1, &pyobj_R2) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) &&
        pyopencv_to_safe(pyobj_T, T, ArgInfo("T", 0)) &&
        pyopencv_to_safe(pyobj_R1, R1, ArgInfo("R1", 1)) &&
        pyopencv_to_safe(pyobj_R2, R2, ArgInfo("R2", 1)) )
    {
        ERRWRAP2(cv::omnidir::stereoRectify(R, T, R1, R2));
        return Py_BuildValue("(NN)", pyopencv_from(R1), pyopencv_from(R2));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_R = NULL;
    UMat R;
    PyObject* pyobj_T = NULL;
    UMat T;
    PyObject* pyobj_R1 = NULL;
    UMat R1;
    PyObject* pyobj_R2 = NULL;
    UMat R2;

    const char* keywords[] = { "R", "T", "R1", "R2", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:stereoRectify", (char**)keywords, &pyobj_R, &pyobj_T, &pyobj_R1, &pyobj_R2) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) &&
        pyopencv_to_safe(pyobj_T, T, ArgInfo("T", 0)) &&
        pyopencv_to_safe(pyobj_R1, R1, ArgInfo("R1", 1)) &&
        pyopencv_to_safe(pyobj_R2, R2, ArgInfo("R2", 1)) )
    {
        ERRWRAP2(cv::omnidir::stereoRectify(R, T, R1, R2));
        return Py_BuildValue("(NN)", pyopencv_from(R1), pyopencv_from(R2));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("stereoRectify");

    return NULL;
}

static PyObject* pyopencv_cv_omnidir_undistortImage(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::omnidir;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_distorted = NULL;
    Mat distorted;
    PyObject* pyobj_undistorted = NULL;
    Mat undistorted;
    PyObject* pyobj_K = NULL;
    Mat K;
    PyObject* pyobj_D = NULL;
    Mat D;
    PyObject* pyobj_xi = NULL;
    Mat xi;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_Knew = NULL;
    Mat Knew=cv::Mat();
    PyObject* pyobj_new_size = NULL;
    Size new_size;
    PyObject* pyobj_R = NULL;
    Mat R=Mat::eye(3, 3, CV_64F);

    const char* keywords[] = { "distorted", "K", "D", "xi", "flags", "undistorted", "Knew", "new_size", "R", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OOOO:undistortImage", (char**)keywords, &pyobj_distorted, &pyobj_K, &pyobj_D, &pyobj_xi, &pyobj_flags, &pyobj_undistorted, &pyobj_Knew, &pyobj_new_size, &pyobj_R) &&
        pyopencv_to_safe(pyobj_distorted, distorted, ArgInfo("distorted", 0)) &&
        pyopencv_to_safe(pyobj_undistorted, undistorted, ArgInfo("undistorted", 1)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_D, D, ArgInfo("D", 0)) &&
        pyopencv_to_safe(pyobj_xi, xi, ArgInfo("xi", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_Knew, Knew, ArgInfo("Knew", 0)) &&
        pyopencv_to_safe(pyobj_new_size, new_size, ArgInfo("new_size", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) )
    {
        ERRWRAP2(cv::omnidir::undistortImage(distorted, undistorted, K, D, xi, flags, Knew, new_size, R));
        return pyopencv_from(undistorted);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_distorted = NULL;
    UMat distorted;
    PyObject* pyobj_undistorted = NULL;
    UMat undistorted;
    PyObject* pyobj_K = NULL;
    UMat K;
    PyObject* pyobj_D = NULL;
    UMat D;
    PyObject* pyobj_xi = NULL;
    UMat xi;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_Knew = NULL;
    UMat Knew=cv::UMat();
    PyObject* pyobj_new_size = NULL;
    Size new_size;
    PyObject* pyobj_R = NULL;
    UMat R=UMat::eye(3, 3, CV_64F);

    const char* keywords[] = { "distorted", "K", "D", "xi", "flags", "undistorted", "Knew", "new_size", "R", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OOOO:undistortImage", (char**)keywords, &pyobj_distorted, &pyobj_K, &pyobj_D, &pyobj_xi, &pyobj_flags, &pyobj_undistorted, &pyobj_Knew, &pyobj_new_size, &pyobj_R) &&
        pyopencv_to_safe(pyobj_distorted, distorted, ArgInfo("distorted", 0)) &&
        pyopencv_to_safe(pyobj_undistorted, undistorted, ArgInfo("undistorted", 1)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_D, D, ArgInfo("D", 0)) &&
        pyopencv_to_safe(pyobj_xi, xi, ArgInfo("xi", 0)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_Knew, Knew, ArgInfo("Knew", 0)) &&
        pyopencv_to_safe(pyobj_new_size, new_size, ArgInfo("new_size", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) )
    {
        ERRWRAP2(cv::omnidir::undistortImage(distorted, undistorted, K, D, xi, flags, Knew, new_size, R));
        return pyopencv_from(undistorted);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("undistortImage");

    return NULL;
}

static PyObject* pyopencv_cv_omnidir_undistortPoints(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::omnidir;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_distorted = NULL;
    Mat distorted;
    PyObject* pyobj_undistorted = NULL;
    Mat undistorted;
    PyObject* pyobj_K = NULL;
    Mat K;
    PyObject* pyobj_D = NULL;
    Mat D;
    PyObject* pyobj_xi = NULL;
    Mat xi;
    PyObject* pyobj_R = NULL;
    Mat R;

    const char* keywords[] = { "distorted", "K", "D", "xi", "R", "undistorted", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|O:undistortPoints", (char**)keywords, &pyobj_distorted, &pyobj_K, &pyobj_D, &pyobj_xi, &pyobj_R, &pyobj_undistorted) &&
        pyopencv_to_safe(pyobj_distorted, distorted, ArgInfo("distorted", 0)) &&
        pyopencv_to_safe(pyobj_undistorted, undistorted, ArgInfo("undistorted", 1)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_D, D, ArgInfo("D", 0)) &&
        pyopencv_to_safe(pyobj_xi, xi, ArgInfo("xi", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) )
    {
        ERRWRAP2(cv::omnidir::undistortPoints(distorted, undistorted, K, D, xi, R));
        return pyopencv_from(undistorted);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_distorted = NULL;
    UMat distorted;
    PyObject* pyobj_undistorted = NULL;
    UMat undistorted;
    PyObject* pyobj_K = NULL;
    UMat K;
    PyObject* pyobj_D = NULL;
    UMat D;
    PyObject* pyobj_xi = NULL;
    UMat xi;
    PyObject* pyobj_R = NULL;
    UMat R;

    const char* keywords[] = { "distorted", "K", "D", "xi", "R", "undistorted", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|O:undistortPoints", (char**)keywords, &pyobj_distorted, &pyobj_K, &pyobj_D, &pyobj_xi, &pyobj_R, &pyobj_undistorted) &&
        pyopencv_to_safe(pyobj_distorted, distorted, ArgInfo("distorted", 0)) &&
        pyopencv_to_safe(pyobj_undistorted, undistorted, ArgInfo("undistorted", 1)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_D, D, ArgInfo("D", 0)) &&
        pyopencv_to_safe(pyobj_xi, xi, ArgInfo("xi", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) )
    {
        ERRWRAP2(cv::omnidir::undistortPoints(distorted, undistorted, K, D, xi, R));
        return pyopencv_from(undistorted);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("undistortPoints");

    return NULL;
}

static PyObject* pyopencv_cv_optflow_DenseRLOFOpticalFlow_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::optflow;

    PyObject* pyobj_rlofParam = NULL;
    Ptr<RLOFOpticalFlowParameter> rlofParam;
    PyObject* pyobj_forwardBackwardThreshold = NULL;
    float forwardBackwardThreshold=1.f;
    PyObject* pyobj_gridStep = NULL;
    Size gridStep=Size(6, 6);
    PyObject* pyobj_interp_type = NULL;
    InterpolationType interp_type=InterpolationType::INTERP_EPIC;
    PyObject* pyobj_epicK = NULL;
    int epicK=128;
    PyObject* pyobj_epicSigma = NULL;
    float epicSigma=0.05f;
    PyObject* pyobj_epicLambda = NULL;
    float epicLambda=999.0f;
    PyObject* pyobj_ricSPSize = NULL;
    int ricSPSize=15;
    PyObject* pyobj_ricSLICType = NULL;
    int ricSLICType=100;
    PyObject* pyobj_use_post_proc = NULL;
    bool use_post_proc=true;
    PyObject* pyobj_fgsLambda = NULL;
    float fgsLambda=500.0f;
    PyObject* pyobj_fgsSigma = NULL;
    float fgsSigma=1.5f;
    PyObject* pyobj_use_variational_refinement = NULL;
    bool use_variational_refinement=false;
    Ptr<DenseRLOFOpticalFlow> retval;

    const char* keywords[] = { "rlofParam", "forwardBackwardThreshold", "gridStep", "interp_type", "epicK", "epicSigma", "epicLambda", "ricSPSize", "ricSLICType", "use_post_proc", "fgsLambda", "fgsSigma", "use_variational_refinement", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOOOOOOOOOO:DenseRLOFOpticalFlow_create", (char**)keywords, &pyobj_rlofParam, &pyobj_forwardBackwardThreshold, &pyobj_gridStep, &pyobj_interp_type, &pyobj_epicK, &pyobj_epicSigma, &pyobj_epicLambda, &pyobj_ricSPSize, &pyobj_ricSLICType, &pyobj_use_post_proc, &pyobj_fgsLambda, &pyobj_fgsSigma, &pyobj_use_variational_refinement) &&
        pyopencv_to_safe(pyobj_rlofParam, rlofParam, ArgInfo("rlofParam", 0)) &&
        pyopencv_to_safe(pyobj_forwardBackwardThreshold, forwardBackwardThreshold, ArgInfo("forwardBackwardThreshold", 0)) &&
        pyopencv_to_safe(pyobj_gridStep, gridStep, ArgInfo("gridStep", 0)) &&
        pyopencv_to_safe(pyobj_interp_type, interp_type, ArgInfo("interp_type", 0)) &&
        pyopencv_to_safe(pyobj_epicK, epicK, ArgInfo("epicK", 0)) &&
        pyopencv_to_safe(pyobj_epicSigma, epicSigma, ArgInfo("epicSigma", 0)) &&
        pyopencv_to_safe(pyobj_epicLambda, epicLambda, ArgInfo("epicLambda", 0)) &&
        pyopencv_to_safe(pyobj_ricSPSize, ricSPSize, ArgInfo("ricSPSize", 0)) &&
        pyopencv_to_safe(pyobj_ricSLICType, ricSLICType, ArgInfo("ricSLICType", 0)) &&
        pyopencv_to_safe(pyobj_use_post_proc, use_post_proc, ArgInfo("use_post_proc", 0)) &&
        pyopencv_to_safe(pyobj_fgsLambda, fgsLambda, ArgInfo("fgsLambda", 0)) &&
        pyopencv_to_safe(pyobj_fgsSigma, fgsSigma, ArgInfo("fgsSigma", 0)) &&
        pyopencv_to_safe(pyobj_use_variational_refinement, use_variational_refinement, ArgInfo("use_variational_refinement", 0)) )
    {
        ERRWRAP2(retval = cv::optflow::DenseRLOFOpticalFlow::create(rlofParam, forwardBackwardThreshold, gridStep, interp_type, epicK, epicSigma, epicLambda, ricSPSize, ricSLICType, use_post_proc, fgsLambda, fgsSigma, use_variational_refinement));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_DualTVL1OpticalFlow_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::optflow;

    PyObject* pyobj_tau = NULL;
    double tau=0.25;
    PyObject* pyobj_lambda = NULL;
    double lambda=0.15;
    PyObject* pyobj_theta = NULL;
    double theta=0.3;
    PyObject* pyobj_nscales = NULL;
    int nscales=5;
    PyObject* pyobj_warps = NULL;
    int warps=5;
    PyObject* pyobj_epsilon = NULL;
    double epsilon=0.01;
    PyObject* pyobj_innnerIterations = NULL;
    int innnerIterations=30;
    PyObject* pyobj_outerIterations = NULL;
    int outerIterations=10;
    PyObject* pyobj_scaleStep = NULL;
    double scaleStep=0.8;
    PyObject* pyobj_gamma = NULL;
    double gamma=0.0;
    PyObject* pyobj_medianFiltering = NULL;
    int medianFiltering=5;
    PyObject* pyobj_useInitialFlow = NULL;
    bool useInitialFlow=false;
    Ptr<DualTVL1OpticalFlow> retval;

    const char* keywords[] = { "tau", "lambda", "theta", "nscales", "warps", "epsilon", "innnerIterations", "outerIterations", "scaleStep", "gamma", "medianFiltering", "useInitialFlow", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOOOOOOOOO:DualTVL1OpticalFlow_create", (char**)keywords, &pyobj_tau, &pyobj_lambda, &pyobj_theta, &pyobj_nscales, &pyobj_warps, &pyobj_epsilon, &pyobj_innnerIterations, &pyobj_outerIterations, &pyobj_scaleStep, &pyobj_gamma, &pyobj_medianFiltering, &pyobj_useInitialFlow) &&
        pyopencv_to_safe(pyobj_tau, tau, ArgInfo("tau", 0)) &&
        pyopencv_to_safe(pyobj_lambda, lambda, ArgInfo("lambda", 0)) &&
        pyopencv_to_safe(pyobj_theta, theta, ArgInfo("theta", 0)) &&
        pyopencv_to_safe(pyobj_nscales, nscales, ArgInfo("nscales", 0)) &&
        pyopencv_to_safe(pyobj_warps, warps, ArgInfo("warps", 0)) &&
        pyopencv_to_safe(pyobj_epsilon, epsilon, ArgInfo("epsilon", 0)) &&
        pyopencv_to_safe(pyobj_innnerIterations, innnerIterations, ArgInfo("innnerIterations", 0)) &&
        pyopencv_to_safe(pyobj_outerIterations, outerIterations, ArgInfo("outerIterations", 0)) &&
        pyopencv_to_safe(pyobj_scaleStep, scaleStep, ArgInfo("scaleStep", 0)) &&
        pyopencv_to_safe(pyobj_gamma, gamma, ArgInfo("gamma", 0)) &&
        pyopencv_to_safe(pyobj_medianFiltering, medianFiltering, ArgInfo("medianFiltering", 0)) &&
        pyopencv_to_safe(pyobj_useInitialFlow, useInitialFlow, ArgInfo("useInitialFlow", 0)) )
    {
        ERRWRAP2(retval = cv::optflow::DualTVL1OpticalFlow::create(tau, lambda, theta, nscales, warps, epsilon, innnerIterations, outerIterations, scaleStep, gamma, medianFiltering, useInitialFlow));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_RLOFOpticalFlowParameter_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::optflow;

    Ptr<RLOFOpticalFlowParameter> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::optflow::RLOFOpticalFlowParameter::create());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_SparseRLOFOpticalFlow_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::optflow;

    PyObject* pyobj_rlofParam = NULL;
    Ptr<RLOFOpticalFlowParameter> rlofParam;
    PyObject* pyobj_forwardBackwardThreshold = NULL;
    float forwardBackwardThreshold=1.f;
    Ptr<SparseRLOFOpticalFlow> retval;

    const char* keywords[] = { "rlofParam", "forwardBackwardThreshold", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OO:SparseRLOFOpticalFlow_create", (char**)keywords, &pyobj_rlofParam, &pyobj_forwardBackwardThreshold) &&
        pyopencv_to_safe(pyobj_rlofParam, rlofParam, ArgInfo("rlofParam", 0)) &&
        pyopencv_to_safe(pyobj_forwardBackwardThreshold, forwardBackwardThreshold, ArgInfo("forwardBackwardThreshold", 0)) )
    {
        ERRWRAP2(retval = cv::optflow::SparseRLOFOpticalFlow::create(rlofParam, forwardBackwardThreshold));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_calcOpticalFlowDenseRLOF(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::optflow;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_I0 = NULL;
    Mat I0;
    PyObject* pyobj_I1 = NULL;
    Mat I1;
    PyObject* pyobj_flow = NULL;
    Mat flow;
    PyObject* pyobj_rlofParam = NULL;
    Ptr<RLOFOpticalFlowParameter> rlofParam;
    PyObject* pyobj_forwardBackwardThreshold = NULL;
    float forwardBackwardThreshold=0;
    PyObject* pyobj_gridStep = NULL;
    Size gridStep=Size(6, 6);
    PyObject* pyobj_interp_type = NULL;
    InterpolationType interp_type=InterpolationType::INTERP_EPIC;
    PyObject* pyobj_epicK = NULL;
    int epicK=128;
    PyObject* pyobj_epicSigma = NULL;
    float epicSigma=0.05f;
    PyObject* pyobj_epicLambda = NULL;
    float epicLambda=100.f;
    PyObject* pyobj_ricSPSize = NULL;
    int ricSPSize=15;
    PyObject* pyobj_ricSLICType = NULL;
    int ricSLICType=100;
    PyObject* pyobj_use_post_proc = NULL;
    bool use_post_proc=true;
    PyObject* pyobj_fgsLambda = NULL;
    float fgsLambda=500.0f;
    PyObject* pyobj_fgsSigma = NULL;
    float fgsSigma=1.5f;
    PyObject* pyobj_use_variational_refinement = NULL;
    bool use_variational_refinement=false;

    const char* keywords[] = { "I0", "I1", "flow", "rlofParam", "forwardBackwardThreshold", "gridStep", "interp_type", "epicK", "epicSigma", "epicLambda", "ricSPSize", "ricSLICType", "use_post_proc", "fgsLambda", "fgsSigma", "use_variational_refinement", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOOOOOOOOOOO:calcOpticalFlowDenseRLOF", (char**)keywords, &pyobj_I0, &pyobj_I1, &pyobj_flow, &pyobj_rlofParam, &pyobj_forwardBackwardThreshold, &pyobj_gridStep, &pyobj_interp_type, &pyobj_epicK, &pyobj_epicSigma, &pyobj_epicLambda, &pyobj_ricSPSize, &pyobj_ricSLICType, &pyobj_use_post_proc, &pyobj_fgsLambda, &pyobj_fgsSigma, &pyobj_use_variational_refinement) &&
        pyopencv_to_safe(pyobj_I0, I0, ArgInfo("I0", 0)) &&
        pyopencv_to_safe(pyobj_I1, I1, ArgInfo("I1", 0)) &&
        pyopencv_to_safe(pyobj_flow, flow, ArgInfo("flow", 1)) &&
        pyopencv_to_safe(pyobj_rlofParam, rlofParam, ArgInfo("rlofParam", 0)) &&
        pyopencv_to_safe(pyobj_forwardBackwardThreshold, forwardBackwardThreshold, ArgInfo("forwardBackwardThreshold", 0)) &&
        pyopencv_to_safe(pyobj_gridStep, gridStep, ArgInfo("gridStep", 0)) &&
        pyopencv_to_safe(pyobj_interp_type, interp_type, ArgInfo("interp_type", 0)) &&
        pyopencv_to_safe(pyobj_epicK, epicK, ArgInfo("epicK", 0)) &&
        pyopencv_to_safe(pyobj_epicSigma, epicSigma, ArgInfo("epicSigma", 0)) &&
        pyopencv_to_safe(pyobj_epicLambda, epicLambda, ArgInfo("epicLambda", 0)) &&
        pyopencv_to_safe(pyobj_ricSPSize, ricSPSize, ArgInfo("ricSPSize", 0)) &&
        pyopencv_to_safe(pyobj_ricSLICType, ricSLICType, ArgInfo("ricSLICType", 0)) &&
        pyopencv_to_safe(pyobj_use_post_proc, use_post_proc, ArgInfo("use_post_proc", 0)) &&
        pyopencv_to_safe(pyobj_fgsLambda, fgsLambda, ArgInfo("fgsLambda", 0)) &&
        pyopencv_to_safe(pyobj_fgsSigma, fgsSigma, ArgInfo("fgsSigma", 0)) &&
        pyopencv_to_safe(pyobj_use_variational_refinement, use_variational_refinement, ArgInfo("use_variational_refinement", 0)) )
    {
        ERRWRAP2(cv::optflow::calcOpticalFlowDenseRLOF(I0, I1, flow, rlofParam, forwardBackwardThreshold, gridStep, interp_type, epicK, epicSigma, epicLambda, ricSPSize, ricSLICType, use_post_proc, fgsLambda, fgsSigma, use_variational_refinement));
        return pyopencv_from(flow);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_I0 = NULL;
    UMat I0;
    PyObject* pyobj_I1 = NULL;
    UMat I1;
    PyObject* pyobj_flow = NULL;
    UMat flow;
    PyObject* pyobj_rlofParam = NULL;
    Ptr<RLOFOpticalFlowParameter> rlofParam;
    PyObject* pyobj_forwardBackwardThreshold = NULL;
    float forwardBackwardThreshold=0;
    PyObject* pyobj_gridStep = NULL;
    Size gridStep=Size(6, 6);
    PyObject* pyobj_interp_type = NULL;
    InterpolationType interp_type=InterpolationType::INTERP_EPIC;
    PyObject* pyobj_epicK = NULL;
    int epicK=128;
    PyObject* pyobj_epicSigma = NULL;
    float epicSigma=0.05f;
    PyObject* pyobj_epicLambda = NULL;
    float epicLambda=100.f;
    PyObject* pyobj_ricSPSize = NULL;
    int ricSPSize=15;
    PyObject* pyobj_ricSLICType = NULL;
    int ricSLICType=100;
    PyObject* pyobj_use_post_proc = NULL;
    bool use_post_proc=true;
    PyObject* pyobj_fgsLambda = NULL;
    float fgsLambda=500.0f;
    PyObject* pyobj_fgsSigma = NULL;
    float fgsSigma=1.5f;
    PyObject* pyobj_use_variational_refinement = NULL;
    bool use_variational_refinement=false;

    const char* keywords[] = { "I0", "I1", "flow", "rlofParam", "forwardBackwardThreshold", "gridStep", "interp_type", "epicK", "epicSigma", "epicLambda", "ricSPSize", "ricSLICType", "use_post_proc", "fgsLambda", "fgsSigma", "use_variational_refinement", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOOOOOOOOOOO:calcOpticalFlowDenseRLOF", (char**)keywords, &pyobj_I0, &pyobj_I1, &pyobj_flow, &pyobj_rlofParam, &pyobj_forwardBackwardThreshold, &pyobj_gridStep, &pyobj_interp_type, &pyobj_epicK, &pyobj_epicSigma, &pyobj_epicLambda, &pyobj_ricSPSize, &pyobj_ricSLICType, &pyobj_use_post_proc, &pyobj_fgsLambda, &pyobj_fgsSigma, &pyobj_use_variational_refinement) &&
        pyopencv_to_safe(pyobj_I0, I0, ArgInfo("I0", 0)) &&
        pyopencv_to_safe(pyobj_I1, I1, ArgInfo("I1", 0)) &&
        pyopencv_to_safe(pyobj_flow, flow, ArgInfo("flow", 1)) &&
        pyopencv_to_safe(pyobj_rlofParam, rlofParam, ArgInfo("rlofParam", 0)) &&
        pyopencv_to_safe(pyobj_forwardBackwardThreshold, forwardBackwardThreshold, ArgInfo("forwardBackwardThreshold", 0)) &&
        pyopencv_to_safe(pyobj_gridStep, gridStep, ArgInfo("gridStep", 0)) &&
        pyopencv_to_safe(pyobj_interp_type, interp_type, ArgInfo("interp_type", 0)) &&
        pyopencv_to_safe(pyobj_epicK, epicK, ArgInfo("epicK", 0)) &&
        pyopencv_to_safe(pyobj_epicSigma, epicSigma, ArgInfo("epicSigma", 0)) &&
        pyopencv_to_safe(pyobj_epicLambda, epicLambda, ArgInfo("epicLambda", 0)) &&
        pyopencv_to_safe(pyobj_ricSPSize, ricSPSize, ArgInfo("ricSPSize", 0)) &&
        pyopencv_to_safe(pyobj_ricSLICType, ricSLICType, ArgInfo("ricSLICType", 0)) &&
        pyopencv_to_safe(pyobj_use_post_proc, use_post_proc, ArgInfo("use_post_proc", 0)) &&
        pyopencv_to_safe(pyobj_fgsLambda, fgsLambda, ArgInfo("fgsLambda", 0)) &&
        pyopencv_to_safe(pyobj_fgsSigma, fgsSigma, ArgInfo("fgsSigma", 0)) &&
        pyopencv_to_safe(pyobj_use_variational_refinement, use_variational_refinement, ArgInfo("use_variational_refinement", 0)) )
    {
        ERRWRAP2(cv::optflow::calcOpticalFlowDenseRLOF(I0, I1, flow, rlofParam, forwardBackwardThreshold, gridStep, interp_type, epicK, epicSigma, epicLambda, ricSPSize, ricSLICType, use_post_proc, fgsLambda, fgsSigma, use_variational_refinement));
        return pyopencv_from(flow);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("calcOpticalFlowDenseRLOF");

    return NULL;
}

static PyObject* pyopencv_cv_optflow_calcOpticalFlowSF(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::optflow;

    pyPrepareArgumentConversionErrorsStorage(4);

    {
    PyObject* pyobj_from = NULL;
    Mat from;
    PyObject* pyobj_to = NULL;
    Mat to;
    PyObject* pyobj_flow = NULL;
    Mat flow;
    PyObject* pyobj_layers = NULL;
    int layers=0;
    PyObject* pyobj_averaging_block_size = NULL;
    int averaging_block_size=0;
    PyObject* pyobj_max_flow = NULL;
    int max_flow=0;

    const char* keywords[] = { "from", "to", "layers", "averaging_block_size", "max_flow", "flow", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|O:calcOpticalFlowSF", (char**)keywords, &pyobj_from, &pyobj_to, &pyobj_layers, &pyobj_averaging_block_size, &pyobj_max_flow, &pyobj_flow) &&
        pyopencv_to_safe(pyobj_from, from, ArgInfo("from", 0)) &&
        pyopencv_to_safe(pyobj_to, to, ArgInfo("to", 0)) &&
        pyopencv_to_safe(pyobj_flow, flow, ArgInfo("flow", 1)) &&
        pyopencv_to_safe(pyobj_layers, layers, ArgInfo("layers", 0)) &&
        pyopencv_to_safe(pyobj_averaging_block_size, averaging_block_size, ArgInfo("averaging_block_size", 0)) &&
        pyopencv_to_safe(pyobj_max_flow, max_flow, ArgInfo("max_flow", 0)) )
    {
        ERRWRAP2(cv::optflow::calcOpticalFlowSF(from, to, flow, layers, averaging_block_size, max_flow));
        return pyopencv_from(flow);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_from = NULL;
    UMat from;
    PyObject* pyobj_to = NULL;
    UMat to;
    PyObject* pyobj_flow = NULL;
    UMat flow;
    PyObject* pyobj_layers = NULL;
    int layers=0;
    PyObject* pyobj_averaging_block_size = NULL;
    int averaging_block_size=0;
    PyObject* pyobj_max_flow = NULL;
    int max_flow=0;

    const char* keywords[] = { "from", "to", "layers", "averaging_block_size", "max_flow", "flow", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|O:calcOpticalFlowSF", (char**)keywords, &pyobj_from, &pyobj_to, &pyobj_layers, &pyobj_averaging_block_size, &pyobj_max_flow, &pyobj_flow) &&
        pyopencv_to_safe(pyobj_from, from, ArgInfo("from", 0)) &&
        pyopencv_to_safe(pyobj_to, to, ArgInfo("to", 0)) &&
        pyopencv_to_safe(pyobj_flow, flow, ArgInfo("flow", 1)) &&
        pyopencv_to_safe(pyobj_layers, layers, ArgInfo("layers", 0)) &&
        pyopencv_to_safe(pyobj_averaging_block_size, averaging_block_size, ArgInfo("averaging_block_size", 0)) &&
        pyopencv_to_safe(pyobj_max_flow, max_flow, ArgInfo("max_flow", 0)) )
    {
        ERRWRAP2(cv::optflow::calcOpticalFlowSF(from, to, flow, layers, averaging_block_size, max_flow));
        return pyopencv_from(flow);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_from = NULL;
    Mat from;
    PyObject* pyobj_to = NULL;
    Mat to;
    PyObject* pyobj_flow = NULL;
    Mat flow;
    PyObject* pyobj_layers = NULL;
    int layers=0;
    PyObject* pyobj_averaging_block_size = NULL;
    int averaging_block_size=0;
    PyObject* pyobj_max_flow = NULL;
    int max_flow=0;
    PyObject* pyobj_sigma_dist = NULL;
    double sigma_dist=0;
    PyObject* pyobj_sigma_color = NULL;
    double sigma_color=0;
    PyObject* pyobj_postprocess_window = NULL;
    int postprocess_window=0;
    PyObject* pyobj_sigma_dist_fix = NULL;
    double sigma_dist_fix=0;
    PyObject* pyobj_sigma_color_fix = NULL;
    double sigma_color_fix=0;
    PyObject* pyobj_occ_thr = NULL;
    double occ_thr=0;
    PyObject* pyobj_upscale_averaging_radius = NULL;
    int upscale_averaging_radius=0;
    PyObject* pyobj_upscale_sigma_dist = NULL;
    double upscale_sigma_dist=0;
    PyObject* pyobj_upscale_sigma_color = NULL;
    double upscale_sigma_color=0;
    PyObject* pyobj_speed_up_thr = NULL;
    double speed_up_thr=0;

    const char* keywords[] = { "from", "to", "layers", "averaging_block_size", "max_flow", "sigma_dist", "sigma_color", "postprocess_window", "sigma_dist_fix", "sigma_color_fix", "occ_thr", "upscale_averaging_radius", "upscale_sigma_dist", "upscale_sigma_color", "speed_up_thr", "flow", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOOOOOOOOOO|O:calcOpticalFlowSF", (char**)keywords, &pyobj_from, &pyobj_to, &pyobj_layers, &pyobj_averaging_block_size, &pyobj_max_flow, &pyobj_sigma_dist, &pyobj_sigma_color, &pyobj_postprocess_window, &pyobj_sigma_dist_fix, &pyobj_sigma_color_fix, &pyobj_occ_thr, &pyobj_upscale_averaging_radius, &pyobj_upscale_sigma_dist, &pyobj_upscale_sigma_color, &pyobj_speed_up_thr, &pyobj_flow) &&
        pyopencv_to_safe(pyobj_from, from, ArgInfo("from", 0)) &&
        pyopencv_to_safe(pyobj_to, to, ArgInfo("to", 0)) &&
        pyopencv_to_safe(pyobj_flow, flow, ArgInfo("flow", 1)) &&
        pyopencv_to_safe(pyobj_layers, layers, ArgInfo("layers", 0)) &&
        pyopencv_to_safe(pyobj_averaging_block_size, averaging_block_size, ArgInfo("averaging_block_size", 0)) &&
        pyopencv_to_safe(pyobj_max_flow, max_flow, ArgInfo("max_flow", 0)) &&
        pyopencv_to_safe(pyobj_sigma_dist, sigma_dist, ArgInfo("sigma_dist", 0)) &&
        pyopencv_to_safe(pyobj_sigma_color, sigma_color, ArgInfo("sigma_color", 0)) &&
        pyopencv_to_safe(pyobj_postprocess_window, postprocess_window, ArgInfo("postprocess_window", 0)) &&
        pyopencv_to_safe(pyobj_sigma_dist_fix, sigma_dist_fix, ArgInfo("sigma_dist_fix", 0)) &&
        pyopencv_to_safe(pyobj_sigma_color_fix, sigma_color_fix, ArgInfo("sigma_color_fix", 0)) &&
        pyopencv_to_safe(pyobj_occ_thr, occ_thr, ArgInfo("occ_thr", 0)) &&
        pyopencv_to_safe(pyobj_upscale_averaging_radius, upscale_averaging_radius, ArgInfo("upscale_averaging_radius", 0)) &&
        pyopencv_to_safe(pyobj_upscale_sigma_dist, upscale_sigma_dist, ArgInfo("upscale_sigma_dist", 0)) &&
        pyopencv_to_safe(pyobj_upscale_sigma_color, upscale_sigma_color, ArgInfo("upscale_sigma_color", 0)) &&
        pyopencv_to_safe(pyobj_speed_up_thr, speed_up_thr, ArgInfo("speed_up_thr", 0)) )
    {
        ERRWRAP2(cv::optflow::calcOpticalFlowSF(from, to, flow, layers, averaging_block_size, max_flow, sigma_dist, sigma_color, postprocess_window, sigma_dist_fix, sigma_color_fix, occ_thr, upscale_averaging_radius, upscale_sigma_dist, upscale_sigma_color, speed_up_thr));
        return pyopencv_from(flow);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_from = NULL;
    UMat from;
    PyObject* pyobj_to = NULL;
    UMat to;
    PyObject* pyobj_flow = NULL;
    UMat flow;
    PyObject* pyobj_layers = NULL;
    int layers=0;
    PyObject* pyobj_averaging_block_size = NULL;
    int averaging_block_size=0;
    PyObject* pyobj_max_flow = NULL;
    int max_flow=0;
    PyObject* pyobj_sigma_dist = NULL;
    double sigma_dist=0;
    PyObject* pyobj_sigma_color = NULL;
    double sigma_color=0;
    PyObject* pyobj_postprocess_window = NULL;
    int postprocess_window=0;
    PyObject* pyobj_sigma_dist_fix = NULL;
    double sigma_dist_fix=0;
    PyObject* pyobj_sigma_color_fix = NULL;
    double sigma_color_fix=0;
    PyObject* pyobj_occ_thr = NULL;
    double occ_thr=0;
    PyObject* pyobj_upscale_averaging_radius = NULL;
    int upscale_averaging_radius=0;
    PyObject* pyobj_upscale_sigma_dist = NULL;
    double upscale_sigma_dist=0;
    PyObject* pyobj_upscale_sigma_color = NULL;
    double upscale_sigma_color=0;
    PyObject* pyobj_speed_up_thr = NULL;
    double speed_up_thr=0;

    const char* keywords[] = { "from", "to", "layers", "averaging_block_size", "max_flow", "sigma_dist", "sigma_color", "postprocess_window", "sigma_dist_fix", "sigma_color_fix", "occ_thr", "upscale_averaging_radius", "upscale_sigma_dist", "upscale_sigma_color", "speed_up_thr", "flow", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOOOOOOOOOO|O:calcOpticalFlowSF", (char**)keywords, &pyobj_from, &pyobj_to, &pyobj_layers, &pyobj_averaging_block_size, &pyobj_max_flow, &pyobj_sigma_dist, &pyobj_sigma_color, &pyobj_postprocess_window, &pyobj_sigma_dist_fix, &pyobj_sigma_color_fix, &pyobj_occ_thr, &pyobj_upscale_averaging_radius, &pyobj_upscale_sigma_dist, &pyobj_upscale_sigma_color, &pyobj_speed_up_thr, &pyobj_flow) &&
        pyopencv_to_safe(pyobj_from, from, ArgInfo("from", 0)) &&
        pyopencv_to_safe(pyobj_to, to, ArgInfo("to", 0)) &&
        pyopencv_to_safe(pyobj_flow, flow, ArgInfo("flow", 1)) &&
        pyopencv_to_safe(pyobj_layers, layers, ArgInfo("layers", 0)) &&
        pyopencv_to_safe(pyobj_averaging_block_size, averaging_block_size, ArgInfo("averaging_block_size", 0)) &&
        pyopencv_to_safe(pyobj_max_flow, max_flow, ArgInfo("max_flow", 0)) &&
        pyopencv_to_safe(pyobj_sigma_dist, sigma_dist, ArgInfo("sigma_dist", 0)) &&
        pyopencv_to_safe(pyobj_sigma_color, sigma_color, ArgInfo("sigma_color", 0)) &&
        pyopencv_to_safe(pyobj_postprocess_window, postprocess_window, ArgInfo("postprocess_window", 0)) &&
        pyopencv_to_safe(pyobj_sigma_dist_fix, sigma_dist_fix, ArgInfo("sigma_dist_fix", 0)) &&
        pyopencv_to_safe(pyobj_sigma_color_fix, sigma_color_fix, ArgInfo("sigma_color_fix", 0)) &&
        pyopencv_to_safe(pyobj_occ_thr, occ_thr, ArgInfo("occ_thr", 0)) &&
        pyopencv_to_safe(pyobj_upscale_averaging_radius, upscale_averaging_radius, ArgInfo("upscale_averaging_radius", 0)) &&
        pyopencv_to_safe(pyobj_upscale_sigma_dist, upscale_sigma_dist, ArgInfo("upscale_sigma_dist", 0)) &&
        pyopencv_to_safe(pyobj_upscale_sigma_color, upscale_sigma_color, ArgInfo("upscale_sigma_color", 0)) &&
        pyopencv_to_safe(pyobj_speed_up_thr, speed_up_thr, ArgInfo("speed_up_thr", 0)) )
    {
        ERRWRAP2(cv::optflow::calcOpticalFlowSF(from, to, flow, layers, averaging_block_size, max_flow, sigma_dist, sigma_color, postprocess_window, sigma_dist_fix, sigma_color_fix, occ_thr, upscale_averaging_radius, upscale_sigma_dist, upscale_sigma_color, speed_up_thr));
        return pyopencv_from(flow);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("calcOpticalFlowSF");

    return NULL;
}

static PyObject* pyopencv_cv_optflow_calcOpticalFlowSparseRLOF(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::optflow;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_prevImg = NULL;
    Mat prevImg;
    PyObject* pyobj_nextImg = NULL;
    Mat nextImg;
    PyObject* pyobj_prevPts = NULL;
    Mat prevPts;
    PyObject* pyobj_nextPts = NULL;
    Mat nextPts;
    PyObject* pyobj_status = NULL;
    Mat status;
    PyObject* pyobj_err = NULL;
    Mat err;
    PyObject* pyobj_rlofParam = NULL;
    Ptr<RLOFOpticalFlowParameter> rlofParam;
    PyObject* pyobj_forwardBackwardThreshold = NULL;
    float forwardBackwardThreshold=0;

    const char* keywords[] = { "prevImg", "nextImg", "prevPts", "nextPts", "status", "err", "rlofParam", "forwardBackwardThreshold", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOO:calcOpticalFlowSparseRLOF", (char**)keywords, &pyobj_prevImg, &pyobj_nextImg, &pyobj_prevPts, &pyobj_nextPts, &pyobj_status, &pyobj_err, &pyobj_rlofParam, &pyobj_forwardBackwardThreshold) &&
        pyopencv_to_safe(pyobj_prevImg, prevImg, ArgInfo("prevImg", 0)) &&
        pyopencv_to_safe(pyobj_nextImg, nextImg, ArgInfo("nextImg", 0)) &&
        pyopencv_to_safe(pyobj_prevPts, prevPts, ArgInfo("prevPts", 0)) &&
        pyopencv_to_safe(pyobj_nextPts, nextPts, ArgInfo("nextPts", 1)) &&
        pyopencv_to_safe(pyobj_status, status, ArgInfo("status", 1)) &&
        pyopencv_to_safe(pyobj_err, err, ArgInfo("err", 1)) &&
        pyopencv_to_safe(pyobj_rlofParam, rlofParam, ArgInfo("rlofParam", 0)) &&
        pyopencv_to_safe(pyobj_forwardBackwardThreshold, forwardBackwardThreshold, ArgInfo("forwardBackwardThreshold", 0)) )
    {
        ERRWRAP2(cv::optflow::calcOpticalFlowSparseRLOF(prevImg, nextImg, prevPts, nextPts, status, err, rlofParam, forwardBackwardThreshold));
        return Py_BuildValue("(NNN)", pyopencv_from(nextPts), pyopencv_from(status), pyopencv_from(err));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_prevImg = NULL;
    UMat prevImg;
    PyObject* pyobj_nextImg = NULL;
    UMat nextImg;
    PyObject* pyobj_prevPts = NULL;
    UMat prevPts;
    PyObject* pyobj_nextPts = NULL;
    UMat nextPts;
    PyObject* pyobj_status = NULL;
    UMat status;
    PyObject* pyobj_err = NULL;
    UMat err;
    PyObject* pyobj_rlofParam = NULL;
    Ptr<RLOFOpticalFlowParameter> rlofParam;
    PyObject* pyobj_forwardBackwardThreshold = NULL;
    float forwardBackwardThreshold=0;

    const char* keywords[] = { "prevImg", "nextImg", "prevPts", "nextPts", "status", "err", "rlofParam", "forwardBackwardThreshold", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOOO:calcOpticalFlowSparseRLOF", (char**)keywords, &pyobj_prevImg, &pyobj_nextImg, &pyobj_prevPts, &pyobj_nextPts, &pyobj_status, &pyobj_err, &pyobj_rlofParam, &pyobj_forwardBackwardThreshold) &&
        pyopencv_to_safe(pyobj_prevImg, prevImg, ArgInfo("prevImg", 0)) &&
        pyopencv_to_safe(pyobj_nextImg, nextImg, ArgInfo("nextImg", 0)) &&
        pyopencv_to_safe(pyobj_prevPts, prevPts, ArgInfo("prevPts", 0)) &&
        pyopencv_to_safe(pyobj_nextPts, nextPts, ArgInfo("nextPts", 1)) &&
        pyopencv_to_safe(pyobj_status, status, ArgInfo("status", 1)) &&
        pyopencv_to_safe(pyobj_err, err, ArgInfo("err", 1)) &&
        pyopencv_to_safe(pyobj_rlofParam, rlofParam, ArgInfo("rlofParam", 0)) &&
        pyopencv_to_safe(pyobj_forwardBackwardThreshold, forwardBackwardThreshold, ArgInfo("forwardBackwardThreshold", 0)) )
    {
        ERRWRAP2(cv::optflow::calcOpticalFlowSparseRLOF(prevImg, nextImg, prevPts, nextPts, status, err, rlofParam, forwardBackwardThreshold));
        return Py_BuildValue("(NNN)", pyopencv_from(nextPts), pyopencv_from(status), pyopencv_from(err));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("calcOpticalFlowSparseRLOF");

    return NULL;
}

static PyObject* pyopencv_cv_optflow_calcOpticalFlowSparseToDense(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::optflow;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_from = NULL;
    Mat from;
    PyObject* pyobj_to = NULL;
    Mat to;
    PyObject* pyobj_flow = NULL;
    Mat flow;
    PyObject* pyobj_grid_step = NULL;
    int grid_step=8;
    PyObject* pyobj_k = NULL;
    int k=128;
    PyObject* pyobj_sigma = NULL;
    float sigma=0.05f;
    PyObject* pyobj_use_post_proc = NULL;
    bool use_post_proc=true;
    PyObject* pyobj_fgs_lambda = NULL;
    float fgs_lambda=500.0f;
    PyObject* pyobj_fgs_sigma = NULL;
    float fgs_sigma=1.5f;

    const char* keywords[] = { "from", "to", "flow", "grid_step", "k", "sigma", "use_post_proc", "fgs_lambda", "fgs_sigma", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOOOOO:calcOpticalFlowSparseToDense", (char**)keywords, &pyobj_from, &pyobj_to, &pyobj_flow, &pyobj_grid_step, &pyobj_k, &pyobj_sigma, &pyobj_use_post_proc, &pyobj_fgs_lambda, &pyobj_fgs_sigma) &&
        pyopencv_to_safe(pyobj_from, from, ArgInfo("from", 0)) &&
        pyopencv_to_safe(pyobj_to, to, ArgInfo("to", 0)) &&
        pyopencv_to_safe(pyobj_flow, flow, ArgInfo("flow", 1)) &&
        pyopencv_to_safe(pyobj_grid_step, grid_step, ArgInfo("grid_step", 0)) &&
        pyopencv_to_safe(pyobj_k, k, ArgInfo("k", 0)) &&
        pyopencv_to_safe(pyobj_sigma, sigma, ArgInfo("sigma", 0)) &&
        pyopencv_to_safe(pyobj_use_post_proc, use_post_proc, ArgInfo("use_post_proc", 0)) &&
        pyopencv_to_safe(pyobj_fgs_lambda, fgs_lambda, ArgInfo("fgs_lambda", 0)) &&
        pyopencv_to_safe(pyobj_fgs_sigma, fgs_sigma, ArgInfo("fgs_sigma", 0)) )
    {
        ERRWRAP2(cv::optflow::calcOpticalFlowSparseToDense(from, to, flow, grid_step, k, sigma, use_post_proc, fgs_lambda, fgs_sigma));
        return pyopencv_from(flow);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_from = NULL;
    UMat from;
    PyObject* pyobj_to = NULL;
    UMat to;
    PyObject* pyobj_flow = NULL;
    UMat flow;
    PyObject* pyobj_grid_step = NULL;
    int grid_step=8;
    PyObject* pyobj_k = NULL;
    int k=128;
    PyObject* pyobj_sigma = NULL;
    float sigma=0.05f;
    PyObject* pyobj_use_post_proc = NULL;
    bool use_post_proc=true;
    PyObject* pyobj_fgs_lambda = NULL;
    float fgs_lambda=500.0f;
    PyObject* pyobj_fgs_sigma = NULL;
    float fgs_sigma=1.5f;

    const char* keywords[] = { "from", "to", "flow", "grid_step", "k", "sigma", "use_post_proc", "fgs_lambda", "fgs_sigma", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOOOOO:calcOpticalFlowSparseToDense", (char**)keywords, &pyobj_from, &pyobj_to, &pyobj_flow, &pyobj_grid_step, &pyobj_k, &pyobj_sigma, &pyobj_use_post_proc, &pyobj_fgs_lambda, &pyobj_fgs_sigma) &&
        pyopencv_to_safe(pyobj_from, from, ArgInfo("from", 0)) &&
        pyopencv_to_safe(pyobj_to, to, ArgInfo("to", 0)) &&
        pyopencv_to_safe(pyobj_flow, flow, ArgInfo("flow", 1)) &&
        pyopencv_to_safe(pyobj_grid_step, grid_step, ArgInfo("grid_step", 0)) &&
        pyopencv_to_safe(pyobj_k, k, ArgInfo("k", 0)) &&
        pyopencv_to_safe(pyobj_sigma, sigma, ArgInfo("sigma", 0)) &&
        pyopencv_to_safe(pyobj_use_post_proc, use_post_proc, ArgInfo("use_post_proc", 0)) &&
        pyopencv_to_safe(pyobj_fgs_lambda, fgs_lambda, ArgInfo("fgs_lambda", 0)) &&
        pyopencv_to_safe(pyobj_fgs_sigma, fgs_sigma, ArgInfo("fgs_sigma", 0)) )
    {
        ERRWRAP2(cv::optflow::calcOpticalFlowSparseToDense(from, to, flow, grid_step, k, sigma, use_post_proc, fgs_lambda, fgs_sigma));
        return pyopencv_from(flow);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("calcOpticalFlowSparseToDense");

    return NULL;
}

static PyObject* pyopencv_cv_optflow_createOptFlow_DeepFlow(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::optflow;

    Ptr<DenseOpticalFlow> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::optflow::createOptFlow_DeepFlow());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_createOptFlow_DenseRLOF(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::optflow;

    Ptr<DenseOpticalFlow> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::optflow::createOptFlow_DenseRLOF());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_createOptFlow_DualTVL1(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::optflow;

    Ptr<DualTVL1OpticalFlow> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::optflow::createOptFlow_DualTVL1());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_createOptFlow_Farneback(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::optflow;

    Ptr<DenseOpticalFlow> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::optflow::createOptFlow_Farneback());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_createOptFlow_PCAFlow(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::optflow;

    Ptr<DenseOpticalFlow> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::optflow::createOptFlow_PCAFlow());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_createOptFlow_SimpleFlow(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::optflow;

    Ptr<DenseOpticalFlow> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::optflow::createOptFlow_SimpleFlow());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_createOptFlow_SparseRLOF(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::optflow;

    Ptr<SparseOpticalFlow> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::optflow::createOptFlow_SparseRLOF());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_optflow_createOptFlow_SparseToDense(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::optflow;

    Ptr<DenseOpticalFlow> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::optflow::createOptFlow_SparseToDense());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_parallel_setParallelForBackend(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::parallel;

    PyObject* pyobj_backendName = NULL;
    std::string backendName;
    PyObject* pyobj_propagateNumThreads = NULL;
    bool propagateNumThreads=true;
    bool retval;

    const char* keywords[] = { "backendName", "propagateNumThreads", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:setParallelForBackend", (char**)keywords, &pyobj_backendName, &pyobj_propagateNumThreads) &&
        pyopencv_to_safe(pyobj_backendName, backendName, ArgInfo("backendName", 0)) &&
        pyopencv_to_safe(pyobj_propagateNumThreads, propagateNumThreads, ArgInfo("propagateNumThreads", 0)) )
    {
        ERRWRAP2(retval = cv::parallel::setParallelForBackend(backendName, propagateNumThreads));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_phase_unwrapping_HistogramPhaseUnwrapping_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::phase_unwrapping;

    PyObject* pyobj_parameters = NULL;
    HistogramPhaseUnwrapping_Params parameters=HistogramPhaseUnwrapping::Params();
    Ptr<HistogramPhaseUnwrapping> retval;

    const char* keywords[] = { "parameters", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|O:HistogramPhaseUnwrapping_create", (char**)keywords, &pyobj_parameters) &&
        pyopencv_to_safe(pyobj_parameters, parameters, ArgInfo("parameters", 0)) )
    {
        ERRWRAP2(retval = cv::phase_unwrapping::HistogramPhaseUnwrapping::create(parameters));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_plot_Plot2d_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::plot;

    pyPrepareArgumentConversionErrorsStorage(4);

    {
    PyObject* pyobj_data = NULL;
    Mat data;
    Ptr<Plot2d> retval;

    const char* keywords[] = { "data", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:Plot2d_create", (char**)keywords, &pyobj_data) &&
        pyopencv_to_safe(pyobj_data, data, ArgInfo("data", 0)) )
    {
        ERRWRAP2(retval = cv::plot::Plot2d::create(data));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_data = NULL;
    UMat data;
    Ptr<Plot2d> retval;

    const char* keywords[] = { "data", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:Plot2d_create", (char**)keywords, &pyobj_data) &&
        pyopencv_to_safe(pyobj_data, data, ArgInfo("data", 0)) )
    {
        ERRWRAP2(retval = cv::plot::Plot2d::create(data));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_dataX = NULL;
    Mat dataX;
    PyObject* pyobj_dataY = NULL;
    Mat dataY;
    Ptr<Plot2d> retval;

    const char* keywords[] = { "dataX", "dataY", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:Plot2d_create", (char**)keywords, &pyobj_dataX, &pyobj_dataY) &&
        pyopencv_to_safe(pyobj_dataX, dataX, ArgInfo("dataX", 0)) &&
        pyopencv_to_safe(pyobj_dataY, dataY, ArgInfo("dataY", 0)) )
    {
        ERRWRAP2(retval = cv::plot::Plot2d::create(dataX, dataY));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_dataX = NULL;
    UMat dataX;
    PyObject* pyobj_dataY = NULL;
    UMat dataY;
    Ptr<Plot2d> retval;

    const char* keywords[] = { "dataX", "dataY", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:Plot2d_create", (char**)keywords, &pyobj_dataX, &pyobj_dataY) &&
        pyopencv_to_safe(pyobj_dataX, dataX, ArgInfo("dataX", 0)) &&
        pyopencv_to_safe(pyobj_dataY, dataY, ArgInfo("dataY", 0)) )
    {
        ERRWRAP2(retval = cv::plot::Plot2d::create(dataX, dataY));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("Plot2d_create");

    return NULL;
}

static PyObject* pyopencv_cv_ppf_match_3d_addNoisePC(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ppf_match_3d;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_pc = NULL;
    Mat pc;
    PyObject* pyobj_scale = NULL;
    double scale=0;
    Mat retval;

    const char* keywords[] = { "pc", "scale", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:addNoisePC", (char**)keywords, &pyobj_pc, &pyobj_scale) &&
        pyopencv_to_safe(pyobj_pc, pc, ArgInfo("pc", 0)) &&
        pyopencv_to_safe(pyobj_scale, scale, ArgInfo("scale", 0)) )
    {
        ERRWRAP2(retval = cv::ppf_match_3d::addNoisePC(pc, scale));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_pc = NULL;
    Mat pc;
    PyObject* pyobj_scale = NULL;
    double scale=0;
    Mat retval;

    const char* keywords[] = { "pc", "scale", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:addNoisePC", (char**)keywords, &pyobj_pc, &pyobj_scale) &&
        pyopencv_to_safe(pyobj_pc, pc, ArgInfo("pc", 0)) &&
        pyopencv_to_safe(pyobj_scale, scale, ArgInfo("scale", 0)) )
    {
        ERRWRAP2(retval = cv::ppf_match_3d::addNoisePC(pc, scale));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("addNoisePC");

    return NULL;
}

static PyObject* pyopencv_cv_ppf_match_3d_computeNormalsPC3d(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ppf_match_3d;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_PC = NULL;
    Mat PC;
    PyObject* pyobj_PCNormals = NULL;
    Mat PCNormals;
    PyObject* pyobj_NumNeighbors = NULL;
    int NumNeighbors=0;
    PyObject* pyobj_FlipViewpoint = NULL;
    bool FlipViewpoint=0;
    PyObject* pyobj_viewpoint = NULL;
    Vec3f viewpoint;
    int retval;

    const char* keywords[] = { "PC", "NumNeighbors", "FlipViewpoint", "viewpoint", "PCNormals", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:computeNormalsPC3d", (char**)keywords, &pyobj_PC, &pyobj_NumNeighbors, &pyobj_FlipViewpoint, &pyobj_viewpoint, &pyobj_PCNormals) &&
        pyopencv_to_safe(pyobj_PC, PC, ArgInfo("PC", 0)) &&
        pyopencv_to_safe(pyobj_PCNormals, PCNormals, ArgInfo("PCNormals", 1)) &&
        pyopencv_to_safe(pyobj_NumNeighbors, NumNeighbors, ArgInfo("NumNeighbors", 0)) &&
        pyopencv_to_safe(pyobj_FlipViewpoint, FlipViewpoint, ArgInfo("FlipViewpoint", 0)) &&
        pyopencv_to_safe(pyobj_viewpoint, viewpoint, ArgInfo("viewpoint", 0)) )
    {
        ERRWRAP2(retval = cv::ppf_match_3d::computeNormalsPC3d(PC, PCNormals, NumNeighbors, FlipViewpoint, viewpoint));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(PCNormals));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_PC = NULL;
    Mat PC;
    PyObject* pyobj_PCNormals = NULL;
    Mat PCNormals;
    PyObject* pyobj_NumNeighbors = NULL;
    int NumNeighbors=0;
    PyObject* pyobj_FlipViewpoint = NULL;
    bool FlipViewpoint=0;
    PyObject* pyobj_viewpoint = NULL;
    Vec3f viewpoint;
    int retval;

    const char* keywords[] = { "PC", "NumNeighbors", "FlipViewpoint", "viewpoint", "PCNormals", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:computeNormalsPC3d", (char**)keywords, &pyobj_PC, &pyobj_NumNeighbors, &pyobj_FlipViewpoint, &pyobj_viewpoint, &pyobj_PCNormals) &&
        pyopencv_to_safe(pyobj_PC, PC, ArgInfo("PC", 0)) &&
        pyopencv_to_safe(pyobj_PCNormals, PCNormals, ArgInfo("PCNormals", 1)) &&
        pyopencv_to_safe(pyobj_NumNeighbors, NumNeighbors, ArgInfo("NumNeighbors", 0)) &&
        pyopencv_to_safe(pyobj_FlipViewpoint, FlipViewpoint, ArgInfo("FlipViewpoint", 0)) &&
        pyopencv_to_safe(pyobj_viewpoint, viewpoint, ArgInfo("viewpoint", 0)) )
    {
        ERRWRAP2(retval = cv::ppf_match_3d::computeNormalsPC3d(PC, PCNormals, NumNeighbors, FlipViewpoint, viewpoint));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(PCNormals));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("computeNormalsPC3d");

    return NULL;
}

static PyObject* pyopencv_cv_ppf_match_3d_getRandomPose(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ppf_match_3d;

    PyObject* pyobj_Pose = NULL;
    Matx44d Pose;

    const char* keywords[] = { "Pose", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:getRandomPose", (char**)keywords, &pyobj_Pose) &&
        pyopencv_to_safe(pyobj_Pose, Pose, ArgInfo("Pose", 0)) )
    {
        ERRWRAP2(cv::ppf_match_3d::getRandomPose(Pose));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ppf_match_3d_loadPLYSimple(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ppf_match_3d;

    char* fileName=(char*)"";
    PyObject* pyobj_withNormals = NULL;
    int withNormals=0;
    Mat retval;

    const char* keywords[] = { "fileName", "withNormals", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "s|O:loadPLYSimple", (char**)keywords, &fileName, &pyobj_withNormals) &&
        pyopencv_to_safe(pyobj_withNormals, withNormals, ArgInfo("withNormals", 0)) )
    {
        ERRWRAP2(retval = cv::ppf_match_3d::loadPLYSimple(fileName, withNormals));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ppf_match_3d_samplePCByQuantization(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ppf_match_3d;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_pc = NULL;
    Mat pc;
    PyObject* pyobj_xrange = NULL;
    Vec2f xrange;
    PyObject* pyobj_yrange = NULL;
    Vec2f yrange;
    PyObject* pyobj_zrange = NULL;
    Vec2f zrange;
    PyObject* pyobj_sample_step_relative = NULL;
    float sample_step_relative=0.f;
    PyObject* pyobj_weightByCenter = NULL;
    int weightByCenter=0;
    Mat retval;

    const char* keywords[] = { "pc", "xrange", "yrange", "zrange", "sample_step_relative", "weightByCenter", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|O:samplePCByQuantization", (char**)keywords, &pyobj_pc, &pyobj_xrange, &pyobj_yrange, &pyobj_zrange, &pyobj_sample_step_relative, &pyobj_weightByCenter) &&
        pyopencv_to_safe(pyobj_pc, pc, ArgInfo("pc", 0)) &&
        pyopencv_to_safe(pyobj_xrange, xrange, ArgInfo("xrange", 0)) &&
        pyopencv_to_safe(pyobj_yrange, yrange, ArgInfo("yrange", 0)) &&
        pyopencv_to_safe(pyobj_zrange, zrange, ArgInfo("zrange", 0)) &&
        pyopencv_to_safe(pyobj_sample_step_relative, sample_step_relative, ArgInfo("sample_step_relative", 0)) &&
        pyopencv_to_safe(pyobj_weightByCenter, weightByCenter, ArgInfo("weightByCenter", 0)) )
    {
        ERRWRAP2(retval = cv::ppf_match_3d::samplePCByQuantization(pc, xrange, yrange, zrange, sample_step_relative, weightByCenter));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_pc = NULL;
    Mat pc;
    PyObject* pyobj_xrange = NULL;
    Vec2f xrange;
    PyObject* pyobj_yrange = NULL;
    Vec2f yrange;
    PyObject* pyobj_zrange = NULL;
    Vec2f zrange;
    PyObject* pyobj_sample_step_relative = NULL;
    float sample_step_relative=0.f;
    PyObject* pyobj_weightByCenter = NULL;
    int weightByCenter=0;
    Mat retval;

    const char* keywords[] = { "pc", "xrange", "yrange", "zrange", "sample_step_relative", "weightByCenter", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|O:samplePCByQuantization", (char**)keywords, &pyobj_pc, &pyobj_xrange, &pyobj_yrange, &pyobj_zrange, &pyobj_sample_step_relative, &pyobj_weightByCenter) &&
        pyopencv_to_safe(pyobj_pc, pc, ArgInfo("pc", 0)) &&
        pyopencv_to_safe(pyobj_xrange, xrange, ArgInfo("xrange", 0)) &&
        pyopencv_to_safe(pyobj_yrange, yrange, ArgInfo("yrange", 0)) &&
        pyopencv_to_safe(pyobj_zrange, zrange, ArgInfo("zrange", 0)) &&
        pyopencv_to_safe(pyobj_sample_step_relative, sample_step_relative, ArgInfo("sample_step_relative", 0)) &&
        pyopencv_to_safe(pyobj_weightByCenter, weightByCenter, ArgInfo("weightByCenter", 0)) )
    {
        ERRWRAP2(retval = cv::ppf_match_3d::samplePCByQuantization(pc, xrange, yrange, zrange, sample_step_relative, weightByCenter));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("samplePCByQuantization");

    return NULL;
}

static PyObject* pyopencv_cv_ppf_match_3d_transformPCPose(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ppf_match_3d;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_pc = NULL;
    Mat pc;
    PyObject* pyobj_Pose = NULL;
    Matx44d Pose;
    Mat retval;

    const char* keywords[] = { "pc", "Pose", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:transformPCPose", (char**)keywords, &pyobj_pc, &pyobj_Pose) &&
        pyopencv_to_safe(pyobj_pc, pc, ArgInfo("pc", 0)) &&
        pyopencv_to_safe(pyobj_Pose, Pose, ArgInfo("Pose", 0)) )
    {
        ERRWRAP2(retval = cv::ppf_match_3d::transformPCPose(pc, Pose));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_pc = NULL;
    Mat pc;
    PyObject* pyobj_Pose = NULL;
    Matx44d Pose;
    Mat retval;

    const char* keywords[] = { "pc", "Pose", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:transformPCPose", (char**)keywords, &pyobj_pc, &pyobj_Pose) &&
        pyopencv_to_safe(pyobj_pc, pc, ArgInfo("pc", 0)) &&
        pyopencv_to_safe(pyobj_Pose, Pose, ArgInfo("Pose", 0)) )
    {
        ERRWRAP2(retval = cv::ppf_match_3d::transformPCPose(pc, Pose));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("transformPCPose");

    return NULL;
}

static PyObject* pyopencv_cv_ppf_match_3d_writePLY(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ppf_match_3d;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_PC = NULL;
    Mat PC;
    char* fileName=(char*)"";

    const char* keywords[] = { "PC", "fileName", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "Os:writePLY", (char**)keywords, &pyobj_PC, &fileName) &&
        pyopencv_to_safe(pyobj_PC, PC, ArgInfo("PC", 0)) )
    {
        ERRWRAP2(cv::ppf_match_3d::writePLY(PC, fileName));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_PC = NULL;
    Mat PC;
    char* fileName=(char*)"";

    const char* keywords[] = { "PC", "fileName", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "Os:writePLY", (char**)keywords, &pyobj_PC, &fileName) &&
        pyopencv_to_safe(pyobj_PC, PC, ArgInfo("PC", 0)) )
    {
        ERRWRAP2(cv::ppf_match_3d::writePLY(PC, fileName));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("writePLY");

    return NULL;
}

static PyObject* pyopencv_cv_ppf_match_3d_writePLYVisibleNormals(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ppf_match_3d;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_PC = NULL;
    Mat PC;
    char* fileName=(char*)"";

    const char* keywords[] = { "PC", "fileName", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "Os:writePLYVisibleNormals", (char**)keywords, &pyobj_PC, &fileName) &&
        pyopencv_to_safe(pyobj_PC, PC, ArgInfo("PC", 0)) )
    {
        ERRWRAP2(cv::ppf_match_3d::writePLYVisibleNormals(PC, fileName));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_PC = NULL;
    Mat PC;
    char* fileName=(char*)"";

    const char* keywords[] = { "PC", "fileName", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "Os:writePLYVisibleNormals", (char**)keywords, &pyobj_PC, &fileName) &&
        pyopencv_to_safe(pyobj_PC, PC, ArgInfo("PC", 0)) )
    {
        ERRWRAP2(cv::ppf_match_3d::writePLYVisibleNormals(PC, fileName));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("writePLYVisibleNormals");

    return NULL;
}

static PyObject* pyopencv_cv_quality_QualityBRISQUE_compute(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::quality;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_model_file_path = NULL;
    String model_file_path;
    PyObject* pyobj_range_file_path = NULL;
    String range_file_path;
    cv::Scalar retval;

    const char* keywords[] = { "img", "model_file_path", "range_file_path", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:QualityBRISQUE_compute", (char**)keywords, &pyobj_img, &pyobj_model_file_path, &pyobj_range_file_path) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_model_file_path, model_file_path, ArgInfo("model_file_path", 0)) &&
        pyopencv_to_safe(pyobj_range_file_path, range_file_path, ArgInfo("range_file_path", 0)) )
    {
        ERRWRAP2(retval = cv::quality::QualityBRISQUE::compute(img, model_file_path, range_file_path));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_model_file_path = NULL;
    String model_file_path;
    PyObject* pyobj_range_file_path = NULL;
    String range_file_path;
    cv::Scalar retval;

    const char* keywords[] = { "img", "model_file_path", "range_file_path", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:QualityBRISQUE_compute", (char**)keywords, &pyobj_img, &pyobj_model_file_path, &pyobj_range_file_path) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_model_file_path, model_file_path, ArgInfo("model_file_path", 0)) &&
        pyopencv_to_safe(pyobj_range_file_path, range_file_path, ArgInfo("range_file_path", 0)) )
    {
        ERRWRAP2(retval = cv::quality::QualityBRISQUE::compute(img, model_file_path, range_file_path));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("QualityBRISQUE_compute");

    return NULL;
}

static PyObject* pyopencv_cv_quality_QualityBRISQUE_computeFeatures(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::quality;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_features = NULL;
    Mat features;

    const char* keywords[] = { "img", "features", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:QualityBRISQUE_computeFeatures", (char**)keywords, &pyobj_img, &pyobj_features) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_features, features, ArgInfo("features", 1)) )
    {
        ERRWRAP2(cv::quality::QualityBRISQUE::computeFeatures(img, features));
        return pyopencv_from(features);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_features = NULL;
    UMat features;

    const char* keywords[] = { "img", "features", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:QualityBRISQUE_computeFeatures", (char**)keywords, &pyobj_img, &pyobj_features) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_features, features, ArgInfo("features", 1)) )
    {
        ERRWRAP2(cv::quality::QualityBRISQUE::computeFeatures(img, features));
        return pyopencv_from(features);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("QualityBRISQUE_computeFeatures");

    return NULL;
}

static PyObject* pyopencv_cv_quality_QualityBRISQUE_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::quality;

    pyPrepareArgumentConversionErrorsStorage(3);

    {
    PyObject* pyobj_model_file_path = NULL;
    String model_file_path;
    PyObject* pyobj_range_file_path = NULL;
    String range_file_path;
    Ptr<QualityBRISQUE> retval;

    const char* keywords[] = { "model_file_path", "range_file_path", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:QualityBRISQUE_create", (char**)keywords, &pyobj_model_file_path, &pyobj_range_file_path) &&
        pyopencv_to_safe(pyobj_model_file_path, model_file_path, ArgInfo("model_file_path", 0)) &&
        pyopencv_to_safe(pyobj_range_file_path, range_file_path, ArgInfo("range_file_path", 0)) )
    {
        ERRWRAP2(retval = cv::quality::QualityBRISQUE::create(model_file_path, range_file_path));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_model = NULL;
    Ptr<ml::SVM> model;
    PyObject* pyobj_range = NULL;
    Mat range;
    Ptr<QualityBRISQUE> retval;

    const char* keywords[] = { "model", "range", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:QualityBRISQUE_create", (char**)keywords, &pyobj_model, &pyobj_range) &&
        pyopencv_to_safe(pyobj_model, model, ArgInfo("model", 0)) &&
        pyopencv_to_safe(pyobj_range, range, ArgInfo("range", 0)) )
    {
        ERRWRAP2(retval = cv::quality::QualityBRISQUE::create(model, range));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_model = NULL;
    Ptr<ml::SVM> model;
    PyObject* pyobj_range = NULL;
    Mat range;
    Ptr<QualityBRISQUE> retval;

    const char* keywords[] = { "model", "range", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:QualityBRISQUE_create", (char**)keywords, &pyobj_model, &pyobj_range) &&
        pyopencv_to_safe(pyobj_model, model, ArgInfo("model", 0)) &&
        pyopencv_to_safe(pyobj_range, range, ArgInfo("range", 0)) )
    {
        ERRWRAP2(retval = cv::quality::QualityBRISQUE::create(model, range));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("QualityBRISQUE_create");

    return NULL;
}

static PyObject* pyopencv_cv_quality_QualityGMSD_compute(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::quality;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_ref = NULL;
    Mat ref;
    PyObject* pyobj_cmp = NULL;
    Mat cmp;
    PyObject* pyobj_qualityMap = NULL;
    Mat qualityMap;
    cv::Scalar retval;

    const char* keywords[] = { "ref", "cmp", "qualityMap", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:QualityGMSD_compute", (char**)keywords, &pyobj_ref, &pyobj_cmp, &pyobj_qualityMap) &&
        pyopencv_to_safe(pyobj_ref, ref, ArgInfo("ref", 0)) &&
        pyopencv_to_safe(pyobj_cmp, cmp, ArgInfo("cmp", 0)) &&
        pyopencv_to_safe(pyobj_qualityMap, qualityMap, ArgInfo("qualityMap", 1)) )
    {
        ERRWRAP2(retval = cv::quality::QualityGMSD::compute(ref, cmp, qualityMap));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(qualityMap));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_ref = NULL;
    UMat ref;
    PyObject* pyobj_cmp = NULL;
    UMat cmp;
    PyObject* pyobj_qualityMap = NULL;
    UMat qualityMap;
    cv::Scalar retval;

    const char* keywords[] = { "ref", "cmp", "qualityMap", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:QualityGMSD_compute", (char**)keywords, &pyobj_ref, &pyobj_cmp, &pyobj_qualityMap) &&
        pyopencv_to_safe(pyobj_ref, ref, ArgInfo("ref", 0)) &&
        pyopencv_to_safe(pyobj_cmp, cmp, ArgInfo("cmp", 0)) &&
        pyopencv_to_safe(pyobj_qualityMap, qualityMap, ArgInfo("qualityMap", 1)) )
    {
        ERRWRAP2(retval = cv::quality::QualityGMSD::compute(ref, cmp, qualityMap));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(qualityMap));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("QualityGMSD_compute");

    return NULL;
}

static PyObject* pyopencv_cv_quality_QualityGMSD_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::quality;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_ref = NULL;
    Mat ref;
    Ptr<QualityGMSD> retval;

    const char* keywords[] = { "ref", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:QualityGMSD_create", (char**)keywords, &pyobj_ref) &&
        pyopencv_to_safe(pyobj_ref, ref, ArgInfo("ref", 0)) )
    {
        ERRWRAP2(retval = cv::quality::QualityGMSD::create(ref));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_ref = NULL;
    UMat ref;
    Ptr<QualityGMSD> retval;

    const char* keywords[] = { "ref", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:QualityGMSD_create", (char**)keywords, &pyobj_ref) &&
        pyopencv_to_safe(pyobj_ref, ref, ArgInfo("ref", 0)) )
    {
        ERRWRAP2(retval = cv::quality::QualityGMSD::create(ref));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("QualityGMSD_create");

    return NULL;
}

static PyObject* pyopencv_cv_quality_QualityMSE_compute(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::quality;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_ref = NULL;
    Mat ref;
    PyObject* pyobj_cmp = NULL;
    Mat cmp;
    PyObject* pyobj_qualityMap = NULL;
    Mat qualityMap;
    cv::Scalar retval;

    const char* keywords[] = { "ref", "cmp", "qualityMap", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:QualityMSE_compute", (char**)keywords, &pyobj_ref, &pyobj_cmp, &pyobj_qualityMap) &&
        pyopencv_to_safe(pyobj_ref, ref, ArgInfo("ref", 0)) &&
        pyopencv_to_safe(pyobj_cmp, cmp, ArgInfo("cmp", 0)) &&
        pyopencv_to_safe(pyobj_qualityMap, qualityMap, ArgInfo("qualityMap", 1)) )
    {
        ERRWRAP2(retval = cv::quality::QualityMSE::compute(ref, cmp, qualityMap));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(qualityMap));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_ref = NULL;
    UMat ref;
    PyObject* pyobj_cmp = NULL;
    UMat cmp;
    PyObject* pyobj_qualityMap = NULL;
    UMat qualityMap;
    cv::Scalar retval;

    const char* keywords[] = { "ref", "cmp", "qualityMap", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:QualityMSE_compute", (char**)keywords, &pyobj_ref, &pyobj_cmp, &pyobj_qualityMap) &&
        pyopencv_to_safe(pyobj_ref, ref, ArgInfo("ref", 0)) &&
        pyopencv_to_safe(pyobj_cmp, cmp, ArgInfo("cmp", 0)) &&
        pyopencv_to_safe(pyobj_qualityMap, qualityMap, ArgInfo("qualityMap", 1)) )
    {
        ERRWRAP2(retval = cv::quality::QualityMSE::compute(ref, cmp, qualityMap));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(qualityMap));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("QualityMSE_compute");

    return NULL;
}

static PyObject* pyopencv_cv_quality_QualityMSE_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::quality;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_ref = NULL;
    Mat ref;
    Ptr<QualityMSE> retval;

    const char* keywords[] = { "ref", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:QualityMSE_create", (char**)keywords, &pyobj_ref) &&
        pyopencv_to_safe(pyobj_ref, ref, ArgInfo("ref", 0)) )
    {
        ERRWRAP2(retval = cv::quality::QualityMSE::create(ref));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_ref = NULL;
    UMat ref;
    Ptr<QualityMSE> retval;

    const char* keywords[] = { "ref", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:QualityMSE_create", (char**)keywords, &pyobj_ref) &&
        pyopencv_to_safe(pyobj_ref, ref, ArgInfo("ref", 0)) )
    {
        ERRWRAP2(retval = cv::quality::QualityMSE::create(ref));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("QualityMSE_create");

    return NULL;
}

static PyObject* pyopencv_cv_quality_QualityPSNR_compute(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::quality;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_ref = NULL;
    Mat ref;
    PyObject* pyobj_cmp = NULL;
    Mat cmp;
    PyObject* pyobj_qualityMap = NULL;
    Mat qualityMap;
    PyObject* pyobj_maxPixelValue = NULL;
    double maxPixelValue=QualityPSNR::MAX_PIXEL_VALUE_DEFAULT;
    cv::Scalar retval;

    const char* keywords[] = { "ref", "cmp", "qualityMap", "maxPixelValue", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:QualityPSNR_compute", (char**)keywords, &pyobj_ref, &pyobj_cmp, &pyobj_qualityMap, &pyobj_maxPixelValue) &&
        pyopencv_to_safe(pyobj_ref, ref, ArgInfo("ref", 0)) &&
        pyopencv_to_safe(pyobj_cmp, cmp, ArgInfo("cmp", 0)) &&
        pyopencv_to_safe(pyobj_qualityMap, qualityMap, ArgInfo("qualityMap", 1)) &&
        pyopencv_to_safe(pyobj_maxPixelValue, maxPixelValue, ArgInfo("maxPixelValue", 0)) )
    {
        ERRWRAP2(retval = cv::quality::QualityPSNR::compute(ref, cmp, qualityMap, maxPixelValue));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(qualityMap));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_ref = NULL;
    UMat ref;
    PyObject* pyobj_cmp = NULL;
    UMat cmp;
    PyObject* pyobj_qualityMap = NULL;
    UMat qualityMap;
    PyObject* pyobj_maxPixelValue = NULL;
    double maxPixelValue=QualityPSNR::MAX_PIXEL_VALUE_DEFAULT;
    cv::Scalar retval;

    const char* keywords[] = { "ref", "cmp", "qualityMap", "maxPixelValue", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:QualityPSNR_compute", (char**)keywords, &pyobj_ref, &pyobj_cmp, &pyobj_qualityMap, &pyobj_maxPixelValue) &&
        pyopencv_to_safe(pyobj_ref, ref, ArgInfo("ref", 0)) &&
        pyopencv_to_safe(pyobj_cmp, cmp, ArgInfo("cmp", 0)) &&
        pyopencv_to_safe(pyobj_qualityMap, qualityMap, ArgInfo("qualityMap", 1)) &&
        pyopencv_to_safe(pyobj_maxPixelValue, maxPixelValue, ArgInfo("maxPixelValue", 0)) )
    {
        ERRWRAP2(retval = cv::quality::QualityPSNR::compute(ref, cmp, qualityMap, maxPixelValue));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(qualityMap));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("QualityPSNR_compute");

    return NULL;
}

static PyObject* pyopencv_cv_quality_QualityPSNR_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::quality;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_ref = NULL;
    Mat ref;
    PyObject* pyobj_maxPixelValue = NULL;
    double maxPixelValue=QualityPSNR::MAX_PIXEL_VALUE_DEFAULT;
    Ptr<QualityPSNR> retval;

    const char* keywords[] = { "ref", "maxPixelValue", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:QualityPSNR_create", (char**)keywords, &pyobj_ref, &pyobj_maxPixelValue) &&
        pyopencv_to_safe(pyobj_ref, ref, ArgInfo("ref", 0)) &&
        pyopencv_to_safe(pyobj_maxPixelValue, maxPixelValue, ArgInfo("maxPixelValue", 0)) )
    {
        ERRWRAP2(retval = cv::quality::QualityPSNR::create(ref, maxPixelValue));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_ref = NULL;
    UMat ref;
    PyObject* pyobj_maxPixelValue = NULL;
    double maxPixelValue=QualityPSNR::MAX_PIXEL_VALUE_DEFAULT;
    Ptr<QualityPSNR> retval;

    const char* keywords[] = { "ref", "maxPixelValue", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:QualityPSNR_create", (char**)keywords, &pyobj_ref, &pyobj_maxPixelValue) &&
        pyopencv_to_safe(pyobj_ref, ref, ArgInfo("ref", 0)) &&
        pyopencv_to_safe(pyobj_maxPixelValue, maxPixelValue, ArgInfo("maxPixelValue", 0)) )
    {
        ERRWRAP2(retval = cv::quality::QualityPSNR::create(ref, maxPixelValue));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("QualityPSNR_create");

    return NULL;
}

static PyObject* pyopencv_cv_quality_QualitySSIM_compute(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::quality;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_ref = NULL;
    Mat ref;
    PyObject* pyobj_cmp = NULL;
    Mat cmp;
    PyObject* pyobj_qualityMap = NULL;
    Mat qualityMap;
    cv::Scalar retval;

    const char* keywords[] = { "ref", "cmp", "qualityMap", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:QualitySSIM_compute", (char**)keywords, &pyobj_ref, &pyobj_cmp, &pyobj_qualityMap) &&
        pyopencv_to_safe(pyobj_ref, ref, ArgInfo("ref", 0)) &&
        pyopencv_to_safe(pyobj_cmp, cmp, ArgInfo("cmp", 0)) &&
        pyopencv_to_safe(pyobj_qualityMap, qualityMap, ArgInfo("qualityMap", 1)) )
    {
        ERRWRAP2(retval = cv::quality::QualitySSIM::compute(ref, cmp, qualityMap));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(qualityMap));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_ref = NULL;
    UMat ref;
    PyObject* pyobj_cmp = NULL;
    UMat cmp;
    PyObject* pyobj_qualityMap = NULL;
    UMat qualityMap;
    cv::Scalar retval;

    const char* keywords[] = { "ref", "cmp", "qualityMap", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:QualitySSIM_compute", (char**)keywords, &pyobj_ref, &pyobj_cmp, &pyobj_qualityMap) &&
        pyopencv_to_safe(pyobj_ref, ref, ArgInfo("ref", 0)) &&
        pyopencv_to_safe(pyobj_cmp, cmp, ArgInfo("cmp", 0)) &&
        pyopencv_to_safe(pyobj_qualityMap, qualityMap, ArgInfo("qualityMap", 1)) )
    {
        ERRWRAP2(retval = cv::quality::QualitySSIM::compute(ref, cmp, qualityMap));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(qualityMap));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("QualitySSIM_compute");

    return NULL;
}

static PyObject* pyopencv_cv_quality_QualitySSIM_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::quality;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_ref = NULL;
    Mat ref;
    Ptr<QualitySSIM> retval;

    const char* keywords[] = { "ref", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:QualitySSIM_create", (char**)keywords, &pyobj_ref) &&
        pyopencv_to_safe(pyobj_ref, ref, ArgInfo("ref", 0)) )
    {
        ERRWRAP2(retval = cv::quality::QualitySSIM::create(ref));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_ref = NULL;
    UMat ref;
    Ptr<QualitySSIM> retval;

    const char* keywords[] = { "ref", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:QualitySSIM_create", (char**)keywords, &pyobj_ref) &&
        pyopencv_to_safe(pyobj_ref, ref, ArgInfo("ref", 0)) )
    {
        ERRWRAP2(retval = cv::quality::QualitySSIM::create(ref));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("QualitySSIM_create");

    return NULL;
}

static PyObject* pyopencv_cv_rapid_OLSTracker_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::rapid;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_pts3d = NULL;
    Mat pts3d;
    PyObject* pyobj_tris = NULL;
    Mat tris;
    PyObject* pyobj_histBins = NULL;
    int histBins=8;
    PyObject* pyobj_sobelThesh = NULL;
    uchar sobelThesh=10;
    Ptr<OLSTracker> retval;

    const char* keywords[] = { "pts3d", "tris", "histBins", "sobelThesh", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:OLSTracker_create", (char**)keywords, &pyobj_pts3d, &pyobj_tris, &pyobj_histBins, &pyobj_sobelThesh) &&
        pyopencv_to_safe(pyobj_pts3d, pts3d, ArgInfo("pts3d", 0)) &&
        pyopencv_to_safe(pyobj_tris, tris, ArgInfo("tris", 0)) &&
        pyopencv_to_safe(pyobj_histBins, histBins, ArgInfo("histBins", 0)) &&
        pyopencv_to_safe(pyobj_sobelThesh, sobelThesh, ArgInfo("sobelThesh", 0)) )
    {
        ERRWRAP2(retval = cv::rapid::OLSTracker::create(pts3d, tris, histBins, sobelThesh));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_pts3d = NULL;
    UMat pts3d;
    PyObject* pyobj_tris = NULL;
    UMat tris;
    PyObject* pyobj_histBins = NULL;
    int histBins=8;
    PyObject* pyobj_sobelThesh = NULL;
    uchar sobelThesh=10;
    Ptr<OLSTracker> retval;

    const char* keywords[] = { "pts3d", "tris", "histBins", "sobelThesh", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:OLSTracker_create", (char**)keywords, &pyobj_pts3d, &pyobj_tris, &pyobj_histBins, &pyobj_sobelThesh) &&
        pyopencv_to_safe(pyobj_pts3d, pts3d, ArgInfo("pts3d", 0)) &&
        pyopencv_to_safe(pyobj_tris, tris, ArgInfo("tris", 0)) &&
        pyopencv_to_safe(pyobj_histBins, histBins, ArgInfo("histBins", 0)) &&
        pyopencv_to_safe(pyobj_sobelThesh, sobelThesh, ArgInfo("sobelThesh", 0)) )
    {
        ERRWRAP2(retval = cv::rapid::OLSTracker::create(pts3d, tris, histBins, sobelThesh));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("OLSTracker_create");

    return NULL;
}

static PyObject* pyopencv_cv_rapid_Rapid_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::rapid;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_pts3d = NULL;
    Mat pts3d;
    PyObject* pyobj_tris = NULL;
    Mat tris;
    Ptr<Rapid> retval;

    const char* keywords[] = { "pts3d", "tris", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:Rapid_create", (char**)keywords, &pyobj_pts3d, &pyobj_tris) &&
        pyopencv_to_safe(pyobj_pts3d, pts3d, ArgInfo("pts3d", 0)) &&
        pyopencv_to_safe(pyobj_tris, tris, ArgInfo("tris", 0)) )
    {
        ERRWRAP2(retval = cv::rapid::Rapid::create(pts3d, tris));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_pts3d = NULL;
    UMat pts3d;
    PyObject* pyobj_tris = NULL;
    UMat tris;
    Ptr<Rapid> retval;

    const char* keywords[] = { "pts3d", "tris", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:Rapid_create", (char**)keywords, &pyobj_pts3d, &pyobj_tris) &&
        pyopencv_to_safe(pyobj_pts3d, pts3d, ArgInfo("pts3d", 0)) &&
        pyopencv_to_safe(pyobj_tris, tris, ArgInfo("tris", 0)) )
    {
        ERRWRAP2(retval = cv::rapid::Rapid::create(pts3d, tris));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("Rapid_create");

    return NULL;
}

static PyObject* pyopencv_cv_rapid_convertCorrespondencies(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::rapid;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_cols = NULL;
    Mat cols;
    PyObject* pyobj_srcLocations = NULL;
    Mat srcLocations;
    PyObject* pyobj_pts2d = NULL;
    Mat pts2d;
    PyObject* pyobj_pts3d = NULL;
    Mat pts3d;
    PyObject* pyobj_mask = NULL;
    Mat mask;

    const char* keywords[] = { "cols", "srcLocations", "pts2d", "pts3d", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:convertCorrespondencies", (char**)keywords, &pyobj_cols, &pyobj_srcLocations, &pyobj_pts2d, &pyobj_pts3d, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_cols, cols, ArgInfo("cols", 0)) &&
        pyopencv_to_safe(pyobj_srcLocations, srcLocations, ArgInfo("srcLocations", 0)) &&
        pyopencv_to_safe(pyobj_pts2d, pts2d, ArgInfo("pts2d", 1)) &&
        pyopencv_to_safe(pyobj_pts3d, pts3d, ArgInfo("pts3d", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::rapid::convertCorrespondencies(cols, srcLocations, pts2d, pts3d, mask));
        return Py_BuildValue("(NN)", pyopencv_from(pts2d), pyopencv_from(pts3d));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_cols = NULL;
    UMat cols;
    PyObject* pyobj_srcLocations = NULL;
    UMat srcLocations;
    PyObject* pyobj_pts2d = NULL;
    UMat pts2d;
    PyObject* pyobj_pts3d = NULL;
    UMat pts3d;
    PyObject* pyobj_mask = NULL;
    UMat mask;

    const char* keywords[] = { "cols", "srcLocations", "pts2d", "pts3d", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:convertCorrespondencies", (char**)keywords, &pyobj_cols, &pyobj_srcLocations, &pyobj_pts2d, &pyobj_pts3d, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_cols, cols, ArgInfo("cols", 0)) &&
        pyopencv_to_safe(pyobj_srcLocations, srcLocations, ArgInfo("srcLocations", 0)) &&
        pyopencv_to_safe(pyobj_pts2d, pts2d, ArgInfo("pts2d", 1)) &&
        pyopencv_to_safe(pyobj_pts3d, pts3d, ArgInfo("pts3d", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::rapid::convertCorrespondencies(cols, srcLocations, pts2d, pts3d, mask));
        return Py_BuildValue("(NN)", pyopencv_from(pts2d), pyopencv_from(pts3d));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("convertCorrespondencies");

    return NULL;
}

static PyObject* pyopencv_cv_rapid_drawCorrespondencies(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::rapid;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_bundle = NULL;
    Mat bundle;
    PyObject* pyobj_cols = NULL;
    Mat cols;
    PyObject* pyobj_colors = NULL;
    Mat colors;

    const char* keywords[] = { "bundle", "cols", "colors", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:drawCorrespondencies", (char**)keywords, &pyobj_bundle, &pyobj_cols, &pyobj_colors) &&
        pyopencv_to_safe(pyobj_bundle, bundle, ArgInfo("bundle", 1)) &&
        pyopencv_to_safe(pyobj_cols, cols, ArgInfo("cols", 0)) &&
        pyopencv_to_safe(pyobj_colors, colors, ArgInfo("colors", 0)) )
    {
        ERRWRAP2(cv::rapid::drawCorrespondencies(bundle, cols, colors));
        return pyopencv_from(bundle);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_bundle = NULL;
    UMat bundle;
    PyObject* pyobj_cols = NULL;
    UMat cols;
    PyObject* pyobj_colors = NULL;
    UMat colors;

    const char* keywords[] = { "bundle", "cols", "colors", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:drawCorrespondencies", (char**)keywords, &pyobj_bundle, &pyobj_cols, &pyobj_colors) &&
        pyopencv_to_safe(pyobj_bundle, bundle, ArgInfo("bundle", 1)) &&
        pyopencv_to_safe(pyobj_cols, cols, ArgInfo("cols", 0)) &&
        pyopencv_to_safe(pyobj_colors, colors, ArgInfo("colors", 0)) )
    {
        ERRWRAP2(cv::rapid::drawCorrespondencies(bundle, cols, colors));
        return pyopencv_from(bundle);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("drawCorrespondencies");

    return NULL;
}

static PyObject* pyopencv_cv_rapid_drawSearchLines(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::rapid;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_locations = NULL;
    Mat locations;
    PyObject* pyobj_color = NULL;
    Scalar color;

    const char* keywords[] = { "img", "locations", "color", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:drawSearchLines", (char**)keywords, &pyobj_img, &pyobj_locations, &pyobj_color) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_locations, locations, ArgInfo("locations", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) )
    {
        ERRWRAP2(cv::rapid::drawSearchLines(img, locations, color));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_locations = NULL;
    UMat locations;
    PyObject* pyobj_color = NULL;
    Scalar color;

    const char* keywords[] = { "img", "locations", "color", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:drawSearchLines", (char**)keywords, &pyobj_img, &pyobj_locations, &pyobj_color) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_locations, locations, ArgInfo("locations", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) )
    {
        ERRWRAP2(cv::rapid::drawSearchLines(img, locations, color));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("drawSearchLines");

    return NULL;
}

static PyObject* pyopencv_cv_rapid_drawWireframe(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::rapid;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_pts2d = NULL;
    Mat pts2d;
    PyObject* pyobj_tris = NULL;
    Mat tris;
    PyObject* pyobj_color = NULL;
    Scalar color;
    PyObject* pyobj_type = NULL;
    int type=LINE_8;
    PyObject* pyobj_cullBackface = NULL;
    bool cullBackface=false;

    const char* keywords[] = { "img", "pts2d", "tris", "color", "type", "cullBackface", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OO:drawWireframe", (char**)keywords, &pyobj_img, &pyobj_pts2d, &pyobj_tris, &pyobj_color, &pyobj_type, &pyobj_cullBackface) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_pts2d, pts2d, ArgInfo("pts2d", 0)) &&
        pyopencv_to_safe(pyobj_tris, tris, ArgInfo("tris", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_type, type, ArgInfo("type", 0)) &&
        pyopencv_to_safe(pyobj_cullBackface, cullBackface, ArgInfo("cullBackface", 0)) )
    {
        ERRWRAP2(cv::rapid::drawWireframe(img, pts2d, tris, color, type, cullBackface));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_pts2d = NULL;
    UMat pts2d;
    PyObject* pyobj_tris = NULL;
    UMat tris;
    PyObject* pyobj_color = NULL;
    Scalar color;
    PyObject* pyobj_type = NULL;
    int type=LINE_8;
    PyObject* pyobj_cullBackface = NULL;
    bool cullBackface=false;

    const char* keywords[] = { "img", "pts2d", "tris", "color", "type", "cullBackface", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OO:drawWireframe", (char**)keywords, &pyobj_img, &pyobj_pts2d, &pyobj_tris, &pyobj_color, &pyobj_type, &pyobj_cullBackface) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 1)) &&
        pyopencv_to_safe(pyobj_pts2d, pts2d, ArgInfo("pts2d", 0)) &&
        pyopencv_to_safe(pyobj_tris, tris, ArgInfo("tris", 0)) &&
        pyopencv_to_safe(pyobj_color, color, ArgInfo("color", 0)) &&
        pyopencv_to_safe(pyobj_type, type, ArgInfo("type", 0)) &&
        pyopencv_to_safe(pyobj_cullBackface, cullBackface, ArgInfo("cullBackface", 0)) )
    {
        ERRWRAP2(cv::rapid::drawWireframe(img, pts2d, tris, color, type, cullBackface));
        return pyopencv_from(img);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("drawWireframe");

    return NULL;
}

static PyObject* pyopencv_cv_rapid_extractControlPoints(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::rapid;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_num = NULL;
    int num=0;
    PyObject* pyobj_len = NULL;
    int len=0;
    PyObject* pyobj_pts3d = NULL;
    Mat pts3d;
    PyObject* pyobj_rvec = NULL;
    Mat rvec;
    PyObject* pyobj_tvec = NULL;
    Mat tvec;
    PyObject* pyobj_K = NULL;
    Mat K;
    PyObject* pyobj_imsize = NULL;
    Size imsize;
    PyObject* pyobj_tris = NULL;
    Mat tris;
    PyObject* pyobj_ctl2d = NULL;
    Mat ctl2d;
    PyObject* pyobj_ctl3d = NULL;
    Mat ctl3d;

    const char* keywords[] = { "num", "len", "pts3d", "rvec", "tvec", "K", "imsize", "tris", "ctl2d", "ctl3d", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOOO|OO:extractControlPoints", (char**)keywords, &pyobj_num, &pyobj_len, &pyobj_pts3d, &pyobj_rvec, &pyobj_tvec, &pyobj_K, &pyobj_imsize, &pyobj_tris, &pyobj_ctl2d, &pyobj_ctl3d) &&
        pyopencv_to_safe(pyobj_num, num, ArgInfo("num", 0)) &&
        pyopencv_to_safe(pyobj_len, len, ArgInfo("len", 0)) &&
        pyopencv_to_safe(pyobj_pts3d, pts3d, ArgInfo("pts3d", 0)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 0)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 0)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_imsize, imsize, ArgInfo("imsize", 0)) &&
        pyopencv_to_safe(pyobj_tris, tris, ArgInfo("tris", 0)) &&
        pyopencv_to_safe(pyobj_ctl2d, ctl2d, ArgInfo("ctl2d", 1)) &&
        pyopencv_to_safe(pyobj_ctl3d, ctl3d, ArgInfo("ctl3d", 1)) )
    {
        ERRWRAP2(cv::rapid::extractControlPoints(num, len, pts3d, rvec, tvec, K, imsize, tris, ctl2d, ctl3d));
        return Py_BuildValue("(NN)", pyopencv_from(ctl2d), pyopencv_from(ctl3d));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_num = NULL;
    int num=0;
    PyObject* pyobj_len = NULL;
    int len=0;
    PyObject* pyobj_pts3d = NULL;
    UMat pts3d;
    PyObject* pyobj_rvec = NULL;
    UMat rvec;
    PyObject* pyobj_tvec = NULL;
    UMat tvec;
    PyObject* pyobj_K = NULL;
    UMat K;
    PyObject* pyobj_imsize = NULL;
    Size imsize;
    PyObject* pyobj_tris = NULL;
    UMat tris;
    PyObject* pyobj_ctl2d = NULL;
    UMat ctl2d;
    PyObject* pyobj_ctl3d = NULL;
    UMat ctl3d;

    const char* keywords[] = { "num", "len", "pts3d", "rvec", "tvec", "K", "imsize", "tris", "ctl2d", "ctl3d", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOOO|OO:extractControlPoints", (char**)keywords, &pyobj_num, &pyobj_len, &pyobj_pts3d, &pyobj_rvec, &pyobj_tvec, &pyobj_K, &pyobj_imsize, &pyobj_tris, &pyobj_ctl2d, &pyobj_ctl3d) &&
        pyopencv_to_safe(pyobj_num, num, ArgInfo("num", 0)) &&
        pyopencv_to_safe(pyobj_len, len, ArgInfo("len", 0)) &&
        pyopencv_to_safe(pyobj_pts3d, pts3d, ArgInfo("pts3d", 0)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 0)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 0)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_imsize, imsize, ArgInfo("imsize", 0)) &&
        pyopencv_to_safe(pyobj_tris, tris, ArgInfo("tris", 0)) &&
        pyopencv_to_safe(pyobj_ctl2d, ctl2d, ArgInfo("ctl2d", 1)) &&
        pyopencv_to_safe(pyobj_ctl3d, ctl3d, ArgInfo("ctl3d", 1)) )
    {
        ERRWRAP2(cv::rapid::extractControlPoints(num, len, pts3d, rvec, tvec, K, imsize, tris, ctl2d, ctl3d));
        return Py_BuildValue("(NN)", pyopencv_from(ctl2d), pyopencv_from(ctl3d));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("extractControlPoints");

    return NULL;
}

static PyObject* pyopencv_cv_rapid_extractLineBundle(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::rapid;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_len = NULL;
    int len=0;
    PyObject* pyobj_ctl2d = NULL;
    Mat ctl2d;
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_bundle = NULL;
    Mat bundle;
    PyObject* pyobj_srcLocations = NULL;
    Mat srcLocations;

    const char* keywords[] = { "len", "ctl2d", "img", "bundle", "srcLocations", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:extractLineBundle", (char**)keywords, &pyobj_len, &pyobj_ctl2d, &pyobj_img, &pyobj_bundle, &pyobj_srcLocations) &&
        pyopencv_to_safe(pyobj_len, len, ArgInfo("len", 0)) &&
        pyopencv_to_safe(pyobj_ctl2d, ctl2d, ArgInfo("ctl2d", 0)) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_bundle, bundle, ArgInfo("bundle", 1)) &&
        pyopencv_to_safe(pyobj_srcLocations, srcLocations, ArgInfo("srcLocations", 1)) )
    {
        ERRWRAP2(cv::rapid::extractLineBundle(len, ctl2d, img, bundle, srcLocations));
        return Py_BuildValue("(NN)", pyopencv_from(bundle), pyopencv_from(srcLocations));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_len = NULL;
    int len=0;
    PyObject* pyobj_ctl2d = NULL;
    UMat ctl2d;
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_bundle = NULL;
    UMat bundle;
    PyObject* pyobj_srcLocations = NULL;
    UMat srcLocations;

    const char* keywords[] = { "len", "ctl2d", "img", "bundle", "srcLocations", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:extractLineBundle", (char**)keywords, &pyobj_len, &pyobj_ctl2d, &pyobj_img, &pyobj_bundle, &pyobj_srcLocations) &&
        pyopencv_to_safe(pyobj_len, len, ArgInfo("len", 0)) &&
        pyopencv_to_safe(pyobj_ctl2d, ctl2d, ArgInfo("ctl2d", 0)) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_bundle, bundle, ArgInfo("bundle", 1)) &&
        pyopencv_to_safe(pyobj_srcLocations, srcLocations, ArgInfo("srcLocations", 1)) )
    {
        ERRWRAP2(cv::rapid::extractLineBundle(len, ctl2d, img, bundle, srcLocations));
        return Py_BuildValue("(NN)", pyopencv_from(bundle), pyopencv_from(srcLocations));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("extractLineBundle");

    return NULL;
}

static PyObject* pyopencv_cv_rapid_findCorrespondencies(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::rapid;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_bundle = NULL;
    Mat bundle;
    PyObject* pyobj_cols = NULL;
    Mat cols;
    PyObject* pyobj_response = NULL;
    Mat response;

    const char* keywords[] = { "bundle", "cols", "response", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:findCorrespondencies", (char**)keywords, &pyobj_bundle, &pyobj_cols, &pyobj_response) &&
        pyopencv_to_safe(pyobj_bundle, bundle, ArgInfo("bundle", 0)) &&
        pyopencv_to_safe(pyobj_cols, cols, ArgInfo("cols", 1)) &&
        pyopencv_to_safe(pyobj_response, response, ArgInfo("response", 1)) )
    {
        ERRWRAP2(cv::rapid::findCorrespondencies(bundle, cols, response));
        return Py_BuildValue("(NN)", pyopencv_from(cols), pyopencv_from(response));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_bundle = NULL;
    UMat bundle;
    PyObject* pyobj_cols = NULL;
    UMat cols;
    PyObject* pyobj_response = NULL;
    UMat response;

    const char* keywords[] = { "bundle", "cols", "response", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:findCorrespondencies", (char**)keywords, &pyobj_bundle, &pyobj_cols, &pyobj_response) &&
        pyopencv_to_safe(pyobj_bundle, bundle, ArgInfo("bundle", 0)) &&
        pyopencv_to_safe(pyobj_cols, cols, ArgInfo("cols", 1)) &&
        pyopencv_to_safe(pyobj_response, response, ArgInfo("response", 1)) )
    {
        ERRWRAP2(cv::rapid::findCorrespondencies(bundle, cols, response));
        return Py_BuildValue("(NN)", pyopencv_from(cols), pyopencv_from(response));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("findCorrespondencies");

    return NULL;
}

static PyObject* pyopencv_cv_rapid_rapid(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::rapid;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_num = NULL;
    int num=0;
    PyObject* pyobj_len = NULL;
    int len=0;
    PyObject* pyobj_pts3d = NULL;
    Mat pts3d;
    PyObject* pyobj_tris = NULL;
    Mat tris;
    PyObject* pyobj_K = NULL;
    Mat K;
    PyObject* pyobj_rvec = NULL;
    Mat rvec;
    PyObject* pyobj_tvec = NULL;
    Mat tvec;
    double rmsd;
    float retval;

    const char* keywords[] = { "img", "num", "len", "pts3d", "tris", "K", "rvec", "tvec", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOOO:rapid", (char**)keywords, &pyobj_img, &pyobj_num, &pyobj_len, &pyobj_pts3d, &pyobj_tris, &pyobj_K, &pyobj_rvec, &pyobj_tvec) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_num, num, ArgInfo("num", 0)) &&
        pyopencv_to_safe(pyobj_len, len, ArgInfo("len", 0)) &&
        pyopencv_to_safe(pyobj_pts3d, pts3d, ArgInfo("pts3d", 0)) &&
        pyopencv_to_safe(pyobj_tris, tris, ArgInfo("tris", 0)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 1)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 1)) )
    {
        ERRWRAP2(retval = cv::rapid::rapid(img, num, len, pts3d, tris, K, rvec, tvec, &rmsd));
        return Py_BuildValue("(NNNN)", pyopencv_from(retval), pyopencv_from(rvec), pyopencv_from(tvec), pyopencv_from(rmsd));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_num = NULL;
    int num=0;
    PyObject* pyobj_len = NULL;
    int len=0;
    PyObject* pyobj_pts3d = NULL;
    UMat pts3d;
    PyObject* pyobj_tris = NULL;
    UMat tris;
    PyObject* pyobj_K = NULL;
    UMat K;
    PyObject* pyobj_rvec = NULL;
    UMat rvec;
    PyObject* pyobj_tvec = NULL;
    UMat tvec;
    double rmsd;
    float retval;

    const char* keywords[] = { "img", "num", "len", "pts3d", "tris", "K", "rvec", "tvec", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOOOO:rapid", (char**)keywords, &pyobj_img, &pyobj_num, &pyobj_len, &pyobj_pts3d, &pyobj_tris, &pyobj_K, &pyobj_rvec, &pyobj_tvec) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_num, num, ArgInfo("num", 0)) &&
        pyopencv_to_safe(pyobj_len, len, ArgInfo("len", 0)) &&
        pyopencv_to_safe(pyobj_pts3d, pts3d, ArgInfo("pts3d", 0)) &&
        pyopencv_to_safe(pyobj_tris, tris, ArgInfo("tris", 0)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_rvec, rvec, ArgInfo("rvec", 1)) &&
        pyopencv_to_safe(pyobj_tvec, tvec, ArgInfo("tvec", 1)) )
    {
        ERRWRAP2(retval = cv::rapid::rapid(img, num, len, pts3d, tris, K, rvec, tvec, &rmsd));
        return Py_BuildValue("(NNNN)", pyopencv_from(retval), pyopencv_from(rvec), pyopencv_from(tvec), pyopencv_from(rmsd));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("rapid");

    return NULL;
}

static PyObject* pyopencv_cv_reg_MapTypeCaster_toAffine(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::reg;

    PyObject* pyobj_sourceMap = NULL;
    Ptr<Map> sourceMap;
    Ptr<MapAffine> retval;

    const char* keywords[] = { "sourceMap", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:MapTypeCaster_toAffine", (char**)keywords, &pyobj_sourceMap) &&
        pyopencv_to_safe(pyobj_sourceMap, sourceMap, ArgInfo("sourceMap", 0)) )
    {
        ERRWRAP2(retval = cv::reg::MapTypeCaster::toAffine(sourceMap));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_reg_MapTypeCaster_toProjec(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::reg;

    PyObject* pyobj_sourceMap = NULL;
    Ptr<Map> sourceMap;
    Ptr<MapProjec> retval;

    const char* keywords[] = { "sourceMap", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:MapTypeCaster_toProjec", (char**)keywords, &pyobj_sourceMap) &&
        pyopencv_to_safe(pyobj_sourceMap, sourceMap, ArgInfo("sourceMap", 0)) )
    {
        ERRWRAP2(retval = cv::reg::MapTypeCaster::toProjec(sourceMap));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_reg_MapTypeCaster_toShift(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::reg;

    PyObject* pyobj_sourceMap = NULL;
    Ptr<Map> sourceMap;
    Ptr<MapShift> retval;

    const char* keywords[] = { "sourceMap", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:MapTypeCaster_toShift", (char**)keywords, &pyobj_sourceMap) &&
        pyopencv_to_safe(pyobj_sourceMap, sourceMap, ArgInfo("sourceMap", 0)) )
    {
        ERRWRAP2(retval = cv::reg::MapTypeCaster::toShift(sourceMap));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_rgbd_DepthCleaner_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::rgbd;

    PyObject* pyobj_depth = NULL;
    int depth=0;
    PyObject* pyobj_window_size = NULL;
    int window_size=5;
    PyObject* pyobj_method = NULL;
    int method=DepthCleaner::DEPTH_CLEANER_NIL;
    Ptr<DepthCleaner> retval;

    const char* keywords[] = { "depth", "window_size", "method", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:DepthCleaner_create", (char**)keywords, &pyobj_depth, &pyobj_window_size, &pyobj_method) &&
        pyopencv_to_safe(pyobj_depth, depth, ArgInfo("depth", 0)) &&
        pyopencv_to_safe(pyobj_window_size, window_size, ArgInfo("window_size", 0)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) )
    {
        ERRWRAP2(retval = cv::rgbd::DepthCleaner::create(depth, window_size, method));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_rgbd_FastICPOdometry_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::rgbd;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_maxDistDiff = NULL;
    float maxDistDiff=Odometry::DEFAULT_MAX_DEPTH_DIFF();
    PyObject* pyobj_angleThreshold = NULL;
    float angleThreshold=(float)(30. * CV_PI / 180.);
    PyObject* pyobj_sigmaDepth = NULL;
    float sigmaDepth=0.04f;
    PyObject* pyobj_sigmaSpatial = NULL;
    float sigmaSpatial=4.5f;
    PyObject* pyobj_kernelSize = NULL;
    int kernelSize=7;
    PyObject* pyobj_iterCounts = NULL;
    vector_int iterCounts=std::vector<int>();
    Ptr<FastICPOdometry> retval;

    const char* keywords[] = { "cameraMatrix", "maxDistDiff", "angleThreshold", "sigmaDepth", "sigmaSpatial", "kernelSize", "iterCounts", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOOOO:FastICPOdometry_create", (char**)keywords, &pyobj_cameraMatrix, &pyobj_maxDistDiff, &pyobj_angleThreshold, &pyobj_sigmaDepth, &pyobj_sigmaSpatial, &pyobj_kernelSize, &pyobj_iterCounts) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_maxDistDiff, maxDistDiff, ArgInfo("maxDistDiff", 0)) &&
        pyopencv_to_safe(pyobj_angleThreshold, angleThreshold, ArgInfo("angleThreshold", 0)) &&
        pyopencv_to_safe(pyobj_sigmaDepth, sigmaDepth, ArgInfo("sigmaDepth", 0)) &&
        pyopencv_to_safe(pyobj_sigmaSpatial, sigmaSpatial, ArgInfo("sigmaSpatial", 0)) &&
        pyopencv_to_safe(pyobj_kernelSize, kernelSize, ArgInfo("kernelSize", 0)) &&
        pyopencv_to_safe(pyobj_iterCounts, iterCounts, ArgInfo("iterCounts", 0)) )
    {
        ERRWRAP2(retval = cv::rgbd::FastICPOdometry::create(cameraMatrix, maxDistDiff, angleThreshold, sigmaDepth, sigmaSpatial, kernelSize, iterCounts));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_maxDistDiff = NULL;
    float maxDistDiff=Odometry::DEFAULT_MAX_DEPTH_DIFF();
    PyObject* pyobj_angleThreshold = NULL;
    float angleThreshold=(float)(30. * CV_PI / 180.);
    PyObject* pyobj_sigmaDepth = NULL;
    float sigmaDepth=0.04f;
    PyObject* pyobj_sigmaSpatial = NULL;
    float sigmaSpatial=4.5f;
    PyObject* pyobj_kernelSize = NULL;
    int kernelSize=7;
    PyObject* pyobj_iterCounts = NULL;
    vector_int iterCounts=std::vector<int>();
    Ptr<FastICPOdometry> retval;

    const char* keywords[] = { "cameraMatrix", "maxDistDiff", "angleThreshold", "sigmaDepth", "sigmaSpatial", "kernelSize", "iterCounts", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOOOO:FastICPOdometry_create", (char**)keywords, &pyobj_cameraMatrix, &pyobj_maxDistDiff, &pyobj_angleThreshold, &pyobj_sigmaDepth, &pyobj_sigmaSpatial, &pyobj_kernelSize, &pyobj_iterCounts) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_maxDistDiff, maxDistDiff, ArgInfo("maxDistDiff", 0)) &&
        pyopencv_to_safe(pyobj_angleThreshold, angleThreshold, ArgInfo("angleThreshold", 0)) &&
        pyopencv_to_safe(pyobj_sigmaDepth, sigmaDepth, ArgInfo("sigmaDepth", 0)) &&
        pyopencv_to_safe(pyobj_sigmaSpatial, sigmaSpatial, ArgInfo("sigmaSpatial", 0)) &&
        pyopencv_to_safe(pyobj_kernelSize, kernelSize, ArgInfo("kernelSize", 0)) &&
        pyopencv_to_safe(pyobj_iterCounts, iterCounts, ArgInfo("iterCounts", 0)) )
    {
        ERRWRAP2(retval = cv::rgbd::FastICPOdometry::create(cameraMatrix, maxDistDiff, angleThreshold, sigmaDepth, sigmaSpatial, kernelSize, iterCounts));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("FastICPOdometry_create");

    return NULL;
}

static PyObject* pyopencv_cv_rgbd_ICPOdometry_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::rgbd;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_minDepth = NULL;
    float minDepth=Odometry::DEFAULT_MIN_DEPTH();
    PyObject* pyobj_maxDepth = NULL;
    float maxDepth=Odometry::DEFAULT_MAX_DEPTH();
    PyObject* pyobj_maxDepthDiff = NULL;
    float maxDepthDiff=Odometry::DEFAULT_MAX_DEPTH_DIFF();
    PyObject* pyobj_maxPointsPart = NULL;
    float maxPointsPart=Odometry::DEFAULT_MAX_POINTS_PART();
    PyObject* pyobj_iterCounts = NULL;
    vector_int iterCounts=std::vector<int>();
    PyObject* pyobj_transformType = NULL;
    int transformType=Odometry::RIGID_BODY_MOTION;
    Ptr<ICPOdometry> retval;

    const char* keywords[] = { "cameraMatrix", "minDepth", "maxDepth", "maxDepthDiff", "maxPointsPart", "iterCounts", "transformType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOOOO:ICPOdometry_create", (char**)keywords, &pyobj_cameraMatrix, &pyobj_minDepth, &pyobj_maxDepth, &pyobj_maxDepthDiff, &pyobj_maxPointsPart, &pyobj_iterCounts, &pyobj_transformType) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_minDepth, minDepth, ArgInfo("minDepth", 0)) &&
        pyopencv_to_safe(pyobj_maxDepth, maxDepth, ArgInfo("maxDepth", 0)) &&
        pyopencv_to_safe(pyobj_maxDepthDiff, maxDepthDiff, ArgInfo("maxDepthDiff", 0)) &&
        pyopencv_to_safe(pyobj_maxPointsPart, maxPointsPart, ArgInfo("maxPointsPart", 0)) &&
        pyopencv_to_safe(pyobj_iterCounts, iterCounts, ArgInfo("iterCounts", 0)) &&
        pyopencv_to_safe(pyobj_transformType, transformType, ArgInfo("transformType", 0)) )
    {
        ERRWRAP2(retval = cv::rgbd::ICPOdometry::create(cameraMatrix, minDepth, maxDepth, maxDepthDiff, maxPointsPart, iterCounts, transformType));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_minDepth = NULL;
    float minDepth=Odometry::DEFAULT_MIN_DEPTH();
    PyObject* pyobj_maxDepth = NULL;
    float maxDepth=Odometry::DEFAULT_MAX_DEPTH();
    PyObject* pyobj_maxDepthDiff = NULL;
    float maxDepthDiff=Odometry::DEFAULT_MAX_DEPTH_DIFF();
    PyObject* pyobj_maxPointsPart = NULL;
    float maxPointsPart=Odometry::DEFAULT_MAX_POINTS_PART();
    PyObject* pyobj_iterCounts = NULL;
    vector_int iterCounts=std::vector<int>();
    PyObject* pyobj_transformType = NULL;
    int transformType=Odometry::RIGID_BODY_MOTION;
    Ptr<ICPOdometry> retval;

    const char* keywords[] = { "cameraMatrix", "minDepth", "maxDepth", "maxDepthDiff", "maxPointsPart", "iterCounts", "transformType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOOOO:ICPOdometry_create", (char**)keywords, &pyobj_cameraMatrix, &pyobj_minDepth, &pyobj_maxDepth, &pyobj_maxDepthDiff, &pyobj_maxPointsPart, &pyobj_iterCounts, &pyobj_transformType) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_minDepth, minDepth, ArgInfo("minDepth", 0)) &&
        pyopencv_to_safe(pyobj_maxDepth, maxDepth, ArgInfo("maxDepth", 0)) &&
        pyopencv_to_safe(pyobj_maxDepthDiff, maxDepthDiff, ArgInfo("maxDepthDiff", 0)) &&
        pyopencv_to_safe(pyobj_maxPointsPart, maxPointsPart, ArgInfo("maxPointsPart", 0)) &&
        pyopencv_to_safe(pyobj_iterCounts, iterCounts, ArgInfo("iterCounts", 0)) &&
        pyopencv_to_safe(pyobj_transformType, transformType, ArgInfo("transformType", 0)) )
    {
        ERRWRAP2(retval = cv::rgbd::ICPOdometry::create(cameraMatrix, minDepth, maxDepth, maxDepthDiff, maxPointsPart, iterCounts, transformType));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("ICPOdometry_create");

    return NULL;
}

static PyObject* pyopencv_cv_rgbd_OdometryFrame_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::rgbd;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_depth = NULL;
    Mat depth;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_normals = NULL;
    Mat normals;
    PyObject* pyobj_ID = NULL;
    int ID=-1;
    Ptr<OdometryFrame> retval;

    const char* keywords[] = { "image", "depth", "mask", "normals", "ID", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOO:OdometryFrame_create", (char**)keywords, &pyobj_image, &pyobj_depth, &pyobj_mask, &pyobj_normals, &pyobj_ID) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_depth, depth, ArgInfo("depth", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_normals, normals, ArgInfo("normals", 0)) &&
        pyopencv_to_safe(pyobj_ID, ID, ArgInfo("ID", 0)) )
    {
        ERRWRAP2(retval = cv::rgbd::OdometryFrame::create(image, depth, mask, normals, ID));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_depth = NULL;
    Mat depth;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_normals = NULL;
    Mat normals;
    PyObject* pyobj_ID = NULL;
    int ID=-1;
    Ptr<OdometryFrame> retval;

    const char* keywords[] = { "image", "depth", "mask", "normals", "ID", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOO:OdometryFrame_create", (char**)keywords, &pyobj_image, &pyobj_depth, &pyobj_mask, &pyobj_normals, &pyobj_ID) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_depth, depth, ArgInfo("depth", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_normals, normals, ArgInfo("normals", 0)) &&
        pyopencv_to_safe(pyobj_ID, ID, ArgInfo("ID", 0)) )
    {
        ERRWRAP2(retval = cv::rgbd::OdometryFrame::create(image, depth, mask, normals, ID));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("OdometryFrame_create");

    return NULL;
}

static PyObject* pyopencv_cv_rgbd_Odometry_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::rgbd;

    PyObject* pyobj_odometryType = NULL;
    String odometryType;
    Ptr<Odometry> retval;

    const char* keywords[] = { "odometryType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:Odometry_create", (char**)keywords, &pyobj_odometryType) &&
        pyopencv_to_safe(pyobj_odometryType, odometryType, ArgInfo("odometryType", 0)) )
    {
        ERRWRAP2(retval = cv::rgbd::Odometry::create(odometryType));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_rgbd_RgbdFrame_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::rgbd;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_depth = NULL;
    Mat depth;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_normals = NULL;
    Mat normals;
    PyObject* pyobj_ID = NULL;
    int ID=-1;
    Ptr<RgbdFrame> retval;

    const char* keywords[] = { "image", "depth", "mask", "normals", "ID", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOO:RgbdFrame_create", (char**)keywords, &pyobj_image, &pyobj_depth, &pyobj_mask, &pyobj_normals, &pyobj_ID) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_depth, depth, ArgInfo("depth", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_normals, normals, ArgInfo("normals", 0)) &&
        pyopencv_to_safe(pyobj_ID, ID, ArgInfo("ID", 0)) )
    {
        ERRWRAP2(retval = cv::rgbd::RgbdFrame::create(image, depth, mask, normals, ID));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_depth = NULL;
    Mat depth;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_normals = NULL;
    Mat normals;
    PyObject* pyobj_ID = NULL;
    int ID=-1;
    Ptr<RgbdFrame> retval;

    const char* keywords[] = { "image", "depth", "mask", "normals", "ID", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOO:RgbdFrame_create", (char**)keywords, &pyobj_image, &pyobj_depth, &pyobj_mask, &pyobj_normals, &pyobj_ID) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_depth, depth, ArgInfo("depth", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_normals, normals, ArgInfo("normals", 0)) &&
        pyopencv_to_safe(pyobj_ID, ID, ArgInfo("ID", 0)) )
    {
        ERRWRAP2(retval = cv::rgbd::RgbdFrame::create(image, depth, mask, normals, ID));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("RgbdFrame_create");

    return NULL;
}

static PyObject* pyopencv_cv_rgbd_RgbdICPOdometry_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::rgbd;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_minDepth = NULL;
    float minDepth=Odometry::DEFAULT_MIN_DEPTH();
    PyObject* pyobj_maxDepth = NULL;
    float maxDepth=Odometry::DEFAULT_MAX_DEPTH();
    PyObject* pyobj_maxDepthDiff = NULL;
    float maxDepthDiff=Odometry::DEFAULT_MAX_DEPTH_DIFF();
    PyObject* pyobj_maxPointsPart = NULL;
    float maxPointsPart=Odometry::DEFAULT_MAX_POINTS_PART();
    PyObject* pyobj_iterCounts = NULL;
    vector_int iterCounts=std::vector<int>();
    PyObject* pyobj_minGradientMagnitudes = NULL;
    vector_float minGradientMagnitudes=std::vector<float>();
    PyObject* pyobj_transformType = NULL;
    int transformType=Odometry::RIGID_BODY_MOTION;
    Ptr<RgbdICPOdometry> retval;

    const char* keywords[] = { "cameraMatrix", "minDepth", "maxDepth", "maxDepthDiff", "maxPointsPart", "iterCounts", "minGradientMagnitudes", "transformType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOOOOO:RgbdICPOdometry_create", (char**)keywords, &pyobj_cameraMatrix, &pyobj_minDepth, &pyobj_maxDepth, &pyobj_maxDepthDiff, &pyobj_maxPointsPart, &pyobj_iterCounts, &pyobj_minGradientMagnitudes, &pyobj_transformType) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_minDepth, minDepth, ArgInfo("minDepth", 0)) &&
        pyopencv_to_safe(pyobj_maxDepth, maxDepth, ArgInfo("maxDepth", 0)) &&
        pyopencv_to_safe(pyobj_maxDepthDiff, maxDepthDiff, ArgInfo("maxDepthDiff", 0)) &&
        pyopencv_to_safe(pyobj_maxPointsPart, maxPointsPart, ArgInfo("maxPointsPart", 0)) &&
        pyopencv_to_safe(pyobj_iterCounts, iterCounts, ArgInfo("iterCounts", 0)) &&
        pyopencv_to_safe(pyobj_minGradientMagnitudes, minGradientMagnitudes, ArgInfo("minGradientMagnitudes", 0)) &&
        pyopencv_to_safe(pyobj_transformType, transformType, ArgInfo("transformType", 0)) )
    {
        ERRWRAP2(retval = cv::rgbd::RgbdICPOdometry::create(cameraMatrix, minDepth, maxDepth, maxDepthDiff, maxPointsPart, iterCounts, minGradientMagnitudes, transformType));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_minDepth = NULL;
    float minDepth=Odometry::DEFAULT_MIN_DEPTH();
    PyObject* pyobj_maxDepth = NULL;
    float maxDepth=Odometry::DEFAULT_MAX_DEPTH();
    PyObject* pyobj_maxDepthDiff = NULL;
    float maxDepthDiff=Odometry::DEFAULT_MAX_DEPTH_DIFF();
    PyObject* pyobj_maxPointsPart = NULL;
    float maxPointsPart=Odometry::DEFAULT_MAX_POINTS_PART();
    PyObject* pyobj_iterCounts = NULL;
    vector_int iterCounts=std::vector<int>();
    PyObject* pyobj_minGradientMagnitudes = NULL;
    vector_float minGradientMagnitudes=std::vector<float>();
    PyObject* pyobj_transformType = NULL;
    int transformType=Odometry::RIGID_BODY_MOTION;
    Ptr<RgbdICPOdometry> retval;

    const char* keywords[] = { "cameraMatrix", "minDepth", "maxDepth", "maxDepthDiff", "maxPointsPart", "iterCounts", "minGradientMagnitudes", "transformType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOOOOO:RgbdICPOdometry_create", (char**)keywords, &pyobj_cameraMatrix, &pyobj_minDepth, &pyobj_maxDepth, &pyobj_maxDepthDiff, &pyobj_maxPointsPart, &pyobj_iterCounts, &pyobj_minGradientMagnitudes, &pyobj_transformType) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_minDepth, minDepth, ArgInfo("minDepth", 0)) &&
        pyopencv_to_safe(pyobj_maxDepth, maxDepth, ArgInfo("maxDepth", 0)) &&
        pyopencv_to_safe(pyobj_maxDepthDiff, maxDepthDiff, ArgInfo("maxDepthDiff", 0)) &&
        pyopencv_to_safe(pyobj_maxPointsPart, maxPointsPart, ArgInfo("maxPointsPart", 0)) &&
        pyopencv_to_safe(pyobj_iterCounts, iterCounts, ArgInfo("iterCounts", 0)) &&
        pyopencv_to_safe(pyobj_minGradientMagnitudes, minGradientMagnitudes, ArgInfo("minGradientMagnitudes", 0)) &&
        pyopencv_to_safe(pyobj_transformType, transformType, ArgInfo("transformType", 0)) )
    {
        ERRWRAP2(retval = cv::rgbd::RgbdICPOdometry::create(cameraMatrix, minDepth, maxDepth, maxDepthDiff, maxPointsPart, iterCounts, minGradientMagnitudes, transformType));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("RgbdICPOdometry_create");

    return NULL;
}

static PyObject* pyopencv_cv_rgbd_RgbdNormals_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::rgbd;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_rows = NULL;
    int rows=0;
    PyObject* pyobj_cols = NULL;
    int cols=0;
    PyObject* pyobj_depth = NULL;
    int depth=0;
    PyObject* pyobj_K = NULL;
    Mat K;
    PyObject* pyobj_window_size = NULL;
    int window_size=5;
    PyObject* pyobj_method = NULL;
    int method=RgbdNormals::RGBD_NORMALS_METHOD_FALS;
    Ptr<RgbdNormals> retval;

    const char* keywords[] = { "rows", "cols", "depth", "K", "window_size", "method", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OO:RgbdNormals_create", (char**)keywords, &pyobj_rows, &pyobj_cols, &pyobj_depth, &pyobj_K, &pyobj_window_size, &pyobj_method) &&
        pyopencv_to_safe(pyobj_rows, rows, ArgInfo("rows", 0)) &&
        pyopencv_to_safe(pyobj_cols, cols, ArgInfo("cols", 0)) &&
        pyopencv_to_safe(pyobj_depth, depth, ArgInfo("depth", 0)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_window_size, window_size, ArgInfo("window_size", 0)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) )
    {
        ERRWRAP2(retval = cv::rgbd::RgbdNormals::create(rows, cols, depth, K, window_size, method));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_rows = NULL;
    int rows=0;
    PyObject* pyobj_cols = NULL;
    int cols=0;
    PyObject* pyobj_depth = NULL;
    int depth=0;
    PyObject* pyobj_K = NULL;
    UMat K;
    PyObject* pyobj_window_size = NULL;
    int window_size=5;
    PyObject* pyobj_method = NULL;
    int method=RgbdNormals::RGBD_NORMALS_METHOD_FALS;
    Ptr<RgbdNormals> retval;

    const char* keywords[] = { "rows", "cols", "depth", "K", "window_size", "method", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OO:RgbdNormals_create", (char**)keywords, &pyobj_rows, &pyobj_cols, &pyobj_depth, &pyobj_K, &pyobj_window_size, &pyobj_method) &&
        pyopencv_to_safe(pyobj_rows, rows, ArgInfo("rows", 0)) &&
        pyopencv_to_safe(pyobj_cols, cols, ArgInfo("cols", 0)) &&
        pyopencv_to_safe(pyobj_depth, depth, ArgInfo("depth", 0)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_window_size, window_size, ArgInfo("window_size", 0)) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) )
    {
        ERRWRAP2(retval = cv::rgbd::RgbdNormals::create(rows, cols, depth, K, window_size, method));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("RgbdNormals_create");

    return NULL;
}

static PyObject* pyopencv_cv_rgbd_RgbdOdometry_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::rgbd;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_minDepth = NULL;
    float minDepth=Odometry::DEFAULT_MIN_DEPTH();
    PyObject* pyobj_maxDepth = NULL;
    float maxDepth=Odometry::DEFAULT_MAX_DEPTH();
    PyObject* pyobj_maxDepthDiff = NULL;
    float maxDepthDiff=Odometry::DEFAULT_MAX_DEPTH_DIFF();
    PyObject* pyobj_iterCounts = NULL;
    vector_int iterCounts=std::vector<int>();
    PyObject* pyobj_minGradientMagnitudes = NULL;
    vector_float minGradientMagnitudes=std::vector<float>();
    PyObject* pyobj_maxPointsPart = NULL;
    float maxPointsPart=Odometry::DEFAULT_MAX_POINTS_PART();
    PyObject* pyobj_transformType = NULL;
    int transformType=Odometry::RIGID_BODY_MOTION;
    Ptr<RgbdOdometry> retval;

    const char* keywords[] = { "cameraMatrix", "minDepth", "maxDepth", "maxDepthDiff", "iterCounts", "minGradientMagnitudes", "maxPointsPart", "transformType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOOOOO:RgbdOdometry_create", (char**)keywords, &pyobj_cameraMatrix, &pyobj_minDepth, &pyobj_maxDepth, &pyobj_maxDepthDiff, &pyobj_iterCounts, &pyobj_minGradientMagnitudes, &pyobj_maxPointsPart, &pyobj_transformType) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_minDepth, minDepth, ArgInfo("minDepth", 0)) &&
        pyopencv_to_safe(pyobj_maxDepth, maxDepth, ArgInfo("maxDepth", 0)) &&
        pyopencv_to_safe(pyobj_maxDepthDiff, maxDepthDiff, ArgInfo("maxDepthDiff", 0)) &&
        pyopencv_to_safe(pyobj_iterCounts, iterCounts, ArgInfo("iterCounts", 0)) &&
        pyopencv_to_safe(pyobj_minGradientMagnitudes, minGradientMagnitudes, ArgInfo("minGradientMagnitudes", 0)) &&
        pyopencv_to_safe(pyobj_maxPointsPart, maxPointsPart, ArgInfo("maxPointsPart", 0)) &&
        pyopencv_to_safe(pyobj_transformType, transformType, ArgInfo("transformType", 0)) )
    {
        ERRWRAP2(retval = cv::rgbd::RgbdOdometry::create(cameraMatrix, minDepth, maxDepth, maxDepthDiff, iterCounts, minGradientMagnitudes, maxPointsPart, transformType));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_minDepth = NULL;
    float minDepth=Odometry::DEFAULT_MIN_DEPTH();
    PyObject* pyobj_maxDepth = NULL;
    float maxDepth=Odometry::DEFAULT_MAX_DEPTH();
    PyObject* pyobj_maxDepthDiff = NULL;
    float maxDepthDiff=Odometry::DEFAULT_MAX_DEPTH_DIFF();
    PyObject* pyobj_iterCounts = NULL;
    vector_int iterCounts=std::vector<int>();
    PyObject* pyobj_minGradientMagnitudes = NULL;
    vector_float minGradientMagnitudes=std::vector<float>();
    PyObject* pyobj_maxPointsPart = NULL;
    float maxPointsPart=Odometry::DEFAULT_MAX_POINTS_PART();
    PyObject* pyobj_transformType = NULL;
    int transformType=Odometry::RIGID_BODY_MOTION;
    Ptr<RgbdOdometry> retval;

    const char* keywords[] = { "cameraMatrix", "minDepth", "maxDepth", "maxDepthDiff", "iterCounts", "minGradientMagnitudes", "maxPointsPart", "transformType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOOOOO:RgbdOdometry_create", (char**)keywords, &pyobj_cameraMatrix, &pyobj_minDepth, &pyobj_maxDepth, &pyobj_maxDepthDiff, &pyobj_iterCounts, &pyobj_minGradientMagnitudes, &pyobj_maxPointsPart, &pyobj_transformType) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_minDepth, minDepth, ArgInfo("minDepth", 0)) &&
        pyopencv_to_safe(pyobj_maxDepth, maxDepth, ArgInfo("maxDepth", 0)) &&
        pyopencv_to_safe(pyobj_maxDepthDiff, maxDepthDiff, ArgInfo("maxDepthDiff", 0)) &&
        pyopencv_to_safe(pyobj_iterCounts, iterCounts, ArgInfo("iterCounts", 0)) &&
        pyopencv_to_safe(pyobj_minGradientMagnitudes, minGradientMagnitudes, ArgInfo("minGradientMagnitudes", 0)) &&
        pyopencv_to_safe(pyobj_maxPointsPart, maxPointsPart, ArgInfo("maxPointsPart", 0)) &&
        pyopencv_to_safe(pyobj_transformType, transformType, ArgInfo("transformType", 0)) )
    {
        ERRWRAP2(retval = cv::rgbd::RgbdOdometry::create(cameraMatrix, minDepth, maxDepth, maxDepthDiff, iterCounts, minGradientMagnitudes, maxPointsPart, transformType));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("RgbdOdometry_create");

    return NULL;
}

static PyObject* pyopencv_cv_rgbd_RgbdPlane_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::rgbd;

    PyObject* pyobj_method = NULL;
    int method=0;
    PyObject* pyobj_block_size = NULL;
    int block_size=0;
    PyObject* pyobj_min_size = NULL;
    int min_size=0;
    PyObject* pyobj_threshold = NULL;
    double threshold=0;
    PyObject* pyobj_sensor_error_a = NULL;
    double sensor_error_a=0;
    PyObject* pyobj_sensor_error_b = NULL;
    double sensor_error_b=0;
    PyObject* pyobj_sensor_error_c = NULL;
    double sensor_error_c=0;
    Ptr<RgbdPlane> retval;

    const char* keywords[] = { "method", "block_size", "min_size", "threshold", "sensor_error_a", "sensor_error_b", "sensor_error_c", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:RgbdPlane_create", (char**)keywords, &pyobj_method, &pyobj_block_size, &pyobj_min_size, &pyobj_threshold, &pyobj_sensor_error_a, &pyobj_sensor_error_b, &pyobj_sensor_error_c) &&
        pyopencv_to_safe(pyobj_method, method, ArgInfo("method", 0)) &&
        pyopencv_to_safe(pyobj_block_size, block_size, ArgInfo("block_size", 0)) &&
        pyopencv_to_safe(pyobj_min_size, min_size, ArgInfo("min_size", 0)) &&
        pyopencv_to_safe(pyobj_threshold, threshold, ArgInfo("threshold", 0)) &&
        pyopencv_to_safe(pyobj_sensor_error_a, sensor_error_a, ArgInfo("sensor_error_a", 0)) &&
        pyopencv_to_safe(pyobj_sensor_error_b, sensor_error_b, ArgInfo("sensor_error_b", 0)) &&
        pyopencv_to_safe(pyobj_sensor_error_c, sensor_error_c, ArgInfo("sensor_error_c", 0)) )
    {
        ERRWRAP2(retval = cv::rgbd::RgbdPlane::create(method, block_size, min_size, threshold, sensor_error_a, sensor_error_b, sensor_error_c));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_rgbd_depthTo3d(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::rgbd;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_depth = NULL;
    Mat depth;
    PyObject* pyobj_K = NULL;
    Mat K;
    PyObject* pyobj_points3d = NULL;
    Mat points3d;
    PyObject* pyobj_mask = NULL;
    Mat mask;

    const char* keywords[] = { "depth", "K", "points3d", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:depthTo3d", (char**)keywords, &pyobj_depth, &pyobj_K, &pyobj_points3d, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_depth, depth, ArgInfo("depth", 0)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_points3d, points3d, ArgInfo("points3d", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::rgbd::depthTo3d(depth, K, points3d, mask));
        return pyopencv_from(points3d);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_depth = NULL;
    UMat depth;
    PyObject* pyobj_K = NULL;
    UMat K;
    PyObject* pyobj_points3d = NULL;
    UMat points3d;
    PyObject* pyobj_mask = NULL;
    UMat mask;

    const char* keywords[] = { "depth", "K", "points3d", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:depthTo3d", (char**)keywords, &pyobj_depth, &pyobj_K, &pyobj_points3d, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_depth, depth, ArgInfo("depth", 0)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_points3d, points3d, ArgInfo("points3d", 1)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::rgbd::depthTo3d(depth, K, points3d, mask));
        return pyopencv_from(points3d);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("depthTo3d");

    return NULL;
}

static PyObject* pyopencv_cv_rgbd_depthTo3dSparse(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::rgbd;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_depth = NULL;
    Mat depth;
    PyObject* pyobj_in_K = NULL;
    Mat in_K;
    PyObject* pyobj_in_points = NULL;
    Mat in_points;
    PyObject* pyobj_points3d = NULL;
    Mat points3d;

    const char* keywords[] = { "depth", "in_K", "in_points", "points3d", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:depthTo3dSparse", (char**)keywords, &pyobj_depth, &pyobj_in_K, &pyobj_in_points, &pyobj_points3d) &&
        pyopencv_to_safe(pyobj_depth, depth, ArgInfo("depth", 0)) &&
        pyopencv_to_safe(pyobj_in_K, in_K, ArgInfo("in_K", 0)) &&
        pyopencv_to_safe(pyobj_in_points, in_points, ArgInfo("in_points", 0)) &&
        pyopencv_to_safe(pyobj_points3d, points3d, ArgInfo("points3d", 1)) )
    {
        ERRWRAP2(cv::rgbd::depthTo3dSparse(depth, in_K, in_points, points3d));
        return pyopencv_from(points3d);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_depth = NULL;
    UMat depth;
    PyObject* pyobj_in_K = NULL;
    UMat in_K;
    PyObject* pyobj_in_points = NULL;
    UMat in_points;
    PyObject* pyobj_points3d = NULL;
    UMat points3d;

    const char* keywords[] = { "depth", "in_K", "in_points", "points3d", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:depthTo3dSparse", (char**)keywords, &pyobj_depth, &pyobj_in_K, &pyobj_in_points, &pyobj_points3d) &&
        pyopencv_to_safe(pyobj_depth, depth, ArgInfo("depth", 0)) &&
        pyopencv_to_safe(pyobj_in_K, in_K, ArgInfo("in_K", 0)) &&
        pyopencv_to_safe(pyobj_in_points, in_points, ArgInfo("in_points", 0)) &&
        pyopencv_to_safe(pyobj_points3d, points3d, ArgInfo("points3d", 1)) )
    {
        ERRWRAP2(cv::rgbd::depthTo3dSparse(depth, in_K, in_points, points3d));
        return pyopencv_from(points3d);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("depthTo3dSparse");

    return NULL;
}

static PyObject* pyopencv_cv_rgbd_registerDepth(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::rgbd;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_unregisteredCameraMatrix = NULL;
    Mat unregisteredCameraMatrix;
    PyObject* pyobj_registeredCameraMatrix = NULL;
    Mat registeredCameraMatrix;
    PyObject* pyobj_registeredDistCoeffs = NULL;
    Mat registeredDistCoeffs;
    PyObject* pyobj_Rt = NULL;
    Mat Rt;
    PyObject* pyobj_unregisteredDepth = NULL;
    Mat unregisteredDepth;
    PyObject* pyobj_outputImagePlaneSize = NULL;
    Size outputImagePlaneSize;
    PyObject* pyobj_registeredDepth = NULL;
    Mat registeredDepth;
    PyObject* pyobj_depthDilation = NULL;
    bool depthDilation=false;

    const char* keywords[] = { "unregisteredCameraMatrix", "registeredCameraMatrix", "registeredDistCoeffs", "Rt", "unregisteredDepth", "outputImagePlaneSize", "registeredDepth", "depthDilation", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|OO:registerDepth", (char**)keywords, &pyobj_unregisteredCameraMatrix, &pyobj_registeredCameraMatrix, &pyobj_registeredDistCoeffs, &pyobj_Rt, &pyobj_unregisteredDepth, &pyobj_outputImagePlaneSize, &pyobj_registeredDepth, &pyobj_depthDilation) &&
        pyopencv_to_safe(pyobj_unregisteredCameraMatrix, unregisteredCameraMatrix, ArgInfo("unregisteredCameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_registeredCameraMatrix, registeredCameraMatrix, ArgInfo("registeredCameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_registeredDistCoeffs, registeredDistCoeffs, ArgInfo("registeredDistCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_Rt, Rt, ArgInfo("Rt", 0)) &&
        pyopencv_to_safe(pyobj_unregisteredDepth, unregisteredDepth, ArgInfo("unregisteredDepth", 0)) &&
        pyopencv_to_safe(pyobj_outputImagePlaneSize, outputImagePlaneSize, ArgInfo("outputImagePlaneSize", 0)) &&
        pyopencv_to_safe(pyobj_registeredDepth, registeredDepth, ArgInfo("registeredDepth", 1)) &&
        pyopencv_to_safe(pyobj_depthDilation, depthDilation, ArgInfo("depthDilation", 0)) )
    {
        ERRWRAP2(cv::rgbd::registerDepth(unregisteredCameraMatrix, registeredCameraMatrix, registeredDistCoeffs, Rt, unregisteredDepth, outputImagePlaneSize, registeredDepth, depthDilation));
        return pyopencv_from(registeredDepth);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_unregisteredCameraMatrix = NULL;
    UMat unregisteredCameraMatrix;
    PyObject* pyobj_registeredCameraMatrix = NULL;
    UMat registeredCameraMatrix;
    PyObject* pyobj_registeredDistCoeffs = NULL;
    UMat registeredDistCoeffs;
    PyObject* pyobj_Rt = NULL;
    UMat Rt;
    PyObject* pyobj_unregisteredDepth = NULL;
    UMat unregisteredDepth;
    PyObject* pyobj_outputImagePlaneSize = NULL;
    Size outputImagePlaneSize;
    PyObject* pyobj_registeredDepth = NULL;
    UMat registeredDepth;
    PyObject* pyobj_depthDilation = NULL;
    bool depthDilation=false;

    const char* keywords[] = { "unregisteredCameraMatrix", "registeredCameraMatrix", "registeredDistCoeffs", "Rt", "unregisteredDepth", "outputImagePlaneSize", "registeredDepth", "depthDilation", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|OO:registerDepth", (char**)keywords, &pyobj_unregisteredCameraMatrix, &pyobj_registeredCameraMatrix, &pyobj_registeredDistCoeffs, &pyobj_Rt, &pyobj_unregisteredDepth, &pyobj_outputImagePlaneSize, &pyobj_registeredDepth, &pyobj_depthDilation) &&
        pyopencv_to_safe(pyobj_unregisteredCameraMatrix, unregisteredCameraMatrix, ArgInfo("unregisteredCameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_registeredCameraMatrix, registeredCameraMatrix, ArgInfo("registeredCameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_registeredDistCoeffs, registeredDistCoeffs, ArgInfo("registeredDistCoeffs", 0)) &&
        pyopencv_to_safe(pyobj_Rt, Rt, ArgInfo("Rt", 0)) &&
        pyopencv_to_safe(pyobj_unregisteredDepth, unregisteredDepth, ArgInfo("unregisteredDepth", 0)) &&
        pyopencv_to_safe(pyobj_outputImagePlaneSize, outputImagePlaneSize, ArgInfo("outputImagePlaneSize", 0)) &&
        pyopencv_to_safe(pyobj_registeredDepth, registeredDepth, ArgInfo("registeredDepth", 1)) &&
        pyopencv_to_safe(pyobj_depthDilation, depthDilation, ArgInfo("depthDilation", 0)) )
    {
        ERRWRAP2(cv::rgbd::registerDepth(unregisteredCameraMatrix, registeredCameraMatrix, registeredDistCoeffs, Rt, unregisteredDepth, outputImagePlaneSize, registeredDepth, depthDilation));
        return pyopencv_from(registeredDepth);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("registerDepth");

    return NULL;
}

static PyObject* pyopencv_cv_rgbd_rescaleDepth(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::rgbd;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_in = NULL;
    Mat in;
    PyObject* pyobj_depth = NULL;
    int depth=0;
    PyObject* pyobj_out = NULL;
    Mat out;
    PyObject* pyobj_depth_factor = NULL;
    double depth_factor=1000.0;

    const char* keywords[] = { "in", "depth", "out", "depth_factor", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:rescaleDepth", (char**)keywords, &pyobj_in, &pyobj_depth, &pyobj_out, &pyobj_depth_factor) &&
        pyopencv_to_safe(pyobj_in, in, ArgInfo("in", 0)) &&
        pyopencv_to_safe(pyobj_depth, depth, ArgInfo("depth", 0)) &&
        pyopencv_to_safe(pyobj_out, out, ArgInfo("out", 1)) &&
        pyopencv_to_safe(pyobj_depth_factor, depth_factor, ArgInfo("depth_factor", 0)) )
    {
        ERRWRAP2(cv::rgbd::rescaleDepth(in, depth, out, depth_factor));
        return pyopencv_from(out);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_in = NULL;
    UMat in;
    PyObject* pyobj_depth = NULL;
    int depth=0;
    PyObject* pyobj_out = NULL;
    UMat out;
    PyObject* pyobj_depth_factor = NULL;
    double depth_factor=1000.0;

    const char* keywords[] = { "in", "depth", "out", "depth_factor", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:rescaleDepth", (char**)keywords, &pyobj_in, &pyobj_depth, &pyobj_out, &pyobj_depth_factor) &&
        pyopencv_to_safe(pyobj_in, in, ArgInfo("in", 0)) &&
        pyopencv_to_safe(pyobj_depth, depth, ArgInfo("depth", 0)) &&
        pyopencv_to_safe(pyobj_out, out, ArgInfo("out", 1)) &&
        pyopencv_to_safe(pyobj_depth_factor, depth_factor, ArgInfo("depth_factor", 0)) )
    {
        ERRWRAP2(cv::rgbd::rescaleDepth(in, depth, out, depth_factor));
        return pyopencv_from(out);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("rescaleDepth");

    return NULL;
}

static PyObject* pyopencv_cv_rgbd_warpFrame(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::rgbd;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_depth = NULL;
    Mat depth;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_Rt = NULL;
    Mat Rt;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeff = NULL;
    Mat distCoeff;
    PyObject* pyobj_warpedImage = NULL;
    Mat warpedImage;
    PyObject* pyobj_warpedDepth = NULL;
    Mat warpedDepth;
    PyObject* pyobj_warpedMask = NULL;
    Mat warpedMask;

    const char* keywords[] = { "image", "depth", "mask", "Rt", "cameraMatrix", "distCoeff", "warpedImage", "warpedDepth", "warpedMask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|OOO:warpFrame", (char**)keywords, &pyobj_image, &pyobj_depth, &pyobj_mask, &pyobj_Rt, &pyobj_cameraMatrix, &pyobj_distCoeff, &pyobj_warpedImage, &pyobj_warpedDepth, &pyobj_warpedMask) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_depth, depth, ArgInfo("depth", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_Rt, Rt, ArgInfo("Rt", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeff, distCoeff, ArgInfo("distCoeff", 0)) &&
        pyopencv_to_safe(pyobj_warpedImage, warpedImage, ArgInfo("warpedImage", 1)) &&
        pyopencv_to_safe(pyobj_warpedDepth, warpedDepth, ArgInfo("warpedDepth", 1)) &&
        pyopencv_to_safe(pyobj_warpedMask, warpedMask, ArgInfo("warpedMask", 1)) )
    {
        ERRWRAP2(cv::rgbd::warpFrame(image, depth, mask, Rt, cameraMatrix, distCoeff, warpedImage, warpedDepth, warpedMask));
        return Py_BuildValue("(NNN)", pyopencv_from(warpedImage), pyopencv_from(warpedDepth), pyopencv_from(warpedMask));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_depth = NULL;
    Mat depth;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_Rt = NULL;
    Mat Rt;
    PyObject* pyobj_cameraMatrix = NULL;
    Mat cameraMatrix;
    PyObject* pyobj_distCoeff = NULL;
    Mat distCoeff;
    PyObject* pyobj_warpedImage = NULL;
    UMat warpedImage;
    PyObject* pyobj_warpedDepth = NULL;
    UMat warpedDepth;
    PyObject* pyobj_warpedMask = NULL;
    UMat warpedMask;

    const char* keywords[] = { "image", "depth", "mask", "Rt", "cameraMatrix", "distCoeff", "warpedImage", "warpedDepth", "warpedMask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO|OOO:warpFrame", (char**)keywords, &pyobj_image, &pyobj_depth, &pyobj_mask, &pyobj_Rt, &pyobj_cameraMatrix, &pyobj_distCoeff, &pyobj_warpedImage, &pyobj_warpedDepth, &pyobj_warpedMask) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_depth, depth, ArgInfo("depth", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_Rt, Rt, ArgInfo("Rt", 0)) &&
        pyopencv_to_safe(pyobj_cameraMatrix, cameraMatrix, ArgInfo("cameraMatrix", 0)) &&
        pyopencv_to_safe(pyobj_distCoeff, distCoeff, ArgInfo("distCoeff", 0)) &&
        pyopencv_to_safe(pyobj_warpedImage, warpedImage, ArgInfo("warpedImage", 1)) &&
        pyopencv_to_safe(pyobj_warpedDepth, warpedDepth, ArgInfo("warpedDepth", 1)) &&
        pyopencv_to_safe(pyobj_warpedMask, warpedMask, ArgInfo("warpedMask", 1)) )
    {
        ERRWRAP2(cv::rgbd::warpFrame(image, depth, mask, Rt, cameraMatrix, distCoeff, warpedImage, warpedDepth, warpedMask));
        return Py_BuildValue("(NNN)", pyopencv_from(warpedImage), pyopencv_from(warpedDepth), pyopencv_from(warpedMask));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("warpFrame");

    return NULL;
}

static PyObject* pyopencv_cv_saliency_MotionSaliencyBinWangApr2014_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::saliency;

    Ptr<MotionSaliencyBinWangApr2014> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::saliency::MotionSaliencyBinWangApr2014::create());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_saliency_ObjectnessBING_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::saliency;

    Ptr<ObjectnessBING> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::saliency::ObjectnessBING::create());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_saliency_StaticSaliencyFineGrained_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::saliency;

    Ptr<StaticSaliencyFineGrained> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::saliency::StaticSaliencyFineGrained::create());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_saliency_StaticSaliencySpectralResidual_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::saliency;

    Ptr<StaticSaliencySpectralResidual> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::saliency::StaticSaliencySpectralResidual::create());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_samples_addSamplesDataSearchPath(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::samples;

    PyObject* pyobj_path = NULL;
    String path;

    const char* keywords[] = { "path", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:addSamplesDataSearchPath", (char**)keywords, &pyobj_path) &&
        pyopencv_to_safe(pyobj_path, path, ArgInfo("path", 0)) )
    {
        ERRWRAP2(cv::samples::addSamplesDataSearchPath(path));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_samples_addSamplesDataSearchSubDirectory(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::samples;

    PyObject* pyobj_subdir = NULL;
    String subdir;

    const char* keywords[] = { "subdir", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:addSamplesDataSearchSubDirectory", (char**)keywords, &pyobj_subdir) &&
        pyopencv_to_safe(pyobj_subdir, subdir, ArgInfo("subdir", 0)) )
    {
        ERRWRAP2(cv::samples::addSamplesDataSearchSubDirectory(subdir));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_samples_findFile(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::samples;

    PyObject* pyobj_relative_path = NULL;
    String relative_path;
    PyObject* pyobj_required = NULL;
    bool required=true;
    PyObject* pyobj_silentMode = NULL;
    bool silentMode=false;
    cv::String retval;

    const char* keywords[] = { "relative_path", "required", "silentMode", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:findFile", (char**)keywords, &pyobj_relative_path, &pyobj_required, &pyobj_silentMode) &&
        pyopencv_to_safe(pyobj_relative_path, relative_path, ArgInfo("relative_path", 0)) &&
        pyopencv_to_safe(pyobj_required, required, ArgInfo("required", 0)) &&
        pyopencv_to_safe(pyobj_silentMode, silentMode, ArgInfo("silentMode", 0)) )
    {
        ERRWRAP2(retval = cv::samples::findFile(relative_path, required, silentMode));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_samples_findFileOrKeep(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::samples;

    PyObject* pyobj_relative_path = NULL;
    String relative_path;
    PyObject* pyobj_silentMode = NULL;
    bool silentMode=false;
    cv::String retval;

    const char* keywords[] = { "relative_path", "silentMode", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:findFileOrKeep", (char**)keywords, &pyobj_relative_path, &pyobj_silentMode) &&
        pyopencv_to_safe(pyobj_relative_path, relative_path, ArgInfo("relative_path", 0)) &&
        pyopencv_to_safe(pyobj_silentMode, silentMode, ArgInfo("silentMode", 0)) )
    {
        ERRWRAP2(retval = cv::samples::findFileOrKeep(relative_path, silentMode));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_sfm_KRtFromProjection(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::sfm;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_P = NULL;
    Mat P;
    PyObject* pyobj_K = NULL;
    Mat K;
    PyObject* pyobj_R = NULL;
    Mat R;
    PyObject* pyobj_t = NULL;
    Mat t;

    const char* keywords[] = { "P", "K", "R", "t", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:KRtFromProjection", (char**)keywords, &pyobj_P, &pyobj_K, &pyobj_R, &pyobj_t) &&
        pyopencv_to_safe(pyobj_P, P, ArgInfo("P", 0)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 1)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 1)) &&
        pyopencv_to_safe(pyobj_t, t, ArgInfo("t", 1)) )
    {
        ERRWRAP2(cv::sfm::KRtFromProjection(P, K, R, t));
        return Py_BuildValue("(NNN)", pyopencv_from(K), pyopencv_from(R), pyopencv_from(t));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_P = NULL;
    UMat P;
    PyObject* pyobj_K = NULL;
    UMat K;
    PyObject* pyobj_R = NULL;
    UMat R;
    PyObject* pyobj_t = NULL;
    UMat t;

    const char* keywords[] = { "P", "K", "R", "t", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:KRtFromProjection", (char**)keywords, &pyobj_P, &pyobj_K, &pyobj_R, &pyobj_t) &&
        pyopencv_to_safe(pyobj_P, P, ArgInfo("P", 0)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 1)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 1)) &&
        pyopencv_to_safe(pyobj_t, t, ArgInfo("t", 1)) )
    {
        ERRWRAP2(cv::sfm::KRtFromProjection(P, K, R, t));
        return Py_BuildValue("(NNN)", pyopencv_from(K), pyopencv_from(R), pyopencv_from(t));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("KRtFromProjection");

    return NULL;
}

static PyObject* pyopencv_cv_sfm_applyTransformationToPoints(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::sfm;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_points = NULL;
    Mat points;
    PyObject* pyobj_T = NULL;
    Mat T;
    PyObject* pyobj_transformed_points = NULL;
    Mat transformed_points;

    const char* keywords[] = { "points", "T", "transformed_points", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:applyTransformationToPoints", (char**)keywords, &pyobj_points, &pyobj_T, &pyobj_transformed_points) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) &&
        pyopencv_to_safe(pyobj_T, T, ArgInfo("T", 0)) &&
        pyopencv_to_safe(pyobj_transformed_points, transformed_points, ArgInfo("transformed_points", 1)) )
    {
        ERRWRAP2(cv::sfm::applyTransformationToPoints(points, T, transformed_points));
        return pyopencv_from(transformed_points);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_points = NULL;
    UMat points;
    PyObject* pyobj_T = NULL;
    UMat T;
    PyObject* pyobj_transformed_points = NULL;
    UMat transformed_points;

    const char* keywords[] = { "points", "T", "transformed_points", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:applyTransformationToPoints", (char**)keywords, &pyobj_points, &pyobj_T, &pyobj_transformed_points) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) &&
        pyopencv_to_safe(pyobj_T, T, ArgInfo("T", 0)) &&
        pyopencv_to_safe(pyobj_transformed_points, transformed_points, ArgInfo("transformed_points", 1)) )
    {
        ERRWRAP2(cv::sfm::applyTransformationToPoints(points, T, transformed_points));
        return pyopencv_from(transformed_points);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("applyTransformationToPoints");

    return NULL;
}

static PyObject* pyopencv_cv_sfm_computeOrientation(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::sfm;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_x1 = NULL;
    vector_Mat x1;
    PyObject* pyobj_x2 = NULL;
    vector_Mat x2;
    PyObject* pyobj_R = NULL;
    Mat R;
    PyObject* pyobj_t = NULL;
    Mat t;
    PyObject* pyobj_s = NULL;
    double s=0;

    const char* keywords[] = { "x1", "x2", "s", "R", "t", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:computeOrientation", (char**)keywords, &pyobj_x1, &pyobj_x2, &pyobj_s, &pyobj_R, &pyobj_t) &&
        pyopencv_to_safe(pyobj_x1, x1, ArgInfo("x1", 0)) &&
        pyopencv_to_safe(pyobj_x2, x2, ArgInfo("x2", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 1)) &&
        pyopencv_to_safe(pyobj_t, t, ArgInfo("t", 1)) &&
        pyopencv_to_safe(pyobj_s, s, ArgInfo("s", 0)) )
    {
        ERRWRAP2(cv::sfm::computeOrientation(x1, x2, R, t, s));
        return Py_BuildValue("(NN)", pyopencv_from(R), pyopencv_from(t));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_x1 = NULL;
    vector_UMat x1;
    PyObject* pyobj_x2 = NULL;
    vector_UMat x2;
    PyObject* pyobj_R = NULL;
    UMat R;
    PyObject* pyobj_t = NULL;
    UMat t;
    PyObject* pyobj_s = NULL;
    double s=0;

    const char* keywords[] = { "x1", "x2", "s", "R", "t", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:computeOrientation", (char**)keywords, &pyobj_x1, &pyobj_x2, &pyobj_s, &pyobj_R, &pyobj_t) &&
        pyopencv_to_safe(pyobj_x1, x1, ArgInfo("x1", 0)) &&
        pyopencv_to_safe(pyobj_x2, x2, ArgInfo("x2", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 1)) &&
        pyopencv_to_safe(pyobj_t, t, ArgInfo("t", 1)) &&
        pyopencv_to_safe(pyobj_s, s, ArgInfo("s", 0)) )
    {
        ERRWRAP2(cv::sfm::computeOrientation(x1, x2, R, t, s));
        return Py_BuildValue("(NN)", pyopencv_from(R), pyopencv_from(t));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("computeOrientation");

    return NULL;
}

static PyObject* pyopencv_cv_sfm_depth(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::sfm;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_R = NULL;
    Mat R;
    PyObject* pyobj_t = NULL;
    Mat t;
    PyObject* pyobj_X = NULL;
    Mat X;
    double retval;

    const char* keywords[] = { "R", "t", "X", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:depth", (char**)keywords, &pyobj_R, &pyobj_t, &pyobj_X) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) &&
        pyopencv_to_safe(pyobj_t, t, ArgInfo("t", 0)) &&
        pyopencv_to_safe(pyobj_X, X, ArgInfo("X", 0)) )
    {
        ERRWRAP2(retval = cv::sfm::depth(R, t, X));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_R = NULL;
    UMat R;
    PyObject* pyobj_t = NULL;
    UMat t;
    PyObject* pyobj_X = NULL;
    UMat X;
    double retval;

    const char* keywords[] = { "R", "t", "X", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:depth", (char**)keywords, &pyobj_R, &pyobj_t, &pyobj_X) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) &&
        pyopencv_to_safe(pyobj_t, t, ArgInfo("t", 0)) &&
        pyopencv_to_safe(pyobj_X, X, ArgInfo("X", 0)) )
    {
        ERRWRAP2(retval = cv::sfm::depth(R, t, X));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("depth");

    return NULL;
}

static PyObject* pyopencv_cv_sfm_essentialFromFundamental(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::sfm;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_F = NULL;
    Mat F;
    PyObject* pyobj_K1 = NULL;
    Mat K1;
    PyObject* pyobj_K2 = NULL;
    Mat K2;
    PyObject* pyobj_E = NULL;
    Mat E;

    const char* keywords[] = { "F", "K1", "K2", "E", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:essentialFromFundamental", (char**)keywords, &pyobj_F, &pyobj_K1, &pyobj_K2, &pyobj_E) &&
        pyopencv_to_safe(pyobj_F, F, ArgInfo("F", 0)) &&
        pyopencv_to_safe(pyobj_K1, K1, ArgInfo("K1", 0)) &&
        pyopencv_to_safe(pyobj_K2, K2, ArgInfo("K2", 0)) &&
        pyopencv_to_safe(pyobj_E, E, ArgInfo("E", 1)) )
    {
        ERRWRAP2(cv::sfm::essentialFromFundamental(F, K1, K2, E));
        return pyopencv_from(E);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_F = NULL;
    UMat F;
    PyObject* pyobj_K1 = NULL;
    UMat K1;
    PyObject* pyobj_K2 = NULL;
    UMat K2;
    PyObject* pyobj_E = NULL;
    UMat E;

    const char* keywords[] = { "F", "K1", "K2", "E", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:essentialFromFundamental", (char**)keywords, &pyobj_F, &pyobj_K1, &pyobj_K2, &pyobj_E) &&
        pyopencv_to_safe(pyobj_F, F, ArgInfo("F", 0)) &&
        pyopencv_to_safe(pyobj_K1, K1, ArgInfo("K1", 0)) &&
        pyopencv_to_safe(pyobj_K2, K2, ArgInfo("K2", 0)) &&
        pyopencv_to_safe(pyobj_E, E, ArgInfo("E", 1)) )
    {
        ERRWRAP2(cv::sfm::essentialFromFundamental(F, K1, K2, E));
        return pyopencv_from(E);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("essentialFromFundamental");

    return NULL;
}

static PyObject* pyopencv_cv_sfm_essentialFromRt(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::sfm;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_R1 = NULL;
    Mat R1;
    PyObject* pyobj_t1 = NULL;
    Mat t1;
    PyObject* pyobj_R2 = NULL;
    Mat R2;
    PyObject* pyobj_t2 = NULL;
    Mat t2;
    PyObject* pyobj_E = NULL;
    Mat E;

    const char* keywords[] = { "R1", "t1", "R2", "t2", "E", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:essentialFromRt", (char**)keywords, &pyobj_R1, &pyobj_t1, &pyobj_R2, &pyobj_t2, &pyobj_E) &&
        pyopencv_to_safe(pyobj_R1, R1, ArgInfo("R1", 0)) &&
        pyopencv_to_safe(pyobj_t1, t1, ArgInfo("t1", 0)) &&
        pyopencv_to_safe(pyobj_R2, R2, ArgInfo("R2", 0)) &&
        pyopencv_to_safe(pyobj_t2, t2, ArgInfo("t2", 0)) &&
        pyopencv_to_safe(pyobj_E, E, ArgInfo("E", 1)) )
    {
        ERRWRAP2(cv::sfm::essentialFromRt(R1, t1, R2, t2, E));
        return pyopencv_from(E);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_R1 = NULL;
    UMat R1;
    PyObject* pyobj_t1 = NULL;
    UMat t1;
    PyObject* pyobj_R2 = NULL;
    UMat R2;
    PyObject* pyobj_t2 = NULL;
    UMat t2;
    PyObject* pyobj_E = NULL;
    UMat E;

    const char* keywords[] = { "R1", "t1", "R2", "t2", "E", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:essentialFromRt", (char**)keywords, &pyobj_R1, &pyobj_t1, &pyobj_R2, &pyobj_t2, &pyobj_E) &&
        pyopencv_to_safe(pyobj_R1, R1, ArgInfo("R1", 0)) &&
        pyopencv_to_safe(pyobj_t1, t1, ArgInfo("t1", 0)) &&
        pyopencv_to_safe(pyobj_R2, R2, ArgInfo("R2", 0)) &&
        pyopencv_to_safe(pyobj_t2, t2, ArgInfo("t2", 0)) &&
        pyopencv_to_safe(pyobj_E, E, ArgInfo("E", 1)) )
    {
        ERRWRAP2(cv::sfm::essentialFromRt(R1, t1, R2, t2, E));
        return pyopencv_from(E);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("essentialFromRt");

    return NULL;
}

static PyObject* pyopencv_cv_sfm_euclideanToHomogeneous(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::sfm;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:euclideanToHomogeneous", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::sfm::euclideanToHomogeneous(src, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:euclideanToHomogeneous", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::sfm::euclideanToHomogeneous(src, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("euclideanToHomogeneous");

    return NULL;
}

static PyObject* pyopencv_cv_sfm_fundamentalFromCorrespondences7PointRobust(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::sfm;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_x1 = NULL;
    Mat x1;
    PyObject* pyobj_x2 = NULL;
    Mat x2;
    PyObject* pyobj_max_error = NULL;
    double max_error=0;
    PyObject* pyobj_F = NULL;
    Mat F;
    PyObject* pyobj_inliers = NULL;
    Mat inliers;
    PyObject* pyobj_outliers_probability = NULL;
    double outliers_probability=1e-2;
    double retval;

    const char* keywords[] = { "x1", "x2", "max_error", "F", "inliers", "outliers_probability", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:fundamentalFromCorrespondences7PointRobust", (char**)keywords, &pyobj_x1, &pyobj_x2, &pyobj_max_error, &pyobj_F, &pyobj_inliers, &pyobj_outliers_probability) &&
        pyopencv_to_safe(pyobj_x1, x1, ArgInfo("x1", 0)) &&
        pyopencv_to_safe(pyobj_x2, x2, ArgInfo("x2", 0)) &&
        pyopencv_to_safe(pyobj_max_error, max_error, ArgInfo("max_error", 0)) &&
        pyopencv_to_safe(pyobj_F, F, ArgInfo("F", 1)) &&
        pyopencv_to_safe(pyobj_inliers, inliers, ArgInfo("inliers", 1)) &&
        pyopencv_to_safe(pyobj_outliers_probability, outliers_probability, ArgInfo("outliers_probability", 0)) )
    {
        ERRWRAP2(retval = cv::sfm::fundamentalFromCorrespondences7PointRobust(x1, x2, max_error, F, inliers, outliers_probability));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(F), pyopencv_from(inliers));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_x1 = NULL;
    UMat x1;
    PyObject* pyobj_x2 = NULL;
    UMat x2;
    PyObject* pyobj_max_error = NULL;
    double max_error=0;
    PyObject* pyobj_F = NULL;
    UMat F;
    PyObject* pyobj_inliers = NULL;
    UMat inliers;
    PyObject* pyobj_outliers_probability = NULL;
    double outliers_probability=1e-2;
    double retval;

    const char* keywords[] = { "x1", "x2", "max_error", "F", "inliers", "outliers_probability", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:fundamentalFromCorrespondences7PointRobust", (char**)keywords, &pyobj_x1, &pyobj_x2, &pyobj_max_error, &pyobj_F, &pyobj_inliers, &pyobj_outliers_probability) &&
        pyopencv_to_safe(pyobj_x1, x1, ArgInfo("x1", 0)) &&
        pyopencv_to_safe(pyobj_x2, x2, ArgInfo("x2", 0)) &&
        pyopencv_to_safe(pyobj_max_error, max_error, ArgInfo("max_error", 0)) &&
        pyopencv_to_safe(pyobj_F, F, ArgInfo("F", 1)) &&
        pyopencv_to_safe(pyobj_inliers, inliers, ArgInfo("inliers", 1)) &&
        pyopencv_to_safe(pyobj_outliers_probability, outliers_probability, ArgInfo("outliers_probability", 0)) )
    {
        ERRWRAP2(retval = cv::sfm::fundamentalFromCorrespondences7PointRobust(x1, x2, max_error, F, inliers, outliers_probability));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(F), pyopencv_from(inliers));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("fundamentalFromCorrespondences7PointRobust");

    return NULL;
}

static PyObject* pyopencv_cv_sfm_fundamentalFromCorrespondences8PointRobust(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::sfm;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_x1 = NULL;
    Mat x1;
    PyObject* pyobj_x2 = NULL;
    Mat x2;
    PyObject* pyobj_max_error = NULL;
    double max_error=0;
    PyObject* pyobj_F = NULL;
    Mat F;
    PyObject* pyobj_inliers = NULL;
    Mat inliers;
    PyObject* pyobj_outliers_probability = NULL;
    double outliers_probability=1e-2;
    double retval;

    const char* keywords[] = { "x1", "x2", "max_error", "F", "inliers", "outliers_probability", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:fundamentalFromCorrespondences8PointRobust", (char**)keywords, &pyobj_x1, &pyobj_x2, &pyobj_max_error, &pyobj_F, &pyobj_inliers, &pyobj_outliers_probability) &&
        pyopencv_to_safe(pyobj_x1, x1, ArgInfo("x1", 0)) &&
        pyopencv_to_safe(pyobj_x2, x2, ArgInfo("x2", 0)) &&
        pyopencv_to_safe(pyobj_max_error, max_error, ArgInfo("max_error", 0)) &&
        pyopencv_to_safe(pyobj_F, F, ArgInfo("F", 1)) &&
        pyopencv_to_safe(pyobj_inliers, inliers, ArgInfo("inliers", 1)) &&
        pyopencv_to_safe(pyobj_outliers_probability, outliers_probability, ArgInfo("outliers_probability", 0)) )
    {
        ERRWRAP2(retval = cv::sfm::fundamentalFromCorrespondences8PointRobust(x1, x2, max_error, F, inliers, outliers_probability));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(F), pyopencv_from(inliers));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_x1 = NULL;
    UMat x1;
    PyObject* pyobj_x2 = NULL;
    UMat x2;
    PyObject* pyobj_max_error = NULL;
    double max_error=0;
    PyObject* pyobj_F = NULL;
    UMat F;
    PyObject* pyobj_inliers = NULL;
    UMat inliers;
    PyObject* pyobj_outliers_probability = NULL;
    double outliers_probability=1e-2;
    double retval;

    const char* keywords[] = { "x1", "x2", "max_error", "F", "inliers", "outliers_probability", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOO:fundamentalFromCorrespondences8PointRobust", (char**)keywords, &pyobj_x1, &pyobj_x2, &pyobj_max_error, &pyobj_F, &pyobj_inliers, &pyobj_outliers_probability) &&
        pyopencv_to_safe(pyobj_x1, x1, ArgInfo("x1", 0)) &&
        pyopencv_to_safe(pyobj_x2, x2, ArgInfo("x2", 0)) &&
        pyopencv_to_safe(pyobj_max_error, max_error, ArgInfo("max_error", 0)) &&
        pyopencv_to_safe(pyobj_F, F, ArgInfo("F", 1)) &&
        pyopencv_to_safe(pyobj_inliers, inliers, ArgInfo("inliers", 1)) &&
        pyopencv_to_safe(pyobj_outliers_probability, outliers_probability, ArgInfo("outliers_probability", 0)) )
    {
        ERRWRAP2(retval = cv::sfm::fundamentalFromCorrespondences8PointRobust(x1, x2, max_error, F, inliers, outliers_probability));
        return Py_BuildValue("(NNN)", pyopencv_from(retval), pyopencv_from(F), pyopencv_from(inliers));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("fundamentalFromCorrespondences8PointRobust");

    return NULL;
}

static PyObject* pyopencv_cv_sfm_fundamentalFromEssential(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::sfm;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_E = NULL;
    Mat E;
    PyObject* pyobj_K1 = NULL;
    Mat K1;
    PyObject* pyobj_K2 = NULL;
    Mat K2;
    PyObject* pyobj_F = NULL;
    Mat F;

    const char* keywords[] = { "E", "K1", "K2", "F", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:fundamentalFromEssential", (char**)keywords, &pyobj_E, &pyobj_K1, &pyobj_K2, &pyobj_F) &&
        pyopencv_to_safe(pyobj_E, E, ArgInfo("E", 0)) &&
        pyopencv_to_safe(pyobj_K1, K1, ArgInfo("K1", 0)) &&
        pyopencv_to_safe(pyobj_K2, K2, ArgInfo("K2", 0)) &&
        pyopencv_to_safe(pyobj_F, F, ArgInfo("F", 1)) )
    {
        ERRWRAP2(cv::sfm::fundamentalFromEssential(E, K1, K2, F));
        return pyopencv_from(F);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_E = NULL;
    UMat E;
    PyObject* pyobj_K1 = NULL;
    UMat K1;
    PyObject* pyobj_K2 = NULL;
    UMat K2;
    PyObject* pyobj_F = NULL;
    UMat F;

    const char* keywords[] = { "E", "K1", "K2", "F", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:fundamentalFromEssential", (char**)keywords, &pyobj_E, &pyobj_K1, &pyobj_K2, &pyobj_F) &&
        pyopencv_to_safe(pyobj_E, E, ArgInfo("E", 0)) &&
        pyopencv_to_safe(pyobj_K1, K1, ArgInfo("K1", 0)) &&
        pyopencv_to_safe(pyobj_K2, K2, ArgInfo("K2", 0)) &&
        pyopencv_to_safe(pyobj_F, F, ArgInfo("F", 1)) )
    {
        ERRWRAP2(cv::sfm::fundamentalFromEssential(E, K1, K2, F));
        return pyopencv_from(F);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("fundamentalFromEssential");

    return NULL;
}

static PyObject* pyopencv_cv_sfm_fundamentalFromProjections(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::sfm;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_P1 = NULL;
    Mat P1;
    PyObject* pyobj_P2 = NULL;
    Mat P2;
    PyObject* pyobj_F = NULL;
    Mat F;

    const char* keywords[] = { "P1", "P2", "F", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:fundamentalFromProjections", (char**)keywords, &pyobj_P1, &pyobj_P2, &pyobj_F) &&
        pyopencv_to_safe(pyobj_P1, P1, ArgInfo("P1", 0)) &&
        pyopencv_to_safe(pyobj_P2, P2, ArgInfo("P2", 0)) &&
        pyopencv_to_safe(pyobj_F, F, ArgInfo("F", 1)) )
    {
        ERRWRAP2(cv::sfm::fundamentalFromProjections(P1, P2, F));
        return pyopencv_from(F);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_P1 = NULL;
    UMat P1;
    PyObject* pyobj_P2 = NULL;
    UMat P2;
    PyObject* pyobj_F = NULL;
    UMat F;

    const char* keywords[] = { "P1", "P2", "F", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:fundamentalFromProjections", (char**)keywords, &pyobj_P1, &pyobj_P2, &pyobj_F) &&
        pyopencv_to_safe(pyobj_P1, P1, ArgInfo("P1", 0)) &&
        pyopencv_to_safe(pyobj_P2, P2, ArgInfo("P2", 0)) &&
        pyopencv_to_safe(pyobj_F, F, ArgInfo("F", 1)) )
    {
        ERRWRAP2(cv::sfm::fundamentalFromProjections(P1, P2, F));
        return pyopencv_from(F);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("fundamentalFromProjections");

    return NULL;
}

static PyObject* pyopencv_cv_sfm_homogeneousToEuclidean(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::sfm;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:homogeneousToEuclidean", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::sfm::homogeneousToEuclidean(src, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "src", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:homogeneousToEuclidean", (char**)keywords, &pyobj_src, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::sfm::homogeneousToEuclidean(src, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("homogeneousToEuclidean");

    return NULL;
}

static PyObject* pyopencv_cv_sfm_importReconstruction(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::sfm;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_file = NULL;
    String file;
    PyObject* pyobj_Rs = NULL;
    vector_Mat Rs;
    PyObject* pyobj_Ts = NULL;
    vector_Mat Ts;
    PyObject* pyobj_Ks = NULL;
    vector_Mat Ks;
    PyObject* pyobj_points3d = NULL;
    vector_Mat points3d;
    PyObject* pyobj_file_format = NULL;
    int file_format=SFM_IO_BUNDLER;

    const char* keywords[] = { "file", "Rs", "Ts", "Ks", "points3d", "file_format", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOOO:importReconstruction", (char**)keywords, &pyobj_file, &pyobj_Rs, &pyobj_Ts, &pyobj_Ks, &pyobj_points3d, &pyobj_file_format) &&
        pyopencv_to_safe(pyobj_file, file, ArgInfo("file", 0)) &&
        pyopencv_to_safe(pyobj_Rs, Rs, ArgInfo("Rs", 1)) &&
        pyopencv_to_safe(pyobj_Ts, Ts, ArgInfo("Ts", 1)) &&
        pyopencv_to_safe(pyobj_Ks, Ks, ArgInfo("Ks", 1)) &&
        pyopencv_to_safe(pyobj_points3d, points3d, ArgInfo("points3d", 1)) &&
        pyopencv_to_safe(pyobj_file_format, file_format, ArgInfo("file_format", 0)) )
    {
        ERRWRAP2(cv::sfm::importReconstruction(file, Rs, Ts, Ks, points3d, file_format));
        return Py_BuildValue("(NNNN)", pyopencv_from(Rs), pyopencv_from(Ts), pyopencv_from(Ks), pyopencv_from(points3d));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_file = NULL;
    String file;
    PyObject* pyobj_Rs = NULL;
    vector_UMat Rs;
    PyObject* pyobj_Ts = NULL;
    vector_UMat Ts;
    PyObject* pyobj_Ks = NULL;
    vector_UMat Ks;
    PyObject* pyobj_points3d = NULL;
    vector_UMat points3d;
    PyObject* pyobj_file_format = NULL;
    int file_format=SFM_IO_BUNDLER;

    const char* keywords[] = { "file", "Rs", "Ts", "Ks", "points3d", "file_format", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOOO:importReconstruction", (char**)keywords, &pyobj_file, &pyobj_Rs, &pyobj_Ts, &pyobj_Ks, &pyobj_points3d, &pyobj_file_format) &&
        pyopencv_to_safe(pyobj_file, file, ArgInfo("file", 0)) &&
        pyopencv_to_safe(pyobj_Rs, Rs, ArgInfo("Rs", 1)) &&
        pyopencv_to_safe(pyobj_Ts, Ts, ArgInfo("Ts", 1)) &&
        pyopencv_to_safe(pyobj_Ks, Ks, ArgInfo("Ks", 1)) &&
        pyopencv_to_safe(pyobj_points3d, points3d, ArgInfo("points3d", 1)) &&
        pyopencv_to_safe(pyobj_file_format, file_format, ArgInfo("file_format", 0)) )
    {
        ERRWRAP2(cv::sfm::importReconstruction(file, Rs, Ts, Ks, points3d, file_format));
        return Py_BuildValue("(NNNN)", pyopencv_from(Rs), pyopencv_from(Ts), pyopencv_from(Ks), pyopencv_from(points3d));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("importReconstruction");

    return NULL;
}

static PyObject* pyopencv_cv_sfm_isotropicPreconditionerFromPoints(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::sfm;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_points = NULL;
    Mat points;
    PyObject* pyobj_T = NULL;
    Mat T;

    const char* keywords[] = { "points", "T", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:isotropicPreconditionerFromPoints", (char**)keywords, &pyobj_points, &pyobj_T) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) &&
        pyopencv_to_safe(pyobj_T, T, ArgInfo("T", 1)) )
    {
        ERRWRAP2(cv::sfm::isotropicPreconditionerFromPoints(points, T));
        return pyopencv_from(T);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_points = NULL;
    UMat points;
    PyObject* pyobj_T = NULL;
    UMat T;

    const char* keywords[] = { "points", "T", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:isotropicPreconditionerFromPoints", (char**)keywords, &pyobj_points, &pyobj_T) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) &&
        pyopencv_to_safe(pyobj_T, T, ArgInfo("T", 1)) )
    {
        ERRWRAP2(cv::sfm::isotropicPreconditionerFromPoints(points, T));
        return pyopencv_from(T);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("isotropicPreconditionerFromPoints");

    return NULL;
}

static PyObject* pyopencv_cv_sfm_meanAndVarianceAlongRows(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::sfm;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_A = NULL;
    Mat A;
    PyObject* pyobj_mean = NULL;
    Mat mean;
    PyObject* pyobj_variance = NULL;
    Mat variance;

    const char* keywords[] = { "A", "mean", "variance", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:meanAndVarianceAlongRows", (char**)keywords, &pyobj_A, &pyobj_mean, &pyobj_variance) &&
        pyopencv_to_safe(pyobj_A, A, ArgInfo("A", 0)) &&
        pyopencv_to_safe(pyobj_mean, mean, ArgInfo("mean", 1)) &&
        pyopencv_to_safe(pyobj_variance, variance, ArgInfo("variance", 1)) )
    {
        ERRWRAP2(cv::sfm::meanAndVarianceAlongRows(A, mean, variance));
        return Py_BuildValue("(NN)", pyopencv_from(mean), pyopencv_from(variance));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_A = NULL;
    UMat A;
    PyObject* pyobj_mean = NULL;
    UMat mean;
    PyObject* pyobj_variance = NULL;
    UMat variance;

    const char* keywords[] = { "A", "mean", "variance", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:meanAndVarianceAlongRows", (char**)keywords, &pyobj_A, &pyobj_mean, &pyobj_variance) &&
        pyopencv_to_safe(pyobj_A, A, ArgInfo("A", 0)) &&
        pyopencv_to_safe(pyobj_mean, mean, ArgInfo("mean", 1)) &&
        pyopencv_to_safe(pyobj_variance, variance, ArgInfo("variance", 1)) )
    {
        ERRWRAP2(cv::sfm::meanAndVarianceAlongRows(A, mean, variance));
        return Py_BuildValue("(NN)", pyopencv_from(mean), pyopencv_from(variance));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("meanAndVarianceAlongRows");

    return NULL;
}

static PyObject* pyopencv_cv_sfm_motionFromEssential(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::sfm;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_E = NULL;
    Mat E;
    PyObject* pyobj_Rs = NULL;
    vector_Mat Rs;
    PyObject* pyobj_ts = NULL;
    vector_Mat ts;

    const char* keywords[] = { "E", "Rs", "ts", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:motionFromEssential", (char**)keywords, &pyobj_E, &pyobj_Rs, &pyobj_ts) &&
        pyopencv_to_safe(pyobj_E, E, ArgInfo("E", 0)) &&
        pyopencv_to_safe(pyobj_Rs, Rs, ArgInfo("Rs", 1)) &&
        pyopencv_to_safe(pyobj_ts, ts, ArgInfo("ts", 1)) )
    {
        ERRWRAP2(cv::sfm::motionFromEssential(E, Rs, ts));
        return Py_BuildValue("(NN)", pyopencv_from(Rs), pyopencv_from(ts));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_E = NULL;
    UMat E;
    PyObject* pyobj_Rs = NULL;
    vector_UMat Rs;
    PyObject* pyobj_ts = NULL;
    vector_UMat ts;

    const char* keywords[] = { "E", "Rs", "ts", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:motionFromEssential", (char**)keywords, &pyobj_E, &pyobj_Rs, &pyobj_ts) &&
        pyopencv_to_safe(pyobj_E, E, ArgInfo("E", 0)) &&
        pyopencv_to_safe(pyobj_Rs, Rs, ArgInfo("Rs", 1)) &&
        pyopencv_to_safe(pyobj_ts, ts, ArgInfo("ts", 1)) )
    {
        ERRWRAP2(cv::sfm::motionFromEssential(E, Rs, ts));
        return Py_BuildValue("(NN)", pyopencv_from(Rs), pyopencv_from(ts));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("motionFromEssential");

    return NULL;
}

static PyObject* pyopencv_cv_sfm_motionFromEssentialChooseSolution(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::sfm;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_Rs = NULL;
    vector_Mat Rs;
    PyObject* pyobj_ts = NULL;
    vector_Mat ts;
    PyObject* pyobj_K1 = NULL;
    Mat K1;
    PyObject* pyobj_x1 = NULL;
    Mat x1;
    PyObject* pyobj_K2 = NULL;
    Mat K2;
    PyObject* pyobj_x2 = NULL;
    Mat x2;
    int retval;

    const char* keywords[] = { "Rs", "ts", "K1", "x1", "K2", "x2", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO:motionFromEssentialChooseSolution", (char**)keywords, &pyobj_Rs, &pyobj_ts, &pyobj_K1, &pyobj_x1, &pyobj_K2, &pyobj_x2) &&
        pyopencv_to_safe(pyobj_Rs, Rs, ArgInfo("Rs", 0)) &&
        pyopencv_to_safe(pyobj_ts, ts, ArgInfo("ts", 0)) &&
        pyopencv_to_safe(pyobj_K1, K1, ArgInfo("K1", 0)) &&
        pyopencv_to_safe(pyobj_x1, x1, ArgInfo("x1", 0)) &&
        pyopencv_to_safe(pyobj_K2, K2, ArgInfo("K2", 0)) &&
        pyopencv_to_safe(pyobj_x2, x2, ArgInfo("x2", 0)) )
    {
        ERRWRAP2(retval = cv::sfm::motionFromEssentialChooseSolution(Rs, ts, K1, x1, K2, x2));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_Rs = NULL;
    vector_UMat Rs;
    PyObject* pyobj_ts = NULL;
    vector_UMat ts;
    PyObject* pyobj_K1 = NULL;
    UMat K1;
    PyObject* pyobj_x1 = NULL;
    UMat x1;
    PyObject* pyobj_K2 = NULL;
    UMat K2;
    PyObject* pyobj_x2 = NULL;
    UMat x2;
    int retval;

    const char* keywords[] = { "Rs", "ts", "K1", "x1", "K2", "x2", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOOO:motionFromEssentialChooseSolution", (char**)keywords, &pyobj_Rs, &pyobj_ts, &pyobj_K1, &pyobj_x1, &pyobj_K2, &pyobj_x2) &&
        pyopencv_to_safe(pyobj_Rs, Rs, ArgInfo("Rs", 0)) &&
        pyopencv_to_safe(pyobj_ts, ts, ArgInfo("ts", 0)) &&
        pyopencv_to_safe(pyobj_K1, K1, ArgInfo("K1", 0)) &&
        pyopencv_to_safe(pyobj_x1, x1, ArgInfo("x1", 0)) &&
        pyopencv_to_safe(pyobj_K2, K2, ArgInfo("K2", 0)) &&
        pyopencv_to_safe(pyobj_x2, x2, ArgInfo("x2", 0)) )
    {
        ERRWRAP2(retval = cv::sfm::motionFromEssentialChooseSolution(Rs, ts, K1, x1, K2, x2));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("motionFromEssentialChooseSolution");

    return NULL;
}

static PyObject* pyopencv_cv_sfm_normalizeFundamental(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::sfm;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_F = NULL;
    Mat F;
    PyObject* pyobj_F_normalized = NULL;
    Mat F_normalized;

    const char* keywords[] = { "F", "F_normalized", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:normalizeFundamental", (char**)keywords, &pyobj_F, &pyobj_F_normalized) &&
        pyopencv_to_safe(pyobj_F, F, ArgInfo("F", 0)) &&
        pyopencv_to_safe(pyobj_F_normalized, F_normalized, ArgInfo("F_normalized", 1)) )
    {
        ERRWRAP2(cv::sfm::normalizeFundamental(F, F_normalized));
        return pyopencv_from(F_normalized);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_F = NULL;
    UMat F;
    PyObject* pyobj_F_normalized = NULL;
    UMat F_normalized;

    const char* keywords[] = { "F", "F_normalized", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:normalizeFundamental", (char**)keywords, &pyobj_F, &pyobj_F_normalized) &&
        pyopencv_to_safe(pyobj_F, F, ArgInfo("F", 0)) &&
        pyopencv_to_safe(pyobj_F_normalized, F_normalized, ArgInfo("F_normalized", 1)) )
    {
        ERRWRAP2(cv::sfm::normalizeFundamental(F, F_normalized));
        return pyopencv_from(F_normalized);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("normalizeFundamental");

    return NULL;
}

static PyObject* pyopencv_cv_sfm_normalizeIsotropicPoints(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::sfm;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_points = NULL;
    Mat points;
    PyObject* pyobj_normalized_points = NULL;
    Mat normalized_points;
    PyObject* pyobj_T = NULL;
    Mat T;

    const char* keywords[] = { "points", "normalized_points", "T", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:normalizeIsotropicPoints", (char**)keywords, &pyobj_points, &pyobj_normalized_points, &pyobj_T) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) &&
        pyopencv_to_safe(pyobj_normalized_points, normalized_points, ArgInfo("normalized_points", 1)) &&
        pyopencv_to_safe(pyobj_T, T, ArgInfo("T", 1)) )
    {
        ERRWRAP2(cv::sfm::normalizeIsotropicPoints(points, normalized_points, T));
        return Py_BuildValue("(NN)", pyopencv_from(normalized_points), pyopencv_from(T));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_points = NULL;
    UMat points;
    PyObject* pyobj_normalized_points = NULL;
    UMat normalized_points;
    PyObject* pyobj_T = NULL;
    UMat T;

    const char* keywords[] = { "points", "normalized_points", "T", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:normalizeIsotropicPoints", (char**)keywords, &pyobj_points, &pyobj_normalized_points, &pyobj_T) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) &&
        pyopencv_to_safe(pyobj_normalized_points, normalized_points, ArgInfo("normalized_points", 1)) &&
        pyopencv_to_safe(pyobj_T, T, ArgInfo("T", 1)) )
    {
        ERRWRAP2(cv::sfm::normalizeIsotropicPoints(points, normalized_points, T));
        return Py_BuildValue("(NN)", pyopencv_from(normalized_points), pyopencv_from(T));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("normalizeIsotropicPoints");

    return NULL;
}

static PyObject* pyopencv_cv_sfm_normalizePoints(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::sfm;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_points = NULL;
    Mat points;
    PyObject* pyobj_normalized_points = NULL;
    Mat normalized_points;
    PyObject* pyobj_T = NULL;
    Mat T;

    const char* keywords[] = { "points", "normalized_points", "T", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:normalizePoints", (char**)keywords, &pyobj_points, &pyobj_normalized_points, &pyobj_T) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) &&
        pyopencv_to_safe(pyobj_normalized_points, normalized_points, ArgInfo("normalized_points", 1)) &&
        pyopencv_to_safe(pyobj_T, T, ArgInfo("T", 1)) )
    {
        ERRWRAP2(cv::sfm::normalizePoints(points, normalized_points, T));
        return Py_BuildValue("(NN)", pyopencv_from(normalized_points), pyopencv_from(T));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_points = NULL;
    UMat points;
    PyObject* pyobj_normalized_points = NULL;
    UMat normalized_points;
    PyObject* pyobj_T = NULL;
    UMat T;

    const char* keywords[] = { "points", "normalized_points", "T", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:normalizePoints", (char**)keywords, &pyobj_points, &pyobj_normalized_points, &pyobj_T) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) &&
        pyopencv_to_safe(pyobj_normalized_points, normalized_points, ArgInfo("normalized_points", 1)) &&
        pyopencv_to_safe(pyobj_T, T, ArgInfo("T", 1)) )
    {
        ERRWRAP2(cv::sfm::normalizePoints(points, normalized_points, T));
        return Py_BuildValue("(NN)", pyopencv_from(normalized_points), pyopencv_from(T));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("normalizePoints");

    return NULL;
}

static PyObject* pyopencv_cv_sfm_normalizedEightPointSolver(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::sfm;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_x1 = NULL;
    Mat x1;
    PyObject* pyobj_x2 = NULL;
    Mat x2;
    PyObject* pyobj_F = NULL;
    Mat F;

    const char* keywords[] = { "x1", "x2", "F", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:normalizedEightPointSolver", (char**)keywords, &pyobj_x1, &pyobj_x2, &pyobj_F) &&
        pyopencv_to_safe(pyobj_x1, x1, ArgInfo("x1", 0)) &&
        pyopencv_to_safe(pyobj_x2, x2, ArgInfo("x2", 0)) &&
        pyopencv_to_safe(pyobj_F, F, ArgInfo("F", 1)) )
    {
        ERRWRAP2(cv::sfm::normalizedEightPointSolver(x1, x2, F));
        return pyopencv_from(F);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_x1 = NULL;
    UMat x1;
    PyObject* pyobj_x2 = NULL;
    UMat x2;
    PyObject* pyobj_F = NULL;
    UMat F;

    const char* keywords[] = { "x1", "x2", "F", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:normalizedEightPointSolver", (char**)keywords, &pyobj_x1, &pyobj_x2, &pyobj_F) &&
        pyopencv_to_safe(pyobj_x1, x1, ArgInfo("x1", 0)) &&
        pyopencv_to_safe(pyobj_x2, x2, ArgInfo("x2", 0)) &&
        pyopencv_to_safe(pyobj_F, F, ArgInfo("F", 1)) )
    {
        ERRWRAP2(cv::sfm::normalizedEightPointSolver(x1, x2, F));
        return pyopencv_from(F);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("normalizedEightPointSolver");

    return NULL;
}

static PyObject* pyopencv_cv_sfm_preconditionerFromPoints(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::sfm;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_points = NULL;
    Mat points;
    PyObject* pyobj_T = NULL;
    Mat T;

    const char* keywords[] = { "points", "T", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:preconditionerFromPoints", (char**)keywords, &pyobj_points, &pyobj_T) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) &&
        pyopencv_to_safe(pyobj_T, T, ArgInfo("T", 1)) )
    {
        ERRWRAP2(cv::sfm::preconditionerFromPoints(points, T));
        return pyopencv_from(T);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_points = NULL;
    UMat points;
    PyObject* pyobj_T = NULL;
    UMat T;

    const char* keywords[] = { "points", "T", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:preconditionerFromPoints", (char**)keywords, &pyobj_points, &pyobj_T) &&
        pyopencv_to_safe(pyobj_points, points, ArgInfo("points", 0)) &&
        pyopencv_to_safe(pyobj_T, T, ArgInfo("T", 1)) )
    {
        ERRWRAP2(cv::sfm::preconditionerFromPoints(points, T));
        return pyopencv_from(T);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("preconditionerFromPoints");

    return NULL;
}

static PyObject* pyopencv_cv_sfm_projectionFromKRt(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::sfm;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_K = NULL;
    Mat K;
    PyObject* pyobj_R = NULL;
    Mat R;
    PyObject* pyobj_t = NULL;
    Mat t;
    PyObject* pyobj_P = NULL;
    Mat P;

    const char* keywords[] = { "K", "R", "t", "P", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:projectionFromKRt", (char**)keywords, &pyobj_K, &pyobj_R, &pyobj_t, &pyobj_P) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) &&
        pyopencv_to_safe(pyobj_t, t, ArgInfo("t", 0)) &&
        pyopencv_to_safe(pyobj_P, P, ArgInfo("P", 1)) )
    {
        ERRWRAP2(cv::sfm::projectionFromKRt(K, R, t, P));
        return pyopencv_from(P);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_K = NULL;
    UMat K;
    PyObject* pyobj_R = NULL;
    UMat R;
    PyObject* pyobj_t = NULL;
    UMat t;
    PyObject* pyobj_P = NULL;
    UMat P;

    const char* keywords[] = { "K", "R", "t", "P", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:projectionFromKRt", (char**)keywords, &pyobj_K, &pyobj_R, &pyobj_t, &pyobj_P) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 0)) &&
        pyopencv_to_safe(pyobj_t, t, ArgInfo("t", 0)) &&
        pyopencv_to_safe(pyobj_P, P, ArgInfo("P", 1)) )
    {
        ERRWRAP2(cv::sfm::projectionFromKRt(K, R, t, P));
        return pyopencv_from(P);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("projectionFromKRt");

    return NULL;
}

static PyObject* pyopencv_cv_sfm_projectionsFromFundamental(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::sfm;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_F = NULL;
    Mat F;
    PyObject* pyobj_P1 = NULL;
    Mat P1;
    PyObject* pyobj_P2 = NULL;
    Mat P2;

    const char* keywords[] = { "F", "P1", "P2", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:projectionsFromFundamental", (char**)keywords, &pyobj_F, &pyobj_P1, &pyobj_P2) &&
        pyopencv_to_safe(pyobj_F, F, ArgInfo("F", 0)) &&
        pyopencv_to_safe(pyobj_P1, P1, ArgInfo("P1", 1)) &&
        pyopencv_to_safe(pyobj_P2, P2, ArgInfo("P2", 1)) )
    {
        ERRWRAP2(cv::sfm::projectionsFromFundamental(F, P1, P2));
        return Py_BuildValue("(NN)", pyopencv_from(P1), pyopencv_from(P2));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_F = NULL;
    UMat F;
    PyObject* pyobj_P1 = NULL;
    UMat P1;
    PyObject* pyobj_P2 = NULL;
    UMat P2;

    const char* keywords[] = { "F", "P1", "P2", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:projectionsFromFundamental", (char**)keywords, &pyobj_F, &pyobj_P1, &pyobj_P2) &&
        pyopencv_to_safe(pyobj_F, F, ArgInfo("F", 0)) &&
        pyopencv_to_safe(pyobj_P1, P1, ArgInfo("P1", 1)) &&
        pyopencv_to_safe(pyobj_P2, P2, ArgInfo("P2", 1)) )
    {
        ERRWRAP2(cv::sfm::projectionsFromFundamental(F, P1, P2));
        return Py_BuildValue("(NN)", pyopencv_from(P1), pyopencv_from(P2));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("projectionsFromFundamental");

    return NULL;
}

static PyObject* pyopencv_cv_sfm_relativeCameraMotion(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::sfm;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_R1 = NULL;
    Mat R1;
    PyObject* pyobj_t1 = NULL;
    Mat t1;
    PyObject* pyobj_R2 = NULL;
    Mat R2;
    PyObject* pyobj_t2 = NULL;
    Mat t2;
    PyObject* pyobj_R = NULL;
    Mat R;
    PyObject* pyobj_t = NULL;
    Mat t;

    const char* keywords[] = { "R1", "t1", "R2", "t2", "R", "t", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OO:relativeCameraMotion", (char**)keywords, &pyobj_R1, &pyobj_t1, &pyobj_R2, &pyobj_t2, &pyobj_R, &pyobj_t) &&
        pyopencv_to_safe(pyobj_R1, R1, ArgInfo("R1", 0)) &&
        pyopencv_to_safe(pyobj_t1, t1, ArgInfo("t1", 0)) &&
        pyopencv_to_safe(pyobj_R2, R2, ArgInfo("R2", 0)) &&
        pyopencv_to_safe(pyobj_t2, t2, ArgInfo("t2", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 1)) &&
        pyopencv_to_safe(pyobj_t, t, ArgInfo("t", 1)) )
    {
        ERRWRAP2(cv::sfm::relativeCameraMotion(R1, t1, R2, t2, R, t));
        return Py_BuildValue("(NN)", pyopencv_from(R), pyopencv_from(t));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_R1 = NULL;
    UMat R1;
    PyObject* pyobj_t1 = NULL;
    UMat t1;
    PyObject* pyobj_R2 = NULL;
    UMat R2;
    PyObject* pyobj_t2 = NULL;
    UMat t2;
    PyObject* pyobj_R = NULL;
    UMat R;
    PyObject* pyobj_t = NULL;
    UMat t;

    const char* keywords[] = { "R1", "t1", "R2", "t2", "R", "t", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OO:relativeCameraMotion", (char**)keywords, &pyobj_R1, &pyobj_t1, &pyobj_R2, &pyobj_t2, &pyobj_R, &pyobj_t) &&
        pyopencv_to_safe(pyobj_R1, R1, ArgInfo("R1", 0)) &&
        pyopencv_to_safe(pyobj_t1, t1, ArgInfo("t1", 0)) &&
        pyopencv_to_safe(pyobj_R2, R2, ArgInfo("R2", 0)) &&
        pyopencv_to_safe(pyobj_t2, t2, ArgInfo("t2", 0)) &&
        pyopencv_to_safe(pyobj_R, R, ArgInfo("R", 1)) &&
        pyopencv_to_safe(pyobj_t, t, ArgInfo("t", 1)) )
    {
        ERRWRAP2(cv::sfm::relativeCameraMotion(R1, t1, R2, t2, R, t));
        return Py_BuildValue("(NN)", pyopencv_from(R), pyopencv_from(t));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("relativeCameraMotion");

    return NULL;
}

static PyObject* pyopencv_cv_sfm_skew(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::sfm;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_x = NULL;
    Mat x;
    Mat retval;

    const char* keywords[] = { "x", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:skew", (char**)keywords, &pyobj_x) &&
        pyopencv_to_safe(pyobj_x, x, ArgInfo("x", 0)) )
    {
        ERRWRAP2(retval = cv::sfm::skew(x));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_x = NULL;
    UMat x;
    Mat retval;

    const char* keywords[] = { "x", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:skew", (char**)keywords, &pyobj_x) &&
        pyopencv_to_safe(pyobj_x, x, ArgInfo("x", 0)) )
    {
        ERRWRAP2(retval = cv::sfm::skew(x));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("skew");

    return NULL;
}

static PyObject* pyopencv_cv_sfm_triangulatePoints(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::sfm;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_points2d = NULL;
    vector_Mat points2d;
    PyObject* pyobj_projection_matrices = NULL;
    vector_Mat projection_matrices;
    PyObject* pyobj_points3d = NULL;
    Mat points3d;

    const char* keywords[] = { "points2d", "projection_matrices", "points3d", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:triangulatePoints", (char**)keywords, &pyobj_points2d, &pyobj_projection_matrices, &pyobj_points3d) &&
        pyopencv_to_safe(pyobj_points2d, points2d, ArgInfo("points2d", 0)) &&
        pyopencv_to_safe(pyobj_projection_matrices, projection_matrices, ArgInfo("projection_matrices", 0)) &&
        pyopencv_to_safe(pyobj_points3d, points3d, ArgInfo("points3d", 1)) )
    {
        ERRWRAP2(cv::sfm::triangulatePoints(points2d, projection_matrices, points3d));
        return pyopencv_from(points3d);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_points2d = NULL;
    vector_UMat points2d;
    PyObject* pyobj_projection_matrices = NULL;
    vector_UMat projection_matrices;
    PyObject* pyobj_points3d = NULL;
    UMat points3d;

    const char* keywords[] = { "points2d", "projection_matrices", "points3d", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:triangulatePoints", (char**)keywords, &pyobj_points2d, &pyobj_projection_matrices, &pyobj_points3d) &&
        pyopencv_to_safe(pyobj_points2d, points2d, ArgInfo("points2d", 0)) &&
        pyopencv_to_safe(pyobj_projection_matrices, projection_matrices, ArgInfo("projection_matrices", 0)) &&
        pyopencv_to_safe(pyobj_points3d, points3d, ArgInfo("points3d", 1)) )
    {
        ERRWRAP2(cv::sfm::triangulatePoints(points2d, projection_matrices, points3d));
        return pyopencv_from(points3d);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("triangulatePoints");

    return NULL;
}

static PyObject* pyopencv_cv_stereo_QuasiDenseStereo_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::stereo;

    PyObject* pyobj_monoImgSize = NULL;
    Size monoImgSize;
    PyObject* pyobj_paramFilepath = NULL;
    String paramFilepath=cv::String();
    cv::Ptr<QuasiDenseStereo> retval;

    const char* keywords[] = { "monoImgSize", "paramFilepath", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:QuasiDenseStereo_create", (char**)keywords, &pyobj_monoImgSize, &pyobj_paramFilepath) &&
        pyopencv_to_safe(pyobj_monoImgSize, monoImgSize, ArgInfo("monoImgSize", 0)) &&
        pyopencv_to_safe(pyobj_paramFilepath, paramFilepath, ArgInfo("paramFilepath", 0)) )
    {
        ERRWRAP2(retval = cv::stereo::QuasiDenseStereo::create(monoImgSize, paramFilepath));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_structured_light_GrayCodePattern_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::structured_light;

    PyObject* pyobj_width = NULL;
    int width=0;
    PyObject* pyobj_height = NULL;
    int height=0;
    Ptr<GrayCodePattern> retval;

    const char* keywords[] = { "width", "height", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:GrayCodePattern_create", (char**)keywords, &pyobj_width, &pyobj_height) &&
        pyopencv_to_safe(pyobj_width, width, ArgInfo("width", 0)) &&
        pyopencv_to_safe(pyobj_height, height, ArgInfo("height", 0)) )
    {
        ERRWRAP2(retval = cv::structured_light::GrayCodePattern::create(width, height));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_structured_light_SinusoidalPattern_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::structured_light;

    PyObject* pyobj_parameters = NULL;
    Ptr<SinusoidalPattern::Params> parameters=makePtr<SinusoidalPattern::Params>();
    Ptr<SinusoidalPattern> retval;

    const char* keywords[] = { "parameters", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|O:SinusoidalPattern_create", (char**)keywords, &pyobj_parameters) &&
        pyopencv_to_safe(pyobj_parameters, parameters, ArgInfo("parameters", 0)) )
    {
        ERRWRAP2(retval = cv::structured_light::SinusoidalPattern::create(parameters));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_utils_dumpBool(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::utils;

    PyObject* pyobj_argument = NULL;
    bool argument=0;
    String retval;

    const char* keywords[] = { "argument", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:dumpBool", (char**)keywords, &pyobj_argument) &&
        pyopencv_to_safe(pyobj_argument, argument, ArgInfo("argument", 0)) )
    {
        ERRWRAP2(retval = cv::utils::dumpBool(argument));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_utils_dumpCString(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::utils;

    char* argument=(char*)"";
    String retval;

    const char* keywords[] = { "argument", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "s:dumpCString", (char**)keywords, &argument) )
    {
        ERRWRAP2(retval = cv::utils::dumpCString(argument));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_utils_dumpDouble(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::utils;

    PyObject* pyobj_argument = NULL;
    double argument=0;
    String retval;

    const char* keywords[] = { "argument", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:dumpDouble", (char**)keywords, &pyobj_argument) &&
        pyopencv_to_safe(pyobj_argument, argument, ArgInfo("argument", 0)) )
    {
        ERRWRAP2(retval = cv::utils::dumpDouble(argument));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_utils_dumpFloat(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::utils;

    PyObject* pyobj_argument = NULL;
    float argument=0.f;
    String retval;

    const char* keywords[] = { "argument", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:dumpFloat", (char**)keywords, &pyobj_argument) &&
        pyopencv_to_safe(pyobj_argument, argument, ArgInfo("argument", 0)) )
    {
        ERRWRAP2(retval = cv::utils::dumpFloat(argument));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_utils_dumpInputArray(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::utils;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_argument = NULL;
    Mat argument;
    String retval;

    const char* keywords[] = { "argument", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:dumpInputArray", (char**)keywords, &pyobj_argument) &&
        pyopencv_to_safe(pyobj_argument, argument, ArgInfo("argument", 0)) )
    {
        ERRWRAP2(retval = cv::utils::dumpInputArray(argument));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_argument = NULL;
    UMat argument;
    String retval;

    const char* keywords[] = { "argument", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:dumpInputArray", (char**)keywords, &pyobj_argument) &&
        pyopencv_to_safe(pyobj_argument, argument, ArgInfo("argument", 0)) )
    {
        ERRWRAP2(retval = cv::utils::dumpInputArray(argument));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("dumpInputArray");

    return NULL;
}

static PyObject* pyopencv_cv_utils_dumpInputArrayOfArrays(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::utils;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_argument = NULL;
    vector_Mat argument;
    String retval;

    const char* keywords[] = { "argument", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:dumpInputArrayOfArrays", (char**)keywords, &pyobj_argument) &&
        pyopencv_to_safe(pyobj_argument, argument, ArgInfo("argument", 0)) )
    {
        ERRWRAP2(retval = cv::utils::dumpInputArrayOfArrays(argument));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_argument = NULL;
    vector_UMat argument;
    String retval;

    const char* keywords[] = { "argument", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:dumpInputArrayOfArrays", (char**)keywords, &pyobj_argument) &&
        pyopencv_to_safe(pyobj_argument, argument, ArgInfo("argument", 0)) )
    {
        ERRWRAP2(retval = cv::utils::dumpInputArrayOfArrays(argument));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("dumpInputArrayOfArrays");

    return NULL;
}

static PyObject* pyopencv_cv_utils_dumpInputOutputArray(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::utils;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_argument = NULL;
    Mat argument;
    String retval;

    const char* keywords[] = { "argument", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:dumpInputOutputArray", (char**)keywords, &pyobj_argument) &&
        pyopencv_to_safe(pyobj_argument, argument, ArgInfo("argument", 1)) )
    {
        ERRWRAP2(retval = cv::utils::dumpInputOutputArray(argument));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(argument));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_argument = NULL;
    UMat argument;
    String retval;

    const char* keywords[] = { "argument", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:dumpInputOutputArray", (char**)keywords, &pyobj_argument) &&
        pyopencv_to_safe(pyobj_argument, argument, ArgInfo("argument", 1)) )
    {
        ERRWRAP2(retval = cv::utils::dumpInputOutputArray(argument));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(argument));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("dumpInputOutputArray");

    return NULL;
}

static PyObject* pyopencv_cv_utils_dumpInputOutputArrayOfArrays(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::utils;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_argument = NULL;
    vector_Mat argument;
    String retval;

    const char* keywords[] = { "argument", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:dumpInputOutputArrayOfArrays", (char**)keywords, &pyobj_argument) &&
        pyopencv_to_safe(pyobj_argument, argument, ArgInfo("argument", 1)) )
    {
        ERRWRAP2(retval = cv::utils::dumpInputOutputArrayOfArrays(argument));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(argument));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_argument = NULL;
    vector_UMat argument;
    String retval;

    const char* keywords[] = { "argument", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:dumpInputOutputArrayOfArrays", (char**)keywords, &pyobj_argument) &&
        pyopencv_to_safe(pyobj_argument, argument, ArgInfo("argument", 1)) )
    {
        ERRWRAP2(retval = cv::utils::dumpInputOutputArrayOfArrays(argument));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(argument));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("dumpInputOutputArrayOfArrays");

    return NULL;
}

static PyObject* pyopencv_cv_utils_dumpInt(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::utils;

    PyObject* pyobj_argument = NULL;
    int argument=0;
    String retval;

    const char* keywords[] = { "argument", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:dumpInt", (char**)keywords, &pyobj_argument) &&
        pyopencv_to_safe(pyobj_argument, argument, ArgInfo("argument", 0)) )
    {
        ERRWRAP2(retval = cv::utils::dumpInt(argument));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_utils_dumpRange(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::utils;

    PyObject* pyobj_argument = NULL;
    Range argument;
    String retval;

    const char* keywords[] = { "argument", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:dumpRange", (char**)keywords, &pyobj_argument) &&
        pyopencv_to_safe(pyobj_argument, argument, ArgInfo("argument", 0)) )
    {
        ERRWRAP2(retval = cv::utils::dumpRange(argument));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_utils_dumpRect(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::utils;

    PyObject* pyobj_argument = NULL;
    Rect argument;
    String retval;

    const char* keywords[] = { "argument", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:dumpRect", (char**)keywords, &pyobj_argument) &&
        pyopencv_to_safe(pyobj_argument, argument, ArgInfo("argument", 0)) )
    {
        ERRWRAP2(retval = cv::utils::dumpRect(argument));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_utils_dumpRotatedRect(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::utils;

    PyObject* pyobj_argument = NULL;
    RotatedRect argument;
    String retval;

    const char* keywords[] = { "argument", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:dumpRotatedRect", (char**)keywords, &pyobj_argument) &&
        pyopencv_to_safe(pyobj_argument, argument, ArgInfo("argument", 0)) )
    {
        ERRWRAP2(retval = cv::utils::dumpRotatedRect(argument));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_utils_dumpSizeT(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::utils;

    PyObject* pyobj_argument = NULL;
    size_t argument=0;
    String retval;

    const char* keywords[] = { "argument", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:dumpSizeT", (char**)keywords, &pyobj_argument) &&
        pyopencv_to_safe(pyobj_argument, argument, ArgInfo("argument", 0)) )
    {
        ERRWRAP2(retval = cv::utils::dumpSizeT(argument));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_utils_dumpString(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::utils;

    PyObject* pyobj_argument = NULL;
    String argument;
    String retval;

    const char* keywords[] = { "argument", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:dumpString", (char**)keywords, &pyobj_argument) &&
        pyopencv_to_safe(pyobj_argument, argument, ArgInfo("argument", 0)) )
    {
        ERRWRAP2(retval = cv::utils::dumpString(argument));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_utils_dumpTermCriteria(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::utils;

    PyObject* pyobj_argument = NULL;
    TermCriteria argument;
    String retval;

    const char* keywords[] = { "argument", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:dumpTermCriteria", (char**)keywords, &pyobj_argument) &&
        pyopencv_to_safe(pyobj_argument, argument, ArgInfo("argument", 0)) )
    {
        ERRWRAP2(retval = cv::utils::dumpTermCriteria(argument));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_utils_testAsyncArray(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::utils;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_argument = NULL;
    Mat argument;
    AsyncArray retval;

    const char* keywords[] = { "argument", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:testAsyncArray", (char**)keywords, &pyobj_argument) &&
        pyopencv_to_safe(pyobj_argument, argument, ArgInfo("argument", 0)) )
    {
        ERRWRAP2(retval = cv::utils::testAsyncArray(argument));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_argument = NULL;
    UMat argument;
    AsyncArray retval;

    const char* keywords[] = { "argument", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:testAsyncArray", (char**)keywords, &pyobj_argument) &&
        pyopencv_to_safe(pyobj_argument, argument, ArgInfo("argument", 0)) )
    {
        ERRWRAP2(retval = cv::utils::testAsyncArray(argument));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("testAsyncArray");

    return NULL;
}

static PyObject* pyopencv_cv_utils_testAsyncException(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::utils;

    AsyncArray retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::utils::testAsyncException());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_utils_testOverloadResolution(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::utils;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_value = NULL;
    int value=0;
    PyObject* pyobj_point = NULL;
    Point point=Point(42, 24);
    String retval;

    const char* keywords[] = { "value", "point", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:testOverloadResolution", (char**)keywords, &pyobj_value, &pyobj_point) &&
        pyopencv_to_safe(pyobj_value, value, ArgInfo("value", 0)) &&
        pyopencv_to_safe(pyobj_point, point, ArgInfo("point", 0)) )
    {
        ERRWRAP2(retval = cv::utils::testOverloadResolution(value, point));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_rect = NULL;
    Rect rect;
    String retval;

    const char* keywords[] = { "rect", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:testOverloadResolution", (char**)keywords, &pyobj_rect) &&
        pyopencv_to_safe(pyobj_rect, rect, ArgInfo("rect", 0)) )
    {
        ERRWRAP2(retval = cv::utils::testOverloadResolution(rect));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("testOverloadResolution");

    return NULL;
}

static PyObject* pyopencv_cv_utils_testRaiseGeneralException(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::utils;


    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(cv::utils::testRaiseGeneralException());
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_utils_fs_getCacheDirectoryForDownloads(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::utils::fs;

    cv::String retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::utils::fs::getCacheDirectoryForDownloads());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_videoio_registry_getBackendName(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::videoio_registry;

    PyObject* pyobj_api = NULL;
    VideoCaptureAPIs api=static_cast<VideoCaptureAPIs>(0);
    cv::String retval;

    const char* keywords[] = { "api", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:getBackendName", (char**)keywords, &pyobj_api) &&
        pyopencv_to_safe(pyobj_api, api, ArgInfo("api", 0)) )
    {
        ERRWRAP2(retval = cv::videoio_registry::getBackendName(api));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_videoio_registry_getBackends(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::videoio_registry;

    std::vector<VideoCaptureAPIs> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::videoio_registry::getBackends());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_videoio_registry_getCameraBackends(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::videoio_registry;

    std::vector<VideoCaptureAPIs> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::videoio_registry::getCameraBackends());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_videoio_registry_getStreamBackends(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::videoio_registry;

    std::vector<VideoCaptureAPIs> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::videoio_registry::getStreamBackends());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_videoio_registry_getWriterBackends(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::videoio_registry;

    std::vector<VideoCaptureAPIs> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::videoio_registry::getWriterBackends());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_BEBLID_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    PyObject* pyobj_scale_factor = NULL;
    float scale_factor=0.f;
    PyObject* pyobj_n_bits = NULL;
    int n_bits=BEBLID::SIZE_512_BITS;
    Ptr<BEBLID> retval;

    const char* keywords[] = { "scale_factor", "n_bits", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:BEBLID_create", (char**)keywords, &pyobj_scale_factor, &pyobj_n_bits) &&
        pyopencv_to_safe(pyobj_scale_factor, scale_factor, ArgInfo("scale_factor", 0)) &&
        pyopencv_to_safe(pyobj_n_bits, n_bits, ArgInfo("n_bits", 0)) )
    {
        ERRWRAP2(retval = cv::xfeatures2d::BEBLID::create(scale_factor, n_bits));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_BoostDesc_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    PyObject* pyobj_desc = NULL;
    int desc=BoostDesc::BINBOOST_256;
    PyObject* pyobj_use_scale_orientation = NULL;
    bool use_scale_orientation=true;
    PyObject* pyobj_scale_factor = NULL;
    float scale_factor=6.25f;
    Ptr<BoostDesc> retval;

    const char* keywords[] = { "desc", "use_scale_orientation", "scale_factor", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOO:BoostDesc_create", (char**)keywords, &pyobj_desc, &pyobj_use_scale_orientation, &pyobj_scale_factor) &&
        pyopencv_to_safe(pyobj_desc, desc, ArgInfo("desc", 0)) &&
        pyopencv_to_safe(pyobj_use_scale_orientation, use_scale_orientation, ArgInfo("use_scale_orientation", 0)) &&
        pyopencv_to_safe(pyobj_scale_factor, scale_factor, ArgInfo("scale_factor", 0)) )
    {
        ERRWRAP2(retval = cv::xfeatures2d::BoostDesc::create(desc, use_scale_orientation, scale_factor));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_BriefDescriptorExtractor_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    PyObject* pyobj_bytes = NULL;
    int bytes=32;
    PyObject* pyobj_use_orientation = NULL;
    bool use_orientation=false;
    Ptr<BriefDescriptorExtractor> retval;

    const char* keywords[] = { "bytes", "use_orientation", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OO:BriefDescriptorExtractor_create", (char**)keywords, &pyobj_bytes, &pyobj_use_orientation) &&
        pyopencv_to_safe(pyobj_bytes, bytes, ArgInfo("bytes", 0)) &&
        pyopencv_to_safe(pyobj_use_orientation, use_orientation, ArgInfo("use_orientation", 0)) )
    {
        ERRWRAP2(retval = cv::xfeatures2d::BriefDescriptorExtractor::create(bytes, use_orientation));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_DAISY_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_radius = NULL;
    float radius=15;
    PyObject* pyobj_q_radius = NULL;
    int q_radius=3;
    PyObject* pyobj_q_theta = NULL;
    int q_theta=8;
    PyObject* pyobj_q_hist = NULL;
    int q_hist=8;
    PyObject* pyobj_norm = NULL;
    DAISY_NormalizationType norm=DAISY::NRM_NONE;
    PyObject* pyobj_H = NULL;
    Mat H;
    PyObject* pyobj_interpolation = NULL;
    bool interpolation=true;
    PyObject* pyobj_use_orientation = NULL;
    bool use_orientation=false;
    Ptr<DAISY> retval;

    const char* keywords[] = { "radius", "q_radius", "q_theta", "q_hist", "norm", "H", "interpolation", "use_orientation", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOOOOO:DAISY_create", (char**)keywords, &pyobj_radius, &pyobj_q_radius, &pyobj_q_theta, &pyobj_q_hist, &pyobj_norm, &pyobj_H, &pyobj_interpolation, &pyobj_use_orientation) &&
        pyopencv_to_safe(pyobj_radius, radius, ArgInfo("radius", 0)) &&
        pyopencv_to_safe(pyobj_q_radius, q_radius, ArgInfo("q_radius", 0)) &&
        pyopencv_to_safe(pyobj_q_theta, q_theta, ArgInfo("q_theta", 0)) &&
        pyopencv_to_safe(pyobj_q_hist, q_hist, ArgInfo("q_hist", 0)) &&
        pyopencv_to_safe(pyobj_norm, norm, ArgInfo("norm", 0)) &&
        pyopencv_to_safe(pyobj_H, H, ArgInfo("H", 0)) &&
        pyopencv_to_safe(pyobj_interpolation, interpolation, ArgInfo("interpolation", 0)) &&
        pyopencv_to_safe(pyobj_use_orientation, use_orientation, ArgInfo("use_orientation", 0)) )
    {
        ERRWRAP2(retval = cv::xfeatures2d::DAISY::create(radius, q_radius, q_theta, q_hist, norm, H, interpolation, use_orientation));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_radius = NULL;
    float radius=15;
    PyObject* pyobj_q_radius = NULL;
    int q_radius=3;
    PyObject* pyobj_q_theta = NULL;
    int q_theta=8;
    PyObject* pyobj_q_hist = NULL;
    int q_hist=8;
    PyObject* pyobj_norm = NULL;
    DAISY_NormalizationType norm=DAISY::NRM_NONE;
    PyObject* pyobj_H = NULL;
    UMat H;
    PyObject* pyobj_interpolation = NULL;
    bool interpolation=true;
    PyObject* pyobj_use_orientation = NULL;
    bool use_orientation=false;
    Ptr<DAISY> retval;

    const char* keywords[] = { "radius", "q_radius", "q_theta", "q_hist", "norm", "H", "interpolation", "use_orientation", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOOOOO:DAISY_create", (char**)keywords, &pyobj_radius, &pyobj_q_radius, &pyobj_q_theta, &pyobj_q_hist, &pyobj_norm, &pyobj_H, &pyobj_interpolation, &pyobj_use_orientation) &&
        pyopencv_to_safe(pyobj_radius, radius, ArgInfo("radius", 0)) &&
        pyopencv_to_safe(pyobj_q_radius, q_radius, ArgInfo("q_radius", 0)) &&
        pyopencv_to_safe(pyobj_q_theta, q_theta, ArgInfo("q_theta", 0)) &&
        pyopencv_to_safe(pyobj_q_hist, q_hist, ArgInfo("q_hist", 0)) &&
        pyopencv_to_safe(pyobj_norm, norm, ArgInfo("norm", 0)) &&
        pyopencv_to_safe(pyobj_H, H, ArgInfo("H", 0)) &&
        pyopencv_to_safe(pyobj_interpolation, interpolation, ArgInfo("interpolation", 0)) &&
        pyopencv_to_safe(pyobj_use_orientation, use_orientation, ArgInfo("use_orientation", 0)) )
    {
        ERRWRAP2(retval = cv::xfeatures2d::DAISY::create(radius, q_radius, q_theta, q_hist, norm, H, interpolation, use_orientation));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("DAISY_create");

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_FREAK_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    PyObject* pyobj_orientationNormalized = NULL;
    bool orientationNormalized=true;
    PyObject* pyobj_scaleNormalized = NULL;
    bool scaleNormalized=true;
    PyObject* pyobj_patternScale = NULL;
    float patternScale=22.0f;
    PyObject* pyobj_nOctaves = NULL;
    int nOctaves=4;
    PyObject* pyobj_selectedPairs = NULL;
    vector_int selectedPairs=std::vector<int>();
    Ptr<FREAK> retval;

    const char* keywords[] = { "orientationNormalized", "scaleNormalized", "patternScale", "nOctaves", "selectedPairs", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOO:FREAK_create", (char**)keywords, &pyobj_orientationNormalized, &pyobj_scaleNormalized, &pyobj_patternScale, &pyobj_nOctaves, &pyobj_selectedPairs) &&
        pyopencv_to_safe(pyobj_orientationNormalized, orientationNormalized, ArgInfo("orientationNormalized", 0)) &&
        pyopencv_to_safe(pyobj_scaleNormalized, scaleNormalized, ArgInfo("scaleNormalized", 0)) &&
        pyopencv_to_safe(pyobj_patternScale, patternScale, ArgInfo("patternScale", 0)) &&
        pyopencv_to_safe(pyobj_nOctaves, nOctaves, ArgInfo("nOctaves", 0)) &&
        pyopencv_to_safe(pyobj_selectedPairs, selectedPairs, ArgInfo("selectedPairs", 0)) )
    {
        ERRWRAP2(retval = cv::xfeatures2d::FREAK::create(orientationNormalized, scaleNormalized, patternScale, nOctaves, selectedPairs));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_HarrisLaplaceFeatureDetector_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    PyObject* pyobj_numOctaves = NULL;
    int numOctaves=6;
    PyObject* pyobj_corn_thresh = NULL;
    float corn_thresh=0.01f;
    PyObject* pyobj_DOG_thresh = NULL;
    float DOG_thresh=0.01f;
    PyObject* pyobj_maxCorners = NULL;
    int maxCorners=5000;
    PyObject* pyobj_num_layers = NULL;
    int num_layers=4;
    Ptr<HarrisLaplaceFeatureDetector> retval;

    const char* keywords[] = { "numOctaves", "corn_thresh", "DOG_thresh", "maxCorners", "num_layers", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOO:HarrisLaplaceFeatureDetector_create", (char**)keywords, &pyobj_numOctaves, &pyobj_corn_thresh, &pyobj_DOG_thresh, &pyobj_maxCorners, &pyobj_num_layers) &&
        pyopencv_to_safe(pyobj_numOctaves, numOctaves, ArgInfo("numOctaves", 0)) &&
        pyopencv_to_safe(pyobj_corn_thresh, corn_thresh, ArgInfo("corn_thresh", 0)) &&
        pyopencv_to_safe(pyobj_DOG_thresh, DOG_thresh, ArgInfo("DOG_thresh", 0)) &&
        pyopencv_to_safe(pyobj_maxCorners, maxCorners, ArgInfo("maxCorners", 0)) &&
        pyopencv_to_safe(pyobj_num_layers, num_layers, ArgInfo("num_layers", 0)) )
    {
        ERRWRAP2(retval = cv::xfeatures2d::HarrisLaplaceFeatureDetector::create(numOctaves, corn_thresh, DOG_thresh, maxCorners, num_layers));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_LATCH_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    PyObject* pyobj_bytes = NULL;
    int bytes=32;
    PyObject* pyobj_rotationInvariance = NULL;
    bool rotationInvariance=true;
    PyObject* pyobj_half_ssd_size = NULL;
    int half_ssd_size=3;
    PyObject* pyobj_sigma = NULL;
    double sigma=2.0;
    Ptr<LATCH> retval;

    const char* keywords[] = { "bytes", "rotationInvariance", "half_ssd_size", "sigma", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOO:LATCH_create", (char**)keywords, &pyobj_bytes, &pyobj_rotationInvariance, &pyobj_half_ssd_size, &pyobj_sigma) &&
        pyopencv_to_safe(pyobj_bytes, bytes, ArgInfo("bytes", 0)) &&
        pyopencv_to_safe(pyobj_rotationInvariance, rotationInvariance, ArgInfo("rotationInvariance", 0)) &&
        pyopencv_to_safe(pyobj_half_ssd_size, half_ssd_size, ArgInfo("half_ssd_size", 0)) &&
        pyopencv_to_safe(pyobj_sigma, sigma, ArgInfo("sigma", 0)) )
    {
        ERRWRAP2(retval = cv::xfeatures2d::LATCH::create(bytes, rotationInvariance, half_ssd_size, sigma));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_LUCID_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    PyObject* pyobj_lucid_kernel = NULL;
    int lucid_kernel=1;
    PyObject* pyobj_blur_kernel = NULL;
    int blur_kernel=2;
    Ptr<LUCID> retval;

    const char* keywords[] = { "lucid_kernel", "blur_kernel", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OO:LUCID_create", (char**)keywords, &pyobj_lucid_kernel, &pyobj_blur_kernel) &&
        pyopencv_to_safe(pyobj_lucid_kernel, lucid_kernel, ArgInfo("lucid_kernel", 0)) &&
        pyopencv_to_safe(pyobj_blur_kernel, blur_kernel, ArgInfo("blur_kernel", 0)) )
    {
        ERRWRAP2(retval = cv::xfeatures2d::LUCID::create(lucid_kernel, blur_kernel));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_PCTSignaturesSQFD_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    PyObject* pyobj_distanceFunction = NULL;
    int distanceFunction=3;
    PyObject* pyobj_similarityFunction = NULL;
    int similarityFunction=2;
    PyObject* pyobj_similarityParameter = NULL;
    float similarityParameter=1.0f;
    Ptr<PCTSignaturesSQFD> retval;

    const char* keywords[] = { "distanceFunction", "similarityFunction", "similarityParameter", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOO:PCTSignaturesSQFD_create", (char**)keywords, &pyobj_distanceFunction, &pyobj_similarityFunction, &pyobj_similarityParameter) &&
        pyopencv_to_safe(pyobj_distanceFunction, distanceFunction, ArgInfo("distanceFunction", 0)) &&
        pyopencv_to_safe(pyobj_similarityFunction, similarityFunction, ArgInfo("similarityFunction", 0)) &&
        pyopencv_to_safe(pyobj_similarityParameter, similarityParameter, ArgInfo("similarityParameter", 0)) )
    {
        ERRWRAP2(retval = cv::xfeatures2d::PCTSignaturesSQFD::create(distanceFunction, similarityFunction, similarityParameter));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_PCTSignatures_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    pyPrepareArgumentConversionErrorsStorage(3);

    {
    PyObject* pyobj_initSampleCount = NULL;
    int initSampleCount=2000;
    PyObject* pyobj_initSeedCount = NULL;
    int initSeedCount=400;
    PyObject* pyobj_pointDistribution = NULL;
    int pointDistribution=0;
    Ptr<PCTSignatures> retval;

    const char* keywords[] = { "initSampleCount", "initSeedCount", "pointDistribution", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOO:PCTSignatures_create", (char**)keywords, &pyobj_initSampleCount, &pyobj_initSeedCount, &pyobj_pointDistribution) &&
        pyopencv_to_safe(pyobj_initSampleCount, initSampleCount, ArgInfo("initSampleCount", 0)) &&
        pyopencv_to_safe(pyobj_initSeedCount, initSeedCount, ArgInfo("initSeedCount", 0)) &&
        pyopencv_to_safe(pyobj_pointDistribution, pointDistribution, ArgInfo("pointDistribution", 0)) )
    {
        ERRWRAP2(retval = cv::xfeatures2d::PCTSignatures::create(initSampleCount, initSeedCount, pointDistribution));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_initSamplingPoints = NULL;
    vector_Point2f initSamplingPoints;
    PyObject* pyobj_initSeedCount = NULL;
    int initSeedCount=0;
    Ptr<PCTSignatures> retval;

    const char* keywords[] = { "initSamplingPoints", "initSeedCount", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:PCTSignatures_create", (char**)keywords, &pyobj_initSamplingPoints, &pyobj_initSeedCount) &&
        pyopencv_to_safe(pyobj_initSamplingPoints, initSamplingPoints, ArgInfo("initSamplingPoints", 0)) &&
        pyopencv_to_safe(pyobj_initSeedCount, initSeedCount, ArgInfo("initSeedCount", 0)) )
    {
        ERRWRAP2(retval = cv::xfeatures2d::PCTSignatures::create(initSamplingPoints, initSeedCount));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_initSamplingPoints = NULL;
    vector_Point2f initSamplingPoints;
    PyObject* pyobj_initClusterSeedIndexes = NULL;
    vector_int initClusterSeedIndexes;
    Ptr<PCTSignatures> retval;

    const char* keywords[] = { "initSamplingPoints", "initClusterSeedIndexes", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:PCTSignatures_create", (char**)keywords, &pyobj_initSamplingPoints, &pyobj_initClusterSeedIndexes) &&
        pyopencv_to_safe(pyobj_initSamplingPoints, initSamplingPoints, ArgInfo("initSamplingPoints", 0)) &&
        pyopencv_to_safe(pyobj_initClusterSeedIndexes, initClusterSeedIndexes, ArgInfo("initClusterSeedIndexes", 0)) )
    {
        ERRWRAP2(retval = cv::xfeatures2d::PCTSignatures::create(initSamplingPoints, initClusterSeedIndexes));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("PCTSignatures_create");

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_PCTSignatures_drawSignature(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_source = NULL;
    Mat source;
    PyObject* pyobj_signature = NULL;
    Mat signature;
    PyObject* pyobj_result = NULL;
    Mat result;
    PyObject* pyobj_radiusToShorterSideRatio = NULL;
    float radiusToShorterSideRatio=1.0 / 8;
    PyObject* pyobj_borderThickness = NULL;
    int borderThickness=1;

    const char* keywords[] = { "source", "signature", "result", "radiusToShorterSideRatio", "borderThickness", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:PCTSignatures_drawSignature", (char**)keywords, &pyobj_source, &pyobj_signature, &pyobj_result, &pyobj_radiusToShorterSideRatio, &pyobj_borderThickness) &&
        pyopencv_to_safe(pyobj_source, source, ArgInfo("source", 0)) &&
        pyopencv_to_safe(pyobj_signature, signature, ArgInfo("signature", 0)) &&
        pyopencv_to_safe(pyobj_result, result, ArgInfo("result", 1)) &&
        pyopencv_to_safe(pyobj_radiusToShorterSideRatio, radiusToShorterSideRatio, ArgInfo("radiusToShorterSideRatio", 0)) &&
        pyopencv_to_safe(pyobj_borderThickness, borderThickness, ArgInfo("borderThickness", 0)) )
    {
        ERRWRAP2(cv::xfeatures2d::PCTSignatures::drawSignature(source, signature, result, radiusToShorterSideRatio, borderThickness));
        return pyopencv_from(result);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_source = NULL;
    UMat source;
    PyObject* pyobj_signature = NULL;
    UMat signature;
    PyObject* pyobj_result = NULL;
    UMat result;
    PyObject* pyobj_radiusToShorterSideRatio = NULL;
    float radiusToShorterSideRatio=1.0 / 8;
    PyObject* pyobj_borderThickness = NULL;
    int borderThickness=1;

    const char* keywords[] = { "source", "signature", "result", "radiusToShorterSideRatio", "borderThickness", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:PCTSignatures_drawSignature", (char**)keywords, &pyobj_source, &pyobj_signature, &pyobj_result, &pyobj_radiusToShorterSideRatio, &pyobj_borderThickness) &&
        pyopencv_to_safe(pyobj_source, source, ArgInfo("source", 0)) &&
        pyopencv_to_safe(pyobj_signature, signature, ArgInfo("signature", 0)) &&
        pyopencv_to_safe(pyobj_result, result, ArgInfo("result", 1)) &&
        pyopencv_to_safe(pyobj_radiusToShorterSideRatio, radiusToShorterSideRatio, ArgInfo("radiusToShorterSideRatio", 0)) &&
        pyopencv_to_safe(pyobj_borderThickness, borderThickness, ArgInfo("borderThickness", 0)) )
    {
        ERRWRAP2(cv::xfeatures2d::PCTSignatures::drawSignature(source, signature, result, radiusToShorterSideRatio, borderThickness));
        return pyopencv_from(result);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("PCTSignatures_drawSignature");

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_PCTSignatures_generateInitPoints(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    PyObject* pyobj_initPoints = NULL;
    vector_Point2f initPoints;
    PyObject* pyobj_count = NULL;
    int count=0;
    PyObject* pyobj_pointDistribution = NULL;
    int pointDistribution=0;

    const char* keywords[] = { "initPoints", "count", "pointDistribution", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:PCTSignatures_generateInitPoints", (char**)keywords, &pyobj_initPoints, &pyobj_count, &pyobj_pointDistribution) &&
        pyopencv_to_safe(pyobj_initPoints, initPoints, ArgInfo("initPoints", 0)) &&
        pyopencv_to_safe(pyobj_count, count, ArgInfo("count", 0)) &&
        pyopencv_to_safe(pyobj_pointDistribution, pointDistribution, ArgInfo("pointDistribution", 0)) )
    {
        ERRWRAP2(cv::xfeatures2d::PCTSignatures::generateInitPoints(initPoints, count, pointDistribution));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_SIFT_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    PyObject* pyobj_nfeatures = NULL;
    int nfeatures=0;
    PyObject* pyobj_nOctaveLayers = NULL;
    int nOctaveLayers=3;
    PyObject* pyobj_contrastThreshold = NULL;
    double contrastThreshold=0.04;
    PyObject* pyobj_edgeThreshold = NULL;
    double edgeThreshold=10;
    PyObject* pyobj_sigma = NULL;
    double sigma=1.6;
    Ptr<cv::SIFT> retval;

    const char* keywords[] = { "nfeatures", "nOctaveLayers", "contrastThreshold", "edgeThreshold", "sigma", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOO:SIFT_create", (char**)keywords, &pyobj_nfeatures, &pyobj_nOctaveLayers, &pyobj_contrastThreshold, &pyobj_edgeThreshold, &pyobj_sigma) &&
        pyopencv_to_safe(pyobj_nfeatures, nfeatures, ArgInfo("nfeatures", 0)) &&
        pyopencv_to_safe(pyobj_nOctaveLayers, nOctaveLayers, ArgInfo("nOctaveLayers", 0)) &&
        pyopencv_to_safe(pyobj_contrastThreshold, contrastThreshold, ArgInfo("contrastThreshold", 0)) &&
        pyopencv_to_safe(pyobj_edgeThreshold, edgeThreshold, ArgInfo("edgeThreshold", 0)) &&
        pyopencv_to_safe(pyobj_sigma, sigma, ArgInfo("sigma", 0)) )
    {
        ERRWRAP2(retval = cv::xfeatures2d::SIFT_create(nfeatures, nOctaveLayers, contrastThreshold, edgeThreshold, sigma));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_SURF_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    PyObject* pyobj_hessianThreshold = NULL;
    double hessianThreshold=100;
    PyObject* pyobj_nOctaves = NULL;
    int nOctaves=4;
    PyObject* pyobj_nOctaveLayers = NULL;
    int nOctaveLayers=3;
    PyObject* pyobj_extended = NULL;
    bool extended=false;
    PyObject* pyobj_upright = NULL;
    bool upright=false;
    Ptr<SURF> retval;

    const char* keywords[] = { "hessianThreshold", "nOctaves", "nOctaveLayers", "extended", "upright", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOO:SURF_create", (char**)keywords, &pyobj_hessianThreshold, &pyobj_nOctaves, &pyobj_nOctaveLayers, &pyobj_extended, &pyobj_upright) &&
        pyopencv_to_safe(pyobj_hessianThreshold, hessianThreshold, ArgInfo("hessianThreshold", 0)) &&
        pyopencv_to_safe(pyobj_nOctaves, nOctaves, ArgInfo("nOctaves", 0)) &&
        pyopencv_to_safe(pyobj_nOctaveLayers, nOctaveLayers, ArgInfo("nOctaveLayers", 0)) &&
        pyopencv_to_safe(pyobj_extended, extended, ArgInfo("extended", 0)) &&
        pyopencv_to_safe(pyobj_upright, upright, ArgInfo("upright", 0)) )
    {
        ERRWRAP2(retval = cv::xfeatures2d::SURF::create(hessianThreshold, nOctaves, nOctaveLayers, extended, upright));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_StarDetector_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    PyObject* pyobj_maxSize = NULL;
    int maxSize=45;
    PyObject* pyobj_responseThreshold = NULL;
    int responseThreshold=30;
    PyObject* pyobj_lineThresholdProjected = NULL;
    int lineThresholdProjected=10;
    PyObject* pyobj_lineThresholdBinarized = NULL;
    int lineThresholdBinarized=8;
    PyObject* pyobj_suppressNonmaxSize = NULL;
    int suppressNonmaxSize=5;
    Ptr<StarDetector> retval;

    const char* keywords[] = { "maxSize", "responseThreshold", "lineThresholdProjected", "lineThresholdBinarized", "suppressNonmaxSize", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOO:StarDetector_create", (char**)keywords, &pyobj_maxSize, &pyobj_responseThreshold, &pyobj_lineThresholdProjected, &pyobj_lineThresholdBinarized, &pyobj_suppressNonmaxSize) &&
        pyopencv_to_safe(pyobj_maxSize, maxSize, ArgInfo("maxSize", 0)) &&
        pyopencv_to_safe(pyobj_responseThreshold, responseThreshold, ArgInfo("responseThreshold", 0)) &&
        pyopencv_to_safe(pyobj_lineThresholdProjected, lineThresholdProjected, ArgInfo("lineThresholdProjected", 0)) &&
        pyopencv_to_safe(pyobj_lineThresholdBinarized, lineThresholdBinarized, ArgInfo("lineThresholdBinarized", 0)) &&
        pyopencv_to_safe(pyobj_suppressNonmaxSize, suppressNonmaxSize, ArgInfo("suppressNonmaxSize", 0)) )
    {
        ERRWRAP2(retval = cv::xfeatures2d::StarDetector::create(maxSize, responseThreshold, lineThresholdProjected, lineThresholdBinarized, suppressNonmaxSize));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_TBMR_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    PyObject* pyobj_min_area = NULL;
    int min_area=60;
    PyObject* pyobj_max_area_relative = NULL;
    float max_area_relative=0.01f;
    PyObject* pyobj_scale_factor = NULL;
    float scale_factor=1.25f;
    PyObject* pyobj_n_scales = NULL;
    int n_scales=-1;
    Ptr<TBMR> retval;

    const char* keywords[] = { "min_area", "max_area_relative", "scale_factor", "n_scales", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOO:TBMR_create", (char**)keywords, &pyobj_min_area, &pyobj_max_area_relative, &pyobj_scale_factor, &pyobj_n_scales) &&
        pyopencv_to_safe(pyobj_min_area, min_area, ArgInfo("min_area", 0)) &&
        pyopencv_to_safe(pyobj_max_area_relative, max_area_relative, ArgInfo("max_area_relative", 0)) &&
        pyopencv_to_safe(pyobj_scale_factor, scale_factor, ArgInfo("scale_factor", 0)) &&
        pyopencv_to_safe(pyobj_n_scales, n_scales, ArgInfo("n_scales", 0)) )
    {
        ERRWRAP2(retval = cv::xfeatures2d::TBMR::create(min_area, max_area_relative, scale_factor, n_scales));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_VGG_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    PyObject* pyobj_desc = NULL;
    int desc=VGG::VGG_120;
    PyObject* pyobj_isigma = NULL;
    float isigma=1.4f;
    PyObject* pyobj_img_normalize = NULL;
    bool img_normalize=true;
    PyObject* pyobj_use_scale_orientation = NULL;
    bool use_scale_orientation=true;
    PyObject* pyobj_scale_factor = NULL;
    float scale_factor=6.25f;
    PyObject* pyobj_dsc_normalize = NULL;
    bool dsc_normalize=false;
    Ptr<VGG> retval;

    const char* keywords[] = { "desc", "isigma", "img_normalize", "use_scale_orientation", "scale_factor", "dsc_normalize", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOOO:VGG_create", (char**)keywords, &pyobj_desc, &pyobj_isigma, &pyobj_img_normalize, &pyobj_use_scale_orientation, &pyobj_scale_factor, &pyobj_dsc_normalize) &&
        pyopencv_to_safe(pyobj_desc, desc, ArgInfo("desc", 0)) &&
        pyopencv_to_safe(pyobj_isigma, isigma, ArgInfo("isigma", 0)) &&
        pyopencv_to_safe(pyobj_img_normalize, img_normalize, ArgInfo("img_normalize", 0)) &&
        pyopencv_to_safe(pyobj_use_scale_orientation, use_scale_orientation, ArgInfo("use_scale_orientation", 0)) &&
        pyopencv_to_safe(pyobj_scale_factor, scale_factor, ArgInfo("scale_factor", 0)) &&
        pyopencv_to_safe(pyobj_dsc_normalize, dsc_normalize, ArgInfo("dsc_normalize", 0)) )
    {
        ERRWRAP2(retval = cv::xfeatures2d::VGG::create(desc, isigma, img_normalize, use_scale_orientation, scale_factor, dsc_normalize));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_matchGMS(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    PyObject* pyobj_size1 = NULL;
    Size size1;
    PyObject* pyobj_size2 = NULL;
    Size size2;
    PyObject* pyobj_keypoints1 = NULL;
    vector_KeyPoint keypoints1;
    PyObject* pyobj_keypoints2 = NULL;
    vector_KeyPoint keypoints2;
    PyObject* pyobj_matches1to2 = NULL;
    vector_DMatch matches1to2;
    vector_DMatch matchesGMS;
    PyObject* pyobj_withRotation = NULL;
    bool withRotation=false;
    PyObject* pyobj_withScale = NULL;
    bool withScale=false;
    PyObject* pyobj_thresholdFactor = NULL;
    double thresholdFactor=6.0;

    const char* keywords[] = { "size1", "size2", "keypoints1", "keypoints2", "matches1to2", "withRotation", "withScale", "thresholdFactor", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OOO:matchGMS", (char**)keywords, &pyobj_size1, &pyobj_size2, &pyobj_keypoints1, &pyobj_keypoints2, &pyobj_matches1to2, &pyobj_withRotation, &pyobj_withScale, &pyobj_thresholdFactor) &&
        pyopencv_to_safe(pyobj_size1, size1, ArgInfo("size1", 0)) &&
        pyopencv_to_safe(pyobj_size2, size2, ArgInfo("size2", 0)) &&
        pyopencv_to_safe(pyobj_keypoints1, keypoints1, ArgInfo("keypoints1", 0)) &&
        pyopencv_to_safe(pyobj_keypoints2, keypoints2, ArgInfo("keypoints2", 0)) &&
        pyopencv_to_safe(pyobj_matches1to2, matches1to2, ArgInfo("matches1to2", 0)) &&
        pyopencv_to_safe(pyobj_withRotation, withRotation, ArgInfo("withRotation", 0)) &&
        pyopencv_to_safe(pyobj_withScale, withScale, ArgInfo("withScale", 0)) &&
        pyopencv_to_safe(pyobj_thresholdFactor, thresholdFactor, ArgInfo("thresholdFactor", 0)) )
    {
        ERRWRAP2(cv::xfeatures2d::matchGMS(size1, size2, keypoints1, keypoints2, matches1to2, matchesGMS, withRotation, withScale, thresholdFactor));
        return pyopencv_from(matchesGMS);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xfeatures2d_matchLOGOS(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::xfeatures2d;

    PyObject* pyobj_keypoints1 = NULL;
    vector_KeyPoint keypoints1;
    PyObject* pyobj_keypoints2 = NULL;
    vector_KeyPoint keypoints2;
    PyObject* pyobj_nn1 = NULL;
    vector_int nn1;
    PyObject* pyobj_nn2 = NULL;
    vector_int nn2;
    PyObject* pyobj_matches1to2 = NULL;
    vector_DMatch matches1to2;

    const char* keywords[] = { "keypoints1", "keypoints2", "nn1", "nn2", "matches1to2", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO:matchLOGOS", (char**)keywords, &pyobj_keypoints1, &pyobj_keypoints2, &pyobj_nn1, &pyobj_nn2, &pyobj_matches1to2) &&
        pyopencv_to_safe(pyobj_keypoints1, keypoints1, ArgInfo("keypoints1", 0)) &&
        pyopencv_to_safe(pyobj_keypoints2, keypoints2, ArgInfo("keypoints2", 0)) &&
        pyopencv_to_safe(pyobj_nn1, nn1, ArgInfo("nn1", 0)) &&
        pyopencv_to_safe(pyobj_nn2, nn2, ArgInfo("nn2", 0)) &&
        pyopencv_to_safe(pyobj_matches1to2, matches1to2, ArgInfo("matches1to2", 0)) )
    {
        ERRWRAP2(cv::xfeatures2d::matchLOGOS(keypoints1, keypoints2, nn1, nn2, matches1to2));
        Py_RETURN_NONE;
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_AdaptiveManifoldFilter_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    Ptr<AdaptiveManifoldFilter> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::ximgproc::AdaptiveManifoldFilter::create());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_FastHoughTransform(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_dstMatDepth = NULL;
    int dstMatDepth=0;
    PyObject* pyobj_angleRange = NULL;
    int angleRange=ARO_315_135;
    PyObject* pyobj_op = NULL;
    int op=FHT_ADD;
    PyObject* pyobj_makeSkew = NULL;
    int makeSkew=HDO_DESKEW;

    const char* keywords[] = { "src", "dstMatDepth", "dst", "angleRange", "op", "makeSkew", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOO:FastHoughTransform", (char**)keywords, &pyobj_src, &pyobj_dstMatDepth, &pyobj_dst, &pyobj_angleRange, &pyobj_op, &pyobj_makeSkew) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_dstMatDepth, dstMatDepth, ArgInfo("dstMatDepth", 0)) &&
        pyopencv_to_safe(pyobj_angleRange, angleRange, ArgInfo("angleRange", 0)) &&
        pyopencv_to_safe(pyobj_op, op, ArgInfo("op", 0)) &&
        pyopencv_to_safe(pyobj_makeSkew, makeSkew, ArgInfo("makeSkew", 0)) )
    {
        ERRWRAP2(cv::ximgproc::FastHoughTransform(src, dst, dstMatDepth, angleRange, op, makeSkew));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_dstMatDepth = NULL;
    int dstMatDepth=0;
    PyObject* pyobj_angleRange = NULL;
    int angleRange=ARO_315_135;
    PyObject* pyobj_op = NULL;
    int op=FHT_ADD;
    PyObject* pyobj_makeSkew = NULL;
    int makeSkew=HDO_DESKEW;

    const char* keywords[] = { "src", "dstMatDepth", "dst", "angleRange", "op", "makeSkew", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOO:FastHoughTransform", (char**)keywords, &pyobj_src, &pyobj_dstMatDepth, &pyobj_dst, &pyobj_angleRange, &pyobj_op, &pyobj_makeSkew) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_dstMatDepth, dstMatDepth, ArgInfo("dstMatDepth", 0)) &&
        pyopencv_to_safe(pyobj_angleRange, angleRange, ArgInfo("angleRange", 0)) &&
        pyopencv_to_safe(pyobj_op, op, ArgInfo("op", 0)) &&
        pyopencv_to_safe(pyobj_makeSkew, makeSkew, ArgInfo("makeSkew", 0)) )
    {
        ERRWRAP2(cv::ximgproc::FastHoughTransform(src, dst, dstMatDepth, angleRange, op, makeSkew));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("FastHoughTransform");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_GradientDericheX(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_op = NULL;
    Mat op;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_alpha = NULL;
    double alpha=0;
    PyObject* pyobj_omega = NULL;
    double omega=0;

    const char* keywords[] = { "op", "alpha", "omega", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:GradientDericheX", (char**)keywords, &pyobj_op, &pyobj_alpha, &pyobj_omega, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_op, op, ArgInfo("op", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_omega, omega, ArgInfo("omega", 0)) )
    {
        ERRWRAP2(cv::ximgproc::GradientDericheX(op, dst, alpha, omega));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_op = NULL;
    UMat op;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_alpha = NULL;
    double alpha=0;
    PyObject* pyobj_omega = NULL;
    double omega=0;

    const char* keywords[] = { "op", "alpha", "omega", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:GradientDericheX", (char**)keywords, &pyobj_op, &pyobj_alpha, &pyobj_omega, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_op, op, ArgInfo("op", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_omega, omega, ArgInfo("omega", 0)) )
    {
        ERRWRAP2(cv::ximgproc::GradientDericheX(op, dst, alpha, omega));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("GradientDericheX");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_GradientDericheY(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_op = NULL;
    Mat op;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_alpha = NULL;
    double alpha=0;
    PyObject* pyobj_omega = NULL;
    double omega=0;

    const char* keywords[] = { "op", "alpha", "omega", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:GradientDericheY", (char**)keywords, &pyobj_op, &pyobj_alpha, &pyobj_omega, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_op, op, ArgInfo("op", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_omega, omega, ArgInfo("omega", 0)) )
    {
        ERRWRAP2(cv::ximgproc::GradientDericheY(op, dst, alpha, omega));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_op = NULL;
    UMat op;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_alpha = NULL;
    double alpha=0;
    PyObject* pyobj_omega = NULL;
    double omega=0;

    const char* keywords[] = { "op", "alpha", "omega", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:GradientDericheY", (char**)keywords, &pyobj_op, &pyobj_alpha, &pyobj_omega, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_op, op, ArgInfo("op", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_omega, omega, ArgInfo("omega", 0)) )
    {
        ERRWRAP2(cv::ximgproc::GradientDericheY(op, dst, alpha, omega));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("GradientDericheY");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_HoughPoint2Line(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_houghPoint = NULL;
    Point houghPoint;
    PyObject* pyobj_srcImgInfo = NULL;
    Mat srcImgInfo;
    PyObject* pyobj_angleRange = NULL;
    int angleRange=ARO_315_135;
    PyObject* pyobj_makeSkew = NULL;
    int makeSkew=HDO_DESKEW;
    PyObject* pyobj_rules = NULL;
    int rules=RO_IGNORE_BORDERS;
    Vec4i retval;

    const char* keywords[] = { "houghPoint", "srcImgInfo", "angleRange", "makeSkew", "rules", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:HoughPoint2Line", (char**)keywords, &pyobj_houghPoint, &pyobj_srcImgInfo, &pyobj_angleRange, &pyobj_makeSkew, &pyobj_rules) &&
        pyopencv_to_safe(pyobj_houghPoint, houghPoint, ArgInfo("houghPoint", 0)) &&
        pyopencv_to_safe(pyobj_srcImgInfo, srcImgInfo, ArgInfo("srcImgInfo", 0)) &&
        pyopencv_to_safe(pyobj_angleRange, angleRange, ArgInfo("angleRange", 0)) &&
        pyopencv_to_safe(pyobj_makeSkew, makeSkew, ArgInfo("makeSkew", 0)) &&
        pyopencv_to_safe(pyobj_rules, rules, ArgInfo("rules", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::HoughPoint2Line(houghPoint, srcImgInfo, angleRange, makeSkew, rules));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_houghPoint = NULL;
    Point houghPoint;
    PyObject* pyobj_srcImgInfo = NULL;
    UMat srcImgInfo;
    PyObject* pyobj_angleRange = NULL;
    int angleRange=ARO_315_135;
    PyObject* pyobj_makeSkew = NULL;
    int makeSkew=HDO_DESKEW;
    PyObject* pyobj_rules = NULL;
    int rules=RO_IGNORE_BORDERS;
    Vec4i retval;

    const char* keywords[] = { "houghPoint", "srcImgInfo", "angleRange", "makeSkew", "rules", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOO:HoughPoint2Line", (char**)keywords, &pyobj_houghPoint, &pyobj_srcImgInfo, &pyobj_angleRange, &pyobj_makeSkew, &pyobj_rules) &&
        pyopencv_to_safe(pyobj_houghPoint, houghPoint, ArgInfo("houghPoint", 0)) &&
        pyopencv_to_safe(pyobj_srcImgInfo, srcImgInfo, ArgInfo("srcImgInfo", 0)) &&
        pyopencv_to_safe(pyobj_angleRange, angleRange, ArgInfo("angleRange", 0)) &&
        pyopencv_to_safe(pyobj_makeSkew, makeSkew, ArgInfo("makeSkew", 0)) &&
        pyopencv_to_safe(pyobj_rules, rules, ArgInfo("rules", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::HoughPoint2Line(houghPoint, srcImgInfo, angleRange, makeSkew, rules));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("HoughPoint2Line");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_PeiLinNormalization(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_I = NULL;
    Mat I;
    PyObject* pyobj_T = NULL;
    Mat T;

    const char* keywords[] = { "I", "T", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:PeiLinNormalization", (char**)keywords, &pyobj_I, &pyobj_T) &&
        pyopencv_to_safe(pyobj_I, I, ArgInfo("I", 0)) &&
        pyopencv_to_safe(pyobj_T, T, ArgInfo("T", 1)) )
    {
        ERRWRAP2(cv::ximgproc::PeiLinNormalization(I, T));
        return pyopencv_from(T);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_I = NULL;
    UMat I;
    PyObject* pyobj_T = NULL;
    UMat T;

    const char* keywords[] = { "I", "T", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:PeiLinNormalization", (char**)keywords, &pyobj_I, &pyobj_T) &&
        pyopencv_to_safe(pyobj_I, I, ArgInfo("I", 0)) &&
        pyopencv_to_safe(pyobj_T, T, ArgInfo("T", 1)) )
    {
        ERRWRAP2(cv::ximgproc::PeiLinNormalization(I, T));
        return pyopencv_from(T);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("PeiLinNormalization");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_RidgeDetectionFilter_create(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    PyObject* pyobj_ddepth = NULL;
    int ddepth=CV_32FC1;
    PyObject* pyobj_dx = NULL;
    int dx=1;
    PyObject* pyobj_dy = NULL;
    int dy=1;
    PyObject* pyobj_ksize = NULL;
    int ksize=3;
    PyObject* pyobj_out_dtype = NULL;
    int out_dtype=CV_8UC1;
    PyObject* pyobj_scale = NULL;
    double scale=1;
    PyObject* pyobj_delta = NULL;
    double delta=0;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;
    Ptr<RidgeDetectionFilter> retval;

    const char* keywords[] = { "ddepth", "dx", "dy", "ksize", "out_dtype", "scale", "delta", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOOOOO:RidgeDetectionFilter_create", (char**)keywords, &pyobj_ddepth, &pyobj_dx, &pyobj_dy, &pyobj_ksize, &pyobj_out_dtype, &pyobj_scale, &pyobj_delta, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_ddepth, ddepth, ArgInfo("ddepth", 0)) &&
        pyopencv_to_safe(pyobj_dx, dx, ArgInfo("dx", 0)) &&
        pyopencv_to_safe(pyobj_dy, dy, ArgInfo("dy", 0)) &&
        pyopencv_to_safe(pyobj_ksize, ksize, ArgInfo("ksize", 0)) &&
        pyopencv_to_safe(pyobj_out_dtype, out_dtype, ArgInfo("out_dtype", 0)) &&
        pyopencv_to_safe(pyobj_scale, scale, ArgInfo("scale", 0)) &&
        pyopencv_to_safe(pyobj_delta, delta, ArgInfo("delta", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::RidgeDetectionFilter::create(ddepth, dx, dy, ksize, out_dtype, scale, delta, borderType));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_amFilter(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_joint = NULL;
    Mat joint;
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_sigma_s = NULL;
    double sigma_s=0;
    PyObject* pyobj_sigma_r = NULL;
    double sigma_r=0;
    PyObject* pyobj_adjust_outliers = NULL;
    bool adjust_outliers=false;

    const char* keywords[] = { "joint", "src", "sigma_s", "sigma_r", "dst", "adjust_outliers", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OO:amFilter", (char**)keywords, &pyobj_joint, &pyobj_src, &pyobj_sigma_s, &pyobj_sigma_r, &pyobj_dst, &pyobj_adjust_outliers) &&
        pyopencv_to_safe(pyobj_joint, joint, ArgInfo("joint", 0)) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_sigma_s, sigma_s, ArgInfo("sigma_s", 0)) &&
        pyopencv_to_safe(pyobj_sigma_r, sigma_r, ArgInfo("sigma_r", 0)) &&
        pyopencv_to_safe(pyobj_adjust_outliers, adjust_outliers, ArgInfo("adjust_outliers", 0)) )
    {
        ERRWRAP2(cv::ximgproc::amFilter(joint, src, dst, sigma_s, sigma_r, adjust_outliers));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_joint = NULL;
    UMat joint;
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_sigma_s = NULL;
    double sigma_s=0;
    PyObject* pyobj_sigma_r = NULL;
    double sigma_r=0;
    PyObject* pyobj_adjust_outliers = NULL;
    bool adjust_outliers=false;

    const char* keywords[] = { "joint", "src", "sigma_s", "sigma_r", "dst", "adjust_outliers", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OO:amFilter", (char**)keywords, &pyobj_joint, &pyobj_src, &pyobj_sigma_s, &pyobj_sigma_r, &pyobj_dst, &pyobj_adjust_outliers) &&
        pyopencv_to_safe(pyobj_joint, joint, ArgInfo("joint", 0)) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_sigma_s, sigma_s, ArgInfo("sigma_s", 0)) &&
        pyopencv_to_safe(pyobj_sigma_r, sigma_r, ArgInfo("sigma_r", 0)) &&
        pyopencv_to_safe(pyobj_adjust_outliers, adjust_outliers, ArgInfo("adjust_outliers", 0)) )
    {
        ERRWRAP2(cv::ximgproc::amFilter(joint, src, dst, sigma_s, sigma_r, adjust_outliers));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("amFilter");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_anisotropicDiffusion(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_alpha = NULL;
    float alpha=0.f;
    PyObject* pyobj_K = NULL;
    float K=0.f;
    PyObject* pyobj_niters = NULL;
    int niters=0;

    const char* keywords[] = { "src", "alpha", "K", "niters", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:anisotropicDiffusion", (char**)keywords, &pyobj_src, &pyobj_alpha, &pyobj_K, &pyobj_niters, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_niters, niters, ArgInfo("niters", 0)) )
    {
        ERRWRAP2(cv::ximgproc::anisotropicDiffusion(src, dst, alpha, K, niters));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_alpha = NULL;
    float alpha=0.f;
    PyObject* pyobj_K = NULL;
    float K=0.f;
    PyObject* pyobj_niters = NULL;
    int niters=0;

    const char* keywords[] = { "src", "alpha", "K", "niters", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:anisotropicDiffusion", (char**)keywords, &pyobj_src, &pyobj_alpha, &pyobj_K, &pyobj_niters, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_K, K, ArgInfo("K", 0)) &&
        pyopencv_to_safe(pyobj_niters, niters, ArgInfo("niters", 0)) )
    {
        ERRWRAP2(cv::ximgproc::anisotropicDiffusion(src, dst, alpha, K, niters));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("anisotropicDiffusion");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_bilateralTextureFilter(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_fr = NULL;
    int fr=3;
    PyObject* pyobj_numIter = NULL;
    int numIter=1;
    PyObject* pyobj_sigmaAlpha = NULL;
    double sigmaAlpha=-1.;
    PyObject* pyobj_sigmaAvg = NULL;
    double sigmaAvg=-1.;

    const char* keywords[] = { "src", "dst", "fr", "numIter", "sigmaAlpha", "sigmaAvg", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOOO:bilateralTextureFilter", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_fr, &pyobj_numIter, &pyobj_sigmaAlpha, &pyobj_sigmaAvg) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_fr, fr, ArgInfo("fr", 0)) &&
        pyopencv_to_safe(pyobj_numIter, numIter, ArgInfo("numIter", 0)) &&
        pyopencv_to_safe(pyobj_sigmaAlpha, sigmaAlpha, ArgInfo("sigmaAlpha", 0)) &&
        pyopencv_to_safe(pyobj_sigmaAvg, sigmaAvg, ArgInfo("sigmaAvg", 0)) )
    {
        ERRWRAP2(cv::ximgproc::bilateralTextureFilter(src, dst, fr, numIter, sigmaAlpha, sigmaAvg));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_fr = NULL;
    int fr=3;
    PyObject* pyobj_numIter = NULL;
    int numIter=1;
    PyObject* pyobj_sigmaAlpha = NULL;
    double sigmaAlpha=-1.;
    PyObject* pyobj_sigmaAvg = NULL;
    double sigmaAvg=-1.;

    const char* keywords[] = { "src", "dst", "fr", "numIter", "sigmaAlpha", "sigmaAvg", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOOO:bilateralTextureFilter", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_fr, &pyobj_numIter, &pyobj_sigmaAlpha, &pyobj_sigmaAvg) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_fr, fr, ArgInfo("fr", 0)) &&
        pyopencv_to_safe(pyobj_numIter, numIter, ArgInfo("numIter", 0)) &&
        pyopencv_to_safe(pyobj_sigmaAlpha, sigmaAlpha, ArgInfo("sigmaAlpha", 0)) &&
        pyopencv_to_safe(pyobj_sigmaAvg, sigmaAvg, ArgInfo("sigmaAvg", 0)) )
    {
        ERRWRAP2(cv::ximgproc::bilateralTextureFilter(src, dst, fr, numIter, sigmaAlpha, sigmaAvg));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("bilateralTextureFilter");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_colorMatchTemplate(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_templ = NULL;
    Mat templ;
    PyObject* pyobj_result = NULL;
    Mat result;

    const char* keywords[] = { "img", "templ", "result", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:colorMatchTemplate", (char**)keywords, &pyobj_img, &pyobj_templ, &pyobj_result) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_templ, templ, ArgInfo("templ", 0)) &&
        pyopencv_to_safe(pyobj_result, result, ArgInfo("result", 1)) )
    {
        ERRWRAP2(cv::ximgproc::colorMatchTemplate(img, templ, result));
        return pyopencv_from(result);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_templ = NULL;
    UMat templ;
    PyObject* pyobj_result = NULL;
    UMat result;

    const char* keywords[] = { "img", "templ", "result", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:colorMatchTemplate", (char**)keywords, &pyobj_img, &pyobj_templ, &pyobj_result) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_templ, templ, ArgInfo("templ", 0)) &&
        pyopencv_to_safe(pyobj_result, result, ArgInfo("result", 1)) )
    {
        ERRWRAP2(cv::ximgproc::colorMatchTemplate(img, templ, result));
        return pyopencv_from(result);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("colorMatchTemplate");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_computeBadPixelPercent(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_GT = NULL;
    Mat GT;
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_ROI = NULL;
    Rect ROI;
    PyObject* pyobj_thresh = NULL;
    int thresh=24;
    double retval;

    const char* keywords[] = { "GT", "src", "ROI", "thresh", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:computeBadPixelPercent", (char**)keywords, &pyobj_GT, &pyobj_src, &pyobj_ROI, &pyobj_thresh) &&
        pyopencv_to_safe(pyobj_GT, GT, ArgInfo("GT", 0)) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_ROI, ROI, ArgInfo("ROI", 0)) &&
        pyopencv_to_safe(pyobj_thresh, thresh, ArgInfo("thresh", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::computeBadPixelPercent(GT, src, ROI, thresh));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_GT = NULL;
    UMat GT;
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_ROI = NULL;
    Rect ROI;
    PyObject* pyobj_thresh = NULL;
    int thresh=24;
    double retval;

    const char* keywords[] = { "GT", "src", "ROI", "thresh", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:computeBadPixelPercent", (char**)keywords, &pyobj_GT, &pyobj_src, &pyobj_ROI, &pyobj_thresh) &&
        pyopencv_to_safe(pyobj_GT, GT, ArgInfo("GT", 0)) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_ROI, ROI, ArgInfo("ROI", 0)) &&
        pyopencv_to_safe(pyobj_thresh, thresh, ArgInfo("thresh", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::computeBadPixelPercent(GT, src, ROI, thresh));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("computeBadPixelPercent");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_computeMSE(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_GT = NULL;
    Mat GT;
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_ROI = NULL;
    Rect ROI;
    double retval;

    const char* keywords[] = { "GT", "src", "ROI", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:computeMSE", (char**)keywords, &pyobj_GT, &pyobj_src, &pyobj_ROI) &&
        pyopencv_to_safe(pyobj_GT, GT, ArgInfo("GT", 0)) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_ROI, ROI, ArgInfo("ROI", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::computeMSE(GT, src, ROI));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_GT = NULL;
    UMat GT;
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_ROI = NULL;
    Rect ROI;
    double retval;

    const char* keywords[] = { "GT", "src", "ROI", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:computeMSE", (char**)keywords, &pyobj_GT, &pyobj_src, &pyobj_ROI) &&
        pyopencv_to_safe(pyobj_GT, GT, ArgInfo("GT", 0)) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_ROI, ROI, ArgInfo("ROI", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::computeMSE(GT, src, ROI));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("computeMSE");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_contourSampling(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_out = NULL;
    Mat out;
    PyObject* pyobj_nbElt = NULL;
    int nbElt=0;

    const char* keywords[] = { "src", "nbElt", "out", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:contourSampling", (char**)keywords, &pyobj_src, &pyobj_nbElt, &pyobj_out) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_out, out, ArgInfo("out", 1)) &&
        pyopencv_to_safe(pyobj_nbElt, nbElt, ArgInfo("nbElt", 0)) )
    {
        ERRWRAP2(cv::ximgproc::contourSampling(src, out, nbElt));
        return pyopencv_from(out);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_out = NULL;
    UMat out;
    PyObject* pyobj_nbElt = NULL;
    int nbElt=0;

    const char* keywords[] = { "src", "nbElt", "out", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:contourSampling", (char**)keywords, &pyobj_src, &pyobj_nbElt, &pyobj_out) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_out, out, ArgInfo("out", 1)) &&
        pyopencv_to_safe(pyobj_nbElt, nbElt, ArgInfo("nbElt", 0)) )
    {
        ERRWRAP2(cv::ximgproc::contourSampling(src, out, nbElt));
        return pyopencv_from(out);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("contourSampling");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_covarianceEstimation(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_windowRows = NULL;
    int windowRows=0;
    PyObject* pyobj_windowCols = NULL;
    int windowCols=0;

    const char* keywords[] = { "src", "windowRows", "windowCols", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:covarianceEstimation", (char**)keywords, &pyobj_src, &pyobj_windowRows, &pyobj_windowCols, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_windowRows, windowRows, ArgInfo("windowRows", 0)) &&
        pyopencv_to_safe(pyobj_windowCols, windowCols, ArgInfo("windowCols", 0)) )
    {
        ERRWRAP2(cv::ximgproc::covarianceEstimation(src, dst, windowRows, windowCols));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_windowRows = NULL;
    int windowRows=0;
    PyObject* pyobj_windowCols = NULL;
    int windowCols=0;

    const char* keywords[] = { "src", "windowRows", "windowCols", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:covarianceEstimation", (char**)keywords, &pyobj_src, &pyobj_windowRows, &pyobj_windowCols, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_windowRows, windowRows, ArgInfo("windowRows", 0)) &&
        pyopencv_to_safe(pyobj_windowCols, windowCols, ArgInfo("windowCols", 0)) )
    {
        ERRWRAP2(cv::ximgproc::covarianceEstimation(src, dst, windowRows, windowCols));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("covarianceEstimation");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_createAMFilter(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    PyObject* pyobj_sigma_s = NULL;
    double sigma_s=0;
    PyObject* pyobj_sigma_r = NULL;
    double sigma_r=0;
    PyObject* pyobj_adjust_outliers = NULL;
    bool adjust_outliers=false;
    Ptr<AdaptiveManifoldFilter> retval;

    const char* keywords[] = { "sigma_s", "sigma_r", "adjust_outliers", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:createAMFilter", (char**)keywords, &pyobj_sigma_s, &pyobj_sigma_r, &pyobj_adjust_outliers) &&
        pyopencv_to_safe(pyobj_sigma_s, sigma_s, ArgInfo("sigma_s", 0)) &&
        pyopencv_to_safe(pyobj_sigma_r, sigma_r, ArgInfo("sigma_r", 0)) &&
        pyopencv_to_safe(pyobj_adjust_outliers, adjust_outliers, ArgInfo("adjust_outliers", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::createAMFilter(sigma_s, sigma_r, adjust_outliers));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_createContourFitting(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    PyObject* pyobj_ctr = NULL;
    int ctr=1024;
    PyObject* pyobj_fd = NULL;
    int fd=16;
    Ptr<ContourFitting> retval;

    const char* keywords[] = { "ctr", "fd", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OO:createContourFitting", (char**)keywords, &pyobj_ctr, &pyobj_fd) &&
        pyopencv_to_safe(pyobj_ctr, ctr, ArgInfo("ctr", 0)) &&
        pyopencv_to_safe(pyobj_fd, fd, ArgInfo("fd", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::createContourFitting(ctr, fd));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_createDTFilter(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_guide = NULL;
    Mat guide;
    PyObject* pyobj_sigmaSpatial = NULL;
    double sigmaSpatial=0;
    PyObject* pyobj_sigmaColor = NULL;
    double sigmaColor=0;
    PyObject* pyobj_mode = NULL;
    int mode=DTF_NC;
    PyObject* pyobj_numIters = NULL;
    int numIters=3;
    Ptr<DTFilter> retval;

    const char* keywords[] = { "guide", "sigmaSpatial", "sigmaColor", "mode", "numIters", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:createDTFilter", (char**)keywords, &pyobj_guide, &pyobj_sigmaSpatial, &pyobj_sigmaColor, &pyobj_mode, &pyobj_numIters) &&
        pyopencv_to_safe(pyobj_guide, guide, ArgInfo("guide", 0)) &&
        pyopencv_to_safe(pyobj_sigmaSpatial, sigmaSpatial, ArgInfo("sigmaSpatial", 0)) &&
        pyopencv_to_safe(pyobj_sigmaColor, sigmaColor, ArgInfo("sigmaColor", 0)) &&
        pyopencv_to_safe(pyobj_mode, mode, ArgInfo("mode", 0)) &&
        pyopencv_to_safe(pyobj_numIters, numIters, ArgInfo("numIters", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::createDTFilter(guide, sigmaSpatial, sigmaColor, mode, numIters));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_guide = NULL;
    UMat guide;
    PyObject* pyobj_sigmaSpatial = NULL;
    double sigmaSpatial=0;
    PyObject* pyobj_sigmaColor = NULL;
    double sigmaColor=0;
    PyObject* pyobj_mode = NULL;
    int mode=DTF_NC;
    PyObject* pyobj_numIters = NULL;
    int numIters=3;
    Ptr<DTFilter> retval;

    const char* keywords[] = { "guide", "sigmaSpatial", "sigmaColor", "mode", "numIters", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:createDTFilter", (char**)keywords, &pyobj_guide, &pyobj_sigmaSpatial, &pyobj_sigmaColor, &pyobj_mode, &pyobj_numIters) &&
        pyopencv_to_safe(pyobj_guide, guide, ArgInfo("guide", 0)) &&
        pyopencv_to_safe(pyobj_sigmaSpatial, sigmaSpatial, ArgInfo("sigmaSpatial", 0)) &&
        pyopencv_to_safe(pyobj_sigmaColor, sigmaColor, ArgInfo("sigmaColor", 0)) &&
        pyopencv_to_safe(pyobj_mode, mode, ArgInfo("mode", 0)) &&
        pyopencv_to_safe(pyobj_numIters, numIters, ArgInfo("numIters", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::createDTFilter(guide, sigmaSpatial, sigmaColor, mode, numIters));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("createDTFilter");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_createDisparityWLSFilter(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    PyObject* pyobj_matcher_left = NULL;
    Ptr<StereoMatcher> matcher_left;
    Ptr<DisparityWLSFilter> retval;

    const char* keywords[] = { "matcher_left", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:createDisparityWLSFilter", (char**)keywords, &pyobj_matcher_left) &&
        pyopencv_to_safe(pyobj_matcher_left, matcher_left, ArgInfo("matcher_left", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::createDisparityWLSFilter(matcher_left));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_createDisparityWLSFilterGeneric(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    PyObject* pyobj_use_confidence = NULL;
    bool use_confidence=0;
    Ptr<DisparityWLSFilter> retval;

    const char* keywords[] = { "use_confidence", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:createDisparityWLSFilterGeneric", (char**)keywords, &pyobj_use_confidence) &&
        pyopencv_to_safe(pyobj_use_confidence, use_confidence, ArgInfo("use_confidence", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::createDisparityWLSFilterGeneric(use_confidence));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_createEdgeAwareInterpolator(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    Ptr<EdgeAwareInterpolator> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::ximgproc::createEdgeAwareInterpolator());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_createEdgeBoxes(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    PyObject* pyobj_alpha = NULL;
    float alpha=0.65f;
    PyObject* pyobj_beta = NULL;
    float beta=0.75f;
    PyObject* pyobj_eta = NULL;
    float eta=1;
    PyObject* pyobj_minScore = NULL;
    float minScore=0.01f;
    PyObject* pyobj_maxBoxes = NULL;
    int maxBoxes=10000;
    PyObject* pyobj_edgeMinMag = NULL;
    float edgeMinMag=0.1f;
    PyObject* pyobj_edgeMergeThr = NULL;
    float edgeMergeThr=0.5f;
    PyObject* pyobj_clusterMinMag = NULL;
    float clusterMinMag=0.5f;
    PyObject* pyobj_maxAspectRatio = NULL;
    float maxAspectRatio=3;
    PyObject* pyobj_minBoxArea = NULL;
    float minBoxArea=1000;
    PyObject* pyobj_gamma = NULL;
    float gamma=2;
    PyObject* pyobj_kappa = NULL;
    float kappa=1.5f;
    Ptr<EdgeBoxes> retval;

    const char* keywords[] = { "alpha", "beta", "eta", "minScore", "maxBoxes", "edgeMinMag", "edgeMergeThr", "clusterMinMag", "maxAspectRatio", "minBoxArea", "gamma", "kappa", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOOOOOOOOO:createEdgeBoxes", (char**)keywords, &pyobj_alpha, &pyobj_beta, &pyobj_eta, &pyobj_minScore, &pyobj_maxBoxes, &pyobj_edgeMinMag, &pyobj_edgeMergeThr, &pyobj_clusterMinMag, &pyobj_maxAspectRatio, &pyobj_minBoxArea, &pyobj_gamma, &pyobj_kappa) &&
        pyopencv_to_safe(pyobj_alpha, alpha, ArgInfo("alpha", 0)) &&
        pyopencv_to_safe(pyobj_beta, beta, ArgInfo("beta", 0)) &&
        pyopencv_to_safe(pyobj_eta, eta, ArgInfo("eta", 0)) &&
        pyopencv_to_safe(pyobj_minScore, minScore, ArgInfo("minScore", 0)) &&
        pyopencv_to_safe(pyobj_maxBoxes, maxBoxes, ArgInfo("maxBoxes", 0)) &&
        pyopencv_to_safe(pyobj_edgeMinMag, edgeMinMag, ArgInfo("edgeMinMag", 0)) &&
        pyopencv_to_safe(pyobj_edgeMergeThr, edgeMergeThr, ArgInfo("edgeMergeThr", 0)) &&
        pyopencv_to_safe(pyobj_clusterMinMag, clusterMinMag, ArgInfo("clusterMinMag", 0)) &&
        pyopencv_to_safe(pyobj_maxAspectRatio, maxAspectRatio, ArgInfo("maxAspectRatio", 0)) &&
        pyopencv_to_safe(pyobj_minBoxArea, minBoxArea, ArgInfo("minBoxArea", 0)) &&
        pyopencv_to_safe(pyobj_gamma, gamma, ArgInfo("gamma", 0)) &&
        pyopencv_to_safe(pyobj_kappa, kappa, ArgInfo("kappa", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::createEdgeBoxes(alpha, beta, eta, minScore, maxBoxes, edgeMinMag, edgeMergeThr, clusterMinMag, maxAspectRatio, minBoxArea, gamma, kappa));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_createEdgeDrawing(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    Ptr<EdgeDrawing> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::ximgproc::createEdgeDrawing());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_createFastBilateralSolverFilter(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_guide = NULL;
    Mat guide;
    PyObject* pyobj_sigma_spatial = NULL;
    double sigma_spatial=0;
    PyObject* pyobj_sigma_luma = NULL;
    double sigma_luma=0;
    PyObject* pyobj_sigma_chroma = NULL;
    double sigma_chroma=0;
    PyObject* pyobj_lambda = NULL;
    double lambda=128.0;
    PyObject* pyobj_num_iter = NULL;
    int num_iter=25;
    PyObject* pyobj_max_tol = NULL;
    double max_tol=1e-5;
    Ptr<FastBilateralSolverFilter> retval;

    const char* keywords[] = { "guide", "sigma_spatial", "sigma_luma", "sigma_chroma", "lambda", "num_iter", "max_tol", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:createFastBilateralSolverFilter", (char**)keywords, &pyobj_guide, &pyobj_sigma_spatial, &pyobj_sigma_luma, &pyobj_sigma_chroma, &pyobj_lambda, &pyobj_num_iter, &pyobj_max_tol) &&
        pyopencv_to_safe(pyobj_guide, guide, ArgInfo("guide", 0)) &&
        pyopencv_to_safe(pyobj_sigma_spatial, sigma_spatial, ArgInfo("sigma_spatial", 0)) &&
        pyopencv_to_safe(pyobj_sigma_luma, sigma_luma, ArgInfo("sigma_luma", 0)) &&
        pyopencv_to_safe(pyobj_sigma_chroma, sigma_chroma, ArgInfo("sigma_chroma", 0)) &&
        pyopencv_to_safe(pyobj_lambda, lambda, ArgInfo("lambda", 0)) &&
        pyopencv_to_safe(pyobj_num_iter, num_iter, ArgInfo("num_iter", 0)) &&
        pyopencv_to_safe(pyobj_max_tol, max_tol, ArgInfo("max_tol", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::createFastBilateralSolverFilter(guide, sigma_spatial, sigma_luma, sigma_chroma, lambda, num_iter, max_tol));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_guide = NULL;
    UMat guide;
    PyObject* pyobj_sigma_spatial = NULL;
    double sigma_spatial=0;
    PyObject* pyobj_sigma_luma = NULL;
    double sigma_luma=0;
    PyObject* pyobj_sigma_chroma = NULL;
    double sigma_chroma=0;
    PyObject* pyobj_lambda = NULL;
    double lambda=128.0;
    PyObject* pyobj_num_iter = NULL;
    int num_iter=25;
    PyObject* pyobj_max_tol = NULL;
    double max_tol=1e-5;
    Ptr<FastBilateralSolverFilter> retval;

    const char* keywords[] = { "guide", "sigma_spatial", "sigma_luma", "sigma_chroma", "lambda", "num_iter", "max_tol", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:createFastBilateralSolverFilter", (char**)keywords, &pyobj_guide, &pyobj_sigma_spatial, &pyobj_sigma_luma, &pyobj_sigma_chroma, &pyobj_lambda, &pyobj_num_iter, &pyobj_max_tol) &&
        pyopencv_to_safe(pyobj_guide, guide, ArgInfo("guide", 0)) &&
        pyopencv_to_safe(pyobj_sigma_spatial, sigma_spatial, ArgInfo("sigma_spatial", 0)) &&
        pyopencv_to_safe(pyobj_sigma_luma, sigma_luma, ArgInfo("sigma_luma", 0)) &&
        pyopencv_to_safe(pyobj_sigma_chroma, sigma_chroma, ArgInfo("sigma_chroma", 0)) &&
        pyopencv_to_safe(pyobj_lambda, lambda, ArgInfo("lambda", 0)) &&
        pyopencv_to_safe(pyobj_num_iter, num_iter, ArgInfo("num_iter", 0)) &&
        pyopencv_to_safe(pyobj_max_tol, max_tol, ArgInfo("max_tol", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::createFastBilateralSolverFilter(guide, sigma_spatial, sigma_luma, sigma_chroma, lambda, num_iter, max_tol));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("createFastBilateralSolverFilter");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_createFastGlobalSmootherFilter(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_guide = NULL;
    Mat guide;
    PyObject* pyobj_lambda = NULL;
    double lambda=0;
    PyObject* pyobj_sigma_color = NULL;
    double sigma_color=0;
    PyObject* pyobj_lambda_attenuation = NULL;
    double lambda_attenuation=0.25;
    PyObject* pyobj_num_iter = NULL;
    int num_iter=3;
    Ptr<FastGlobalSmootherFilter> retval;

    const char* keywords[] = { "guide", "lambda", "sigma_color", "lambda_attenuation", "num_iter", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:createFastGlobalSmootherFilter", (char**)keywords, &pyobj_guide, &pyobj_lambda, &pyobj_sigma_color, &pyobj_lambda_attenuation, &pyobj_num_iter) &&
        pyopencv_to_safe(pyobj_guide, guide, ArgInfo("guide", 0)) &&
        pyopencv_to_safe(pyobj_lambda, lambda, ArgInfo("lambda", 0)) &&
        pyopencv_to_safe(pyobj_sigma_color, sigma_color, ArgInfo("sigma_color", 0)) &&
        pyopencv_to_safe(pyobj_lambda_attenuation, lambda_attenuation, ArgInfo("lambda_attenuation", 0)) &&
        pyopencv_to_safe(pyobj_num_iter, num_iter, ArgInfo("num_iter", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::createFastGlobalSmootherFilter(guide, lambda, sigma_color, lambda_attenuation, num_iter));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_guide = NULL;
    UMat guide;
    PyObject* pyobj_lambda = NULL;
    double lambda=0;
    PyObject* pyobj_sigma_color = NULL;
    double sigma_color=0;
    PyObject* pyobj_lambda_attenuation = NULL;
    double lambda_attenuation=0.25;
    PyObject* pyobj_num_iter = NULL;
    int num_iter=3;
    Ptr<FastGlobalSmootherFilter> retval;

    const char* keywords[] = { "guide", "lambda", "sigma_color", "lambda_attenuation", "num_iter", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OO:createFastGlobalSmootherFilter", (char**)keywords, &pyobj_guide, &pyobj_lambda, &pyobj_sigma_color, &pyobj_lambda_attenuation, &pyobj_num_iter) &&
        pyopencv_to_safe(pyobj_guide, guide, ArgInfo("guide", 0)) &&
        pyopencv_to_safe(pyobj_lambda, lambda, ArgInfo("lambda", 0)) &&
        pyopencv_to_safe(pyobj_sigma_color, sigma_color, ArgInfo("sigma_color", 0)) &&
        pyopencv_to_safe(pyobj_lambda_attenuation, lambda_attenuation, ArgInfo("lambda_attenuation", 0)) &&
        pyopencv_to_safe(pyobj_num_iter, num_iter, ArgInfo("num_iter", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::createFastGlobalSmootherFilter(guide, lambda, sigma_color, lambda_attenuation, num_iter));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("createFastGlobalSmootherFilter");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_createFastLineDetector(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    PyObject* pyobj__length_threshold = NULL;
    int _length_threshold=10;
    PyObject* pyobj__distance_threshold = NULL;
    float _distance_threshold=1.414213562f;
    PyObject* pyobj__canny_th1 = NULL;
    double _canny_th1=50.0;
    PyObject* pyobj__canny_th2 = NULL;
    double _canny_th2=50.0;
    PyObject* pyobj__canny_aperture_size = NULL;
    int _canny_aperture_size=3;
    PyObject* pyobj__do_merge = NULL;
    bool _do_merge=false;
    Ptr<FastLineDetector> retval;

    const char* keywords[] = { "_length_threshold", "_distance_threshold", "_canny_th1", "_canny_th2", "_canny_aperture_size", "_do_merge", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOOO:createFastLineDetector", (char**)keywords, &pyobj__length_threshold, &pyobj__distance_threshold, &pyobj__canny_th1, &pyobj__canny_th2, &pyobj__canny_aperture_size, &pyobj__do_merge) &&
        pyopencv_to_safe(pyobj__length_threshold, _length_threshold, ArgInfo("_length_threshold", 0)) &&
        pyopencv_to_safe(pyobj__distance_threshold, _distance_threshold, ArgInfo("_distance_threshold", 0)) &&
        pyopencv_to_safe(pyobj__canny_th1, _canny_th1, ArgInfo("_canny_th1", 0)) &&
        pyopencv_to_safe(pyobj__canny_th2, _canny_th2, ArgInfo("_canny_th2", 0)) &&
        pyopencv_to_safe(pyobj__canny_aperture_size, _canny_aperture_size, ArgInfo("_canny_aperture_size", 0)) &&
        pyopencv_to_safe(pyobj__do_merge, _do_merge, ArgInfo("_do_merge", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::createFastLineDetector(_length_threshold, _distance_threshold, _canny_th1, _canny_th2, _canny_aperture_size, _do_merge));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_createGuidedFilter(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_guide = NULL;
    Mat guide;
    PyObject* pyobj_radius = NULL;
    int radius=0;
    PyObject* pyobj_eps = NULL;
    double eps=0;
    Ptr<GuidedFilter> retval;

    const char* keywords[] = { "guide", "radius", "eps", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:createGuidedFilter", (char**)keywords, &pyobj_guide, &pyobj_radius, &pyobj_eps) &&
        pyopencv_to_safe(pyobj_guide, guide, ArgInfo("guide", 0)) &&
        pyopencv_to_safe(pyobj_radius, radius, ArgInfo("radius", 0)) &&
        pyopencv_to_safe(pyobj_eps, eps, ArgInfo("eps", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::createGuidedFilter(guide, radius, eps));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_guide = NULL;
    UMat guide;
    PyObject* pyobj_radius = NULL;
    int radius=0;
    PyObject* pyobj_eps = NULL;
    double eps=0;
    Ptr<GuidedFilter> retval;

    const char* keywords[] = { "guide", "radius", "eps", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:createGuidedFilter", (char**)keywords, &pyobj_guide, &pyobj_radius, &pyobj_eps) &&
        pyopencv_to_safe(pyobj_guide, guide, ArgInfo("guide", 0)) &&
        pyopencv_to_safe(pyobj_radius, radius, ArgInfo("radius", 0)) &&
        pyopencv_to_safe(pyobj_eps, eps, ArgInfo("eps", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::createGuidedFilter(guide, radius, eps));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("createGuidedFilter");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_createQuaternionImage(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_qimg = NULL;
    Mat qimg;

    const char* keywords[] = { "img", "qimg", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:createQuaternionImage", (char**)keywords, &pyobj_img, &pyobj_qimg) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_qimg, qimg, ArgInfo("qimg", 1)) )
    {
        ERRWRAP2(cv::ximgproc::createQuaternionImage(img, qimg));
        return pyopencv_from(qimg);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_qimg = NULL;
    UMat qimg;

    const char* keywords[] = { "img", "qimg", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:createQuaternionImage", (char**)keywords, &pyobj_img, &pyobj_qimg) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_qimg, qimg, ArgInfo("qimg", 1)) )
    {
        ERRWRAP2(cv::ximgproc::createQuaternionImage(img, qimg));
        return pyopencv_from(qimg);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("createQuaternionImage");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_createRFFeatureGetter(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    Ptr<RFFeatureGetter> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::ximgproc::createRFFeatureGetter());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_createRICInterpolator(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    Ptr<RICInterpolator> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::ximgproc::createRICInterpolator());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_createRightMatcher(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    PyObject* pyobj_matcher_left = NULL;
    Ptr<StereoMatcher> matcher_left;
    Ptr<StereoMatcher> retval;

    const char* keywords[] = { "matcher_left", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:createRightMatcher", (char**)keywords, &pyobj_matcher_left) &&
        pyopencv_to_safe(pyobj_matcher_left, matcher_left, ArgInfo("matcher_left", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::createRightMatcher(matcher_left));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_createStructuredEdgeDetection(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    PyObject* pyobj_model = NULL;
    String model;
    PyObject* pyobj_howToGetFeatures = NULL;
    Ptr<RFFeatureGetter> howToGetFeatures;
    Ptr<StructuredEdgeDetection> retval;

    const char* keywords[] = { "model", "howToGetFeatures", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:createStructuredEdgeDetection", (char**)keywords, &pyobj_model, &pyobj_howToGetFeatures) &&
        pyopencv_to_safe(pyobj_model, model, ArgInfo("model", 0)) &&
        pyopencv_to_safe(pyobj_howToGetFeatures, howToGetFeatures, ArgInfo("howToGetFeatures", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::createStructuredEdgeDetection(model, howToGetFeatures));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_createSuperpixelLSC(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_region_size = NULL;
    int region_size=10;
    PyObject* pyobj_ratio = NULL;
    float ratio=0.075f;
    Ptr<SuperpixelLSC> retval;

    const char* keywords[] = { "image", "region_size", "ratio", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:createSuperpixelLSC", (char**)keywords, &pyobj_image, &pyobj_region_size, &pyobj_ratio) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_region_size, region_size, ArgInfo("region_size", 0)) &&
        pyopencv_to_safe(pyobj_ratio, ratio, ArgInfo("ratio", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::createSuperpixelLSC(image, region_size, ratio));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_region_size = NULL;
    int region_size=10;
    PyObject* pyobj_ratio = NULL;
    float ratio=0.075f;
    Ptr<SuperpixelLSC> retval;

    const char* keywords[] = { "image", "region_size", "ratio", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:createSuperpixelLSC", (char**)keywords, &pyobj_image, &pyobj_region_size, &pyobj_ratio) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_region_size, region_size, ArgInfo("region_size", 0)) &&
        pyopencv_to_safe(pyobj_ratio, ratio, ArgInfo("ratio", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::createSuperpixelLSC(image, region_size, ratio));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("createSuperpixelLSC");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_createSuperpixelSEEDS(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    PyObject* pyobj_image_width = NULL;
    int image_width=0;
    PyObject* pyobj_image_height = NULL;
    int image_height=0;
    PyObject* pyobj_image_channels = NULL;
    int image_channels=0;
    PyObject* pyobj_num_superpixels = NULL;
    int num_superpixels=0;
    PyObject* pyobj_num_levels = NULL;
    int num_levels=0;
    PyObject* pyobj_prior = NULL;
    int prior=2;
    PyObject* pyobj_histogram_bins = NULL;
    int histogram_bins=5;
    PyObject* pyobj_double_step = NULL;
    bool double_step=false;
    Ptr<SuperpixelSEEDS> retval;

    const char* keywords[] = { "image_width", "image_height", "image_channels", "num_superpixels", "num_levels", "prior", "histogram_bins", "double_step", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OOO:createSuperpixelSEEDS", (char**)keywords, &pyobj_image_width, &pyobj_image_height, &pyobj_image_channels, &pyobj_num_superpixels, &pyobj_num_levels, &pyobj_prior, &pyobj_histogram_bins, &pyobj_double_step) &&
        pyopencv_to_safe(pyobj_image_width, image_width, ArgInfo("image_width", 0)) &&
        pyopencv_to_safe(pyobj_image_height, image_height, ArgInfo("image_height", 0)) &&
        pyopencv_to_safe(pyobj_image_channels, image_channels, ArgInfo("image_channels", 0)) &&
        pyopencv_to_safe(pyobj_num_superpixels, num_superpixels, ArgInfo("num_superpixels", 0)) &&
        pyopencv_to_safe(pyobj_num_levels, num_levels, ArgInfo("num_levels", 0)) &&
        pyopencv_to_safe(pyobj_prior, prior, ArgInfo("prior", 0)) &&
        pyopencv_to_safe(pyobj_histogram_bins, histogram_bins, ArgInfo("histogram_bins", 0)) &&
        pyopencv_to_safe(pyobj_double_step, double_step, ArgInfo("double_step", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::createSuperpixelSEEDS(image_width, image_height, image_channels, num_superpixels, num_levels, prior, histogram_bins, double_step));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_createSuperpixelSLIC(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_image = NULL;
    Mat image;
    PyObject* pyobj_algorithm = NULL;
    int algorithm=SLICO;
    PyObject* pyobj_region_size = NULL;
    int region_size=10;
    PyObject* pyobj_ruler = NULL;
    float ruler=10.0f;
    Ptr<SuperpixelSLIC> retval;

    const char* keywords[] = { "image", "algorithm", "region_size", "ruler", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:createSuperpixelSLIC", (char**)keywords, &pyobj_image, &pyobj_algorithm, &pyobj_region_size, &pyobj_ruler) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_algorithm, algorithm, ArgInfo("algorithm", 0)) &&
        pyopencv_to_safe(pyobj_region_size, region_size, ArgInfo("region_size", 0)) &&
        pyopencv_to_safe(pyobj_ruler, ruler, ArgInfo("ruler", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::createSuperpixelSLIC(image, algorithm, region_size, ruler));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_image = NULL;
    UMat image;
    PyObject* pyobj_algorithm = NULL;
    int algorithm=SLICO;
    PyObject* pyobj_region_size = NULL;
    int region_size=10;
    PyObject* pyobj_ruler = NULL;
    float ruler=10.0f;
    Ptr<SuperpixelSLIC> retval;

    const char* keywords[] = { "image", "algorithm", "region_size", "ruler", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:createSuperpixelSLIC", (char**)keywords, &pyobj_image, &pyobj_algorithm, &pyobj_region_size, &pyobj_ruler) &&
        pyopencv_to_safe(pyobj_image, image, ArgInfo("image", 0)) &&
        pyopencv_to_safe(pyobj_algorithm, algorithm, ArgInfo("algorithm", 0)) &&
        pyopencv_to_safe(pyobj_region_size, region_size, ArgInfo("region_size", 0)) &&
        pyopencv_to_safe(pyobj_ruler, ruler, ArgInfo("ruler", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::createSuperpixelSLIC(image, algorithm, region_size, ruler));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("createSuperpixelSLIC");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_dtFilter(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_guide = NULL;
    Mat guide;
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_sigmaSpatial = NULL;
    double sigmaSpatial=0;
    PyObject* pyobj_sigmaColor = NULL;
    double sigmaColor=0;
    PyObject* pyobj_mode = NULL;
    int mode=DTF_NC;
    PyObject* pyobj_numIters = NULL;
    int numIters=3;

    const char* keywords[] = { "guide", "src", "sigmaSpatial", "sigmaColor", "dst", "mode", "numIters", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:dtFilter", (char**)keywords, &pyobj_guide, &pyobj_src, &pyobj_sigmaSpatial, &pyobj_sigmaColor, &pyobj_dst, &pyobj_mode, &pyobj_numIters) &&
        pyopencv_to_safe(pyobj_guide, guide, ArgInfo("guide", 0)) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_sigmaSpatial, sigmaSpatial, ArgInfo("sigmaSpatial", 0)) &&
        pyopencv_to_safe(pyobj_sigmaColor, sigmaColor, ArgInfo("sigmaColor", 0)) &&
        pyopencv_to_safe(pyobj_mode, mode, ArgInfo("mode", 0)) &&
        pyopencv_to_safe(pyobj_numIters, numIters, ArgInfo("numIters", 0)) )
    {
        ERRWRAP2(cv::ximgproc::dtFilter(guide, src, dst, sigmaSpatial, sigmaColor, mode, numIters));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_guide = NULL;
    UMat guide;
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_sigmaSpatial = NULL;
    double sigmaSpatial=0;
    PyObject* pyobj_sigmaColor = NULL;
    double sigmaColor=0;
    PyObject* pyobj_mode = NULL;
    int mode=DTF_NC;
    PyObject* pyobj_numIters = NULL;
    int numIters=3;

    const char* keywords[] = { "guide", "src", "sigmaSpatial", "sigmaColor", "dst", "mode", "numIters", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:dtFilter", (char**)keywords, &pyobj_guide, &pyobj_src, &pyobj_sigmaSpatial, &pyobj_sigmaColor, &pyobj_dst, &pyobj_mode, &pyobj_numIters) &&
        pyopencv_to_safe(pyobj_guide, guide, ArgInfo("guide", 0)) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_sigmaSpatial, sigmaSpatial, ArgInfo("sigmaSpatial", 0)) &&
        pyopencv_to_safe(pyobj_sigmaColor, sigmaColor, ArgInfo("sigmaColor", 0)) &&
        pyopencv_to_safe(pyobj_mode, mode, ArgInfo("mode", 0)) &&
        pyopencv_to_safe(pyobj_numIters, numIters, ArgInfo("numIters", 0)) )
    {
        ERRWRAP2(cv::ximgproc::dtFilter(guide, src, dst, sigmaSpatial, sigmaColor, mode, numIters));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("dtFilter");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_edgePreservingFilter(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_d = NULL;
    int d=0;
    PyObject* pyobj_threshold = NULL;
    double threshold=0;

    const char* keywords[] = { "src", "d", "threshold", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:edgePreservingFilter", (char**)keywords, &pyobj_src, &pyobj_d, &pyobj_threshold, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_d, d, ArgInfo("d", 0)) &&
        pyopencv_to_safe(pyobj_threshold, threshold, ArgInfo("threshold", 0)) )
    {
        ERRWRAP2(cv::ximgproc::edgePreservingFilter(src, dst, d, threshold));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_d = NULL;
    int d=0;
    PyObject* pyobj_threshold = NULL;
    double threshold=0;

    const char* keywords[] = { "src", "d", "threshold", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:edgePreservingFilter", (char**)keywords, &pyobj_src, &pyobj_d, &pyobj_threshold, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_d, d, ArgInfo("d", 0)) &&
        pyopencv_to_safe(pyobj_threshold, threshold, ArgInfo("threshold", 0)) )
    {
        ERRWRAP2(cv::ximgproc::edgePreservingFilter(src, dst, d, threshold));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("edgePreservingFilter");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_fastBilateralSolverFilter(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_guide = NULL;
    Mat guide;
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_confidence = NULL;
    Mat confidence;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_sigma_spatial = NULL;
    double sigma_spatial=8;
    PyObject* pyobj_sigma_luma = NULL;
    double sigma_luma=8;
    PyObject* pyobj_sigma_chroma = NULL;
    double sigma_chroma=8;
    PyObject* pyobj_lambda = NULL;
    double lambda=128.0;
    PyObject* pyobj_num_iter = NULL;
    int num_iter=25;
    PyObject* pyobj_max_tol = NULL;
    double max_tol=1e-5;

    const char* keywords[] = { "guide", "src", "confidence", "dst", "sigma_spatial", "sigma_luma", "sigma_chroma", "lambda", "num_iter", "max_tol", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOOOOO:fastBilateralSolverFilter", (char**)keywords, &pyobj_guide, &pyobj_src, &pyobj_confidence, &pyobj_dst, &pyobj_sigma_spatial, &pyobj_sigma_luma, &pyobj_sigma_chroma, &pyobj_lambda, &pyobj_num_iter, &pyobj_max_tol) &&
        pyopencv_to_safe(pyobj_guide, guide, ArgInfo("guide", 0)) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_confidence, confidence, ArgInfo("confidence", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_sigma_spatial, sigma_spatial, ArgInfo("sigma_spatial", 0)) &&
        pyopencv_to_safe(pyobj_sigma_luma, sigma_luma, ArgInfo("sigma_luma", 0)) &&
        pyopencv_to_safe(pyobj_sigma_chroma, sigma_chroma, ArgInfo("sigma_chroma", 0)) &&
        pyopencv_to_safe(pyobj_lambda, lambda, ArgInfo("lambda", 0)) &&
        pyopencv_to_safe(pyobj_num_iter, num_iter, ArgInfo("num_iter", 0)) &&
        pyopencv_to_safe(pyobj_max_tol, max_tol, ArgInfo("max_tol", 0)) )
    {
        ERRWRAP2(cv::ximgproc::fastBilateralSolverFilter(guide, src, confidence, dst, sigma_spatial, sigma_luma, sigma_chroma, lambda, num_iter, max_tol));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_guide = NULL;
    UMat guide;
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_confidence = NULL;
    UMat confidence;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_sigma_spatial = NULL;
    double sigma_spatial=8;
    PyObject* pyobj_sigma_luma = NULL;
    double sigma_luma=8;
    PyObject* pyobj_sigma_chroma = NULL;
    double sigma_chroma=8;
    PyObject* pyobj_lambda = NULL;
    double lambda=128.0;
    PyObject* pyobj_num_iter = NULL;
    int num_iter=25;
    PyObject* pyobj_max_tol = NULL;
    double max_tol=1e-5;

    const char* keywords[] = { "guide", "src", "confidence", "dst", "sigma_spatial", "sigma_luma", "sigma_chroma", "lambda", "num_iter", "max_tol", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOOOOO:fastBilateralSolverFilter", (char**)keywords, &pyobj_guide, &pyobj_src, &pyobj_confidence, &pyobj_dst, &pyobj_sigma_spatial, &pyobj_sigma_luma, &pyobj_sigma_chroma, &pyobj_lambda, &pyobj_num_iter, &pyobj_max_tol) &&
        pyopencv_to_safe(pyobj_guide, guide, ArgInfo("guide", 0)) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_confidence, confidence, ArgInfo("confidence", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_sigma_spatial, sigma_spatial, ArgInfo("sigma_spatial", 0)) &&
        pyopencv_to_safe(pyobj_sigma_luma, sigma_luma, ArgInfo("sigma_luma", 0)) &&
        pyopencv_to_safe(pyobj_sigma_chroma, sigma_chroma, ArgInfo("sigma_chroma", 0)) &&
        pyopencv_to_safe(pyobj_lambda, lambda, ArgInfo("lambda", 0)) &&
        pyopencv_to_safe(pyobj_num_iter, num_iter, ArgInfo("num_iter", 0)) &&
        pyopencv_to_safe(pyobj_max_tol, max_tol, ArgInfo("max_tol", 0)) )
    {
        ERRWRAP2(cv::ximgproc::fastBilateralSolverFilter(guide, src, confidence, dst, sigma_spatial, sigma_luma, sigma_chroma, lambda, num_iter, max_tol));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("fastBilateralSolverFilter");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_fastGlobalSmootherFilter(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_guide = NULL;
    Mat guide;
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_lambda = NULL;
    double lambda=0;
    PyObject* pyobj_sigma_color = NULL;
    double sigma_color=0;
    PyObject* pyobj_lambda_attenuation = NULL;
    double lambda_attenuation=0.25;
    PyObject* pyobj_num_iter = NULL;
    int num_iter=3;

    const char* keywords[] = { "guide", "src", "lambda", "sigma_color", "dst", "lambda_attenuation", "num_iter", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:fastGlobalSmootherFilter", (char**)keywords, &pyobj_guide, &pyobj_src, &pyobj_lambda, &pyobj_sigma_color, &pyobj_dst, &pyobj_lambda_attenuation, &pyobj_num_iter) &&
        pyopencv_to_safe(pyobj_guide, guide, ArgInfo("guide", 0)) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_lambda, lambda, ArgInfo("lambda", 0)) &&
        pyopencv_to_safe(pyobj_sigma_color, sigma_color, ArgInfo("sigma_color", 0)) &&
        pyopencv_to_safe(pyobj_lambda_attenuation, lambda_attenuation, ArgInfo("lambda_attenuation", 0)) &&
        pyopencv_to_safe(pyobj_num_iter, num_iter, ArgInfo("num_iter", 0)) )
    {
        ERRWRAP2(cv::ximgproc::fastGlobalSmootherFilter(guide, src, dst, lambda, sigma_color, lambda_attenuation, num_iter));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_guide = NULL;
    UMat guide;
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_lambda = NULL;
    double lambda=0;
    PyObject* pyobj_sigma_color = NULL;
    double sigma_color=0;
    PyObject* pyobj_lambda_attenuation = NULL;
    double lambda_attenuation=0.25;
    PyObject* pyobj_num_iter = NULL;
    int num_iter=3;

    const char* keywords[] = { "guide", "src", "lambda", "sigma_color", "dst", "lambda_attenuation", "num_iter", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OOO:fastGlobalSmootherFilter", (char**)keywords, &pyobj_guide, &pyobj_src, &pyobj_lambda, &pyobj_sigma_color, &pyobj_dst, &pyobj_lambda_attenuation, &pyobj_num_iter) &&
        pyopencv_to_safe(pyobj_guide, guide, ArgInfo("guide", 0)) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_lambda, lambda, ArgInfo("lambda", 0)) &&
        pyopencv_to_safe(pyobj_sigma_color, sigma_color, ArgInfo("sigma_color", 0)) &&
        pyopencv_to_safe(pyobj_lambda_attenuation, lambda_attenuation, ArgInfo("lambda_attenuation", 0)) &&
        pyopencv_to_safe(pyobj_num_iter, num_iter, ArgInfo("num_iter", 0)) )
    {
        ERRWRAP2(cv::ximgproc::fastGlobalSmootherFilter(guide, src, dst, lambda, sigma_color, lambda_attenuation, num_iter));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("fastGlobalSmootherFilter");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_fourierDescriptor(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_nbElt = NULL;
    int nbElt=-1;
    PyObject* pyobj_nbFD = NULL;
    int nbFD=-1;

    const char* keywords[] = { "src", "dst", "nbElt", "nbFD", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:fourierDescriptor", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_nbElt, &pyobj_nbFD) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_nbElt, nbElt, ArgInfo("nbElt", 0)) &&
        pyopencv_to_safe(pyobj_nbFD, nbFD, ArgInfo("nbFD", 0)) )
    {
        ERRWRAP2(cv::ximgproc::fourierDescriptor(src, dst, nbElt, nbFD));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_nbElt = NULL;
    int nbElt=-1;
    PyObject* pyobj_nbFD = NULL;
    int nbFD=-1;

    const char* keywords[] = { "src", "dst", "nbElt", "nbFD", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:fourierDescriptor", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_nbElt, &pyobj_nbFD) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_nbElt, nbElt, ArgInfo("nbElt", 0)) &&
        pyopencv_to_safe(pyobj_nbFD, nbFD, ArgInfo("nbFD", 0)) )
    {
        ERRWRAP2(cv::ximgproc::fourierDescriptor(src, dst, nbElt, nbFD));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("fourierDescriptor");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_getDisparityVis(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_scale = NULL;
    double scale=1.0;

    const char* keywords[] = { "src", "dst", "scale", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:getDisparityVis", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_scale) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_scale, scale, ArgInfo("scale", 0)) )
    {
        ERRWRAP2(cv::ximgproc::getDisparityVis(src, dst, scale));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_scale = NULL;
    double scale=1.0;

    const char* keywords[] = { "src", "dst", "scale", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:getDisparityVis", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_scale) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_scale, scale, ArgInfo("scale", 0)) )
    {
        ERRWRAP2(cv::ximgproc::getDisparityVis(src, dst, scale));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("getDisparityVis");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_guidedFilter(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_guide = NULL;
    Mat guide;
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_radius = NULL;
    int radius=0;
    PyObject* pyobj_eps = NULL;
    double eps=0;
    PyObject* pyobj_dDepth = NULL;
    int dDepth=-1;

    const char* keywords[] = { "guide", "src", "radius", "eps", "dst", "dDepth", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OO:guidedFilter", (char**)keywords, &pyobj_guide, &pyobj_src, &pyobj_radius, &pyobj_eps, &pyobj_dst, &pyobj_dDepth) &&
        pyopencv_to_safe(pyobj_guide, guide, ArgInfo("guide", 0)) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_radius, radius, ArgInfo("radius", 0)) &&
        pyopencv_to_safe(pyobj_eps, eps, ArgInfo("eps", 0)) &&
        pyopencv_to_safe(pyobj_dDepth, dDepth, ArgInfo("dDepth", 0)) )
    {
        ERRWRAP2(cv::ximgproc::guidedFilter(guide, src, dst, radius, eps, dDepth));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_guide = NULL;
    UMat guide;
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_radius = NULL;
    int radius=0;
    PyObject* pyobj_eps = NULL;
    double eps=0;
    PyObject* pyobj_dDepth = NULL;
    int dDepth=-1;

    const char* keywords[] = { "guide", "src", "radius", "eps", "dst", "dDepth", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|OO:guidedFilter", (char**)keywords, &pyobj_guide, &pyobj_src, &pyobj_radius, &pyobj_eps, &pyobj_dst, &pyobj_dDepth) &&
        pyopencv_to_safe(pyobj_guide, guide, ArgInfo("guide", 0)) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_radius, radius, ArgInfo("radius", 0)) &&
        pyopencv_to_safe(pyobj_eps, eps, ArgInfo("eps", 0)) &&
        pyopencv_to_safe(pyobj_dDepth, dDepth, ArgInfo("dDepth", 0)) )
    {
        ERRWRAP2(cv::ximgproc::guidedFilter(guide, src, dst, radius, eps, dDepth));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("guidedFilter");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_jointBilateralFilter(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_joint = NULL;
    Mat joint;
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_d = NULL;
    int d=0;
    PyObject* pyobj_sigmaColor = NULL;
    double sigmaColor=0;
    PyObject* pyobj_sigmaSpace = NULL;
    double sigmaSpace=0;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "joint", "src", "d", "sigmaColor", "sigmaSpace", "dst", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OO:jointBilateralFilter", (char**)keywords, &pyobj_joint, &pyobj_src, &pyobj_d, &pyobj_sigmaColor, &pyobj_sigmaSpace, &pyobj_dst, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_joint, joint, ArgInfo("joint", 0)) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_d, d, ArgInfo("d", 0)) &&
        pyopencv_to_safe(pyobj_sigmaColor, sigmaColor, ArgInfo("sigmaColor", 0)) &&
        pyopencv_to_safe(pyobj_sigmaSpace, sigmaSpace, ArgInfo("sigmaSpace", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::ximgproc::jointBilateralFilter(joint, src, dst, d, sigmaColor, sigmaSpace, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_joint = NULL;
    UMat joint;
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_d = NULL;
    int d=0;
    PyObject* pyobj_sigmaColor = NULL;
    double sigmaColor=0;
    PyObject* pyobj_sigmaSpace = NULL;
    double sigmaSpace=0;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "joint", "src", "d", "sigmaColor", "sigmaSpace", "dst", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OO:jointBilateralFilter", (char**)keywords, &pyobj_joint, &pyobj_src, &pyobj_d, &pyobj_sigmaColor, &pyobj_sigmaSpace, &pyobj_dst, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_joint, joint, ArgInfo("joint", 0)) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_d, d, ArgInfo("d", 0)) &&
        pyopencv_to_safe(pyobj_sigmaColor, sigmaColor, ArgInfo("sigmaColor", 0)) &&
        pyopencv_to_safe(pyobj_sigmaSpace, sigmaSpace, ArgInfo("sigmaSpace", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::ximgproc::jointBilateralFilter(joint, src, dst, d, sigmaColor, sigmaSpace, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("jointBilateralFilter");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_l0Smooth(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_lambda = NULL;
    double lambda=0.02;
    PyObject* pyobj_kappa = NULL;
    double kappa=2.0;

    const char* keywords[] = { "src", "dst", "lambda", "kappa", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:l0Smooth", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_lambda, &pyobj_kappa) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_lambda, lambda, ArgInfo("lambda", 0)) &&
        pyopencv_to_safe(pyobj_kappa, kappa, ArgInfo("kappa", 0)) )
    {
        ERRWRAP2(cv::ximgproc::l0Smooth(src, dst, lambda, kappa));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_lambda = NULL;
    double lambda=0.02;
    PyObject* pyobj_kappa = NULL;
    double kappa=2.0;

    const char* keywords[] = { "src", "dst", "lambda", "kappa", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOO:l0Smooth", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_lambda, &pyobj_kappa) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_lambda, lambda, ArgInfo("lambda", 0)) &&
        pyopencv_to_safe(pyobj_kappa, kappa, ArgInfo("kappa", 0)) )
    {
        ERRWRAP2(cv::ximgproc::l0Smooth(src, dst, lambda, kappa));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("l0Smooth");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_niBlackThreshold(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj__src = NULL;
    Mat _src;
    PyObject* pyobj__dst = NULL;
    Mat _dst;
    PyObject* pyobj_maxValue = NULL;
    double maxValue=0;
    PyObject* pyobj_type = NULL;
    int type=0;
    PyObject* pyobj_blockSize = NULL;
    int blockSize=0;
    PyObject* pyobj_k = NULL;
    double k=0;
    PyObject* pyobj_binarizationMethod = NULL;
    int binarizationMethod=BINARIZATION_NIBLACK;
    PyObject* pyobj_r = NULL;
    double r=128;

    const char* keywords[] = { "_src", "maxValue", "type", "blockSize", "k", "_dst", "binarizationMethod", "r", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OOO:niBlackThreshold", (char**)keywords, &pyobj__src, &pyobj_maxValue, &pyobj_type, &pyobj_blockSize, &pyobj_k, &pyobj__dst, &pyobj_binarizationMethod, &pyobj_r) &&
        pyopencv_to_safe(pyobj__src, _src, ArgInfo("_src", 0)) &&
        pyopencv_to_safe(pyobj__dst, _dst, ArgInfo("_dst", 1)) &&
        pyopencv_to_safe(pyobj_maxValue, maxValue, ArgInfo("maxValue", 0)) &&
        pyopencv_to_safe(pyobj_type, type, ArgInfo("type", 0)) &&
        pyopencv_to_safe(pyobj_blockSize, blockSize, ArgInfo("blockSize", 0)) &&
        pyopencv_to_safe(pyobj_k, k, ArgInfo("k", 0)) &&
        pyopencv_to_safe(pyobj_binarizationMethod, binarizationMethod, ArgInfo("binarizationMethod", 0)) &&
        pyopencv_to_safe(pyobj_r, r, ArgInfo("r", 0)) )
    {
        ERRWRAP2(cv::ximgproc::niBlackThreshold(_src, _dst, maxValue, type, blockSize, k, binarizationMethod, r));
        return pyopencv_from(_dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj__src = NULL;
    UMat _src;
    PyObject* pyobj__dst = NULL;
    UMat _dst;
    PyObject* pyobj_maxValue = NULL;
    double maxValue=0;
    PyObject* pyobj_type = NULL;
    int type=0;
    PyObject* pyobj_blockSize = NULL;
    int blockSize=0;
    PyObject* pyobj_k = NULL;
    double k=0;
    PyObject* pyobj_binarizationMethod = NULL;
    int binarizationMethod=BINARIZATION_NIBLACK;
    PyObject* pyobj_r = NULL;
    double r=128;

    const char* keywords[] = { "_src", "maxValue", "type", "blockSize", "k", "_dst", "binarizationMethod", "r", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOOO|OOO:niBlackThreshold", (char**)keywords, &pyobj__src, &pyobj_maxValue, &pyobj_type, &pyobj_blockSize, &pyobj_k, &pyobj__dst, &pyobj_binarizationMethod, &pyobj_r) &&
        pyopencv_to_safe(pyobj__src, _src, ArgInfo("_src", 0)) &&
        pyopencv_to_safe(pyobj__dst, _dst, ArgInfo("_dst", 1)) &&
        pyopencv_to_safe(pyobj_maxValue, maxValue, ArgInfo("maxValue", 0)) &&
        pyopencv_to_safe(pyobj_type, type, ArgInfo("type", 0)) &&
        pyopencv_to_safe(pyobj_blockSize, blockSize, ArgInfo("blockSize", 0)) &&
        pyopencv_to_safe(pyobj_k, k, ArgInfo("k", 0)) &&
        pyopencv_to_safe(pyobj_binarizationMethod, binarizationMethod, ArgInfo("binarizationMethod", 0)) &&
        pyopencv_to_safe(pyobj_r, r, ArgInfo("r", 0)) )
    {
        ERRWRAP2(cv::ximgproc::niBlackThreshold(_src, _dst, maxValue, type, blockSize, k, binarizationMethod, r));
        return pyopencv_from(_dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("niBlackThreshold");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_qconj(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_qimg = NULL;
    Mat qimg;
    PyObject* pyobj_qcimg = NULL;
    Mat qcimg;

    const char* keywords[] = { "qimg", "qcimg", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:qconj", (char**)keywords, &pyobj_qimg, &pyobj_qcimg) &&
        pyopencv_to_safe(pyobj_qimg, qimg, ArgInfo("qimg", 0)) &&
        pyopencv_to_safe(pyobj_qcimg, qcimg, ArgInfo("qcimg", 1)) )
    {
        ERRWRAP2(cv::ximgproc::qconj(qimg, qcimg));
        return pyopencv_from(qcimg);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_qimg = NULL;
    UMat qimg;
    PyObject* pyobj_qcimg = NULL;
    UMat qcimg;

    const char* keywords[] = { "qimg", "qcimg", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:qconj", (char**)keywords, &pyobj_qimg, &pyobj_qcimg) &&
        pyopencv_to_safe(pyobj_qimg, qimg, ArgInfo("qimg", 0)) &&
        pyopencv_to_safe(pyobj_qcimg, qcimg, ArgInfo("qcimg", 1)) )
    {
        ERRWRAP2(cv::ximgproc::qconj(qimg, qcimg));
        return pyopencv_from(qcimg);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("qconj");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_qdft(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_img = NULL;
    Mat img;
    PyObject* pyobj_qimg = NULL;
    Mat qimg;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_sideLeft = NULL;
    bool sideLeft=0;

    const char* keywords[] = { "img", "flags", "sideLeft", "qimg", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:qdft", (char**)keywords, &pyobj_img, &pyobj_flags, &pyobj_sideLeft, &pyobj_qimg) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_qimg, qimg, ArgInfo("qimg", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_sideLeft, sideLeft, ArgInfo("sideLeft", 0)) )
    {
        ERRWRAP2(cv::ximgproc::qdft(img, qimg, flags, sideLeft));
        return pyopencv_from(qimg);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_img = NULL;
    UMat img;
    PyObject* pyobj_qimg = NULL;
    UMat qimg;
    PyObject* pyobj_flags = NULL;
    int flags=0;
    PyObject* pyobj_sideLeft = NULL;
    bool sideLeft=0;

    const char* keywords[] = { "img", "flags", "sideLeft", "qimg", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:qdft", (char**)keywords, &pyobj_img, &pyobj_flags, &pyobj_sideLeft, &pyobj_qimg) &&
        pyopencv_to_safe(pyobj_img, img, ArgInfo("img", 0)) &&
        pyopencv_to_safe(pyobj_qimg, qimg, ArgInfo("qimg", 1)) &&
        pyopencv_to_safe(pyobj_flags, flags, ArgInfo("flags", 0)) &&
        pyopencv_to_safe(pyobj_sideLeft, sideLeft, ArgInfo("sideLeft", 0)) )
    {
        ERRWRAP2(cv::ximgproc::qdft(img, qimg, flags, sideLeft));
        return pyopencv_from(qimg);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("qdft");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_qmultiply(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src1 = NULL;
    Mat src1;
    PyObject* pyobj_src2 = NULL;
    Mat src2;
    PyObject* pyobj_dst = NULL;
    Mat dst;

    const char* keywords[] = { "src1", "src2", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:qmultiply", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::ximgproc::qmultiply(src1, src2, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src1 = NULL;
    UMat src1;
    PyObject* pyobj_src2 = NULL;
    UMat src2;
    PyObject* pyobj_dst = NULL;
    UMat dst;

    const char* keywords[] = { "src1", "src2", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|O:qmultiply", (char**)keywords, &pyobj_src1, &pyobj_src2, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src1, src1, ArgInfo("src1", 0)) &&
        pyopencv_to_safe(pyobj_src2, src2, ArgInfo("src2", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(cv::ximgproc::qmultiply(src1, src2, dst));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("qmultiply");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_qunitary(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_qimg = NULL;
    Mat qimg;
    PyObject* pyobj_qnimg = NULL;
    Mat qnimg;

    const char* keywords[] = { "qimg", "qnimg", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:qunitary", (char**)keywords, &pyobj_qimg, &pyobj_qnimg) &&
        pyopencv_to_safe(pyobj_qimg, qimg, ArgInfo("qimg", 0)) &&
        pyopencv_to_safe(pyobj_qnimg, qnimg, ArgInfo("qnimg", 1)) )
    {
        ERRWRAP2(cv::ximgproc::qunitary(qimg, qnimg));
        return pyopencv_from(qnimg);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_qimg = NULL;
    UMat qimg;
    PyObject* pyobj_qnimg = NULL;
    UMat qnimg;

    const char* keywords[] = { "qimg", "qnimg", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:qunitary", (char**)keywords, &pyobj_qimg, &pyobj_qnimg) &&
        pyopencv_to_safe(pyobj_qimg, qimg, ArgInfo("qimg", 0)) &&
        pyopencv_to_safe(pyobj_qnimg, qnimg, ArgInfo("qnimg", 1)) )
    {
        ERRWRAP2(cv::ximgproc::qunitary(qimg, qnimg));
        return pyopencv_from(qnimg);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("qunitary");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_readGT(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src_path = NULL;
    String src_path;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    int retval;

    const char* keywords[] = { "src_path", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:readGT", (char**)keywords, &pyobj_src_path, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src_path, src_path, ArgInfo("src_path", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(retval = cv::ximgproc::readGT(src_path, dst));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(dst));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src_path = NULL;
    String src_path;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    int retval;

    const char* keywords[] = { "src_path", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|O:readGT", (char**)keywords, &pyobj_src_path, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src_path, src_path, ArgInfo("src_path", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) )
    {
        ERRWRAP2(retval = cv::ximgproc::readGT(src_path, dst));
        return Py_BuildValue("(NN)", pyopencv_from(retval), pyopencv_from(dst));
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("readGT");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_rollingGuidanceFilter(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_d = NULL;
    int d=-1;
    PyObject* pyobj_sigmaColor = NULL;
    double sigmaColor=25;
    PyObject* pyobj_sigmaSpace = NULL;
    double sigmaSpace=3;
    PyObject* pyobj_numOfIter = NULL;
    int numOfIter=4;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "dst", "d", "sigmaColor", "sigmaSpace", "numOfIter", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOOOO:rollingGuidanceFilter", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_d, &pyobj_sigmaColor, &pyobj_sigmaSpace, &pyobj_numOfIter, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_d, d, ArgInfo("d", 0)) &&
        pyopencv_to_safe(pyobj_sigmaColor, sigmaColor, ArgInfo("sigmaColor", 0)) &&
        pyopencv_to_safe(pyobj_sigmaSpace, sigmaSpace, ArgInfo("sigmaSpace", 0)) &&
        pyopencv_to_safe(pyobj_numOfIter, numOfIter, ArgInfo("numOfIter", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::ximgproc::rollingGuidanceFilter(src, dst, d, sigmaColor, sigmaSpace, numOfIter, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_d = NULL;
    int d=-1;
    PyObject* pyobj_sigmaColor = NULL;
    double sigmaColor=25;
    PyObject* pyobj_sigmaSpace = NULL;
    double sigmaSpace=3;
    PyObject* pyobj_numOfIter = NULL;
    int numOfIter=4;
    PyObject* pyobj_borderType = NULL;
    int borderType=BORDER_DEFAULT;

    const char* keywords[] = { "src", "dst", "d", "sigmaColor", "sigmaSpace", "numOfIter", "borderType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOOOO:rollingGuidanceFilter", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_d, &pyobj_sigmaColor, &pyobj_sigmaSpace, &pyobj_numOfIter, &pyobj_borderType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_d, d, ArgInfo("d", 0)) &&
        pyopencv_to_safe(pyobj_sigmaColor, sigmaColor, ArgInfo("sigmaColor", 0)) &&
        pyopencv_to_safe(pyobj_sigmaSpace, sigmaSpace, ArgInfo("sigmaSpace", 0)) &&
        pyopencv_to_safe(pyobj_numOfIter, numOfIter, ArgInfo("numOfIter", 0)) &&
        pyopencv_to_safe(pyobj_borderType, borderType, ArgInfo("borderType", 0)) )
    {
        ERRWRAP2(cv::ximgproc::rollingGuidanceFilter(src, dst, d, sigmaColor, sigmaSpace, numOfIter, borderType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("rollingGuidanceFilter");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_thinning(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_thinningType = NULL;
    int thinningType=THINNING_ZHANGSUEN;

    const char* keywords[] = { "src", "dst", "thinningType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:thinning", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_thinningType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_thinningType, thinningType, ArgInfo("thinningType", 0)) )
    {
        ERRWRAP2(cv::ximgproc::thinning(src, dst, thinningType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_thinningType = NULL;
    int thinningType=THINNING_ZHANGSUEN;

    const char* keywords[] = { "src", "dst", "thinningType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OO:thinning", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_thinningType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_thinningType, thinningType, ArgInfo("thinningType", 0)) )
    {
        ERRWRAP2(cv::ximgproc::thinning(src, dst, thinningType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("thinning");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_transformFD(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_t = NULL;
    Mat t;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_fdContour = NULL;
    bool fdContour=true;

    const char* keywords[] = { "src", "t", "dst", "fdContour", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:transformFD", (char**)keywords, &pyobj_src, &pyobj_t, &pyobj_dst, &pyobj_fdContour) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_t, t, ArgInfo("t", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_fdContour, fdContour, ArgInfo("fdContour", 0)) )
    {
        ERRWRAP2(cv::ximgproc::transformFD(src, t, dst, fdContour));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_t = NULL;
    UMat t;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_fdContour = NULL;
    bool fdContour=true;

    const char* keywords[] = { "src", "t", "dst", "fdContour", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OO:transformFD", (char**)keywords, &pyobj_src, &pyobj_t, &pyobj_dst, &pyobj_fdContour) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_t, t, ArgInfo("t", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_fdContour, fdContour, ArgInfo("fdContour", 0)) )
    {
        ERRWRAP2(cv::ximgproc::transformFD(src, t, dst, fdContour));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("transformFD");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_weightedMedianFilter(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_joint = NULL;
    Mat joint;
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_r = NULL;
    int r=0;
    PyObject* pyobj_sigma = NULL;
    double sigma=25.5;
    PyObject* pyobj_weightType = NULL;
    int weightType=WMF_EXP;
    PyObject* pyobj_mask = NULL;
    Mat mask;

    const char* keywords[] = { "joint", "src", "r", "dst", "sigma", "weightType", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOO:weightedMedianFilter", (char**)keywords, &pyobj_joint, &pyobj_src, &pyobj_r, &pyobj_dst, &pyobj_sigma, &pyobj_weightType, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_joint, joint, ArgInfo("joint", 0)) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_r, r, ArgInfo("r", 0)) &&
        pyopencv_to_safe(pyobj_sigma, sigma, ArgInfo("sigma", 0)) &&
        pyopencv_to_safe(pyobj_weightType, weightType, ArgInfo("weightType", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::ximgproc::weightedMedianFilter(joint, src, dst, r, sigma, weightType, mask));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_joint = NULL;
    UMat joint;
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_r = NULL;
    int r=0;
    PyObject* pyobj_sigma = NULL;
    double sigma=25.5;
    PyObject* pyobj_weightType = NULL;
    int weightType=WMF_EXP;
    PyObject* pyobj_mask = NULL;
    UMat mask;

    const char* keywords[] = { "joint", "src", "r", "dst", "sigma", "weightType", "mask", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|OOOO:weightedMedianFilter", (char**)keywords, &pyobj_joint, &pyobj_src, &pyobj_r, &pyobj_dst, &pyobj_sigma, &pyobj_weightType, &pyobj_mask) &&
        pyopencv_to_safe(pyobj_joint, joint, ArgInfo("joint", 0)) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_r, r, ArgInfo("r", 0)) &&
        pyopencv_to_safe(pyobj_sigma, sigma, ArgInfo("sigma", 0)) &&
        pyopencv_to_safe(pyobj_weightType, weightType, ArgInfo("weightType", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) )
    {
        ERRWRAP2(cv::ximgproc::weightedMedianFilter(joint, src, dst, r, sigma, weightType, mask));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("weightedMedianFilter");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_segmentation_createGraphSegmentation(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc::segmentation;

    PyObject* pyobj_sigma = NULL;
    double sigma=0.5;
    PyObject* pyobj_k = NULL;
    float k=300;
    PyObject* pyobj_min_size = NULL;
    int min_size=100;
    Ptr<GraphSegmentation> retval;

    const char* keywords[] = { "sigma", "k", "min_size", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOO:createGraphSegmentation", (char**)keywords, &pyobj_sigma, &pyobj_k, &pyobj_min_size) &&
        pyopencv_to_safe(pyobj_sigma, sigma, ArgInfo("sigma", 0)) &&
        pyopencv_to_safe(pyobj_k, k, ArgInfo("k", 0)) &&
        pyopencv_to_safe(pyobj_min_size, min_size, ArgInfo("min_size", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::segmentation::createGraphSegmentation(sigma, k, min_size));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_segmentation_createSelectiveSearchSegmentation(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc::segmentation;

    Ptr<SelectiveSearchSegmentation> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::ximgproc::segmentation::createSelectiveSearchSegmentation());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_segmentation_createSelectiveSearchSegmentationStrategyColor(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc::segmentation;

    Ptr<SelectiveSearchSegmentationStrategyColor> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::ximgproc::segmentation::createSelectiveSearchSegmentationStrategyColor());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_segmentation_createSelectiveSearchSegmentationStrategyFill(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc::segmentation;

    Ptr<SelectiveSearchSegmentationStrategyFill> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::ximgproc::segmentation::createSelectiveSearchSegmentationStrategyFill());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_segmentation_createSelectiveSearchSegmentationStrategyMultiple(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc::segmentation;

    pyPrepareArgumentConversionErrorsStorage(5);

    {
    Ptr<SelectiveSearchSegmentationStrategyMultiple> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::ximgproc::segmentation::createSelectiveSearchSegmentationStrategyMultiple());
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_s1 = NULL;
    Ptr<SelectiveSearchSegmentationStrategy> s1;
    Ptr<SelectiveSearchSegmentationStrategyMultiple> retval;

    const char* keywords[] = { "s1", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O:createSelectiveSearchSegmentationStrategyMultiple", (char**)keywords, &pyobj_s1) &&
        pyopencv_to_safe(pyobj_s1, s1, ArgInfo("s1", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::segmentation::createSelectiveSearchSegmentationStrategyMultiple(s1));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_s1 = NULL;
    Ptr<SelectiveSearchSegmentationStrategy> s1;
    PyObject* pyobj_s2 = NULL;
    Ptr<SelectiveSearchSegmentationStrategy> s2;
    Ptr<SelectiveSearchSegmentationStrategyMultiple> retval;

    const char* keywords[] = { "s1", "s2", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO:createSelectiveSearchSegmentationStrategyMultiple", (char**)keywords, &pyobj_s1, &pyobj_s2) &&
        pyopencv_to_safe(pyobj_s1, s1, ArgInfo("s1", 0)) &&
        pyopencv_to_safe(pyobj_s2, s2, ArgInfo("s2", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::segmentation::createSelectiveSearchSegmentationStrategyMultiple(s1, s2));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_s1 = NULL;
    Ptr<SelectiveSearchSegmentationStrategy> s1;
    PyObject* pyobj_s2 = NULL;
    Ptr<SelectiveSearchSegmentationStrategy> s2;
    PyObject* pyobj_s3 = NULL;
    Ptr<SelectiveSearchSegmentationStrategy> s3;
    Ptr<SelectiveSearchSegmentationStrategyMultiple> retval;

    const char* keywords[] = { "s1", "s2", "s3", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO:createSelectiveSearchSegmentationStrategyMultiple", (char**)keywords, &pyobj_s1, &pyobj_s2, &pyobj_s3) &&
        pyopencv_to_safe(pyobj_s1, s1, ArgInfo("s1", 0)) &&
        pyopencv_to_safe(pyobj_s2, s2, ArgInfo("s2", 0)) &&
        pyopencv_to_safe(pyobj_s3, s3, ArgInfo("s3", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::segmentation::createSelectiveSearchSegmentationStrategyMultiple(s1, s2, s3));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_s1 = NULL;
    Ptr<SelectiveSearchSegmentationStrategy> s1;
    PyObject* pyobj_s2 = NULL;
    Ptr<SelectiveSearchSegmentationStrategy> s2;
    PyObject* pyobj_s3 = NULL;
    Ptr<SelectiveSearchSegmentationStrategy> s3;
    PyObject* pyobj_s4 = NULL;
    Ptr<SelectiveSearchSegmentationStrategy> s4;
    Ptr<SelectiveSearchSegmentationStrategyMultiple> retval;

    const char* keywords[] = { "s1", "s2", "s3", "s4", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO:createSelectiveSearchSegmentationStrategyMultiple", (char**)keywords, &pyobj_s1, &pyobj_s2, &pyobj_s3, &pyobj_s4) &&
        pyopencv_to_safe(pyobj_s1, s1, ArgInfo("s1", 0)) &&
        pyopencv_to_safe(pyobj_s2, s2, ArgInfo("s2", 0)) &&
        pyopencv_to_safe(pyobj_s3, s3, ArgInfo("s3", 0)) &&
        pyopencv_to_safe(pyobj_s4, s4, ArgInfo("s4", 0)) )
    {
        ERRWRAP2(retval = cv::ximgproc::segmentation::createSelectiveSearchSegmentationStrategyMultiple(s1, s2, s3, s4));
        return pyopencv_from(retval);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("createSelectiveSearchSegmentationStrategyMultiple");

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_segmentation_createSelectiveSearchSegmentationStrategySize(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc::segmentation;

    Ptr<SelectiveSearchSegmentationStrategySize> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::ximgproc::segmentation::createSelectiveSearchSegmentationStrategySize());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_ximgproc_segmentation_createSelectiveSearchSegmentationStrategyTexture(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::ximgproc::segmentation;

    Ptr<SelectiveSearchSegmentationStrategyTexture> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::ximgproc::segmentation::createSelectiveSearchSegmentationStrategyTexture());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xphoto_applyChannelGains(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::xphoto;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_gainB = NULL;
    float gainB=0.f;
    PyObject* pyobj_gainG = NULL;
    float gainG=0.f;
    PyObject* pyobj_gainR = NULL;
    float gainR=0.f;

    const char* keywords[] = { "src", "gainB", "gainG", "gainR", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:applyChannelGains", (char**)keywords, &pyobj_src, &pyobj_gainB, &pyobj_gainG, &pyobj_gainR, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_gainB, gainB, ArgInfo("gainB", 0)) &&
        pyopencv_to_safe(pyobj_gainG, gainG, ArgInfo("gainG", 0)) &&
        pyopencv_to_safe(pyobj_gainR, gainR, ArgInfo("gainR", 0)) )
    {
        ERRWRAP2(cv::xphoto::applyChannelGains(src, dst, gainB, gainG, gainR));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_gainB = NULL;
    float gainB=0.f;
    PyObject* pyobj_gainG = NULL;
    float gainG=0.f;
    PyObject* pyobj_gainR = NULL;
    float gainR=0.f;

    const char* keywords[] = { "src", "gainB", "gainG", "gainR", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:applyChannelGains", (char**)keywords, &pyobj_src, &pyobj_gainB, &pyobj_gainG, &pyobj_gainR, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_gainB, gainB, ArgInfo("gainB", 0)) &&
        pyopencv_to_safe(pyobj_gainG, gainG, ArgInfo("gainG", 0)) &&
        pyopencv_to_safe(pyobj_gainR, gainR, ArgInfo("gainR", 0)) )
    {
        ERRWRAP2(cv::xphoto::applyChannelGains(src, dst, gainB, gainG, gainR));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("applyChannelGains");

    return NULL;
}

static PyObject* pyopencv_cv_xphoto_bm3dDenoising(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::xphoto;

    pyPrepareArgumentConversionErrorsStorage(4);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dstStep1 = NULL;
    Mat dstStep1;
    PyObject* pyobj_dstStep2 = NULL;
    Mat dstStep2;
    PyObject* pyobj_h = NULL;
    float h=1;
    PyObject* pyobj_templateWindowSize = NULL;
    int templateWindowSize=4;
    PyObject* pyobj_searchWindowSize = NULL;
    int searchWindowSize=16;
    PyObject* pyobj_blockMatchingStep1 = NULL;
    int blockMatchingStep1=2500;
    PyObject* pyobj_blockMatchingStep2 = NULL;
    int blockMatchingStep2=400;
    PyObject* pyobj_groupSize = NULL;
    int groupSize=8;
    PyObject* pyobj_slidingStep = NULL;
    int slidingStep=1;
    PyObject* pyobj_beta = NULL;
    float beta=2.0f;
    PyObject* pyobj_normType = NULL;
    int normType=cv::NORM_L2;
    PyObject* pyobj_step = NULL;
    int step=cv::xphoto::BM3D_STEPALL;
    PyObject* pyobj_transformType = NULL;
    int transformType=cv::xphoto::HAAR;

    const char* keywords[] = { "src", "dstStep1", "dstStep2", "h", "templateWindowSize", "searchWindowSize", "blockMatchingStep1", "blockMatchingStep2", "groupSize", "slidingStep", "beta", "normType", "step", "transformType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOOOOOOOOOO:bm3dDenoising", (char**)keywords, &pyobj_src, &pyobj_dstStep1, &pyobj_dstStep2, &pyobj_h, &pyobj_templateWindowSize, &pyobj_searchWindowSize, &pyobj_blockMatchingStep1, &pyobj_blockMatchingStep2, &pyobj_groupSize, &pyobj_slidingStep, &pyobj_beta, &pyobj_normType, &pyobj_step, &pyobj_transformType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dstStep1, dstStep1, ArgInfo("dstStep1", 1)) &&
        pyopencv_to_safe(pyobj_dstStep2, dstStep2, ArgInfo("dstStep2", 1)) &&
        pyopencv_to_safe(pyobj_h, h, ArgInfo("h", 0)) &&
        pyopencv_to_safe(pyobj_templateWindowSize, templateWindowSize, ArgInfo("templateWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_searchWindowSize, searchWindowSize, ArgInfo("searchWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_blockMatchingStep1, blockMatchingStep1, ArgInfo("blockMatchingStep1", 0)) &&
        pyopencv_to_safe(pyobj_blockMatchingStep2, blockMatchingStep2, ArgInfo("blockMatchingStep2", 0)) &&
        pyopencv_to_safe(pyobj_groupSize, groupSize, ArgInfo("groupSize", 0)) &&
        pyopencv_to_safe(pyobj_slidingStep, slidingStep, ArgInfo("slidingStep", 0)) &&
        pyopencv_to_safe(pyobj_beta, beta, ArgInfo("beta", 0)) &&
        pyopencv_to_safe(pyobj_normType, normType, ArgInfo("normType", 0)) &&
        pyopencv_to_safe(pyobj_step, step, ArgInfo("step", 0)) &&
        pyopencv_to_safe(pyobj_transformType, transformType, ArgInfo("transformType", 0)) )
    {
        ERRWRAP2(cv::xphoto::bm3dDenoising(src, dstStep1, dstStep2, h, templateWindowSize, searchWindowSize, blockMatchingStep1, blockMatchingStep2, groupSize, slidingStep, beta, normType, step, transformType));
        return Py_BuildValue("(NN)", pyopencv_from(dstStep1), pyopencv_from(dstStep2));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dstStep1 = NULL;
    UMat dstStep1;
    PyObject* pyobj_dstStep2 = NULL;
    UMat dstStep2;
    PyObject* pyobj_h = NULL;
    float h=1;
    PyObject* pyobj_templateWindowSize = NULL;
    int templateWindowSize=4;
    PyObject* pyobj_searchWindowSize = NULL;
    int searchWindowSize=16;
    PyObject* pyobj_blockMatchingStep1 = NULL;
    int blockMatchingStep1=2500;
    PyObject* pyobj_blockMatchingStep2 = NULL;
    int blockMatchingStep2=400;
    PyObject* pyobj_groupSize = NULL;
    int groupSize=8;
    PyObject* pyobj_slidingStep = NULL;
    int slidingStep=1;
    PyObject* pyobj_beta = NULL;
    float beta=2.0f;
    PyObject* pyobj_normType = NULL;
    int normType=cv::NORM_L2;
    PyObject* pyobj_step = NULL;
    int step=cv::xphoto::BM3D_STEPALL;
    PyObject* pyobj_transformType = NULL;
    int transformType=cv::xphoto::HAAR;

    const char* keywords[] = { "src", "dstStep1", "dstStep2", "h", "templateWindowSize", "searchWindowSize", "blockMatchingStep1", "blockMatchingStep2", "groupSize", "slidingStep", "beta", "normType", "step", "transformType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OO|OOOOOOOOOOOO:bm3dDenoising", (char**)keywords, &pyobj_src, &pyobj_dstStep1, &pyobj_dstStep2, &pyobj_h, &pyobj_templateWindowSize, &pyobj_searchWindowSize, &pyobj_blockMatchingStep1, &pyobj_blockMatchingStep2, &pyobj_groupSize, &pyobj_slidingStep, &pyobj_beta, &pyobj_normType, &pyobj_step, &pyobj_transformType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dstStep1, dstStep1, ArgInfo("dstStep1", 1)) &&
        pyopencv_to_safe(pyobj_dstStep2, dstStep2, ArgInfo("dstStep2", 1)) &&
        pyopencv_to_safe(pyobj_h, h, ArgInfo("h", 0)) &&
        pyopencv_to_safe(pyobj_templateWindowSize, templateWindowSize, ArgInfo("templateWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_searchWindowSize, searchWindowSize, ArgInfo("searchWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_blockMatchingStep1, blockMatchingStep1, ArgInfo("blockMatchingStep1", 0)) &&
        pyopencv_to_safe(pyobj_blockMatchingStep2, blockMatchingStep2, ArgInfo("blockMatchingStep2", 0)) &&
        pyopencv_to_safe(pyobj_groupSize, groupSize, ArgInfo("groupSize", 0)) &&
        pyopencv_to_safe(pyobj_slidingStep, slidingStep, ArgInfo("slidingStep", 0)) &&
        pyopencv_to_safe(pyobj_beta, beta, ArgInfo("beta", 0)) &&
        pyopencv_to_safe(pyobj_normType, normType, ArgInfo("normType", 0)) &&
        pyopencv_to_safe(pyobj_step, step, ArgInfo("step", 0)) &&
        pyopencv_to_safe(pyobj_transformType, transformType, ArgInfo("transformType", 0)) )
    {
        ERRWRAP2(cv::xphoto::bm3dDenoising(src, dstStep1, dstStep2, h, templateWindowSize, searchWindowSize, blockMatchingStep1, blockMatchingStep2, groupSize, slidingStep, beta, normType, step, transformType));
        return Py_BuildValue("(NN)", pyopencv_from(dstStep1), pyopencv_from(dstStep2));
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_h = NULL;
    float h=1;
    PyObject* pyobj_templateWindowSize = NULL;
    int templateWindowSize=4;
    PyObject* pyobj_searchWindowSize = NULL;
    int searchWindowSize=16;
    PyObject* pyobj_blockMatchingStep1 = NULL;
    int blockMatchingStep1=2500;
    PyObject* pyobj_blockMatchingStep2 = NULL;
    int blockMatchingStep2=400;
    PyObject* pyobj_groupSize = NULL;
    int groupSize=8;
    PyObject* pyobj_slidingStep = NULL;
    int slidingStep=1;
    PyObject* pyobj_beta = NULL;
    float beta=2.0f;
    PyObject* pyobj_normType = NULL;
    int normType=cv::NORM_L2;
    PyObject* pyobj_step = NULL;
    int step=cv::xphoto::BM3D_STEPALL;
    PyObject* pyobj_transformType = NULL;
    int transformType=cv::xphoto::HAAR;

    const char* keywords[] = { "src", "dst", "h", "templateWindowSize", "searchWindowSize", "blockMatchingStep1", "blockMatchingStep2", "groupSize", "slidingStep", "beta", "normType", "step", "transformType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOOOOOOOOOO:bm3dDenoising", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_h, &pyobj_templateWindowSize, &pyobj_searchWindowSize, &pyobj_blockMatchingStep1, &pyobj_blockMatchingStep2, &pyobj_groupSize, &pyobj_slidingStep, &pyobj_beta, &pyobj_normType, &pyobj_step, &pyobj_transformType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_h, h, ArgInfo("h", 0)) &&
        pyopencv_to_safe(pyobj_templateWindowSize, templateWindowSize, ArgInfo("templateWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_searchWindowSize, searchWindowSize, ArgInfo("searchWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_blockMatchingStep1, blockMatchingStep1, ArgInfo("blockMatchingStep1", 0)) &&
        pyopencv_to_safe(pyobj_blockMatchingStep2, blockMatchingStep2, ArgInfo("blockMatchingStep2", 0)) &&
        pyopencv_to_safe(pyobj_groupSize, groupSize, ArgInfo("groupSize", 0)) &&
        pyopencv_to_safe(pyobj_slidingStep, slidingStep, ArgInfo("slidingStep", 0)) &&
        pyopencv_to_safe(pyobj_beta, beta, ArgInfo("beta", 0)) &&
        pyopencv_to_safe(pyobj_normType, normType, ArgInfo("normType", 0)) &&
        pyopencv_to_safe(pyobj_step, step, ArgInfo("step", 0)) &&
        pyopencv_to_safe(pyobj_transformType, transformType, ArgInfo("transformType", 0)) )
    {
        ERRWRAP2(cv::xphoto::bm3dDenoising(src, dst, h, templateWindowSize, searchWindowSize, blockMatchingStep1, blockMatchingStep2, groupSize, slidingStep, beta, normType, step, transformType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_h = NULL;
    float h=1;
    PyObject* pyobj_templateWindowSize = NULL;
    int templateWindowSize=4;
    PyObject* pyobj_searchWindowSize = NULL;
    int searchWindowSize=16;
    PyObject* pyobj_blockMatchingStep1 = NULL;
    int blockMatchingStep1=2500;
    PyObject* pyobj_blockMatchingStep2 = NULL;
    int blockMatchingStep2=400;
    PyObject* pyobj_groupSize = NULL;
    int groupSize=8;
    PyObject* pyobj_slidingStep = NULL;
    int slidingStep=1;
    PyObject* pyobj_beta = NULL;
    float beta=2.0f;
    PyObject* pyobj_normType = NULL;
    int normType=cv::NORM_L2;
    PyObject* pyobj_step = NULL;
    int step=cv::xphoto::BM3D_STEPALL;
    PyObject* pyobj_transformType = NULL;
    int transformType=cv::xphoto::HAAR;

    const char* keywords[] = { "src", "dst", "h", "templateWindowSize", "searchWindowSize", "blockMatchingStep1", "blockMatchingStep2", "groupSize", "slidingStep", "beta", "normType", "step", "transformType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "O|OOOOOOOOOOOO:bm3dDenoising", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_h, &pyobj_templateWindowSize, &pyobj_searchWindowSize, &pyobj_blockMatchingStep1, &pyobj_blockMatchingStep2, &pyobj_groupSize, &pyobj_slidingStep, &pyobj_beta, &pyobj_normType, &pyobj_step, &pyobj_transformType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_h, h, ArgInfo("h", 0)) &&
        pyopencv_to_safe(pyobj_templateWindowSize, templateWindowSize, ArgInfo("templateWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_searchWindowSize, searchWindowSize, ArgInfo("searchWindowSize", 0)) &&
        pyopencv_to_safe(pyobj_blockMatchingStep1, blockMatchingStep1, ArgInfo("blockMatchingStep1", 0)) &&
        pyopencv_to_safe(pyobj_blockMatchingStep2, blockMatchingStep2, ArgInfo("blockMatchingStep2", 0)) &&
        pyopencv_to_safe(pyobj_groupSize, groupSize, ArgInfo("groupSize", 0)) &&
        pyopencv_to_safe(pyobj_slidingStep, slidingStep, ArgInfo("slidingStep", 0)) &&
        pyopencv_to_safe(pyobj_beta, beta, ArgInfo("beta", 0)) &&
        pyopencv_to_safe(pyobj_normType, normType, ArgInfo("normType", 0)) &&
        pyopencv_to_safe(pyobj_step, step, ArgInfo("step", 0)) &&
        pyopencv_to_safe(pyobj_transformType, transformType, ArgInfo("transformType", 0)) )
    {
        ERRWRAP2(cv::xphoto::bm3dDenoising(src, dst, h, templateWindowSize, searchWindowSize, blockMatchingStep1, blockMatchingStep2, groupSize, slidingStep, beta, normType, step, transformType));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("bm3dDenoising");

    return NULL;
}

static PyObject* pyopencv_cv_xphoto_createGrayworldWB(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::xphoto;

    Ptr<GrayworldWB> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::xphoto::createGrayworldWB());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xphoto_createLearningBasedWB(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::xphoto;

    PyObject* pyobj_path_to_model = NULL;
    String path_to_model;
    Ptr<LearningBasedWB> retval;

    const char* keywords[] = { "path_to_model", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|O:createLearningBasedWB", (char**)keywords, &pyobj_path_to_model) &&
        pyopencv_to_safe(pyobj_path_to_model, path_to_model, ArgInfo("path_to_model", 0)) )
    {
        ERRWRAP2(retval = cv::xphoto::createLearningBasedWB(path_to_model));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xphoto_createSimpleWB(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::xphoto;

    Ptr<SimpleWB> retval;

    if(PyObject_Size(py_args) == 0 && (!kw || PyObject_Size(kw) == 0))
    {
        ERRWRAP2(retval = cv::xphoto::createSimpleWB());
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xphoto_createTonemapDurand(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::xphoto;

    PyObject* pyobj_gamma = NULL;
    float gamma=1.0f;
    PyObject* pyobj_contrast = NULL;
    float contrast=4.0f;
    PyObject* pyobj_saturation = NULL;
    float saturation=1.0f;
    PyObject* pyobj_sigma_color = NULL;
    float sigma_color=2.0f;
    PyObject* pyobj_sigma_space = NULL;
    float sigma_space=2.0f;
    Ptr<TonemapDurand> retval;

    const char* keywords[] = { "gamma", "contrast", "saturation", "sigma_color", "sigma_space", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "|OOOOO:createTonemapDurand", (char**)keywords, &pyobj_gamma, &pyobj_contrast, &pyobj_saturation, &pyobj_sigma_color, &pyobj_sigma_space) &&
        pyopencv_to_safe(pyobj_gamma, gamma, ArgInfo("gamma", 0)) &&
        pyopencv_to_safe(pyobj_contrast, contrast, ArgInfo("contrast", 0)) &&
        pyopencv_to_safe(pyobj_saturation, saturation, ArgInfo("saturation", 0)) &&
        pyopencv_to_safe(pyobj_sigma_color, sigma_color, ArgInfo("sigma_color", 0)) &&
        pyopencv_to_safe(pyobj_sigma_space, sigma_space, ArgInfo("sigma_space", 0)) )
    {
        ERRWRAP2(retval = cv::xphoto::createTonemapDurand(gamma, contrast, saturation, sigma_color, sigma_space));
        return pyopencv_from(retval);
    }

    return NULL;
}

static PyObject* pyopencv_cv_xphoto_dctDenoising(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::xphoto;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_sigma = NULL;
    double sigma=0;
    PyObject* pyobj_psize = NULL;
    int psize=16;

    const char* keywords[] = { "src", "dst", "sigma", "psize", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:dctDenoising", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_sigma, &pyobj_psize) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 0)) &&
        pyopencv_to_safe(pyobj_sigma, sigma, ArgInfo("sigma", 0)) &&
        pyopencv_to_safe(pyobj_psize, psize, ArgInfo("psize", 0)) )
    {
        ERRWRAP2(cv::xphoto::dctDenoising(src, dst, sigma, psize));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_sigma = NULL;
    double sigma=0;
    PyObject* pyobj_psize = NULL;
    int psize=16;

    const char* keywords[] = { "src", "dst", "sigma", "psize", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:dctDenoising", (char**)keywords, &pyobj_src, &pyobj_dst, &pyobj_sigma, &pyobj_psize) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 0)) &&
        pyopencv_to_safe(pyobj_sigma, sigma, ArgInfo("sigma", 0)) &&
        pyopencv_to_safe(pyobj_psize, psize, ArgInfo("psize", 0)) )
    {
        ERRWRAP2(cv::xphoto::dctDenoising(src, dst, sigma, psize));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("dctDenoising");

    return NULL;
}

static PyObject* pyopencv_cv_xphoto_inpaint(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::xphoto;

    pyPrepareArgumentConversionErrorsStorage(2);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_algorithmType = NULL;
    int algorithmType=0;

    const char* keywords[] = { "src", "mask", "dst", "algorithmType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO:inpaint", (char**)keywords, &pyobj_src, &pyobj_mask, &pyobj_dst, &pyobj_algorithmType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 0)) &&
        pyopencv_to_safe(pyobj_algorithmType, algorithmType, ArgInfo("algorithmType", 0)) )
    {
        ERRWRAP2(cv::xphoto::inpaint(src, mask, dst, algorithmType));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_mask = NULL;
    Mat mask;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_algorithmType = NULL;
    int algorithmType=0;

    const char* keywords[] = { "src", "mask", "dst", "algorithmType", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO:inpaint", (char**)keywords, &pyobj_src, &pyobj_mask, &pyobj_dst, &pyobj_algorithmType) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_mask, mask, ArgInfo("mask", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 0)) &&
        pyopencv_to_safe(pyobj_algorithmType, algorithmType, ArgInfo("algorithmType", 0)) )
    {
        ERRWRAP2(cv::xphoto::inpaint(src, mask, dst, algorithmType));
        Py_RETURN_NONE;
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("inpaint");

    return NULL;
}

static PyObject* pyopencv_cv_xphoto_oilPainting(PyObject* , PyObject* py_args, PyObject* kw)
{
    using namespace cv::xphoto;

    pyPrepareArgumentConversionErrorsStorage(4);

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_size = NULL;
    int size=0;
    PyObject* pyobj_dynRatio = NULL;
    int dynRatio=0;
    PyObject* pyobj_code = NULL;
    int code=0;

    const char* keywords[] = { "src", "size", "dynRatio", "code", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:oilPainting", (char**)keywords, &pyobj_src, &pyobj_size, &pyobj_dynRatio, &pyobj_code, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_size, size, ArgInfo("size", 0)) &&
        pyopencv_to_safe(pyobj_dynRatio, dynRatio, ArgInfo("dynRatio", 0)) &&
        pyopencv_to_safe(pyobj_code, code, ArgInfo("code", 0)) )
    {
        ERRWRAP2(cv::xphoto::oilPainting(src, dst, size, dynRatio, code));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_size = NULL;
    int size=0;
    PyObject* pyobj_dynRatio = NULL;
    int dynRatio=0;
    PyObject* pyobj_code = NULL;
    int code=0;

    const char* keywords[] = { "src", "size", "dynRatio", "code", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOOO|O:oilPainting", (char**)keywords, &pyobj_src, &pyobj_size, &pyobj_dynRatio, &pyobj_code, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_size, size, ArgInfo("size", 0)) &&
        pyopencv_to_safe(pyobj_dynRatio, dynRatio, ArgInfo("dynRatio", 0)) &&
        pyopencv_to_safe(pyobj_code, code, ArgInfo("code", 0)) )
    {
        ERRWRAP2(cv::xphoto::oilPainting(src, dst, size, dynRatio, code));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    Mat src;
    PyObject* pyobj_dst = NULL;
    Mat dst;
    PyObject* pyobj_size = NULL;
    int size=0;
    PyObject* pyobj_dynRatio = NULL;
    int dynRatio=0;

    const char* keywords[] = { "src", "size", "dynRatio", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:oilPainting", (char**)keywords, &pyobj_src, &pyobj_size, &pyobj_dynRatio, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_size, size, ArgInfo("size", 0)) &&
        pyopencv_to_safe(pyobj_dynRatio, dynRatio, ArgInfo("dynRatio", 0)) )
    {
        ERRWRAP2(cv::xphoto::oilPainting(src, dst, size, dynRatio));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    

    {
    PyObject* pyobj_src = NULL;
    UMat src;
    PyObject* pyobj_dst = NULL;
    UMat dst;
    PyObject* pyobj_size = NULL;
    int size=0;
    PyObject* pyobj_dynRatio = NULL;
    int dynRatio=0;

    const char* keywords[] = { "src", "size", "dynRatio", "dst", NULL };
    if( PyArg_ParseTupleAndKeywords(py_args, kw, "OOO|O:oilPainting", (char**)keywords, &pyobj_src, &pyobj_size, &pyobj_dynRatio, &pyobj_dst) &&
        pyopencv_to_safe(pyobj_src, src, ArgInfo("src", 0)) &&
        pyopencv_to_safe(pyobj_dst, dst, ArgInfo("dst", 1)) &&
        pyopencv_to_safe(pyobj_size, size, ArgInfo("size", 0)) &&
        pyopencv_to_safe(pyobj_dynRatio, dynRatio, ArgInfo("dynRatio", 0)) )
    {
        ERRWRAP2(cv::xphoto::oilPainting(src, dst, size, dynRatio));
        return pyopencv_from(dst);
    }


        pyPopulateArgumentConversionErrors();
    }
    pyRaiseCVOverloadException("oilPainting");

    return NULL;
}

